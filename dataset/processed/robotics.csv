id,title,content,tags
1,what is the right approach to write the spin controller for a soccer robot ,imagine programming a   wheel soccer robot  what type of controller would you use for spinning it  p  pid  the goal for this controller is that it should make the robot stand in a defined angle     degree   and turn back if rotated by hand or other robot   i use stepper motors for my robot and not servos so i need to implement this in my software  i have written a sample p type controller already and the movement is fairly good  but i would like to make it better if possible  the code is as follows   correction is a range   in which robot has no movement   degree is a number between      and     which is returned from the compass  motorspeed is a number between   and     which is applied to the pwm  ,soccer control
2,how can i modify a low cost hobby servo to run  freely  ,i ve got some hobby servos  power hd     mgs  and i d like to be able to control them  via an arduino  so they will either go to the angle i set  or put them in a  free running  mode  where the load will take them wherever it goes  is this even possible  or am i just going to end up stripping the gears  my first thought is to simply kill the power to the servo  but the force required to move them in that state is more than i d like  if it is possible  am i looking at a hardware change  or could i do it in software  ,control rcservo
3,what useful gaits exist for a six legged robot  and what are their pros and cons , lists three gaits   the tripod wave  and ripple   can these be improved  or can their relative pros and cons be altered  and are there other gaits worth considering  ,gait walk
4,good microcontrollers socs for a robotics project,i am looking for a starting point for my project  preferably using popular systems  ones there is a lot of support for   i have an arduino uno  a raspberry pi  and a lot of willpower    anyone here built a project using the systems above  observation  i d like to start with a simple line following vehicle and build up afterwards  ,microcontroller arduino raspberry-pi
5,nearest neighbor data structure for non euclidean configuration space,i m trying to implement a nearest neighbor structure for use in an rrt motion planner  in order to do better than a linear brute force nearest neighbor search  i d like to implement something like a kd tree  however  it seems like the classical implementation of the kd tree assumes that each dimension of the space can be split into  left  and  right   this notion doesn t seem to apply to non euclidean spaces like so     for instance  i m working with a serial manipulator arm with fully rotational links  meaning that each dimension of the robot s configuration space is so     and therefore non euclidean  can the kd tree algorithm be modified to handle these kinds of subspaces  if not  is there another nearest neighbor structure that can handle these non euclidean subspaces while still being easy to update and query  i also took a look at flann  but it wasn t clear to me from their documentation whether they can handle non euclidean subspaces  ,motion-planning rrt
6,what good robotics software platforms   operating systems are available ,my company will soon be starting a brand new robotics project  and we are still trying to decide whether we should design and code a robotics software platform from scratch  or if there are any good existing ones  it would be very useful if there was a software platform which was commonly used among both academics and industry so that our robotic system was generally compatible with others  and so that people were already familiar with it  we would like the software platform to be able to   integrate new robotic hardware components easily  already contain a wide array of useful data processing and visualisation tools make efficient use of computing hardware  ,software platform
11,what software do you use to design your pcb in the robotics field ,what is the best software  despite the price  for designing the circuits and pcb boards for robots  i mean having lots of components  different designing methods  best accuracy      i myself use the altium designer which i think answers my needs  but maybe there are better ones in the market i don t know about  ,software circuit
18,what are good methods for tuning the process noise on kalman filters ,most often tuning the kalman filter noise matrices is done by trial and error or domain knowledge  are there more principled ways for tuning all the kalman filter parameters  ,odometry localization kalman-filter
19,keyboard control map for scalar based movement ,i m working with a wild thumper   wheel chasis that is designed for use with an rc controller  however i d like to have a mapping to a keyboard for control as well  can you suggest a set of keys and behaviors that you ve used to deal with the continuous value control normally offered by a joystick or pair of joysticks  the standard wasd keys   an accelerate decelerate pair  i d also take a pointer to a videogame that you think does this well  ,untagged
20,ideas for shooting the ball in a soccer robot,what is the best option to use for the shooting system of a soccer robot  i have already implemented a solenoid based system for shooting and it works perfectly   however  i d like some other methods to check if they are better than mine   ,soccer mechanism
23,f oss optical object avoidance,i am beginning work on a larger scale          lbs wheeled robot and looking to use both optical and other means of object avoidance  i am concerned with a robot this large causing issues with running into things  including people as it has a top speed of   mph and that would cause issues with safety  i am starting out with a remote control but am looking to have the robot become self contained  i have been loosely following the darpa driver less car project but will not have anywhere near the fiscal or power budget that they do for sensors and computers  am i thinking to far afield with my idea of having a self contained robot in the         lbs range that does not break the bank on optical object avoidance  any comments or experiences will be greatly appreciated  ,computer-vision wheeled-robot
25,how to choose the right propeller motor combination for a quadcopter ,there are many sites which explain briefly this problem and even propose combinations  i however would like a much more detailed explanation  what is going to give my quad the most agility  do i need bigger motors props in a heavy quad to achieve the same level of agility than in a lighter quad  edit  here is what i have understood on the subject   a quadcopter doesn t need high revving motors as there are   propellers providing thrust and high revving motors require more battery power  larger propellers give more thrust per revolution from the motor   the question is focused more on the general characteristics of various combinations but some specific questions do spring to mind    for a given combination what would be the effect of upgrading propeller size in comparison to installing higher revving motors  what changes would need to be made to lift a heavier quad  how can i achieve more agility in my quad   ,quadcopter
26,cheap web to buy robotic pieces from,i love computer programming  and if i can interact with the world programming  it s even better  i used to steal them from school  and make little robots that bounce when collided with a wall  but i want to go further  but i don t have the needed pieces  and i don t know any good place to buy pieces   like servos  etc  either  also  i m spanish  so if the page can sell to places in spain  even better  i would highly appreciate your help  aritzh ,servos
37,mobile robot localization in a known map,i want to localize a mobile robot equipped with a  d laser scanner in a known indoor environment   the map is a  d occupancy grid  but is not perfect  what algorithms are appropriate for mobile robot localization  ,localization mobile-robot
39,i d like to use gesture based input for my robot  what are the pros and cons between the xtion live and the kinect ,as in the title  i d like to implement gesture recognition on my robot and i m looking for the pros and cons between the kinect and the xtion   and also if there are any other sensible options available  i m thinking of the following  but open to other suggestions   accuracy price driver quality power draw  ,kinect input
42,what tyre tread would be best suited to an off road robot expected to deal with frequently muddy conditions ,i m looking to potentially build an autonomous robot that will frequently venture off road  and remain autonomous for up to   hours at a time  i ve found limited information however about the best tyre tread for this purpose  what could be most suitable  i m especially looking for a tread pattern that won t need regular cleaning  to save setting this up automatically  a tread that gets  clogged  very quickly clearly won t be that effective at tackling tough terrain autonomously   ,wheel
43,what algorithm should i use for balancing a two wheeled robot using a gyroscope ,is there a good  popular and reliable algorithm i can use by taking input from a gyroscope and using this to control two independant wheels to keep such a balanced robot reliably upright  i m looking for an algorithm that will let me use it to drive a robot around as well as keep it upright when stationary  the ability to deal with inclines and people nudging it would also be a bonus  but not essential  ,control gyroscope balance two-wheeled
44,choosing the right dimensions for an underwater glider,i m looking to potentially build an underwater glider  a type of submarine that s slow but can operate on extremely low power draw  however  in order for it to work effectively i ve found several sources hinting that the dimensions of the components  especially the wings  are critical to its success  however  i ve found very sparse information about what these dimensions should be  i m happy to do a bit of trial and error if it comes down to it  but to save some work does anyone have any information on what the critical dimensions should be  ,design underwater auv
46,what s the most effective type of rechargeable battery when taking into account size   weight   ah ,i m looking to build an underwater glider robot that will need to remain autonomous for long periods of time  perhaps even months  power draw should be minimal  and i m thinking of including some form of charging device  such as a solar charger  however i d also like the battery capacity to be large enough so i don t hugely need to worry about this  large current draw isn t really needed  but the battery does need to hold its charge effectively for long periods of time  considering this is an underwater vehicle  weight and size are also a concern  cost isn t too much of an issue  as long as it s within reason of a hobbyist project  i am looking to understand the pros and cons of each technology  lead acid  lipo  nicad  fuel cell    so i can decide what type of battery would be best suited to my purpose  as such  i m looking at battery technology rather than looking for a specific shopping recommendation  ,underwater battery auv
48,how can i best protect sensitive components against damage through vibration ,it s common for components on some types of robots to experience large environmental stresses  one key one being vibration  is this something i need to worry about with typical electronics and other sensitive components  or not really  if it is  then how do i secure such components   i ve heard of two main philosophies behind this  the first being that you should use a damping system such as with springs to absorb the shock  the second is that you should keep everything rigidly in place so it can t move  and therefore can t hit against anything else and break  which one should i follow  or if the answer is  it depends  what should i use as a guide as to best protect sensitive components  ,electronics protection
49,what s the most accurate way to obtain a locational fix using gps ,obviously gps is the most obvious and accessible technology for obtaining a locational  fix  for a robot at any particular time  however  while it s great sometimes  in other locations and situations it s not as accurate as i d like  so i m investigating whether there s a relatively easy way to improve on this accuracy  or not  if that turns out to be the case   i ve considered the following options  but found limited information online   would using a much better antenna help  especially for low signal areas  i m thinking yes to this  but if so how would i construct such an antenna and know that it s an improvement  are there any good guides on how to do this  i could use a ready made antenna if they re not too expensive  would using multiple separate receivers in tandem help  or would they likely all be off by a similar amount  or would i not be able to extract a meaningful average with this approach  what sort of characteristics should i look for when choosing a good gps receiver to help accuracy  is there anything else i should consider which i ve missed   ,localization gps
53,what algorithm can i use for constructing a map of an explored area using a number of ultrasound sensors ,ultrasound sensors are incredibly cheap these days which makes them a popular choice for many hobbyist robotic applications  and i d like to use a bunch of them  say     around a robot with an algorithm to build a rough map of an area  as the robot explores it   i m not interested in dealing with moving objects at this stage  just pinpointing stationary ones  and i ll be using gps for location  i realise that other components such as a laser scanner would produce much more accurate results  however such devices are also astronomically more expensive  does an algorithm exist for this purpose  ,slam localization gps mapping acoustic-rangefinder
55,adding external heat sinking to a dynamixel rx   f servo ,hobby servos are generally not sufficient for real robotics for a number of reasons  quality  precision  range of motion  torque  etc  meanwhile  industrial servos  such as abb  emerson  ge  etc  are generally both heavy and expensive  and not suitable for small humanoid scale actuation  similarly  building your own servo from motors  gearboxes  and encoders  is akin to trying to design your own cpu just to control a motor    too much detail getting in the way of real work  there exists an in between level of servos    reasonably priced  reasonable performance  and reasonably controllable    in the form of the competing brands of dynamixel and herculex servos  the smallest offerings in those lines generally are not strong enough for real world interaction  but the next step up hold a lot of promise  for the robotis dynamixel line  this is the rx   f servo  priced between the cheap ax   f and the next step up the mx   r   asking around  it seems that the specs and interface on that servo is great  but that it shuts down from thermal overload if you actually try to run it at rated load    something that i d expect from a hobby servo  but not a robotics servo  now  stepping up to the mx   r doubles the price  thus  if the rx   f heat flaw could be fixed  it would be positioned at a nice price performance point  does anyone have experience in providing additional cooling for this servo  anything from thermal gluing heat sinks to the case  to drilling holes and running cooling fluid tubing to any hot parts on the interior would be reasonable approaches  however  before i spend significant time and effort investigating this  i d like a second opinion    is it possible  does anyone have experience doing this  is it worth it  ,servos heat-management cooling
57,how can i detect if a dc motor on a robot is starting to fail ,what characteristics can i look for which could be reliable early warning signs that a dc motor on my robot  say one used for the drive  could be failing  i m looking for an answer that deals in terms of sensors rather than manual inspection  so a circuit could be constructed to warn of a potential failure before it happens  i have a few ideas such as an increase in current draw or decrease in rotation speed   voltage  but i want to guard against false warnings caused by reasonable wear and tear  or just the robot struggling on tough terrain  obviously such a system will never be foolproof  but are there any points i can look out for  ,sensors failure motor
60,is it possible to both move and stabilize a two wheeled robot with no gyroscopes ,with two wheeled robot like this one  i have managed to stabilize it while keeping it stationary  this was done using a digital feedback control system by reading the position of the wheels to determine position  and the natural back electromotive force from the wheel motors was used in the feedback loop to determine velocity  it was kept stable with a pid controller  which was designed using a root locus algorithm to keep it stable and modulate the performance parameters  such as percent overshoot  settling time  etc    i wanted to attempt to keep it stable while simultaneously propelling it forward  but i couldn t figure out how to go about designing a linear controller that could do that  is it possible to both propel the robot forward and keep it stable using a feedback controller on the wheels  or is a gyroscope necessary  ,two-wheeled stability
65,calculating the efficiency of mecanum wheels,i m part of a first robotics team  and we re looking into using mecanum wheels for our robot  what are the advantages and disadvantages of using mecanum wheel versus regular ones  from looking through google  it looks like mecanum wheels give more mobility but don t have as much traction  are there any other advantages or disadvantages  compared to regular wheels  are mecanum wheels less efficient or more efficient in any way  and if so  is there a quantifiable way to determine by how much  are there equations i can use to calculate efficiency  or inefficiency  and or speed of moving forwards  sideways  or at arbitrary angles  a picture of a robot with mecanum wheels   ,mobile-robot design movement wheel first-robotics
75,using an arduino to control an on   off connection between two pins,i ve got this driver       a a     stepper motor driver carrier  i m attempting to control a connection between the reset and sleep pins with logic   code   running on my arduino  the motor runs perfectly when these two pins are connected however i d like to control when the stepper is powered off from my arduino   and thus not generating extra heat   i d like to   designate a pin to control the connection between these two pins use a  digitalwrite  to the above pin with a high or low to switch power on and off from the stepper  note  the data sheet mentioned that for the driver to be powering the stepper both reset and sleep needed to be in switched on   high   ,arduino logic-control stepper-motor stepper-driver
85,shape memory alloy wire for robot gripper arm actuation  how to vary grip pressure ,for a robotic gripper arm we are designing for factory floor use on very small components  we propose to use electrically activated shape memory alloy  sma  wire harnesses for actuation   the device being designed is akin to pick   place machines used for circuit assembly  but moves over an aircraft hanger sized work surface on wheels  it manipulates irregular shaped and porous objects between     cu cm and   cu cm each   hence the traditional vacuum p p mechanism does not appeal  also  individual objects in the assembly line have varying hardness and weights  our design constraints are    ensuring minimal to zero vibration and sound  using minimal volume within the mechanism  batteries are at the wheelbase  providing stability  so their weight is not a concern  fine variation of gripper pressure  we believe sma meets the first two constraints well  but need some guidance on achieving constraint    i e  different levels of pressure of the gripper controlled electronically  my questions   can pwm of a current above the activation threshold      ma for       inch flexinol ht  provide variable  repeatable actuation force   would we need pressure sensors on each fingertip and a closed loop control for grip  or can the gripper be calibrated periodically and maintain repeatable force  is there any well documented precedent or study we should be referring to   ,mobile-robot
88,mechanical design for motorized spherical caster wheels,design goal is to have a mobile robot that operates on   large casters  essentially   to   inch diameter steel ball bearings  that are motorized  no other mechanism would touch the surface  the robot should thus be able to move in any xy direction on a flat surface  with steering being achieved by varying the speed and rolling direction of these wheels  the robot has no designated  front  side  so it does not need to  and should not have to  bodily turn  in order to move off in any given direction   conventional wheels or tracks are not the preferred approach   looking for suggested mechanical layouts of multiple rubber wheels  pressing down onto the steel ball from within the castor housing  to drive the ball in any direction  a single wheel on a stepper  rotated around the vertical axis using a sail winch servo  is one approach under consideration  would this be ideal  or are there any serious flaws in this approach  alternatively  is there any other suggested method of driving such a steel ball in any arbitrary direction under electronic control  ,servos mobile-robot stepper-motor
91,what determines the amount of noise an actuator produces ,many robots and other mechanical devices produce the signature whirring noise as they move  some produce less  what makes the difference  what restrictions a silence requirement places on a robot  ,motor actuator noise
93,what bldc servo drive takes sinusoidal hall sensor signals ,i am looking for a servo drive to control a brushless dc motor  with at least   a    v rating  however  i want to know if any exist which take sinusoidal hall sensor signals directly  i already know there are servo drives taking hall sensor pulses  with   different phases   but that is trapezoidal control  note  a servo drive includes the driving electronics  no additional transistors required   ,brushless-motor hall-sensor
94,developing for   bit avr s  what are the current  open and free libraries out there ,i would be very interested to ask for a list of repos of free open code  applicable to   bit avr s and having relation to robotics   object avoidance  process controllers  battery management  etc  this would be of huge help for me  preventing me from wasting weeks and months to invent the wheel  ,software microcontroller
99,how to manage interrupts on an avr ,i have a number of interrupt service routines on an avr  these include interrupts for usart serial communication  timers  and spi communication  for all of these  i use circular queues  using a start and end pointer  without boundary checking   some problems start to occur if the avr starts to get overloaded  the circular queues will lose chunks of data  to solve this  i can reduce the load on the avr  for example  by skipping some cycles in the timer   however  this is a manual process  where it is reduced if the avr appears to have problems  this is partly because i do want relatively consistent timer periods  however  even at     average processor load  the queues can fill up randomly by chance  in case of spurious overloading at times  how can i make this more adaptive to avoid queue overflows  ,microcontroller avr interrupts
100,what connectors are most reliable ,if you have used connectors for signal wiring for any length of time  you may find that they are unreliable  specifically  i find these to be unreliable when used for a long time  with a number of disconnections and re connections   this is due to the loss of springy ness of the crimped metal end on the wire  which causes contact problems  which connectors  with rapid connection time  are reliable for multiple re connections for simple signal wiring  this excludes screw terminals and connectors with screws  eg  d subminiature connectors   because they are not simple plug in connectors  ,wiring
106,what is a suitable model for two wheeled robots ,what is a suitable model for two wheeled robots  that is  what equations of motion describe the dynamics of a two wheeled robot  model of varying fidelity are welcome  this includes non linear models  as well as linearized models  ,mobile-robot two-wheeled
112,how should emergency stops be wired ,emergency stops are obviously a good idea on most robots  how should they be wired   what systems should be killed immediately  and what should stay working  ,mobile-robot errors
113,how to model the noise in a range sensor s return ,range sensors  for example sonar  infrared  and lidar  are notoriously noisy   how can i characterize the noise characteristics to include these in a probabilistic localization sensor model  ,sensors noise
117,what is the difference between   point and   point connectivity in graph based planning ,in graph based planning  say  a    states are connected to their neighbors   how should one decide whether to connect to the   neighbors or the   neighbors   what are the pros and cons of each approach  ,motion-planning artificial-intelligence planning
118,properly flashing the firmware on a lego mindstorms nxt,i am attempting to upload a custom firmware to a lego mindstorms nxt and am having issues  first of all  i m attempting to use nxtosek  which would let me run c   programs on it   the problem is  everytime i put it into firmware update mode  the download doesn t seem to actually occur  what i mean by this is that  according to the output in my terminal  both mac and windows   the download was successful  however when the nxt reboots  i still see the normal logo  not nxtosek   so  what i m doing is first holding down the  button for a few seconds  then hitting the orange button  giving me that tic tic tic sound   then i run the firmware update  either using the windows nexttool or mac osx gui nexttool  and attempt the download   i get a success message  yet the robot is still using the old firmware  what could be the cause of this problem and how can i solve it  ,mindstorms nxt
119,is it better to have weight distributed over the wheels or the center of the robot ,when designing a standard   or   wheel robot  is it better to have the weight distributed primarily in the center of the robot  or over the wheels  or is there no difference  specifically  which weight distribution will make the robot less likely to tip over  ,mobile-robot design stability wheeled-robot
128,how mature is real time programming in robotics ,edit  i don t know why  but this question seems to be confusing many people  i am aware of when where why how to use real time  i am interested in knowing whether people who have a real time task would actually care enough to implement it in real time or not  there s no need to mention why real time operations are important for a robot  my question is however  how much is it actually used in robotics  take this question for example  only one answer mentions any platform with real time capabilities  and it is far from the top too  ros apparently  being a very popular platform which is not real time  in the real time world however  rtai  seems to be the only workable free real time platform of use  it is however  limited to linux  no problem   badly documented and slowly developed  so  how much is real time behavior sought after among robotics developers  the question is  how much are developers inclined to write real time applications when real time behavior is actually needed  if not much  why  for example  reflexive behavior based on tactile data  cannot go through ros because it would lose its real time property  but do people really come up with a real time solution or use ros anyway  ignoring the real time property    or similarly xenomai ,software platform real-time
131,connecting two microcontrollers using i c,i have an atmega   mc which is master on the i c and a atmega  mc which is slave on the i c  i have connected the two mcs  sda and scl ports to each other alongside a pullup resistor  now i want to read a register from the atmega  using the atmega     the problem is that i don t want to assign all the variables manually  is there any libs or headers that will do this thing for me  ,software microcontroller i2c
138,mathematical prerequisites for beginning graduate student in robotics,a beginning graduate student in robotics asked me the areas of mathematics that he should brush up on  prerequisites  to begin a masters research program in robotics  what are some good materials books that are indispensable for a research student  which ones should we suggest in order that the student develops a solid foundation in robotics  ,research
142,technology behind kiva systems mobile robots,what kind of sensors and algorithms are the mobile robots of kiva systems equipped with   ,mobile-robot industrial-robot
143,how do i calculate the required loop frequency for a servo controller ,i have a motor which drives a string connected to a load cell  i would like to implement a closed loop controller to control the load applied by the motor to the string   how do i go about determining the required loop frequency in order to create a stable control system  is it something like the nyquist frequency  where the loop speed should be at least twice the highest frequency inherent in the mechanical system  ,control motor force
146,what rail material is best used for linear bearings ,for the  d printer reprap prusa there are several rails  smooth rods  that guide the printer head on the different axises  the printer head uses several linear bearings to glide along the rails   there isn t any specification on what kind of material would be best suited for this purpose with the linear bearings  my first assumption would be for stainless steel because it won t corrode  rust  on the surface  but i m not sure if this is true for all printers  whether they are  d printers or not  as a different material may allow the linear bearings to glide more easily  aluminum would have been my second choice but i have the same reservations of which grade would be least resistant   this resource has some limited information but does not help with which would be best suited for this particular application  what material is best suited for this purpose  ,reprap 3d-printing linear-bearing
148,detect nao robot in kinect,i am not sure if this has been tried before but i am trying to use kinect and detect gestures made by the nao robot  i have made a kinect application  a gesture based picture viewer and it detects humans fine obviously it does   what i wanted to try was  lazy as i am   to see if i could use some  say  voice  command to tell the nao to do a swipe right gesture and have my application identify that gesture  the nao can easily identify my command and do some gesture  the problem however is  when i put the nao in front of the kinect sensor  the kinect does not track it   what i want to know is  are there some basics behind kinect s human body motion tracking that essentially fails when a robot is placed in front of it instead of a human  ps  i have kept the nao at the right distance from the sensor  i have also checked if the entire robot is in the field of view of the sensor  edit  this has been posted on stackoverflow and on msdn by me so as to target a large audience as this problem has not been encountered by anyone in the past  ,kinect
150,preventing leaks in motor shafts for underwater bots,whenever building an aquatic bot  we always have to take care to prevent leakages  for obvious reasons  now  holes for wires can be made watertight easily  but what about motors  we can easily seal the casing in place  and fill in any holes in the casing   but the part where the axle meets the casing is still left unprotected    water leaking into the motor is still quite bad  i doubt there s any way to seal up this area properly  since any solid seal will not let the axle move  and any liquid seal  or something like grease  will rub off eventually  i was thinking of putting a second casing around the motor  maybe with a custom rubber orifice for the shaft  something like  forgive the bad drawing  not used to gimp    this would probably stop leakage  but would reduce the torque rpm significantly via friction  so  how does one prevent water from leaking into a motor without significantly affecting the motor s performance   to clarify  i don t want to buy a special underwater motor  i d prefer a way to make my own motors watertight  ,motor underwater auv protection
154,fixed point arithmetic on microcontrollers,often we use microcontrollers to do things in our robots  but need to make some calculations in decimal  using floating point variables is very slow  because a software floating point library is automatically included  unless you have a high end microcontroller   therefore  we generally use fixed point arithmetic  whenever i do this  i just use an integer  and remember where the decimal place is  however  it does take some care to ensure that everything is consistent  especially when calculations involve variables where the decimal point is in a different place  i have implemented a fixed point atan  function  but because i was trying to squeeze every last drop of limited precision     bits   i would often change the definition of where the decimal point is  and it would change as i tweaked it  in addition  i would have some constants  as a quasi look up table  which themselves have an implied decimal point somewhere  i want to know if there is a better way  is there a library  or set of macros  that can simplify the use of fixed point variables  making multiplication and division between mixed variables easier  and allowing declaration of decimal numbers or constant expressions  but automatically converting to the desired fixed point representation at compile time  ,microcontroller c
155,how to choose a good imu for a wheeled robot ,at our lab  we have a several  kurt  type robots  about the size of a pioneer  six wheels  differential drive   the built in gyroscopes are by now really outdated  the main problem is that the gyroscopes have a large drift that increases as the gyro heats up  the error is up to    s   we mainly use the imu to get initial pose estimates that are later corrected by some localization algorithm  but even so the large initial pose error caused by the imu is often annoying  we ve temporarily used an android phone  galaxy s   as a replacement imu  and the results are so much better compared to the old imus  however  i don t like depending on a wifi connection between imu and the control computer  a laptop running ros ubuntu   so we re looking to buy a new imu  what imu should we choose  what criteria are important to consider for our application  please share your experiences      ,ros imu odometry gyroscope ugv
167,what are good strategies for tuning pid loops ,tuning controller gains can be difficult  what general strategies work well to get a stable system that converges to the right solution  ,control pid tuning
172,absolute positioning without gps,using an imu a robot can estimate its current position relative to its starting position  but this incurs error over time  gps is especially useful for providing position information not biased by local error accumulation  but gps cannot be used indoors  and even outdoors it can be spotty  so what are some methods or sensors that a robot can use to localize  relative to some frame of reference  without using gps   ,localization gps sensors slam
178,hmms vs  crfs to model time series force data of robots interacting with environment ,i have a time series of force data of robots interacting with environment objects with various textures  i would like to develop models of various textures using the time series data to classify textures into smooth  rough  moderate  etc  categories  for this purpose  will hidden markov models be sufficient or should i use conditional random fields  if i decide to classify into more categories and the distinction between each of are categories are very subtle  in that case what would be a good choice  will force data be sufficient to capture all the information i need to classify textures into these categories  thanks for your replies    ,artificial-intelligence
182,suitable control algorithm for air muscle based joint ,i have a joint actuated by an antagonistic pair of pneumatic muscles   there are two valves per muscle  one to fill and one to empty each muscle  the joint has an angle sensor  and each muscle also contain an air pressure sensor  what is a suitable control algorithm set up   a pid controller controlling the valve orifice sizes  a pid controller controlling the mass flow rate  a pid controller controlling the pressure using two pid pressure controllers  a fuzzy logic controller  a neural network   ,control pid air-muscle
184,robotics trends,robotics has always been one of those engineering fields which has promised so much  but is taking a long time to deliver all the things that people imagine  when someone asks   how long before we have  x  type of robots   are there any resources we can call upon to try to calculate a rough answer  these resources might include   rate of progress of computational power  and some estimate of how much will be needed for various types of ai  rate of progress of electrical energy storage density  and some estimate of how much will be needed for various types of robot  rate of progress of actuation systems  and some estimate of what would be needed for various types of robot  lists of milestones towards various types of robot  and which ones have been achieved and when   are these types of studies performed  and are the results published   added  in response to jakob s comment  i am not looking for opinions or discussions on this subject  what i am looking for are published studies which might shed light on this question  ,research
205,creating a fast  uniform  linear actuator,most of the linear actuators i ve seen are nonuniform and or slow  those using a cam or crankshaft like mechanism  and nearly anything hydraulic pneumatic  cannot be moved at a constant speed without some programming  those using a screw like mechanism are uniform  but slow   aside from a rack and pinion rope wound around a stick  what other fast  uniform linear actuators exist  by uniform  i mean that the speed is uniform  or the distance moved is linearly dependant on the angle rotated by the motor  ,actuator
209,how to determine quality of icp matches ,in slam frontends which use the iterative closest point  icp  algorithm for identifying the association between two matching point clouds  how can you determine if the algorithm is stuck in a local minimum and returns a wrong result   the problem is defined as matching two pointclouds which are both samples of some arbitrary surface structure  and the sampled areas have an overlap of        which is unknown  i know the trimmed icp variant works by iteratively trying to determine the overlap  but even this one can be stuck in a local minimum   a naive approach would be to look a the mean square error of the identified point pairs  but without some estimate of the sampling this seems a risky thresholding  in the manual for the leica cyclone they suggest manual inspection of the pair error histogram  if it has a gaussian shape the fit is good  if there is a linear fall off the match is probably bad  this seems plausible for me  but i ve never seen it used in an algorithm  ,slam
210,how can i automatically adjust pid parameters on the fly ,i have a simple servo system that uses a pid controller implemented in an mcu to perform the feedback  however  the properties of the system change dynamically  and so the pid parameters can never be tuned for all circumstances  my robot is a light weight arm with back drivable electric motors  similar to this one   the arm performs several tasks  including picking up heavy weights  pushing and pulling objects across the desk  each of these tasks requires different pid tuning parameters which i cannot easily predict  what i would really like is for some higher level function which can carefully adjust the parameters in response to the arm s behaviour  for example  if it notices that the arm is oscillating  it might reduce p and increase d  or if it noticed that the arm wasn t reaching its target  it might increase i  do such algorithms exist  i would be happy even if the algorithm didn t perfect the parameters immediately  e g  the arm could oscillate a few times before the parameters were adjusted to their new values   ,control pid automatic tuning
213,how can i integrate a smart phone with my robotics project ,smart phones these days typically come with a gyroscope  accelerometer  compass  camera  and gps sensor all on board  they also usually have a connection to the internet with wifi and mobile data networks  i ve seen many cases of using a phone as a remote control for a robot  but to me  it seems like the phone itself is a perfect lightweight computing and sensing platform for an autonomous robot  the main obstacle i see is interfacing with actuators  being able to control motors to steer even a table top robot  or control servos  for example  connecting and communicating to a microcontroller could be an obstacle as well   as a robot hobbyist  i d like to know how i can overcome these and other obstacles to be able to harness the power of my smart phone with my robotics projects  ,actuator
215,starting out advice on making robots and tinkering with microcontrollers,i d like to start making robots and tinkering with microcontrollers  where do i start  and what do i need  i d like to make my own robots  i m comfortable with programming  assembly and c  so i ve got that part covered  but my electronics circuits knowledge is a little weak  i have no idea what material to start with and which tools i need  nor how to put stuff together  for the microcontroller  i m thinking about going with the pololu orangutan lv     or the arduino duemilanove  although i m leaning more towards the orangutan because of the built in lcd and pushbuttons  which i would expect to use  especially for debugging and user interaction   am i on the right track  it seems to me like the number of i o ports is small  but is that the case in practice  ,arduino microcontroller beginner
222,floor segmentation to determine navigable paths,in my application  my robot has the following physical setup   differential drive mechanics with feedback  wheel encoders  commercially available webcam mounted with a known transform to the base of the robot  rgb  no depth   the robot will be navigating through a structured  indoor type environment  think office  home  or university   and i would like to be able to determine the navigable paths through the environment using my vision sensor  what is the best way to approach the problem of finding safe paths to travel when given a single vision sensor  edit   i think that i am more interested in the vision processing techniques than the actual path planning mechanics  ,computer-vision
229,red  error  output in python in ros,in ros  i cannot get  error  logs to print in red when i use python  how can i make them appear in red instead of black   for example  the following python   produces this output in black    error   walltime                    no analog input received    whereas the following c    ros error  no analog input received      produces the following output in red    error                      no analog input received   ,ros python
230,can ros run on a raspberry pi ,can ros run on a raspberry pi  ros is resigned to run on a network of machines  with different machines  even different cores on the same machine doing different jobs  can one of those machines be a raspberry pi  i am considering using an r pi as the ethercat master on a mobile robot  communicating with the main pc over wifi  using a dongle   can an r pi even run ros at all  would an r pi have enough processing power to do some  khz servoing  would it be possible to run some servoing on the host through the wifi connecion   ,ros raspberry-pi wifi
231,what frequency does my quadcopter output sense calculate output update loop need to stay stable ,with a     mm    foot  motor to motor quadcopter  what frequency does my output sense calculate output update loop need to stay stable  i m estimating a total takeoff weight of very roughly   pounds       kg    which i expect to be mostly motors and batteries  ,stability quadcopter
235,is it better to have batteries distributed at the rotors or the center of the multicopter ,i ve seen   approaches to mounting batteries on a multicopter   all the batteries rigidly mounted near the center of the airframe all the batteries in a bag hanging under the center of the airframe each rotor has its share of the batteries rigidly mounted near under it   for example  a quadcopter with     of all the batteries mounted underneath each motor    which design is the best  and why  if there is no one best design  what are the advantages tradeoffs between the designs  is there some other design i m overlooking that is better in some way   this question focuses on multirotor flying machines  for ground vehicles  see   is it better to have weight distributed over the wheels or the center of the robot      ,design stability quadcopter
237,how to calculate serial speed and buffer requirements for pc to microcontroller communications ,a common scenario is to have a pc that sends commands to a microcontroller via rs      my pc program is sending commands  each of which are composed of multiple bytes  as fast as it can to a small robot   the microcontroller on the robot is a parallax propellor  i have noticed that if i don t process bytes quickly enough on the microcontroller side of things  it can very quickly overflow the default buffers in the popular serial port drivers that are available for the propellor   the buffers are generally anywhere from    to     bytes    i can arbitrarily increase these buffers or create my own larger circular buffer  but i would like to have a more methodical approach to determining appropriate size requirements and or the minimal amount of time i can wait before pulling bytes out of the serial port driver buffer  at  st glance                   bits per millisecond          bytes per millisecond  assuming   stop bit      is that a valid way to calculate timing for serial transmissions  also  given my specific setup   pc program      bluetooth serial profile driver      bluetooth transceiver       bluesmirf wireless modem      parallax propellor program     what is the maximum amount of data i can send for a given period of time consistently without eventually running in to problems  maybe i m over complicating things  but it seems like there are potentially multiple buffers involved in the transmission chain above   how do others commonly deal with this  do they throttle the pc sending to a known safe rate  implement flow control   if implementing flow control  how does that affect bandwidth and response times   if it matters  my experiment is to use a joystick on the pc to control multiple servos with instant reaction to the joystick movements  so every small movement of the joystick results in multiple commands being sent to the microcontroller  the commands are not just simple positional commands though  they also involve acceleration deacceleration of servos over time and this is the reason that the microcontroller spends a significant amount of clock cycles before processing new bytes   ,microcontroller serial rs232
249,how does a six axis force torque sensor work ,i would really like a six axis force torque sensor for my robot  but i just can t afford one  i was thinking about making one of my own  i have experience using strain gauges  but i can t work out how to arrange them so as to create a six axis force torque sensor   is this something i could feasibly make myself  how do they work  what is the theory behind them   i m curious to know how they work  even if it s not feasible to make one myself   added  just to be clear  i m talking about force   torque sensors  like this ati nano      i am not talking about accelerometers or gyros  or mems imus  ,sensors force-sensor
254,should i switch my servo system from brushed to brushless motors ,i have a robot that uses brushed motors in its servo system  these are maxon  w motors  with       planetary gearboxes  the motors are controlled by a pic microcontroller  running a  khz pid controller  the servos are for a low speed high torque application  there is significant backlash between the sensor and the motor  maxon offer   w brushless motors which are the same size  these are better in many ways  double the torque  better heat dissipation  higher efficiency  the problem  obviously  is that they require more complex drive electronics  also  i have heard a couple of people mention that brushed motors are better for servo applications  though they never explained why   has anyone else implemented this kind of system  are there any gotchas when using brushed motors for servos  is it possible to servo it at low speeds if i only have the   integral digital hall sensors  and no encoder   i would prefer not to add an encoder because of the money and space cost  it torque ripple likely to be a problem   ,brushless-motor servomotor
255,what uav kit s  would be suitable for a beginner roboticist with programming experience ,i m really new to robotics  however i am a programmer familiar with several different languages  i don t have a ton of money to spend and i was wondering what is a really good starter kit   my criteria is for the kit to be inexpensive and powerful  in that its functionality is extensible    something that would allow the builder to be creative and possibly invent new ways to use it  not just a glorified model kit    being extendable to smartphones is a plus  i m not looking for something easy or introductory  just something powerful  flexible  and cost effective  ,uav kit
256,quadcopter localization beacon,i want to use an rf beacon to localize my quadcopter for autolanding  when gps is not precise enough  for example  when my driveway is only    feet wide  and the gps is only showing       ft  accuracy  with a proverbial lake of lava on either side   the quadcopter would use the gps to fly to the rough location until it had a strong enough signal off the beacon  when it would begin to use that signal to come to a landing in a precise location  referenced off said beacon  can someone please explain to me the concepts and theories behind building the beacon and it s accompanying receiver  suitable for connection to an arduino via any digital or analog method  and achieving  say  a    or better horizontal and vertical accuracy within a     sphere  minimally  the quad should have range and altitude  i e   i am    feet away from the beacon and   feet above it   how much added complexity would it take to make the robot fully position aware about the beacon  i e   x ft  south  y ft  west and z ft  above it   where the coordinate system is determined by the beacon and not linked to any sort of geographic coordinate system  if the beacon is mounted on a  say     ft pole  are there any changes to be made versus having it on the ground and presuming that all activity takes place above it s x y plane  last note  this thing would prefferably operate in the   mhz band  please presume that where i m operating  there are not other devices operating on the same band  ,localization quadcopter gps
261,what do the commutation waveforms look like for a brushless motor ,i have seen waveforms for driving a brushless motor   i guess this is the waveform used for the simpler block commutation  but if i want to do sinusoidal waveforms  what does the pwm signal look like now  is there a need to carefully synchronise the edges on the three phases  ,brushless-motor pwm
262,effectiveness of a mobile robot in relation to mass,do mobile and or autonomous robots become more or less effective the bigger they get  for example  a bigger robot has bigger batteries  and thus bigger motors  whereas a smaller robot has the exact opposite  making it need less energy  but also have smaller motors  is there any known theorem that models this  ,mobile-robot design dynamics
267,why are capacitors added to motors  in parallel   what is their purpose ,i ve seen many motors having capacitors attached in parallel in bots  apparently  this is for the  safety  of the motor  as i understand it  all these will do is smoothen any fluctuations  and i doubt that fluctuations can have any adverse effects on a motor  apparently these protect the motor if the shaft is being slowed blocked  but i fail to see how  what exactly is the function of such a capacitor  what does it prevent  and how  ,motor protection
271,spatial tracking between two uavs,i have two unmanned aerial vehicles  planes  which work well  they can fly to various waypoints automatically using gps  now i would like them to fly together in formation  i would like them to fly side by side fairly close  this is too close to reliably use gps to guarantee that they keep the correct relative positions safely  and so i am looking for another way  somehow the uavs need to be able to measure their position and orientation in space relative to the other one  how can i do this  is there some kind of sensor which can do this  it would need to have the following properties     axes  position and orientation  range  m    m   from between plane centres  but planes won t actually ever touch wingtips  works in day or night and all weather conditions light weight  this is for    m wingspan rc planes  so max extra weight of about    g  probably need about   hz      hz refresh rate  but might get away with less  using the imu to fill in the gaps  ,sensors uav multi-agent
274,low cost servo with digital control interfaces ,some years ago  there where some projects that provided hardware and software to perform modifications on standard hobby servos to convert them to digital servos  with all the advantages that come with it    openservo is a little outdated  and does not seem to be worked on anymore  and there is no hardware to buy  sparkfun has its own version of the openservo  which at least is available for buying   do you know if there are other mods  or even complete low cost digital servos  i am mostly interested in position feedback  and servo chaining  ,servos i2c
277,why do i need a kalman filter ,i am designing an unmanned aerial vehicle  which will include several types of sensors      axis accelerometer   axis gyroscope    axis magnetometer horizon sensor gps  downward facing ultrasound   a friend of mine told me that i will need to put all of this sensor data through a kalman filter  but i don t understand why  why can t i just put this straight into my micro controller  how does the kalman filter help me about my sensor data  ,kalman-filter uav
284,which type of actuator will be suitable for a very strong robot arm,i wish to build a robotic arm that can lift a useful amount of weight  such as    kg on an arm that can extend to approx      meters   what actuators are available to accomplish this  the main factors and design points are   not expensive   to   d o f  to be mounted on a yet to be designed mobile platform battery powered stronger than hobby servos  at least for the  shoulder  and  elbow  joints  not slow to actuate  ,mobile-robot robotic-arm actuator
287,programming robots with javascript,as somebody who is spending the majority of his time programming in javascript  what s the best route to get into small robotics without needing to deviate too much from my current language focus  are there any project kits or tools that make use of the javascript language that might make the field more approachable for developers like myself  i would even be interested in virtual environments where all code is executed in a simulation  ,software programming-languages
299,how can the inverse kinematics problem be solved ,the forward kinematics of a robot arm can be solved easily  we can represent each joint using denavit hartenberg transformation matrices  for example  if the  joint is a linear actuator  it may have the transformation matrix   where the extension length is defined by  whereas  a rotating link may be   where  is the angle  and  is the length of the link  we can then find the position and orientation of the end effector by multiplying all the transformation matrices    the question is  how do we solve the inverse problem  mathematically  for a desired end effector position   find the parameters    such that   what methods exist to solve this equation  ,inverse-kinematics kinematics joint arm
301,which spline function would be best suited for the trajectory of a differential drive,what s the best kind of spline that can be used for generating trajectory that can be adapted during execution time  the use case is having a differential drive which has to move towards a point  x y theta  without stopping during the movement  e g  no  turn toward the goal  straight move to the goal position  turn to the goal orientation   the robot is provided with a laser scanner for detecting dynamic obstacles which have to be avoided  what s the best kind of controller in this case  ,control motion-planning
309,correct way to use subsumption architecture with robot c,i ve been doing a lot of reading lately about subsumption architecture and there are a few different ways people seem to advocate   for instance some people use a global  flag  variable to have a task take control  others use the  and allow the arbiter to really choose  and i think this is correct   i have this small section of robotc code that i m working on for a line following robot but am not sure i am doing it right as currently the track method will always take over the find method  the correct flow should be that find should guide the robot to the line using a spiral path to find the line  once the line is found track should take over   task evade        if sensorvalue forwardsonarsensor    threshold                 box the obstruction          task find        if sensorvalue lightsensor    threshold                 spiral the robot          task track         if sensorvalue lightsensor    threshold                 go straight      else                    execute turns to follow the line          task main        while true           starttask evade             starttask track             starttask find             wait msec                i ve just used some comments here rather than the actual code to keep it brief  are my if statements not good enough as conditions because when the robot is off the line  track   takes over  is this due to the else statement within track  if so  how to have track   perform turns when it looses the line without taking over from forage at the start of the program   ,mobile-robot software two-wheeled robotc
317,how much can working with cnc machines teach you about robotics ,i have built a few simple x y z cnc machines   i ve learned about g code  motor control  firmware and open loop systems   i see machines like rovers  big dog and factory arms that seem incredibly complex by comparison  yet they don t seem that magical any more    what are the important skills to pick up from working with cnc machines   what s the next logical thing to learn   what things would cnc machines never teach me  ,control
323,ipc bridge problem,is anyone able to help me out getting ipc bridge working on my ubuntu lucid installation  with matlab     a   i m not being able to finish the last step on here  compiling the messages folders    i m able to rosmake the ipc bridge ros  however when i enter this  roscd ipc roslib    make   it seems mex does not recognize the commands  here is what i get  screen shot    note  i m going to use ipc bridge so that i can control a pioneer  dx and implement a fast slam algorithm in matlab  ,mobile-robot software slam ros
327,learning algorithms for walking quadruped,i m building a   legged robot  quadruped  with   degrees of freedom per leg  the goal of my project is to make this robot able to learn how to walk  what learning algorithms will i need to implement for it to work  i m using an arduino uno for the microcontroller  ,arduino microcontroller machine-learning walking-robot
331,robot serial communication error,we are using a koro robot for our pc based automation solution  but sometimes the robot is getting the command but refuses to respond  then i get a serial communication timeout error  the error is happening for a random type of commands and it is also not happening all the time making the troubleshooting difficult  i doubt the driver problem  how do you approach this problem   thanks ,logic-control
338,is there a list of maneuvers related to control of a tracked platform ,i have a platform with two tracks and two motors  each one uses an electronic speed control with  double tap to reverse   each esc takes an input pulse train frequency from at      neutral         i m interested in learning if there are algorithms or a list of commands i can use to control how such platform executes maneuvers  for example   lock one thread and have the platform rotate by using the other one have two treads rotate in opposite directions execute a u turn  i m struggling with expressing in code how such maneuvers should be executed  there s a  dead  zone around the      pulse train frequency where the esc output is too weak to cause the platform to move  the double tap to reverse also makes it tough to understand for how long each track should be turned off  thank you for your input ,control motion-planning tracks
341,tendon longevity,i am thinking of developing a tendon driven robot manipulator for an industrial application that requires a high level of reliability  however  i am aware that tendons in a robot are prone to wear and tear  and failure  how can i go about selecting a suitable tendon material  steel  kevlar  spectra  etc   and use it appropriately  have any studies been undertaken to examine longevity and failure patterns in robotic tendon materials  if i were to perform tests on materials myself  how can i perform those tests efficiently  and make best use of the testing time  learn as much as possible about tendon failure in a reasonable length of time   ,failure reliability
342,what are some common mistakes that robots make ,is there a taxonomy of errors that are common in robotics  things that come to mind but i don t have names for are   getting stuck in a stable infinite loop going into an unstable feedback loop  a balancing robot overcompensating more with each correction  an inability to generalize between tasks  pick up a bowl vs pick up a glass  an inability to generalize between  similar  sensory inputs  causing damage to itself or its environment   these would be things that make a robot look  stupid  to a non roboticist  if you re curious i want to have this list so i can then prepare a clear answer ready for people who don t know why these various things are hard  ,errors
344,with a   axis robot  given end effector position and range of orientations  how to find optimal joint values,given a six axis articulated robot arm holding a tool at its end effector   if i have a desired tool position and tool orientation   there will be exactly   solution to the inverse kinematics equation for the robot to reach that position   or rather up to    different solutions  depending on range of the joints   but if the robot is holding something like a pen  and i want the robot to mark a specific point with that pen on the target  then i do not care how the pen is oriented  as long as it is perpendicular to the marked surface  so the inverse kinematics equation will have infinitely many solutions  how can i pick among these solutions the joint configuration that is closest to the current configuration  the one that will require the least amount of movement to reach   or the joint configuration that is optimal according to some other similar criterion  such as that all joint angles are furthest from their maximum and minimum   ,localization motion-planning industrial-robot inverse-kinematics kinematics
354,is subsumption architecture still an active area of research ,i am interested in learning more about subsumption architecture  i have read a number of books that talk about the idea but none of them go into great detail  i have also read a fair number of dr  brooks papers on the topic however he hasn t published much on the topic in recent years  is this still an active area of research  are there are any must read papers on the topic  ,control research
358,restricting range of motion with complex constraints,i am looking for a way to restrict a robot s range of motion  using complex constraints such as not tearing of a cable attached to the robot  take an articulated   axis robot arm as shown below  with attached cable  red   fixed at points x  before axis a   and y  after axis a     the cable will limit the range of movement for the robot  it can stretch and bend only to some extend  but something like a full      turn of axis a   with all other axes remaining as they are in the picture  will tie the cable around the arm and rip it off  if joint a  is at     then a  and a  can still move the full       but they cannot diverge too much from each other  as that would twist the cable  if a  is tilted  the relationship becomes even more complicated  how can you express such a constraint    it is not a simple joint constraint  where you can independently limit the range of the joints  and it is also not a positional constraint  where you can define a region the robot must not enter  checking a start and a goal posture is not sufficient  since along the path from start to goal posture there may still be a posture that puts too much strain on the cable  without limiting the robot to a small set of pre tested paths  how can you limit the robot to movements that will not rip off the cable  what are the standard techniques used for this sort of problem  ,motion-planning industrial-robot joint
359,what kind of performance can i expect when using an extended kalman filter for calibration and localization ,currently i have a tricycle style robot that uses an extended kalman filter in order to track   state variables  the inputs to the system are a steer encoder  a distance encoder  and a rotating laser that returns bearing only information to known landmarks  currently both encoders are located on the main wheel  the one that steers  and is also powered   the   variables tracked by the kalman filter are x  y  heading  distance scaling  calibration of the distance encoder   steer calibration  offset of the steer encoder   and finally a bearing calibration of a rotating laser   with this kind of system we put together a vehicle give it a known good location with plenty of landmarks  drive it around a bit  and end up with a well calibrated vehicle that can drive extended distances reliably with few landmarks  its simple and it works great  over time if an encoder drifts it will automatically follow the drift and adjust   we are now attempting to apply the same principles to a robot with multiple steer and drive wheels  in this case the vehicle will be able to move in any direction  spin in place  etc    each steer drive wheel will have its own steer and distance encoder that each need to be calibrated   can i expect to get the same kind of reliability and performance out of the more complex system  are there any common pitfalls to look out for when expanding a kalman filter to include more variables  is there a risk of it settling on sub optimal values  ,localization kalman-filter
361,programming a line following robot with reinforcement learning,i am considering programming a line following robot using reinforcement learning algorithms  the question i am pondering over is how can i get the algorithm to learn navigating through any arbitrary path  having followed the sutton   barto book for reinforcement learning  i did solve an exercise problem involving a racetrack where in the car agent learnt not to go off the track and regulate its speed  however  that exercise problem got the agent to learn how to navigate the track it trained on  is it in the scope of reinforcement learning to get a robot to navigate arbitrary paths  does the agent absolutely have to have a map of the race circuit or path  what parameters could i possibly use for my state space  ,machine-learning artificial-intelligence reinforcement-learning line-following
369,are inverse kinematics and reinforcement learning competitive techniques ,are inverse kinematics and reinforcement learning techniques contending techniques to solve the same problem viz  movement of robotic manipulators or arm  by a glance through the wikipedia article  it appears that inverse kinematics seems to attempt to achieve a solution  as opposed to reinforcement learning which attempts to optimizes the problem  have i misunderstood anything  ,inverse-kinematics reinforcement-learning machine-learning
380,processor and command interface preference for a robot arm,i want to build a robot arm that ll be approximately      meter long and will be able to lift up to   kilograms  it ll have   dof and it is an expensive project  and most importantly  i am the only programmer in this brand new robotics facility of ours     the robot that i want to build will be led by inverse kinematics  so with all these parameters and matrices  i think that i ll need a tough processor  not so sure   assuming that my robots control interface will be on an android tablet  i thought that i also could develop my program for android  and send necessary commands to the control chip via rs     interface  so  my question is  are standart   ghz android tablets suitable for these tasks  if not  has anybody got an advice for me  ,software inverse-kinematics arm rs232
382,how to fuse linear and angular data from sensors,my team and i are setting up an outdoor robot that has encoders  a commercial grade imu  and gps sensor  the robot has a basic tank drive  so the encoders sufficiently supply ticks from the left and right wheels  the imu gives roll  pitch  yaw  and linear accelerations in x  y  and z  we could later add other imus  which would give redundancy  but could also additionally provide angular rates of roll  pitch  and yaw  the gps publishes global x  y  and z coordinates  knowing the robot s x y position and heading will useful for the robot to localize and map out it s environment to navigate  the robot s velocity could also be useful for making smooth movement decisions  it s a ground based robot  so we don t care too much about the z axis  the robot also has a lidar sensor and a camera  so roll and pitch will be useful for transforming the lidar and camera data for better orientation   i m trying to figure out how to fuse all these numbers together in a way that optimally takes advantage of all sensors  accuracy  right now we re using a kalman filter to generate an estimate of  with the simple transition matrix       dt     dt dt                                   dt                                                                               dt     dt dt                                   dt                                         the filter estimates state exclusively based on the accelerations provided by the imu   the imu isn t the best quality  within about    seconds it will show the robot  at rest  drifting a good    meters from its initial location   i want to know out how to use roll  pitch  and yaw from the imu  and potentially roll  pitch  and yaw rates  encoder data from the wheels  and gps data to improve the state estimate   using a bit of math  we can use the two encoders to generate x  y  and heading information on the robot  as well as linear and angular velocities  the encoders are very accurate  but they can be susceptible to slippage on an outdoor field   it seems to me that there are two separate sets of data here  which are difficult to fuse   estimates of x  x vel  x accel  y  y vel  y accel estimates of roll  pitch  yaw  and rates of roll  pitch  and yaw  even though there s crossover between these two sets  i m having trouble reasoning about how to put them together  for example  if the robot is going  at a constant speed  the direction of robot  determined by its x vel and y vel  will be the same as its yaw  although  if the robot is at rest  the yaw cannot be accurately determined by the x and y velocities  also  data provided by the encoders  translated to angular velocity  could  be an update to the yaw rate    but how could an update to the yaw rate end up providing better positional estimates  does it make sense to put all    numbers into the same filter  or are they normally kept separate  is there already a well developed way of dealing with this type of problem  ,sensors kalman-filter sensor-fusion
390,can i use imus to improve the position posture measurement of fingers in a  data glove  ,i have been using the cyberglove to control a humanoid robot hand  but found it disappointing as it doesn t measure the posture of the human hand very accurately   i have been wondering about the possibility of using inertial measurement units  imus  mounted on the fingers to track position and measure posture  but i m not sure how feasible it is   would an imu return enough data to make tracking reliable in all circumstances  would it be possible to fool the system into incorrectly tracking the fingers  might it be possible to get away with using simple   axis accelerometers  or would it need   axis  accelerometer  gyro  and magnetometer    ,imu sensor-fusion hri
397,resources for learning basics of robotics,i am interested in robotics  practically i have no idea about robotics  i want to start learning the basics of robotics  but i am confused what to start with  so i need suggestions about what will be the best resources to start robotics with  that may be books  sites  or others  please help me with this  ,books
403,what is the current state of the google self driving car project ,i am aware of the legislation s in nevada  but what is happening with the technology currently  when is it expected to be commercialized   ,ugv
405,selecting an accelerometer for deduced reckoning,i have never used an accelerometer before  but i am aware that they come with i c  spi and analog outputs  if i choose to use an i c or spi  device  will i accumulate errors due to communication time  is the fast sampling of an analog signal likely to get me a more accurate deduced position than using am i c  will this be true for   a robot moving in a room  a robot moving in an outdoor terrain and is likely to slip and roll down a slope   also  i have no sense of gs  i tried to move my hand around fast with my phone running andro sensor in my fist and saw that the readings saturated at   m s   what g can i expect my robot to experience if it is hit by another fat moving bot or bumped by a fast walking human  ,sensors deduced-reckoning navigation accelerometer
413,questions about quadcopter and radio controller,i have not bought any parts yet  but i am making my own quadcopter  i have done the research and know all about the parts that i need  but many guides are sponsored and cost thousand s  of euros dollars while not explaining things entirely clearly  firstly  i have found this flight control board  would i need another microcontroller  such as the arduino nano  for it to work   if anyone has experience with this board  let me know    secondly  would the above board work with this radio controller  are controllers universal   please tell me if i m not in the right section here  or if this doesn t count as a relevant topic   ,microcontroller quadcopter radio-control
416,what is the best way to power a large number      servos at   v ,i apologize if this question may sound a little vague  i am working on a robotics project that will contain    servos of various sizes and i am having trouble figuring it how they should be powered  i was hoping to use several         w       battery boxes to power them  but the smallest motors would use     w each  so   battery box can only power two  the larger servos  obviously  use even more current  so this plan of using a small number of       s becomes infeasible  there is not enough room on the robot for a    v car battery  and adding one would require recalculating the sizes of the servomotors that would be needed  furthermore  i am not sure how to convert the    v it gives down to   v for the servomotors  p s  what about the stall current of the motors  should the power supply be able to supply the stall current of all the motors it supplies  at the same time  or just the working current  should i use a fuse to handle when  if   the servomotors stall  should i use a fuse or a circuit breaker  do they make   v fuses  if so  where can i get one  something like a larger version of the       box would be most preferable  ,design servos power
419,how do you implement an ins from an accelerometer and  optionally  gyros and a magnetometer ,i m building a walking robot that will need to know when it moves forward  i m using on board intelligence and i plan on using accelerometers  gyros  and magnometers  if needed  to be able to detect if the robot moves forward  the problem is  i dont know how to program an internal navigation system or an imu   what software algorithms are needed  to clarify my problem  i need to know how to program the micro controller to read the sensors and be able to tell if the robot has displaced itself forward since a previous measurement  also if i used this sensor board  or similar  could i use it to determine the displacement   ,software imu deduced-reckoning artificial-intelligence
431,inverse kinematics in java,i m planning to write an inverse kinematics controlled   dof virtual robot for android  i did some research on packages avaliable and couldn t choose the right one which will satisfy my needs on this project  i ve seen a work with eigen in c    and used it  it was just fine  but since i m not so experienced in java  i wanted to ask before i start  if someone knows some appropiate packages for these operations  here is what i found so far  jama  vecmath  jmathtools  ejml  jampack i ask this because i really dont want to get stuck in the middle of my project  thanks in advance  ,inverse-kinematics programming-languages
433,visual odometry options ,what are the pros cons of the different visual odometry options    stereo camera optical flow slam other   criteria   how well it performs vs other odometry options sensors  lidar  radar  sensor fidelity computation accuracy precision drift native resilience and repeadability in sensor noise or vehicle speed ease of integrating with imu gps etc  in general  of course  because there are a lot of different ways the trade offs go when we get into specifics about applications and hardware   i m asking out of curiosity  not for designing anything in particular  ,mobile-robot localization computer-vision odometry
436,how do i model a robot ,the answers i received to the question on training a line following robot using reinforcement learning techniques  got me to think on how to train a robot  i believe there are essentially two ways    train the physical robot  model the robot and simulate the training  did i miss something   approach   is definitely the better approach  however  a priori knowledge of the motion  response   a certain pwm signal  stimulus  would cause when the robot is in a given state is required  the motion caused by a pwm signal may depend on the     current battery voltage      the mass of the robot and the     current velocity  did i miss something    how do i model such a robot  and how do i model it quick  if i change the battery or add a few boards and other peripherals and change the mass of the robot  i would have to remodel and retrain the robot  can i do this by providing some random stimulus pwms and measuring the response  added  my related question in dsp se update  a suggested edit to the title by ian worth mentioning    how do i model train a robot so that if its dynamics change  it does not need complete re training   i think this is a good question too but different from the one i am asking here  i am okay with re training for now  ,reinforcement-learning pwm
442,how can the dynamic effects of motor current on a digital compass be characterized and compensated for ,digital compasses  magnetometers  require a hard soft iron calibration in order to be accurate   this compensates for the magnetic disturbances caused by nearby metal objects    the robot s chassis    image from   however  digital compasses are also susceptible to the electric fields caused by the relatively high amount of current drawn by motors    in order to get an accurate compass reading  what is the best way to measure  and compensate for  the interference caused by changing motor current levels  ,mobile-robot sensors
445,how to obtain dense point clouds from stereo cameras ,i am trying to use a stereo camera for scene reconstruction  but i can usually only obtain sparse point clouds  i e  over half the image does not have any proper depth information    i realize that stereo processing algorithms rely on the presence of texture in the images and have a few parameters that can be tweaked to obtain better results  such as the disparity range or correlation window size  as much as i tune these parameters  though  i am never able to get results that are even remotely close to what can be obtained using an active sensor such as the kinect  the reason why i want that is because very often point clouds corresponding to adjacent regions don t have enough overlap for me to obtain a match  so reconstruction is severely impaired  my question to the computer vision experts out there is the following  what can i do to obtain denser point clouds in general  without arbitrarily modifying my office environment   ,slam computer-vision
446,how much torque do i need for a cnc machine ,i have a handful of     oz in stepper motors  mouser com   applied motion  ht      d   and i was curious if they would be big enough to run a  d printing cutting etching type  think reprap  of machine  i had in mind to attach them via  a simple gear to a screw type drive to run the tool head back and forth    maximum bed size would probably be          heaviest tool head would be something about half the weight of a dremel tool  hardest substances i would use it on would probably be hardwoods  with high speed cutter  and copper  for pcb etching    how do i figure the amount of torque needed to drive the head  and would the motors that i already have be big enough to do the job  ,stepper-motor reprap
453,how can one determine whether a lipo battery is going bad ,in our lab we use lipo batteries to power our quadrotors  lately we have been experiencing stability issues when using certain batteries  the batteries seem to charge and balance normally and our battery monitor indicates they are fine even when putting them under load  however when we attempt to fly the quadrotor with one of these batteries  manually or autonomously  it has a severe tendency to pitch and or roll  my guess is that the battery is not supplying sufficient power to all the motors which brings me to my question  is this behavior indicative of a lipo going bad  if so what is the best way to test a battery to confirm my suspicions  ,battery troubleshooting
461,in pid control  what do the poles and zeros represent ,whenever i read a text about control  e g  pid control  it often mentions  poles  and  zeros   what do they mean by that   what physical state does a pole or a zero describe  ,control pid
463,connecting a   pole motor to a motor driver ,we are trying to power this motor with this motor driver   using a     v    ah lithium ion polymer battery   we re in over our heads with this and really need the help   we checked with the company  e flite  and the motor is definitely dc    we re a bit confused as to the purpose of three wires  and how we should connect them to the motor   any help would be appreciated  ,brushless-motor driver
469,is there a working implementation of  navigation among movable obstacles  for a bi pedal robot ,i would like to have a better understanding of work in the field of  navigation among movable obstacles   i started off with michael stilman s thesis under james kuffner  but that has not yet sated my appetite  i am currently trying to simulate a scenario where debris  tables and table parts  from a disaster scenario block pathways  the debris forms part of a movable obstacle  the robot which will be used is a bipedal humanoid  the thesis describes an approach to define the search space of possible actions leading from the start point to the goal  however  it assumes a mobile robot which works via gliding   i think the state space definitions would change for a bi pedal robot  why is why i wonder what other work is being done in this field  perhaps the work of other research groups could give me clues as to how to design and perhaps reduce the search space for a bipedal humanoid robot  an implementation of navigation among movable obstacles would also aid me in understanding how to reduce the search space of possible actions  so does anyone know of a working implementation of navigation among movable obstacles   any supporting information about other professors or research groups working on similar problems would also be very useful  i hope this edit is sufficient for the problem description  ,navigation
472,humble beginnings,i want to learn robotics and build my first robot  i am looking for a well supported kit that is simple enough and can walk me through  the initial stages of my intellectual pursuit in robotics  i want to be able to do the basic things first and build a solid foundation in robotics  and then i want to be able to use the solid foundation  to gain confidence in my ability to build new and interesting robotic contraptions  in other words  i want to be able to follow the rules off the game to gain a solid foundation and then once i m comfortable with what i know  i want to break free of the rules and start making my own robots   i would like help with   things   i would like to begin my robotics learning with a good kit that can walk me through my initial stages  i expect that this initial stage might take quite a while  so  any recommendations for how i can start and or what kit i can buy  to get my feet wet  would be helpful  i would like suggestions for  other  actions i can take  that will set me on a path to gain confidence in my knowledge of robotics   a little bit about myself  i have a bs and ms in it  so i am not new to programming  i like to code in golang and haskell  i do not know if it is possible  but it would be awesome if i can write the software aspect of all my robotic projects in haskell  thanks ,kit
474,usb instead of rs   ,rs    is not popular as it used to be and is mainly replaced by usb  wikipedia   problems such as mentioned in this question doesn t help its reputation either  in a new system design therefore  one could think of using usb instead of serial port for communication  however  it still seems like rs    is the serial communication protocol port of choice  why is that  i understand changing old machinery that work with rs    is costly  but what prevents new system designers from using usb instead of rs     ,rs232 usb
478,how can i optimise control parameters for a stepper motor ,as an industrial roboticist i spent most of my time working with robots and machines which used brushless dc motors or linear motors  so i have lots of experience tuning pid parameters for those motors  now i m moving to doing hobby robotics using stepper motors  i m building my first reprap   i wonder what i need to do differently   obviously without encoder feedback i need to be much more conservative in requests to the motor  making sure that i always keep within the envelope of what is possible  but how do i find out whether my tuning is optimal  sub optimal or  worst case  marginally unstable  obviously for a given load  in my case the extruder head  i need to generate step pulse trains which cause a demanded acceleration and speed that the motor can cope with  without missing steps  my first thought is to do some test sequences  for instance   home motor precisely on it s home sensor  move  steps away from home slowly  move  steps away from home with a conservative move profile  move  steps with the test acceleration speed profile  move  steps back to the start of the test move with a conservative move profile  move  steps back to home with a conservative move profile  move  steps back to the home sensor slowly  verifying that the sensor is triggered at the correct position  repeat for a variety of     acceleration speed   load profiles   this should reliably detect missed steps in the test profile move  but it does seem like an awfully large space to test through however  so i wonder what techniques have been developed to optimise stepper motor control parameters  ,control stepper-motor tuning
479,particle filters  how to do resampling ,i understand the basic principle of a particle filter and tried to implement one  however  i got hung up on the resampling part   theoretically speaking  it is quite simple  from the old  and weighted  set of particles  draw a new set of particles with replacement  while doing so  favor those particles that have high weights  particles with high weights get drawn more often and particles with low weights less often  perhaps only once or not at all  after resampling  all weights get assigned the same weight  my first idea on how to implement this was essentially this   normalize the weights multiply each weight by the total number of particles round those scaled weights to the nearest integer  e g  with  in python   now i should know how often to draw each particle  but due to the roundoff errors  i end up having less particles than before the resampling step   the question  how do i  fill up  the missing particles in order to get to the same number of particles as before the resampling step  or  in case i am completely off track here  how do i resample correctly  ,localization particle-filter
483,strategies for managing power on electrical systems for mobile robots,what are some good strategies to follow while designing power supply for electrical systems on mobile robots  such robots typically comprise of systems with  microprocessor  microcontroller  dsp  etc units and boards along with immediate peripherals motor control  analog sensors proximity  audio  voltage  etc  digital sensors  vision  imu  and other exotica  radio comm circuits  wifi  bluetooth  zigbee  etc  other things more specific to the purpose of the robot being designed   are there unified approaches architectural rules to designing power systems which can manage clean power supply to all these various units which may be distributed across boards  without issues of interference  common ground  etc  furthermore  also including aspects of redundancy  failure management  and other such  power management monitoring  features  well explained examples of some such existing power systems on robots would make for excellent answers  ,mobile-robot electronics
488,matlab  system  function with ros,is it possible to use the matlab s  system  function to call ros commands  for example  using  system  rostopic pub  cmd vel geometry msgs twist        or system  rospack find ipc bridge  i m trying to send some commands to ros without using something like ipc bridge  ps  i know  however  that i need to use ipc bridge to subscribe to topics  ,mobile-robot software ros
494,more powerful alternatives to lego mindstorm nxt     ,i m interested to build robot from my imagination  and i was looking to purchase a robotic kit  i find the lego mindstorm nxt     really interesting for many reasons   you can plug whatever brick you want  and you can develop in the language you want  i am a developer  and the use of this kind of robotic would be interaction mostly  not moving  so the servo motors are useless to me  at least now   but regarding the spec of the nxt main component  i feel it s a bit low  proc  ram   rom   that made me wonder if any of you know something similar  where i can plug whatever i want on it  and most importantly  program the reaction   but with a more powerful hardware   price will also be a limitation   i like the nxt also because i can build what i want under     usd  i don t want to spend   k usd on my first kit  but i would appreciate buying a better piece of robotic if the price isn t too distant from the nxt s  do you have some alternatives to check out   thanks for your help       ,nxt
497,collaborative behavior  implementing a bucket brigade with robot arms,i was wondering whether something like this is possible  a block of ice say  needs to be transferred piece by piece from a source to a destination with the help of   robots standing in a straight line between the source and destination  the first robot picks up a piece of the block from the source and checks if the next robot in line is busy  if yes  it waits for it to complete its task and proceeds  otherwise it transfers the piece and goes back to collect another piece  please help me on implementing this if it is possible  as i am thinking to make it a project topic  to clear out the confusions  here s a smaller prototype of the project i m thinking  i have two cars  one wired  another wireless  the wired car is the master here  the wireless  the slave  through a remote  i send a command to the wired car to instead command the wireless car to move forward  the wired car will then check if the wireless slave is already executing some previously given command or no  and accordingly send the command  conversely  the master may send the command as soon as it receives it  it s on the slave now to complete the task it s doing  and then execute the command it just received  ,mobile-robot multi-agent
499,i don t understand integral part of pid controller,i dont understand integral part of pid controller  let s assume this pseudocode from wikipedia   integral is set to zero in the beginning  and then in the loop it s integrating the error over the time  when i make a  positive  change in setpoint  the error will become positive and integral will  eat  the values over the time  from the beginning   but what i dont understand is  when error stabilizes back to zero  the integral part will still have some value  integrated errors over time  and will still contribute to the output value of controller  but it should not  because if error is zero  output of pid should be zero as well  right  can somebody explain me that please  ,control pid
502,is there a place for posting  look at what i did  videos ,robots are somewhat videogenic  and the old saying  show me  don t tell me  is especially applicable  but of course  a video is not a question  so it doesn t fit the stack exchange format   maybe video links would be more suitable in a codeproject post   it just seems like this board hits the right cross section of people  whose projects i would be interested in seeing  ,untagged
504,choosing motors for   wheel drive robot,i am making a   wheel drive robot  suppose i know that my robot is going to weight x kg when finished and i know the diameter of the wheels y  geared motors will be connected directly to the wheels   i can choose from several geared motors and i know the peak torque of each motor and the idling speed  how can i calculate the load that a specific motor can take  i e  will a motor with a given torque be able to move my robot without being too overloaded  what rpm will the motor have when it has load  ,motor
511,where can i find a tutorial or sample code for the juniper wifi arduino shield ,i recently got an arduino wifi shield known as  juniper   i believe it was by cutedigi   i ve tried to find code examples  but when i saw code  it was un commented and very little explained  i could really use a tutorial or some sample code with a good explanation  can anyone help me find a place to start  i found a piece of code here   and i just want to connect to a network  maybe send some get requests  or open a socket  edit  after poking around for a while  i found documentation  but i still can t get it to work  my code   i can t seem to get any input at all from the wifi shield  ,arduino electronics wifi
512,how can i start learning robotics ,for someone interested in robotics but do not know the abc of robotics or mechanical electronic engineering  what s a good roadmap for becoming an amateur roboticist   i m studying theoretical physics so that i have no problems on the physics math   if the question is too broad and doesn t meet the criteria of posting on this site   please inform me of any helpful advice study material etc  before the question get closed   thanks in advance  ,books
519,ekf slam update step  kalman gain becomes singular,i m using an ekf for slam and i m having some problem with the update step   i m getting a warning that k is singular  rcond evaluates to near eps or nan  i think i ve traced the problem to the inversion of z   is there a way to calculate the kalman gain without inverting the last term   i m not      positive this is the cause of the problem  so i ve also put my entire code here    the main entry point is slam d   edits  project x r   x lmk   should have been project x r   x lmk idx   and is now corrected above    k goes singular after a little while  but not immediately   i think it s around    seconds or so   i ll try the changes  josh suggested when i get home tonight and post the results  update    my simulation first observes   landmarks  so k is  x     p rl rl    e rl     inv  z   results in a  x  matrix  so it can t be added to x in the next line    k becomes singular after      seconds  with measurements at   hz      steps    following the advice here     i tried k    p    rl    e rl   z which results in     steps before a warning about k being singular is produced    this tells me the problem isn t with matrix inversion  but it s somewhere else that s causing the problem      update   my main loop is  with a robot object to store x p and landmark pointers   for t     sample time max time     p   robot p      x   robot x      lmks   robot lmks      mapspace   robot mapspace       u   robot control t       m   robot measure t          added to show eigenvalues at each step      val  vec    eig p       disp            disp val           motion prediction      x  p    predict x  p  u  dt            correction     lids   intersect m       lmks           find all observed landmarks     lids new   setdiff m       lmks            for lid   lids           expectation         idx   find  lmks         lid              lmk   lmks      idx           mid   m         lid          yi   m      mid             x  p    expectation x  p  lmk  yi       end   end correction          new landmarks      for id     length lids new        if id              lid   lids new id           lmk   find lmks       false              s   find mapspace              if  isempty s              mapspace s                   lmks   lmk     lid  s                yi   m     m         lid                 x s   l r  l y    backproject x r   yi                p s      l r   p r                 p   s     p s      eye                  p s s    l r   p r r    l r           end     end    end new landmarks          save state     robot save state x  p  mapspace  lmks      end   end  at the end of this loop  i save x and p back to the robot  so i believe i m propagating the covariance through each iteration    more edits the  hopefully  correct eigenvalues are now here   there are a number of eigenvalues that are negative   although their magnitude is never very large        at most  it happens on the iteration immediately after the first landmark is observed and added to the map  in the  new landmarks  section of the main loop   ,slam kalman-filter
520,is it practical to  d print a refractive lens ,a lot of awesome optics projects like hacking cameras and projectors become possible with cad lens modelling software   if we can also easily prototype the lenses we design  what are some materials and additive or subtractive  d fabrication strategies that can make a clear lens with strong refraction and the ability to be polished    here is a helpful list of    different lens design   simulation programs  ,3d-printing manufacturing
521,computing the jacobian matrix for inverse kinematics,when computing the jacobian matrix for solving an inverse kinematic analytically i read from many places that i could use this formula to create each of the columns of a joint in the jacobian matrix   such that  is the rotation axis in world space   is the pivot point in world space  and  is the position of end effector in world space  however  i don t understand how this can work when the joints have more than one dofs  take the following as example   the  are the rotational dof  the  is the end effector  the  is the goal of the end effector  the    and  are the joints  first  if i were to compute the jacobian matrix based on the formula above for the diagram  i will get something like this  j  begin bmatrix           times  vec   e       x              times   vec   e     vec   p              x              times   vec   e     vec   p              x               times  vec   e       y              times   vec   e     vec   p              y              times   vec   e     vec   p              y               times  vec   e       z              times   vec   e     vec   p              z              times   vec   e     vec   p              z                                            end bmatrix   this is assumed that all the rotation axes are  and all of them only have one rotational dof  so  i believe each column is for one dof  in this case  the   now  here s the problem  what if all the joints have full   dofs  say now  for every joint  i have rotational dofs in all axes     and   and also translational dofs in all axes     and   to make my question clearer  suppose if i were to  forcefully  apply the formula above to all the dofs of all the joints  then i probably will get a jacobian matrix like this    click for full size  but this is incredibly weird because all the   columns of the dof for every joint is repeating the same thing  how can i use the same formula to build the jacobian matrix with all the dofs  how would the jacobian matrix look like in this case  ,inverse-kinematics kinematics
524,compatable esc s with brushless   phase motors,am trying to find the right esc for the following two motors   can t figure out which of the esc s listed on the site would be best  are there alternative  cheaper or better   options  ,motor brushless-motor
530,rainbowduino       arduino ide fails to upload,ok  not really robotics  but has anyone been able to upload to a rainboduino v    using the arduino ide  i can t seem to figure it out  and there is virutally no documentation online  i followed this blog entry  but got no connection to the board   if anyone can give me some suggestions  i would appreciate it   ,software arduino programming-languages
531,using an imu to build an ins,what s needed to utilize an imu such as the arduimu  v  to be used in an ins  is there any other hardware needed   ,arduino slam imu deduced-reckoning
533,what was the earliest concept of a robot ,i m a highschool student studying electronics and for an assessment task on the history of electronics i have decided to focus on the history of robotics  i want to begin with the earliest possible concept of a robot and progress through major developments in robotics to the current day  where should i begin my research  ,electronics research
535,how computationally powerful is an arduino uno board ,what can an arduino board such as the uno really do  of course simple things like controlling a couple servos is very easy for it  however  i don t think an uno board would be able to preform real time  d slam from point cloud data gathered from a kinect sensor on a mobile robot  right  if the robot had any speed at all the arduino wouldn t be able to keep up  correct  could it do  d slam while moving and be able to keep up  what about taking      of the points from the kinect sensor and processing only those  basically  what are some examples of the resource limitations of such an arduino board  ,arduino slam kinect
541,wheels vs continuous tracks  tank treads ,i m building a small robot using some cheap vex robotics tank treads  however  my choice of picking tank treads is almost purely based on the fact that they seem like more fun than wheels  i don t actually know if they really have much of an advantage or disadvantage when compared to wheels  what are the pros and cons of both wheels and continuous tracks  ,mobile-robot design wheeled-robot tracks
543,why are quadcopters more common in robotics than other configurations ,i ve noticed that almost all research being done with helicopter robots is done using quadcopters  four propellers   why is there so little work done using tricopters in comparison  or a different number of propellers  what about four propellers has made quadcopters the most popular choice  ,quadcopter design uav
550,how to determine heading without compass,lets say i drop a robot into a featureless environment and any magnetic field based sensors  magnetometer compass  are not allowed  what methods are there of determining where north is  tracking the sun stars is an option but not reliable enough when the weather is considered  can you pick up the rotation of the earth using gyros  are there any more clever solutions  ,localization
554,quadcopter lipo battery weight capacity trade off,i m trying to find where additional battery capacity becomes worthless in relation to the added weight in terms of a quadcopter  currently with a      mah battery      v  i can get between    minutes and       flight time out of it  my question  then  is this   within the quads lifting capability of course  is there any way to find out where the added weight of a larger battery  or more batteries  cancels out any flight time improvement  obviously it s not going to be as long as two separate flights  landing and swapping batteries  i m just trying to maximize my continuous  in air  time  i m trying to figure out where the line is  and if i ve already crossed it  with tacking bigger batteries onto the quad and seeing diminishing returns  thanks   again  for now presume that the quad is strong enough to lift whatever you throw at it  with one     mah        grams  my max throttle is about      ,battery quadcopter power
556,is an accelerometer sufficient to detect displacement  or do i need an ins ,do i need a complex system  of gyros  accelerometers etc   to detect if a robot has moved forward or can i simply use an accelerometer   i m building a robot that learns to walk and i need to detect displacement for machine learning  can i use an accelerometer or will i need a complicated expensive internal navigation system  ,slam machine-learning deduced-reckoning gyroscope accelerometer
558,why do mars rovers designers prefer wheels over tracks ,typically mars rovers use wheels and not tracks  i guess spirit would have better chances getting out of that soft soil should it have tracks  in general  mars surface structure is not known in advance  so it seems wiser to be prepaired for difficult terrain and so use tracks  why do mars rovers typically use wheels and not tracks  ,mobile-robot design
565,kinect   libfreenect vs openni sensorkinect,what are the pros and cons of each  which is better maintained  which allows for more functionality  which utilizes the hardware more efficiently  etc  ,software sensors kinect
566,decision trees for solving  d inverse kinematics ,while experimenting with the opencv machine learning library  i tried to make an example to learn the inverse kinematics of a  d    link arm using decision trees  the forward kinematics code looks like this   i generate a random set of       xy    alpha  and  xy    beta  pairs  and then use that data to train two decision tree models in opencv  one for alpha  one for beta   then i use the models to predict joint angles for a given xy position   it seems like it sometimes gets the right answer  but is wildly inconsistent  i understand that inverse kinematic problems like this have multiple solutions  but some of the answers i get back are just wrong  is this a reasonable thing to try to do  or will it never work  are there other learning algorithms that would be better suited to this kind of problem than decision trees  ,inverse-kinematics machine-learning
568,is it possible to run a neural network on a microcontroller,could you implement a simple neural network on a microprocessor such as the arduino uno to be used in machine learning  ,microcontroller machine-learning
578,which programming language should i use with the nxt ,we have an optional course in our high school which is about robotics  we re using the lego mindstorms nxt and program it with the original mindstorms software  however  we want to advance and use a major programming language  we have tried nxc and lejos  plus  i tried out the microsoft robotics development studio  but with all these different possibilities we are a little bit overwhelmed  because of that  now it becomes interesting   i want to ask  what technology is the best for nxt and especially  what is easy to use  i don t want to need    steps just to compile a program and get it running on the nxt  also  it would be nice  if it s an extend able language  like using c   but are there some better or easier possibilities  ,programming-languages nxt
583,inverse kinematics with joint contraints,i have a manipulator having   revolute joints with some movement limitations  so  when i apply inverse kinematics  i m getting results which are out of limits  please provide me an algorithm that implements inverse kinematics considering joint limitations  ,inverse-kinematics
585,king robota  does he speak for himself ,i want to know if its currently possible for a robot to speak by it self as  does  or is just someone speaking on his behalf  youtube video ,control software
599,who coined  or popularized  the term  slam  ,according to wikipedia s article on slam  the original idea came from randal smith and peter cheeseman  on the estimation and representation of spatial uncertainty  pdf   in       and was refined by hugh f  durrant whyte and j j  leonard  simultaneous map building and localization for an autonomous mobile robot  in        however  neither paper uses the term  slam    where  and when  did that term come from   was there a particular author or whitepaper that popularized it  ,slam
602,vex motors and tank treads drained   volt battery more quickly than expected,i ve got a couple vex     motors hooked up to an arduino duemilanove  these motors run a some vex tank treads  i powered the whole setup with an off brand   volt battery  everything seems to run great  except that it is only able to run for about    seconds worth of motor movement  then the battery quickly isn t able to pump out the energy needed to move the treads and the whole thing quickly slows to being unusable  what s my problem here  the tank treads seem loose enough that i don t think they re so restricting the motor has to pump out too much energy to move them  there s nothing else being powered except the arduino and the motors  is it because this enercell   volt  alkaline  is just a terrible battery choice  should i only expect that long of battery life for this robot on a   volt  or is there something else i m missing  thank you much  ,battery tracks troubleshooting
603,how to get two continuous tracks  tank treads  to move at the same rate ,i ve got a couple vex     motors hooked up to an arduino duemilanove  these motors run a some vex tank treads  the two motors are run as servos on the arduino using the servo library  the problem i m having is that the two tracks don t turn at the same speed when sent the same servo angle  this is clearly due to the fact that the continuous tracks have so many moving parts that having identical friction forces on each track is hard to get  how do i get them to move the same speed  should they be moving the same speed given the same servo angle regardless of the friction and the vex     motors just aren t strong enough  meaning i should use the vex     or some other more powerful motor   is it best to just doing trial and error long enough to figure out which servo angle results in equal speeds on each  should i tinker with the tracks until they have nearly identical frictions  thank you much  ,mobile-robot motor tracks
609,including a raspberrypi within a robot    does this allow for a  universal api  ,i know this is a broad statement  but when you ve got support for both tcp as well as a full fledged computer on board  to integrate run an arduino   does this essentially allow for anything that would run on a linux box  raspberrypi  to run and operate your robot  i know clock speed as well as the dependency libraries for a given code base  on the pi  would add some complexity here  but what are some of the big issues that i m overlooking in such a vertically integrated control system  including a raspberrypi within a robot    does this allow for a  universal api   ,software arduino raspberry-pi
613,what is stall current and free current of motors ,what are the stall and free currents of an electric motor  for example  this vex motor lists its stall and free currents at the bottom of the page  i think i understand the general idea  but a detailed description would be helpful  ,motor current
616,arduino vin current limit,i ve found that arduino  duemilanove  has a current limit of   ma per pin  does this include the vin pin  or does the vin pin have some sort of work around in place on the board to allow for higher currents  if this is the limit on the vin  is there good way of using still using the power supply jack on the board and allowing other sources to draw on that supply without it needing to pass through the chip first  thank you much  edit  for the second part  what should i do if i wanted to get up to something like   amps  ,arduino current
619,programming an esc to have reverse mode,how do you program an esc to have a reverse mode  we re looking to control an esc from a servo board  for a robotics project   assuming that the input will be between   and      we re looking for     as off      as fully forward and   as full reverse  so how do we achieve that  ,control motor
623,when taking vcc power from an arduino to a   v regulator  then to a  v  do i need two sets of capacitors ,i m building an open source bio research hardware  ask me how you can help   and i ve got this guy here   my big questions are   can i get away with all the ground being common   i ve got a   v and  v needing to be grounded  do i need two sets of capacitors  there are   wired up to the   v regulator and   wired to the  v regulator   these are shown in blue   i ve generally denoted connections which go under the shield as orange  and those above as green  if anyone happens to see something which might backfire  feel free to point it out  as this is also my first time making anything quite like this   i ve verified the regulator positions and they are correct  this is a proto shield for an arduino r  uno   a larger version of the image can be seen here   ,arduino electronics
627,formatting an sd card for panda board es,i have a panda board es  i am not able to get it to boot  i sent it back to svtronics to get it checked and they said that the board is ok  i am the one who is not able to configure it properly  after doing a little research and following all the directions on the panda board and ubuntu website  i am still not able to get the board to boot  i think the problem is how i am formatting the sd card  i am using disk utility for mac to format the sd card to  msdos fat   partition  i would like to know how to format an  sd card  on a macintosh to install ubuntu on it for panda board es  ,electronics operating-systems
628,what algorithm should i implement to program a room cleaning robot ,for this question assume that the following things are unknown   the size and shape of the room the location of the robot the presence of any obstacles  also assume that the following things are constant   the size and shape of the room the number  shape and location of all  if any  obstacles  and assume that the robot has the following properties   it can only move forward in increments of absolute units and turn in degrees  also the operation that moves will return true if it succeeded or false if it failed to move due to an obstruction a reasonably unlimited source of power  let s say it is a solar powered robot placed on a space station that faces the sun at all times with no ceiling  every movement and rotation is carried out with absolute precision every time  don t worry about unreliable data   finally please consider the following properties of the robot s environment   being on a ceiling less space station the room is a safe but frustratingly close distance to passing comets  so the dust  and ice  are constantly littering the environment   i was asked a much simpler version of this question  room is a rectangle and there are no obstacles  how would you move over it guaranteeing you could over every part at least once  and after i started wondering how you would approach this if you couldn t guarantee the shape or the presence of obstacles  i ve started looking at this with dijkstra s algorithm  but i m fascinated to hear how others approach this  or if there is a well accepted answer to this   how does roomba do it   ,mobile-robot artificial-intelligence algorithm coverage theory
634,how to charge a lifepo  battery ,from what i ve seen  lifepo  batteries seem like one of the top battery choices for robotics applications  however  i ve seen people mentioning that you can t use a charger for a different battery to charge these  but i haven t seen why  if i were to build my own setup to charge lifepo  batteries what would it specifically need to do  what kind of voltages or current rates does it need to supply to charge these  more specifically  i was think about setting up a solar charger for these batteries  is there any immediate reason why this is a bad solution  such as  the battery needs to charge with a current above some amount for it to work properly  if you re ambitious enough to provide an example along with your explanation  i m specifically thinking of having   of these batteries with   pairs of   in series in parallel   ,battery
636,will turning an nxt motor by hand damage it ,many people claim that turning an nxt motor by hand will damage it  is this true  does it matter if the motor is idle or set on break  are there any facts to confirm or refute this argument  i know that some projects  e g  etch a sketch  use the built in rotation sensor to measure how much the motor has turned  does this indicate that hand turning nxt motors is okay  do they need to be put in a special  rotation sensor  mode  ,motor nxt mindstorms
637,protecting electronics against voltage current extremes and bad polarity,i have built a robot from a wheelchair that has worked very well thus far  it is now time for me to take the next step  i need to implement a permanent power circuit with proper protection   the lowest level of protection i can think of is a fuse  but i would like to take a step further  current voltage direction switches high low voltages   if some one could give some insight on this project of mine any info will be greatly appreciated   moderator comment   please see how do we address questions about related subject areas  before answering   this question is close to the boundary  but is on topic here  ,mobile-robot wheeled-robot protection circuit
641,good book on mechanisms,i am working with students   th     th grade  on robotics and wanted to get a good book which covers basic mechanisms   does anyone have any recommendations   searching google or amazon yields many results  however  i thought the community might have a standard book to use    ,design mechanism
642,mma     accelerometer always displays same values,i recently purchased a   axis accelerometer from amazon  and can t seem to find how it works  i ve been looking for quite a while now  and haven t found any real clues  the x  y  and z values always seem to return the same values  they change when i tilt or move the accelerometer  but revert to about     for each reading  i am currently using this device with the arduino uno  using the following code    also  how would i go about converting this to tilt  ,arduino sensors accelerometer
646,mems accelerometer calibration,i am trying to calibrate a mems accelerometer  i was able to calibrate it for the current axis which is parallel to gravity and shows correctly   g  but the other two axes which should be     g are showing       g instead   so  e g   when the accelerometer s x axis is parallel to gravity  it should show   g   g   g  and not   g      g       g  like now  how could i eliminate those values  e g  further calibrate accelerometer   edit  the acelerometer s datasheet says nothing about calibrating except that the ic interface is factory calibrated for sensitivity  so  and zero g level  off   page      ,design electronics accelerometer calibration
649,does rrt  guarantee asymptotic optimality for a minimum clearance cost metric ,the optimal sampling based motion planning algorithm   described in this paper  has been shown to yield collision free paths which converge to the optimal path as planning time increases  however  as far as i can see  the optimality proofs and experiments have assumed that the path cost metric is euclidean distance in configuration space  can  also yield optimality properties for other path quality metrics  such as maximizing minimum clearance from obstacles throughout the path  to define minimum clearance  for simplicity  we can consider a point robot moving about in euclidean space  for any configuration  that is in the collision free configuration space  define a function  which returns the distance between the robot and the nearest c obstacle  for a path   the minimum clearance  is the minimum value of  for all   in optimal motion planning  one might wish to maximize minimum clearance from obstacles along a path  this would mean defining some cost metric  such that  increases as the minimum clearance decreases  one simple function would be   in the first paper introducing   several assumptions are made about the path cost metric so that the proofs hold  one of the assumptions concerned additivity of the cost metric  which doesn t hold for the above minimum clearance metric  however  in the more recent journal article describing the algorithm  several of the prior assumptions weren t listed  and it seemed that the minimum clearance cost metric might also be optimized by the algorithm  does anyone know if the proofs for the optimality of  can hold for a minimum clearance cost metric  perhaps not the one i gave above  but another which has the same minimum   or if experiments have been performed to support the algorithm s usefulness for such a metric  ,motion-planning algorithm rrt theory
650,can i make a simple bluetooth receiver ,i can control a relay from an android smartphone using arduino and bluetooth as seen here  however  it seems too costly to be using arduino and a bluetooth receiver for driving a switch  as long as bluetooth is a radio frequency  is it possible to make a simple bluetooth receiver which can output   or   to drive a relay  if yes  how tough that is going to be  the main factor here is the cost  which should be      ,sensors circuit
653,what are the notable limitations on using java with mindstorms nxt     ,i m a long time java developer who is starting to learn on the lego mindstorms nxt      are there any limitations to using the java api  which language is the most robust on the platform  i found a post  which programming language should i use with the nxt  which mentions many of the alternatives  the answer is helpful  but doesn t mention the different languages  limitations  ,nxt programming-languages mindstorms
654,what is the difference between kinect for windows and kinect for xbox ,as i see there is a huge price gap between the two      at amazon   my intention is to use one of those from ubuntu linux to perform depth sensing  navigation etc  and naturally i prefer the cheaper   however i am not sure if i miss some important point while betting on the kinect for xbox version   as it seems the windows version is overpriced because it has the license for development  here it is stated that there are internal differences but without exact details  the minimum sensing distance seems to be better for windows version    could anyone give a comparison chart  it would be good to know about  connectivity  usb  special connector        hardware differences  are they the same or do they really differ in weight  energy consumption  speed  sensing range       driver  could i use xbox version under ubuntu  api usage  could i develop on xbox version  could i use the same similar api on both  is the api for xbox mature enough  license  is it against the license of xbox version to develop for home hobby educational use   thanks  ,sensors kinect
656,lightweight  commercially available robotic arms,i was wondering what options are there in terms of lightweight      lbs  robotic arms  i see robai cyton gamma      and crustcrawler ax   look like interesting options  what lightweight arms do people use like   ,mobile-robot arm
667,raspberry pi operating system for robotics,is there an operating system for the raspberry pi that is specifically made for running robotics applications  or an operating system whose purpose is to optimized just to run a few specific programs  i ve been working with an arduino for a while now  as far as efficiency goes  it makes sense to me to just upload a specific set of commands and have the hardware only need to handle that  and not have to worry about running a full fledged operating system  is something like this possible to do on a raspberry pi  ,raspberry-pi operating-systems
671,check if task exists in not exactly c,is there a way to check if a task  function or variable exists in not exactly c  i know that in php you can use  to check if a variable exists and function exists   to do the same for a function  but is there a way to do that in nxc  i am specifically interested in checking whether a task exists or it is alive  ,nxt programming-languages mindstorms not-exactly-c
672,pid line follow with three sensors in not exactly c,i m currently working on a line following robot which uses three sensors to follow a black line  the sensors are pretty much in line and right next to each other  right now  i m doing a simple line follow  if on the line go forward  otherwise turn left or right to regain the line  this means that the robot is wiggling along the line most of the time  i m looking for a better way for this robot to follow the line using three sensors  the program i m writing is in not exactly c code  i m trying to get the robot to utilize the power of pid control  but i m not sure how one would go about writing a three sensor pid line follower program in nxc  ,nxt programming-languages mindstorms algorithm not-exactly-c
679,why are mars rovers so slow ,mars rovers are typically very slow  curiosity  for example  has average speed of about    meters per hour  why is it designed so slow  is it because of some specific power restrictions or for other reasons  what is the top reason why it is so slow  ,mobile-robot design
684,why does our lm     circuit suddenly cut down the power ,i have an lm     circuit plus an adjuster to adjust the output voltage  for controlling motor speed in a line follower robot  the circuit works great when adjusted to give out low voltages  but when i adjust it to higher voltages for my motors to go faster  it works great for     minutes  then suddenly cuts down the power and motors start to go extremely slow  even when i decrease or increase the output voltage  it won t respond until i turn off the power and turn it back on again  there is something mentioned in the lm     datasheet that if we overload the ic it will cut down the power until the load comes lower  so i think it might be a problem with that  since this problem has already caused us to lose the competitions with    teams  i would like to solve it for our next competition  so why does our lm     circuit suddenly reduce the power  ,motor electronics power
687,robotics with kinect,i want to learn robotics and really interested in making a robot based on kinect sensor  i see so many projects like this one    and just wondering how it works on top level  i downloaded kinect sdk and did some basic tutorials  but i just don t think that microsoft sdk is the library to use for real robotics projects  any suggestions where to start and what library to use  any good books in particular or online resources  any help is appreciated  thank you  ,kinect
689,cable routing in theta  x  y motion control system  better inside or outside ,i m building a motion control platform with   dof    axis of rotation  theta  and   cartesian  x y   in most applications  like wrist actuation  you have an x y stage with a rotating servo as the stage s payload  this configuration works well since little of the power and data wiring needs to transit to the non linear moving portion of the platform   for my inverted application  the stackup is reversed  the rotating axis comes first  from the mounting plane  with the stage connected as the rotating platform s payload  now nearly all of the wiring  power  command  sensor  and otherwise  must be routed to the non linearly moving section  i can see two broad approaches    the inside track  i route the cabling through the center of rotation  the outside track  i route the cabling around outside the outer diameter of the rotating platform   mathematically  i can see that     results in minimum cable length  but maximum torsional loading  while     results in maximum cable length  but minimum torsional loading on the wires  having limited experience with cable routing  and the associated carriers  strategies  and products  in non linear applications  my question is       which approach is better in practice  cost isn t really the issue here  i m more interested in reliability  ease of construction  availability of commercial components  says something about the popularity of the technique   etc    e g  the generic concepts behind why you pick one over the other      of course  if you have some part numbers for me i wouldn t be upset     i know i m not supposed ask that here     ,control wiring routing motion
690,noise in motion and measurement models,when using an ekf for slam  i often see the motion and measurement models being described as having some noise term    this makes sense to me if you re doing a simulation  where you need to add noise to a simulated measurement to make it stochastic   but what about when using real robot data   is the noise already in the measurement and thus does not need to be added  or does the noise matrix mean something else  for example  in probabilistic robotics  on page       there is a measurement model    where  is a noise covariance   does  need to be calculated when working with real data  ,slam kalman-filter
693,can i use ros with a roomba ,is there anything different between a irobot roomba and the create   i want go start building my own turtlebot and playing with ros but with the cost of all the parts i m going to have to do it piece by piece   it s pretty easy to find cheap used roombas    ,ros roomba irobot-create
696,are there working instances of kilobot projects ,the interesting kilobot project from harvard for investigating multi robot behavior with masses of small dumb robots has been made open hardware for a year now   however i cannot find so much activity about robot creation and movies about results  is it too hard to create the robots  the programmer  the charger or isn t the project interesting enough  ,multi-agent
697,standalone  or capable of being  robotics simulator,i m a software engineer who volunteers with a non profit that introduces young girls to technology  we have recently been talking about methods of introducing these children to the world of robotics  and i am curious what types of low cost options we have  one very appealing idea would be to have an online simulator  or  more preferable  an off line standalone simulator that we can build and program simple robots with  perhaps nothing more than dragging components together  and then programming the interactions between those components  what solution s  exist that i might be able to make use of in our outreach  ,software simulator children
704,wifly shield not connecting,i recently asked a question about the juniper wifi shield  and am now working with wifly from spark fun  i ve been using an updated version of their experimental library  and have been attempting to set up a webserver  unfortunately  when i attempt to connect through a web browser  i get an error saying that the page sent no data  here s my code   i am using arduino uno  and the serial monitor looks like this  connection succesful               receving client input     is there anything obviously wrong with my code  edit  i now have a new shield  but i m still working with the same problem  is it a malfunction in the hardware  i just can t figure this out  ,arduino software wifi c
709,why are servo motors so noisy ,i was working on a project to make a bedside night light out of a stuffed butterfly or bird  i was making a mechanism to make the wings flap with a servo motor and some small gears  the servo motor was very loud as it moved  and this was whether or not the servo was moving large amounts  small amounts  fast or slow   i ve worked with small servos before and realized they usually are pretty noisy machines  but i can t really explain why  why are small servo motors noisy when they move  is it backlash in the internal gearing  ,rcservo
712,quadruped learning simulator,i m currently building a robot with four legs  quadruped     dof  degrees of freedom  and its been suggested here that i use a simulator to do the learning on a computer and then upload the algorithms to the robot  i m using an arduino uno for the robot and what software could i use to simulate the learning and then be able to upload to the arduino board  ,mobile-robot arduino microcontroller machine-learning simulator
716,c   robust model fitting library,often when i need to perform model fitting i find myself looking for a decent c   library to do this  there is the ransac implementation in mrpt  but i was wondering if there are alternatives available  to give an example for the type of problems i would like to solve  for a set  of  approx       d point pairs  i would like to find the isometry transform   which maps the points onto each other so that   i would like to get the largest subset of  for a given   alternatively i guess i could have the subset size fixed and ask for the lowest   ,c++ ransac
718,how can computer vision distinguish one object being contained by another vs being on top of it ,how do we know that an object is contained inside another object or is just lying on top of it   lets take an example of a cup plate spoon  the cup is lying on top of the plate  but the spoon is inside the cup  how do we distinguish between the   situations  what are the criteria to decide whether a is contained inside b or just lying above b  i am trying to solve it using kinect  ,kinect computer-vision algorithm
725,least squares map joining,there is a lot of background here  scroll to the bottom for the question i am trying out the map joining algorithm described in how far is slam from a linear least squares problem  specifically  formula        the code i have written seems to always take the values of the second map for landmark positions   my question is  am i understanding the text correctly or am i making some sort of error  i ll try to explain the formulas as i understand them and show how my code implements that   i m trying to do the simple case of joining just two local maps   from the paper      says joining two local maps is finding the a state vector  that minimizes    sum  j     k   hat x j l    h  j rel  x  join rel    t p j l        hat x j l    h  j rel  x  join rel     expanded for two local maps  and  i have     hat x   l    h  j rel  x  join rel    t p   l        hat x   l    h  j rel  x  join rel        hat x   l    h  j rel  x  join rel    t p   l        hat x   l    h  j rel  x  join rel     as i understand it  a submap can be viewed as an integrated observation for a global map  so  is noise associated with the submap  as opposed to being the process noise in the ekf i used to make the submap  which may or may not be different    the vector  is the pose from the first map  the pose from the second map and the union of the landmarks in both maps  the function  is    begin bmatrix  x  r  je    r   j   e                       phi  r  je    r   j   e                      r  phi  r   j   e    r  m  j  e                             x  r  m  j  e    f  j                               x  r  m  j  e    r   j   e                                r  phi  r   j   e    r  m  jl e                             x  r  m  jl e    f  jl                              x  r  m  jl e    r   j   e                               x  f  j l       r  j  e                                                                 x  f  jn    r  j  e    end bmatrix   i m not convinced that my assessment below is correct  the first two elements are the robot s pose in the reference frame of the previous map   for example  for map    the pose will be in initial frame at   for map    it will be in the frame of map    the next group of elements are those common to map   and map    which are transformed into map   s reference frame  the final rows are the features unique to map    in the frame of the first map  my matlab implementation is as follows   i am using the optimization toolbox to find the minimum of the fitness function described above   the fitness function itself is pretty straightforward i think   the function h returns the vector h described above  the result is  when i run join maps on the two vectors map                              robot x  y  angle                                  landmark x  y  id map                                                                 note the slightly different x y   g fv output exitflag    join maps map    map     the output is  warning  gradient must be provided for trust region algorithm    using line search algorithm instead     in fminunc at       in join maps at    local minimum found   optimization completed because the size of the gradient is less than the default value of the function tolerance    stopping criteria details    local minimum possible   fminunc stopped because it cannot decrease the objective function along the current search direction    stopping criteria details   g                                                                                                                            fv              e      output         iterations          funccount             stepsize        e      firstorderopt        e          algorithm   medium scale  quasi newton line search          message    x    char    exitflag         the question  my program gives map   is the minimum of the map joining function   it seems like the minimum should be somewhere between map   and map     i m pretty sure the problem is with the matrix h   what am i doing wrong  ,slam
726,guiding a quadrotor towards a target,i am working on a quadrotor   i know its position      where i would like to go    target position   and from that i calculate a vector     a unit vector that will take me to my target   since a quadrotor can move in any direction without rotation  what i have tried to do is   rotate  by the robots yaw angle split it into its  components  pass them to the robot as roll and pitch angles     the problem is that if the yaw is       then this works  but if the yaw is near     or     it fails and steers to wrong directions  my question is am i missing something obvious here  ,quadcopter uav navigation
730,good method for building a pan and tilt controller ,have you ever seen one those video games that has headset goggles you stand in and look around the virtual scene with  i m building one of those  and i m trying to design a simple controller  i need the output of the controller to emulate a mouse input  so if you look to the left  it s as if you were moving the mouse to the left  supposing i use optical encoders  the pan and tilt will need to be in separate locations  a couple of inches apart   it seems that many mouse hacks online have the components very close together  do you think it s possible to have one of the encoders some distance away from the controller chip  for oem purposes  is there a good mouse controller chip that will output usb protocol mouse movements that i could buy in bulk  many thanks for any suggestions  cheers ,microcontroller
734,comparing maps to groundtruth,when you ve created a map with a slam implementation and you have some groundtruth data  what is the best way to determine the accuracy of that map    my first thought is to use the euclidean distance between the map and groundtruth  is there some other measure that would be better   i m wondering if it s also possible to take into account the covariance of the map estimate in this comparison   ,slam mapping
736,inter processor communication for robotic arm,i m building a hobby   dof robotic arm and am wondering what the best way is to communicate between the processors      avrs     inches max separation   i d like to have the control loop run on the computer  which sends commands to the microprocessors via an atmega  u  usb to     bridge  some ideas i m considering   rs     pros  all processors on same wire  differential signal more robust cons  requires additional chips  need to write  or find   protocol to prevent processors from transmitting at the same time  uart loop  ie  tx of one processor is connected to rx of next   pros  simple firmware  processors have uart built in cons  last connection has to travel length of robot  each processor has to spend cycles retransmitting messages  canbus  i know very little about this   my main considerations are hardware and firmware complexity  performance  and price  i can t buy an expensive out of box system   ,microcontroller electronics arm
738,what are methods for dealing with compass lag  rate dependent hysteresis  ,i ve got a tread driven robot  with low precision wheel encoders for tracking distance and an electronic compass for determining heading   the compass has significant      second  lag when the robot turns quickly  e g  after reaching a waypoint   pivoting in place to point to its new heading    what are ways for dealing with the lag   i would think one could take a lot of measurements and model the compass response   however  this seems problematic since it s rate dependent and i don t know the instantaneous rate  as a simple but slow approach  i have the robot turn until it s very roughly pointed in the right direction  then make very small incremental turns with brief measurement pauses until it s pointed the right way   are there other ways of dealing with this   ,sensors compass
741,how do you determine ekf process noise for pre recorded data sets ,i ve seen this question  which asks about determining the process noise for an ekf   i don t see anything there about pre recorded data sets    my thought on how to determine the noise parameters  assuming ground truth is available  would be to run the data several times with the ekf and minimize the mean square error  while varying the noise parameters  is this an acceptable way to determine noise for a pre recorded data set   are there better  or just other  ways from determining the optimal noise values based just on the data set  ,noise ekf
748,how many amps do i want my switching bec to provide ,i m trying to power      servos  and i was under the impression that each one would need about an amp  but in looking around for an appropriate bec to supply them  i notice that most seem to output around       amps  they won t all be running at once  but often  say   will be drawing enough juice to move  obviously  i m missing some link in my understanding   how do i determine how many amps will be needed from the power supply  ,design power rcservo bec
751,confused about the variables in robotc ,i m trying to program advanced functions in robotc but i m not too sure i m doing it right  i want to specify the motor port i m using  but i assigned names to all the motors  funny thing though  they don t exactly work the same as regular variables  for instance  motor port   s alternate name is light blue   i m not really sure if these are new variables  or just specifications   anyway  here is the variable s signature  int motor tmotor motor   my code plans on doing something similar to this  void testthing  motor motorname      motorname   somevalue     testthing light blue    but with the int motor hybrid variable unidentified i m not sure how well that would work out  or at all  ,robotc
757,how can i upgrade an existing robot with a higher torque  sensored motor        watts ,i would like a high torque motor     oz in        rpm  for souping up a scorbot   i bought  i really need it to have an encoder to count the number of revolutions and to allow high start up torque  so far  i m having difficulty finding a suitable motor  the closest i ve found are   revolver s stubby  still not ready for purchase  team novak ballistic     t  i ve found other rc car motors  but they are usually too big  some alternatives i thought about are   adding hall sensors to an existing motor   how hard is this  rewinding a motor with more turns to increase torque  decrease kv   does anybody know of any motors that fit these requirements or modifications i can make to existing ones   update  i had almost given up hope  until someone at homebrew robotics suggested using the maxon motor finder  if you just type in my given torque and speed  it returns   motors  but they re all over powered because the search interprets your specs as a continuous operating point  whereas my robot will only need that much power     of the time  and maybe for   second max  if i type in   v      rpm  and    oz in  then it returns   brushless motors  of which  the motor ec    is the best fit  which has this operating curve   however  i don t want to pay what maxon is charging  so instead  i ve contacted the guy who makes the yet to be released revolver stubby and he has kindly offered to build a custom high torque  low rpm motor for me  can anyone comment on why high torque  low rpm motors like the one i want seem so rare  is due to lack of applications  robotics  or is there some intrinsic difficulty in making them  ,motor brushless-motor
758,in hri  how is the  uncanny valley  experienced by people on the autism spectrum ,i m familiar with the idea of the uncanny valley theory in human robot interaction  where robots with almost human appearance are perceived as creepy  i also know that there have been research studies done to support this theory using mri scans   the effect is an important consideration when designing robotic systems that can successfully interact with people  in order to avoid the uncanny valley  designers often create robots that are very far from humanlike  for example  many therapeutic robots  paro  keepon  are designed to look like animals or be  cute  and non threatening  other therapeutic robots  like kaspar  look very humanlike  kaspar is an excellent example of the uncanny valley  since when i look at kaspar it creeps me out  however  people on the autism spectrum may not experience kaspar the same way that i do  and according to shahbaz s comment  children with autism have responded well to kaspar  in the application of therapeutic robots for people on the autism spectrum  some of the basic principles of human robot interaction  like the uncanny valley  may not be valid  i can find some anecdotal evidence  with google  that people on the autism spectrum don t experience the uncanny valley  but so far i haven t seen any real studies in that area  does anyone know of active research in human robot interaction for people on the autism spectrum   in particular  how does the uncanny valley apply  or doesn t it apply  when people on the autism spectrum interact with a humanlike robot  ,research hri uncanny-valley
763,differences between ackermann steering and standard bi tricycles concerning kinematics ,i got the following homework question   what are the general differences between robots with ackermann steering and standard bicycles or tricycles concerning the kinematics   but  i don t see what differences there should be  because a car like robot  with   fixed rear wheels and   dependent adjustable front wheels  can be seen as a tricycle like robot  with a single adjustable front wheel in the middle   then  if you let the distance between the two rear wheels approach zero  you get the bicycle  so  i can t see any difference between those three mobile robots  is there something i am missing  ,mobile-robot design kinematics theory
764,the relationship between point cloud maps and graph maps,i am most familiar with slam maps that are point clouds  usually in the form of a vector like    i also understand how to create a map like this using an ekf  today i came across a  graph file format  which as you would expect consists of vertices and edges in the format   edge  observed vertex id observing vertex id forward sideward rotate inf ff inf fs inf ss inf rr inf fr inf sr i know that there s a connection between matrices and graphs  an adjacency matrix for example    but it s not clear to me how this graph format of a map is equivalent to a point cloud map that i m familiar with    what is the relationship   are the vertices both poses and landmarks  are they in a global reference frame  how is this created from say velocity information and a range bearing sensor   is there a transformation between a graph map and a point cloud    ,slam mapping
768,how to balance a flying quadcopter ,im using my own code to create a quadcopter robot  the hardware part is done but i need to balance the copter   this is the video of its current status    i have tried to play with the speed of each motor to get it balanced  it didnt go   i actually have a gyro and accelerometer onboard  but how shall i adjust the motor speed based on these values  what are the rules that i should beware of  is there any better solution other that try and error  where shall i begin  any tips   ,balance quadcopter
775,getting started with robotic arm design,i would like to design a robotic arm to hold a weight x at length y  in my case i want to hold x     lbs at y     inches   starting out simply  i would like try building an arm with a gripper plus one servo joint    servo joint        y         gripper    when designing an arm  would i want to say that the gripper has to have enough torque to hold the desired weight  e g      lbs  at a minimal distance  however long the fingers are  then design the servo joint to bear the weight of the gripper   the load  i would like to be able to hold the object at full extension ,design servos arm
777,building a controllable  knob ,i am trying to build a semi analog timer  something like those old egg timers that you rotate the face of  i want a knob that i can turn that can be read by a microcontroller  and i also want the microcontroller to be able to position the knob  i d like to implement  stops  by letting the microcontroller push the knob towards certain positions  as it runs down  the knob should turn  this is my first project of this kind  i ve built small robots in the past  but it s been many years  i ve considered hacking a servo motor to read its position  but the small hobby servos i ve tried are too hard to turn  very noisy  and pick up too much momentum when turned  they don t act like a good knob  i m now considering a rotary encoder connected to a motor  but after hunting at several sites  sparkfun  servocity  digikey  trossen  and some others   i haven t been able to find anything that seemed appropriate  i m not certain how to find a motor that s going to have the right kind of low torque  this seems like it shouldn t be a really uncommon problem  is there a fairly normal approach to creating a knob that can be adjusted both by the user and a microcontroller  ,motor servos
780,what are the reasons for not having autonomous robots in our daily activities ,the fact is that the more i search the less i find autonomous  real  robots in use  the companion robots are all toys with limited useless functionality  whenever there is a natural disaster you don t see operational search and rescue robots in the news  even military robots in service are all remotely controlled machines  they are not intelligent machines  industrial robotic arms are deterministic machines  the only robots with some levels of autonomous functionality are cleaning bots  warehouse operations bots and farming robots  on the other hand  today   the artificial intelligence algorithms are very good in making decisions  the sensing technologies are very sophisticated the communication technologies are very fast we can manufacture cheap parts people are extremely gadget savvy  so  why there is no real robot in our day to day life  no investment in the domain  no market yet  not enough knowledge in the domain  a missing technology  any idea  ,mobile-robot
783,would ros benefit from a multicore processor like epiphany or xmos ,i am looking for a good embedded pc to run ros on  i recently came across a couple of little machines using new very multi core processors  such as the epiphany and the xmos  since the one thing that ros really seems to want is cores  would ros be able to take advantage of all of these cores  or are they all just too feeble with too little ram to be of any use  would it make more sense to focus on machines with fewer  more powerful cores  ,ros
788,do  nano bots   that can fit inside the human body  actually exist ,i was wondering  do we have real nano bots  like the ones in the movies   i think we have bots which can move through the blood vessels  am i right  ,mobile-robot
790,do  toy  robots move technology forwards ,over the last month  i saw many robots that don t have any real purpose  which made me ask myself   does this have any value   i saw dancing robot on ces  advanced lego based robots and also robots combined for very limited purpose  i saw ten year old children playing with robots  and competitions for them  someone has told me that this is just for education and logic spreading   in other cases  there were arguments like   this is for informing people that everything is going forwards   i know that people will buy robotic vacuum cleaners because they think that they ll save some time  but these robotic cleaners are not very reliable and i see it only as marketing   do these things  children s education  dancing robots  and other instances of selling a pig in a poke  have any value in terms of robotics  and are really advancing the field as manufacturers say  ,research
795,how can microhard     series modems be made compatible with microhard     series ,microhard systems currently sells several types of    mhz modems  which are mostly used in robotics and scada applications   one of their product lines  the     series  mhx     n     spectra       is obsolete and no longer sold   however  some older equipment is built with oem versions of the     series soldered in place  microhard currently sells a     series  mhx     n     spectra      that shares many of the specs with the     series  but cannot establish a radio link with a     series modem due to differences in encryption and hopping pattern   therefore  if you want to make new equipment communicate with equipment using the     series  your options are   de solder the old     modem and replace it with the footprint compatible     modem  or reconfigure a     series modem to communicate with the     series modem   option   is undesirable  since i don t have access to the firmware on the older equipment in question   does anyone know how to accomplish option    ,radio-control
797,plans to use vendor id to identify ethercat devices ,i also asked this question on ros answers  but it s not getting much interest there  currently the ethercat package in ros uses the slaves  product ids to identify the devices  and load the correct drivers  this works great when all of the devices are manufactured by a single vendor  but are there any plans to prevent product id collisions when multiple vendors make ros compatible ethercat devices  we manufacture our own ethercat devices  and are just using some large values for product id  just hoping that these don t collide with anyone else s  ideally  ros would concatenate the vendor and product ids into a single    bit value  and use that to identify the correct driver  ,ros
801,simple neural network with hardcoded positions for walk optimisation,i m building a quadrupedal robot that will learn how to walk  from the responses i got from asking if  its possible to run a nn on a micro controller i realised i needed to think of a clever system that wouldn t take      years to be effective and would still be able to demonstrate onboard learning  i ve designed a system but i m not sure how effective it will be  firstly i hardcode      positions for the legs  i set up a  simple  neural network where each node is a different set of positions for the legs  which i will write  the robot moves from one node to another and the weight of the joint is determined by how far forward the robot moves  eventually there will be strong connections between the best nodes positions and the robot will have found a pattern of moves that are most successful in walking   how effective would this be in learning to walk   note  instead of positions i could write short gaits and the process would work out which sets work best when combined  ,microcontroller machine-learning walk
807,how can i control a fast     hz  realtime system with a slow    hz  system ,we are currently designing a mobile robot   mounted arm with multiple controlled degrees of freedom and sensors   i am considering an architecture in two parts   a set of realtime controllers  either raspeberry pis running an rtos such as xenomai or bare metal microcontrollers  to control the arm motors and encoders   let us call these machines rtx  with x        depending on the number of microcontrollers   this control loop will run at    hz  a powerful vanilla linux machine running ros to compute slam  mocap  and execute high level logic  decide the robot s task and compute the motors  desired position and speed    this control loop will run at   hz   i know my framework needs to be scalable to account for more motors  more sensors  more pcs  eg  for external mocap    my main problem is to decide how to have the different rtx communicate with pc   i have looked at papers related to robots architecture  e g  hrp    most often they describe the high level control architecture but i have yet to find information on how to have the low level communicate with the high level and in a scalable way  did i miss something  in order to connect the fast rt machines ensuring the motor control with pc   i have considered tcp ip  can and uart   tcp ip  not deterministic but easy to put in place  is non determinism a real issue  as it will only be used at at slow speed   hz anyways   can  slow  very reliable  targeted to cars   have seen there are some exemples using can with robots but it looked exotic  uart  if i had only had one rt machine for motor control i would have considered uart but i guess this port does not scale well with many rtx is tcp ip really a no go because of its non deterministic characteristics  it is so easy to use   at the moment no solution really seems obvious to me  and as i can find no serious robot example using a specific reliable and scalable solution  i do not feel confident to make a choice   does anyone have a clear view on this point or literature to point to   are there typical or mainstream communication solutions used on robots  ,control design communication
810,can ultrasonic and button sensors be run in a vex analog port ,i m running out of digital ports  and have no sensors that fit the definition  analog   would it be possible to run a touch sensor  a quadrature encoder  or an ultrasonic sensor on an analog port   i m thinking not  but i didn t run across anything that said otherwise  ,sensors
812,how to find out how far a motor has taken a vehicle ,i have a small motorized vehicle with gears as wheels running up and down a track made of gear racks  how can this robot know when it has run half the track  and what s the best method to keep it from running off its track at the end and then return to start  the robot is carrying water  not exactly the same amount each time  so it will not weigh the same  therefore it might not be the same amount of steps in the stepper motor each time  here i have some ideas that might work  though i am a beginner  and don t know what s the best solution   gps tracking it  overkill on such a small scale   some kind of distance measurer have a knob it will hit at the middle of the track  telling program to delay for a given time track amount of steps the motor has performed  won t be as accurate    ,mobile-robot arduino sensors
815,arduino motor control,i m working on a rather low budget project  and need some way to control four or more motors using one arduino  i ve looked at motor shields a little  but i have a shield on top of it already  it does have female input on the top though  so a motor shield may work  any suggestions  ,control arduino microcontroller motor power
819,adding rotary encoders to an electronic wheel chair,we have an electric wheel chair  and are looking to add a rotary encoder to each wheel   we don t want to hack the motor itself  so want to add the encoder without harming the motor to wheel connection   we will be using an arduino to read the signal  does anyone have any experience adding rotary encoders to already assembled wheel assemblies    ,arduino microcontroller
826,can i use digital animation software to define the movements of humanoid robots ,i m working with a lifesize      cm  humanoid robot  hubo   and looking for a way to easily program new motions and gestures into him  obviously  i could write my own tool  but i am looking for a solution that can leverage existing tools or standards for robot motion  my first thought was trying to use animation software like blender or maya  and writing a script to extract the joint angles at keyframes  however  few robotics researchers are probably proficient with maya   i know i m not   is there already some kind of  d posing tool for robotics that is a standard  the only things i have seen so far that comes close is the pose utility in roboplus and choregraphe for the nao  but both programs seem limited to particular robots and don t appear to be extendable to hubo  so my questions are   are there standard file formats for robot motion  not  d wheeled robot motion  arm and leg motion  something equivalent to the  bvh file format used in motion capture  do you know of any wysiwygish tool for creating robot motion using keyframes and inverse kinematics   ,software motion
829,which is model is best for feedback control of robotic manipulators  mimo or parallel siso ,i m currently designing a robotic arm with   dof  and my goal is to be able to give setpoints for  d position  velocity and orientation     i only had feedback control for siso systems so far in college  so  taking the learning curve of multivariable control in consideration  should i approach this problem trying to model the system as a mimo or multiple sisos  if possible please mention possible disadvantages and advantages in each strategy  ,control manipulator robotic-arm
832,how do i interpret this data  received by the i c controller on an nxt   brick ,i have been trying to write code to connect a hitechnic prototype board to my lego brick  although i am using msrds studio  that isn t the issue  reading and writing to the serial port that the device is connected to works fine   where i am lacking is that i don t understand the data is that is being sent and received  it goes out and comes back in the form of a byte array  for example                                  is this byte array converted from hex  what is this response telling me   obviously i am a total newbie at this  i can program but i don t really understand electronics and i am trying to make that connection between what i have read about how an i c controller works and what is happening when i send and receive data over a serial port   ,nxt i2c
835,cncing an injection mold,i want to injection mold several thousand of a part that fits in a    x    x    bed  i would like to be able to use only tooling that i can make myself  so i can rapidly iterate on the tooling as production problems are discovered  i know that typical injection mold  hard tooling  is created using electrical discharge machining  which requires first cncing a carbon positive and then using that as an electrode to spark burn out a negative mold from hard steel  however  i do not have the equipment for edm  instead  i would prefer to directly cnc the negative mold  i know that a soft enough steel to be cnced will not last very long as an injection mold  but like i said  my run size is tiny  and i am ok with making a new mold every     units or so if necessary  i am open to buying an endmill that is diamond tipped  to work with harder steel  but then the limitation will probably be how much torque the cnc can produce on the endmill  what are some recommendations or links to helpful resources  in particular  what is a good cnc with enough torque  and what blend of steel should i use  thanks  ,cnc
838,what microcontroller should be used for quadcopter flight control and esc ,i am working on building my own quadcopter from scratch  i noticed that many solutions available online use arduino  but i am not a fan of arduino  so my questions are  what microcontrollers should be used  what are the crucial features of those microcontrollers etc  i would like to build it from total scratch  i was thinking about pic microcontrollers  also what should be used for esc  since i would build that from scratch too  summing it all up     escs gyro acceloremeter gps transceiver which is about   slaves and one master microcontroller   ,microcontroller quadcopter esc
839,sonar for obstacle avoidance  how many sensors and where to place them ,for avoiding obstacles during  d robot navigation what is the best position angle to place the sonar sensors  how many should there be  i would like to know if there is some theory or examples for the problem of placing  i realize that it depends on the way that the robot moves and its geometry  but i am searching for general answers  ,mobile-robot sensors navigation acoustic-rangefinder
840,is there a tool for building and analysing robots  kinematics  control  visually ,i am reading research papers about robotics and many of them follow the same pattern   some construction is established kinematical formulas are read from the mechanical structure the state space is analysed  e g  how far the robot can reach  what the maximum speed can be  what is left underspecified and how to handle such mathematically incorrect systems and so on   is there some tool or software product that can receive  as input  the mechanical structure and then output the kinematical formulas   preferably  it would provide some kind of plots  analysis  suggestions for optimal design parameters  e g  length  angles of the sturcture  optimum parameters of motors and so on    does this exist  ,software design inverse-kinematics research kinematics
845,how to identify objects in space,using a depth sensing camera like kinect  i would like to retrieve the position of an predetermined object  e g  a cup  fork etc so that i would ultimately be able to grab the object   what would be a way to achieve this  ,computer-vision algorithm
848,why must i loop     times for a    bit  address in this example ,i am learning about i c on the arduino  i was looking at a sample program to scan for i c devices and saw this   with the following code       for address      address         address                         the i c scanner uses the return value of            the write endtransmisstion to see if            a device did acknowledge to the address          wire begintransmission address           error   wire endtransmission             if  error                           serial print  i c device found at address  x              if  address                  serial print                 serial print address hex             serial println                 as far as i understand it  a bit is just     so  why how do   bits loop from           ,arduino i2c
851,optimal control for a simple pendulum,i m studying various optimal control methods  and implements them in matlab   and as test case i choose  for now  a simple pendulum  fixed to the ground   which i want to control to the upper position  i managed to control it using  simple  feedback method  swing up based on energy control   lqr stabilization for the upper position   and the state trajectory is show in figure  i forgot the axis description  x is theta  y is theta dot   now i want to try a  full  optimal control method  starting with an iterative lqr method  which i found implemented here   the method requires one dynamic function and one cost function   is the motor torque  one motor only    function  xdot  xdot x  xdot u    ilqr fndyn x  u      xdot    x              g l   sin x       d  m l     x         m l      u       if nargout             xdot x                        g l cos x       d  m l              xdot u          m l          end end  function  l  l x  l xx  l u  l uu  l ux    ilqr fncost x  u  t       trying j   x f  qf x f   int dt   u          qf              eye         r          wt          x diff    wraptopi x      reference      x    reference           if isnan t          l   x diff   qf   x diff      else         l   u  r u      end      if nargout             l x   zeros               l xx   zeros               l u     r u          l uu       r          l ux   zeros                if isnan t              l x   qf   x diff              l xx   qf          end     end end  some info on the pendulum  the origin of my system is where the pendulum is fixed to the ground  the angle theta is zero in the stable position  and pi in the unstable goal position   m is the bob mass  l is the rod length  d is a damping factor  for simplicity i put m    l    d      my cost is simple  penalize the control   the final error  this is how i call the ilqr function tspan           dt         steps   floor tspan    dt   x     pi        umin       umax       x   u   l  j opt     ilqg det  ilqr fndyn   ilqr fncost  dt  steps  x      umin  umax    this is the output  time from   to     initial conditions                       goal                          length            mass            damping           using iterative lqr control iterations       cost                  the nominal trajectory  that is the optimal trajectory the control finds  is   the control is  off     it doesn t even try to reach the goal    what am i doing wrong   the algorithm  from todorov seems to work   at least with his examples  ,control
854,sensors for differential drive,i have the following chassis along with an arduino and a motor shield   i m in the process of developing a tracking mechanism for use with differential drive  normally  a photo reflector can be placed adjacent to the wheel that will reflect when each spoke passes through therefore allowing code to be written that will accurately measure each wheels position  the problem i have is that you cannot see the wheels from inside the chassis  only small holes for the driveshaft  placing sensors on the outside would look ridiculous and a wall crash would cause havoc  would i be able to use a photo reflector on the gears  as shown  if i accurately placed it to count each spoke on the gear itself  i m a bit hesitant though because even a small bump could misalign the sensor   again causing havoc  so does any one have an idea on how to track the wheel movements  ,arduino two-wheeled
857,can you seed a kalman filter with a particle filter ,is there a way of initializing a kalman filter using a population of particles that belong to the same  cluster   how can you determine a good estimate for the mean value  compute weighted average    and the covariance matrix   each particle is represented as   ,localization kalman-filter particle-filter
863,how do i simulate an assembly line ,i need to simulate a stream of vehicles  such as on an assembly line  automatons are performing operations on the vehicles when they come within reach   the automatons do not keep track of the individual vehicles  they simply collect data  we need to choose a method of matching the data gathered by each automaton with the vehicle it belongs to   for example  we could guess the identity of a vehicle using its timing when arriving in the operation range  sensors  of an automaton  i have to check the possible problems we will face  so i would like a little  hopefully simple  video simulation tool that i could play with   vehicles could be symbolized has moving black squares automatons sensors could be static points or circles  it should be possible to change the time interval between two vehicles  and their speed  and add some random delays   what kind of software should i search for  or where should i look  should i consider to developing it from scratch   ,simulator
865,how to tell a stepper motor s position  or detect slippage,i am creating a cnc machine on a budget  using old motors out of printers scanners etc   i am limited to about    ma for the whole system  so my fear is that when the cutting bit touches the material  the stepper might be moving too quickly and won t have enough torque   this would mean it will become one rotation behind  which could really mess up a cnc project  detecting when the motor  misses  a step would allow me to readjust the motor speed until it reaches a balance between working quickly and having adequate torque   how can i achieve this  ,arduino stepper-motor current cnc
869,building robotic arm joint,i am very new to robotic design and i need to determine what parts i will need to assemble an arm joint   the joint will contain one timing belt pulley which a remote motor will be turning  a forearm that the pulley will be rotating and an upper arm piece that will actually be two parallel arms that will grip the pulley on top and bottom in order to brace the pulley from off axis torque from the timing belt  i am kind of at a lost as to how to mount all of these together   i would like to mount the forearm directly to the pulley and then the two parallel arms  comprising the upper arm  sandwich the top of the pulley and the lower part of the forearm   this would be attached using a turn table   any ideas on how a shaft would mount to these   or how to attach the pulley to the arms themselves  any kind of direction or links would be greatly appreciated  i don t even know the names of the parts i would be looking for  in this ascii art model the dashed lines     are the arms   the arm on the left is the forearm and the two arms on the right are the two parallel parts of the upper arm   the stars are the belt and the bars      are the pulleys at the elbow  e  and shoulder  s      i am thinking of mounting the pulley to the left arm directly  a bushing   and then maybe using turntables to mount the pulley to the top arm and another turn table to mount the left arm to the bottom arm  here is a picture of the design to help you visualize   ,design arm joint
872,do i really need a gyro for an airplane flight stabilization system ,i m working on a basic airplane flight stabilization system  as the precursor to a full autopilot system  i m using a salvaged wii motion plus and nunchuk to create a  dof imu  the first goal is to keep the wings level  then mix in the users commands  am i correct in saying that this would not require a gyro  just a        axis accelerometer  to detect pitch and roll  then adjust the ailerons and elevator to compensate  secondly  if we extend my design goal from  keeping the wings level  to  flying in a straight line   obviously two different things  given wind and turbulence   does the gyro become necessary  insofar as this can be accomplished without gps guidance  i ve tried integrating over the gyro values to get roll  pitch   yaw from that  however  as evidenced by this question   i m at a level in my knowledge on the topic where i d prefer simpler mathematics in my code  thanks for any help  ,uav accelerometer imu gyroscope
873, d mapping from a quadcopter with kinect,i have a quadcopter robot that has a kinect on it and i want to do  d mapping with it    is kinect reliable on a moving robot  i e   can it give me stable images and maps with this movement   is there an sdk for producing  d maps from kinect data   will slam algorithms work  is the arduino board on the copter  atmega       powerful enough to handle this   ,arduino slam kinect quadcopter
876,remote car controlling,before i start asking you for help let you know that i am newbie in electronic field  all i want to know is the principle of wheel rotation  left right  from remote car gadget  i am not talking about changing the spin rotation of dc motor  up down buttons from remote   i am asking about left and right movement of wheel  i know that spin change depends on polarity of dc motor  so changing polarity changes spin  but what is the principle of changing the left and right positions of front wheels  ,control wheel
878,accurate  d printing w sketchup,i have  d printers at my school  but unfortunately they are not super high quality  i want to try  d printing a model i made on google sketchup  but i would like for it to be fairly accurate  what measures can i take to prevent error in the model  i understand that i need to export the file as an stl  is there anything i can do to the model before hand to ensure accuracy   what can i do to calibrate a  d printer for best results    ,3d-printing
882,force measurement on grab bars,i recently start a project to measure the force on a bathroom grab bar  the force load is applied by the person who need to the grab bar for assistant  what i want to measure is the load against the wall and do the the real time monitoring of the load for further analysis to improve the design  i am not quite sure about what kind of sensor would be suitable to do the measurement  i am looking at different load cells but cannot get the idea how to mount commercial load cells to do the measurement  what i am trying right now is using strain gauge to measure the strain near the end of the bar wall side  and roughly calculate the load  i think  might be wrong  there may exists some kind of force load sensors that can clamp on the bar to do the measurement  any sensor types models or suggestion are welcome  i also posted this question to ee forum  ,sensors force
883,measuring speed of movement in webots,i have been experimenting with different fitness functions for my webots robot simulation  in short  i m using genetic algorithm to evolve interesting behaviour   the idea i have now is to reward punish aibo based on its speed of movement  the movement is performed by setting new joint position  and currently it results in jerky random movements  i have been looking at the nodes available in webots  but apart from gps node  which is not available in aibo  i couldn t find anything relevant  what i want to achieve is to measure the distance from previous location to current location after each movement   how can i do this  ,mobile-robot reinforcement-learning simulator
884,using a sick laser with matlab in windows,is there a matlab toolbox available to use sick lasers in windows  i found one toolbox for matlab in gnu linux   is there another way to use sick laser via matlab in windows  ,mobile-robot localization
885,would is be possible to connect a hitechnic prototype board to an arduino ,does anyone know if this is possible  it s just an i c device right  i mean you would have to cut the cable and make it so you could plug into the pins on the arduino but you should just be able to use the wire library and say something like    the nxt hardware developers kit tells you what pins are which   thanks edit  turns out this is very possible  the main problem was that hitechnic says the address is  x   and it is actually  x   but here is a short sketch that reads and prints some into about the device  i e  the manufacturer and version    include  wire h    define address  x    void setup       wire begin      serial begin           void loop       readchardata          serial println          readchardata          serial println      readchardata           serial println       serial println                                      delay           void readchardata int startaddress  int bytestoread      wire begintransmission address     wire write startaddress     wire endtransmission       wire requestfrom address  bytestoread      while wire available              char c   wire read         serial print c            ,arduino
891,arduino nano   raspberry pi   uav ground station ,i m a programmer by trade  and an amateur aerospace nut  with some degree level training in both fields  i m working on a uav project  and while the good people over at diy drones have been very helpful  this question is a little less drone related and a little more general robotics electronics  essentially  i m looking at options for ground stations  and my current rough plan is something like this  i have a pc joystick with a broken sensor in the base  which i plan to dismantle  separate the handle from the base  insert an arduino nano into the  mostly hollow  handle and hook it up to all the buttons and the hat thumbstick  then  where the hole is that used to accept the stem to the base  i fit a bracket that runs horizontally to hold a smallish touchscreen  think razer s project fiona tablet with only one stick   behind which is mounted a raspberry pi  the nano talks to the rpi over usb as a hid input  the rpi will be running some custom software to display telemetry and other data sent down from the uav  my main question whether that nano would have enough power to run the xbee that provides the telemetry link without causing lag in the control inputs  it s worth mentioning that the uav will be doing fly by wire moderation  so slight stutters won t result in wobbly flying  but serious interruptions will still be problematic   and annoying  it s also worth mentioning that this will only be used as a simplified  guiding hand  control  there will always be a regular remote control available  not least because of eu flight regulations  so this is just for when i don t want to use that  if that nano won t do  what are my options  my first thought is to get a second nano and get that to drive the xbee  the rpi has two usb ports after all  but there may well be a better way  ,arduino control uav raspberry-pi radio-control
892,is it possible to achieve arbitrary precision in camera calibration ,is it possible to achieve arbitrary precision to the calibration of the extrinsic parameters of a camera or is there a minimum error wich can not be compensated  probably dictated by the camera s resolution   ,computer-vision calibration
896,how to select cameras for a stereo vision system ,i am in the process of building a stereo vision system to be used on a ugv  the system is for a robot that will be used in a competition wherein the robot is teleoperated to find relatively small colored rocks in a large outdoor field  i understand how to calibrate such a system and process the data for a stereo vision system  i do not however know how to select cameras for such a system  what are the best practices for picking cameras for a stereo vision system  ,computer-vision stereo-vision cameras
897,high voltage motor control with arduino,i m trying to control a higher voltage motor than an arduino can source with a pin  with an arduino  i am trying to hook it up to a transistor  the battery pack is not supposed to be    v  it s  v    d batteries  here is the setup   here is the arduino code i m trying to run to it   code gives me no errors  but no motor movement happens  what would make this work  thanks  ,arduino motor
900,how do i select the best configuration for a known workspace  load and task ,given workspace constraints  load and task to be done  how do i select the best configuration of my robot  how do i select between a cartesian or scara robot for instance  how do i select a manipulator  how do i determine how many axes that i need  most of what i have seen is based on experience  rules of thumb and readily available standard devices  but i would like a more formal answer to quantify my choice  is there some technique  genetic algorithm   which describes the task  load  workspace  budget  speed etc  and rates and selects an optimal robot configuration or maybe even multiple configurations  how can i be mathematically ensure i ultimately chose the optimal solution  the only thing i found online was a thesis from      titled automated synthesis and optimization of robot configurations  an evolutionary approach  pdf  cmu ri tr         it is a synthesis and optimization tool called darwin k presented in a thesis written by chris leger at cmu  i am surprised no one has updated it or created a tool similar to it  to provide some context for my question  we are developing a robot to assist the elderly with domestic tasks  in this instance  the robot identifies and picks food items from a previously stored and known location  the hand opens the package and place it in the oven  the pick and place locations are fixed and nearby so the robot is stationary  ,design algorithm industrial-robot theory manipulator
907,calibrate a  d scanner mounted on a rotary axis,a  d laser scanner is mounted on a rotary axis  i wish to determine the transformation matrix from the center of the axis to the center of the scanner  using only the input from the scanner and the angle of rotation   the  d scanner itself is assumed to be calibrated  it will accurately measure the position of any object inside the plane of the laser  in regards to the scanner origin  the rotary axis is calibrated as well  it will accurately measure the angle of its own movement  the scanner is aligned and mounted close to the center of rotation  but the exact offset is unknown  and may drift over time  assume it is impractical to measure the position and orientation of the scanner directly   i am looking for a way to determine the exact values for the   degrees of offset the scanner may have in relation to the axis  determined solely on the  d information from the scanner and the rotation angle from the axis   i am mainly interested in the   offsets depicted here  since the other two do not matter in regard to generating a consistent  d point cloud from the input data  by scanning a known calibration object  it should be possible to determine these offsets  what are the mathematical formulas for this   what sort of calibration information is required at a minimum  is it for example possible to determine all parameters simply by scanning a flat surface  knowing nothing about the surface except that it is flat   the transformation matrix from rotation axis to world is unknown as well  but that one is trivial to determine once the transformation from axis to camera is known    example  on the left the camera is placed exactly on the rotational axis   the camera scans a planar object with reference points a b and c  based on the laser distance measurements and the angle of the axis  this planar object can be reconstructed  on the right  the camera has an unknown offset to the axis  it scans the same object  if the point cloud is constructed without knowing this offset  the planar surface maps to a curved surface   can i calculate the offset based on the surface curvature  if i know the real world distances and angles between a  b and c  how can i calculate the camera offsets from that  what would be the minimum number of reference points i need for all   offsets  ,calibration
908,how does the makeblock threaded slot work ,i ve been looking into a makeblock robotics kit but have found no information on the web that comes from end users  and one of the main advertised features is not clear to me   the slot threads shown below are straight  while the screw thread that will mate with them is angled   is there just very little contact between screw thread and rail thread vs  regular screw hole threads   or would the screw want to rest angled somewhat  and then the head would not be flush with the rim of the rail   or would the screw deform the aluminum rail if over torqued  this is a close up picture of the slot with screws   ,mechanism kit
909,gps tracking device,i m looking for a gps tracking device without screen or apps  i just need it to look for the current position of a bus and send it to a server through tcp ip protocol  this process must be constant so i can have a real time tracking  the bus already has a wireless access point   what device can be useful  do i need another piece of hardware to send the coordinates to the server  i have no experience but    can something like an arduino connected to the gps send the data  ,gps
913,are power and torque required related in some way ,i am designing a new platform for outdoor robotics and i need to calculate the power and or torque that is needed to move the platform  i have calculated that i need about     w of total power to move it     w per motor   but i don t know how to calculate the torque that i need   is it really just about having the required power and ignoring the torque or is there a way to calculate it easily  already known parameters of the platform are   weight of the whole platform     kg  number of wheels     number of powered wheels     diameter of wheels     cm  number of motors     wanted speed      rpm    m s   wanted acceleration        m s    ,mobile-robot design motor
918,storing kinect data on a usb drive,does anybody know if kinect data can be stored directly onto a usb drive    i have a kinect for windows that i cannot use on linux ros   however what i plan is to mount the kinect on my robot  store the captured frames on a usb and then un mount the usb  transfer to linux and process them on ros  is this possible   any suggestions    ,kinect ros
921,how can i send video from my arduino camera module video to my android screen ,i m trying to connect a camera module to my arduino mega  connect my mega to my android phone  throught bluetooth or other   and send the live view of the camera to the mobile phone  i saw a video online that showed this for still images    an image captured by the camera module on the arduino was sent to android and the output image was viewed after a couple of seconds  the time to send image by bt   is this doable with live video instead of image   if yes  please guide me  if no  please suggest some workarounds  ,arduino cameras
922,how do i design for a target speed ,i need to make an omni wheeled robot platform    wheels   which should go at a minimum speed of    cm s   i have an idea for the design  but since this is my first time doing something like this i have made a lot of assumptions   i decided to choose the tgy s    b servos as my motor system  i intend to attach these servos to fxa   b wheels  finally  i intend to power my servos with one turnigy lsd    v     mah ni mh flat receiver packs  not sure if lipo is a better choice   i need to be able to run the servos continuously for roughly   minutes  you can ignore the microcontroller and other stuff  relatively speaking they will consume much less power  the robot will have four wheels  thus  four servos   the basic specifications of each servo is   type  analog gear train  plastic bearings  dual motor type  carbon brushed weight    g      oz  lead    cm torque     kg cm      v      kg cm    v speed      sec         v               v  so based on my battery pack  i will be running the servos at  v  that gives me a speed of    degrees per      seconds  i plan on modifying these servos for continuous rotation  and connected them directly to the wheel  since the wheel has a diameter of    cm  it has a circumference of     cm  based on these specs  it seems to me that my robot can move at roughly    cm     seconds  or    cm s  quite fast actually   i don t intend to run it constantly at that speed  so in the   minute run  assume my average speed to be    cm s  are these assumptions reasonable  and are the calculations correct   i would really appreciate any insight  advice  recommendations  and criticisms you may have  ,mobile-robot wheel rcservo
924,ti arm with stacked ram,do any of the ti arm socs  e g  omap or da vinci  have a version with stacked ram   e g  ddr  or mddr  for miniature robots like micro drones  it would be really nice to not need to spend board area on an external ram chip  thanks  ,arm
939,will connecting two servo motors double the torque ,for my robot  i am using two continuous rotation servos to spin a threaded rod  i am trying to make this project as cheap as possible  here are the servos that i can find   servo     this is a very cheap option and it has half of the torque i need  servo     this has all of the torque my project requires  but it is much more expensive that two of servo      can i hook up two of servo    to each end of the rod and have them move synchronized  i can spare a few extra pins on my microprocessor that i am using  that isn t a issue  i know hooking two together will increase torque  but i don t want     of the torque i want in this situation  also  i don t care if i only have     of my torque  goal  with the extra weight  which probably won t happen  but i don t want to  like i said earlier  have             of my  target goal  of torque if possible  any help appreciated  thanks in advance  ,motor rcservo
940,how do i convert link parameters and angles  in kinematics  into transformation matrices in programming logic ,i m doing robotics research as an undergraduate  and i understand the conceptual math for the most part  however  when it comes to actually implementing code to calculate the forward kinematics for my robot  i am stuck  i m just not getting the way the book or websites i ve found explain it  i would like to calculate the x y z angles given the link parameters  denavit hartenberg parameters   such as the following   begin array  ccc   bf i     bf  alpha i       bf a i       bf d i     bf  theta i                         theta               circ             theta             a     d      theta               circ    a     d      theta              circ             theta               circ             theta      end array  i don t understand how to turn this table of values into the proper transformation matrices needed to get   the cartesian position and rotation of the last link  from there  i m hoping i can figure out the x y z angle s  from reading my book  but any help would be appreciated  ,kinematics forward-kinematics
946,how can i detect the edge of a table ,i m new to robot making and just got my first arduino to play around  i want to make a robot that will wander on a table  and it will last longer i think if i could make it avoid falling from the table  what will be the best way to make it detect the edge of a table so i can make it stop and turn around   it have to be something reliable and preferably cheap  it will also be better if i don t need to add extra stuff to the table so i can use it on any surface  my first idea was to draw path lines on the table and make a line follower robot  but i don t like this idea very much   ,sensors
948,what is the opposite of  antagonistic  ,a robotic joint is connected to two actuators  e g  air muscles  one flexes the joint  while the other extends it  this arrangement is called  antagonistic    but what if i had an electric motor instead of the air muscles  in that case it can only pull on one tendon at a time  and it s not antagonistic  what it the arrangement called in this case  untagonistic  ,motor air-muscle
952,what s an efficient way to visit every reachable space on a grid with unknown obstacles ,i m trying to create a map of the obstacles in a fairly coarse  d grid space  using exploration   i detect obstacles by attempting to move from one space to an adjacent space  and if that fails then there s an obstacle in the destination space  there is no concept of a rangefinding sensor in this problem     for example  the process is complete when all the reachable squares have been visited   in other words  some spaces might be completely unreachable even if they don t have obstacles because they re surrounded   this is expected  in the simplest case  i could use a dfs algorithm  but i m worried that this will take an excessively long time to complete   the robot will spend more time backtracking than exploring new territory   i expect this to be especially problematic when attempting to reach the unreachable squares  because the robot will exhaust every option  in the more sophisticated method  the proper thing to do seems to be boustrophedon cell decomposition   however  i can t seem to find a good description of the boustrophedon cell decomposition algorithm  that is  a complete description in simple terms    there are resources like this one  or this more general one on vertical cell decomposition but they don t offer much insight into the high level algorithms nor the low level data structures involved  how can i visit  map  this grid efficiently   if it exists  i would like an algorithm that performs better than  with respect to the total number of grid squares  i e  better than  for an  grid   ,algorithm coverage planning
953,dropping pwm on ardrone parrot    ,i am having some issues with the ardrone parrot     and hope someone else may be running into the same thing  while hovering  the drone is  seemingly  randomly losing altitude then recovering   it is doing so while not being commanded any velocity inputs and should hold altitude   we are using the drivers from the ardrone autonomy  dev unstable branch  on github  we are able to watch the pwm outputs being sent to the motor and they are dropping from the hover command do a small value before exponentially returning to the hover value when this drop occurs  the issue could be a communication between the imu and the onboard controller or on our software control implementation  has anyone seen a similar problem or suggestions to test troubleshoot what is happening  ,ros quadcopter pwm
954,controlling more than    servos with the arduino servo library,i m using teensy hardware specifically   i have a teensy     and a teensy      and from the documentation it seems like there are two    bit timers available  and each should be able to control    servos   however  i ve attached a logic analyzer and have confirmed that only the first    servos attached ever function  is there anything special i have to do with my sketch in order to convince the servo library to allocate the second timer for servos attached beyond number     this works   but this  below  only ever shows activity on the first twelve pins attached   define num servos     servo servos num servos       teensy     pins int pin assignments num servos                                                                                              void setup        for int i      i   num servos  i          servos i  attach pin assignments i            ,arduino rcservo
957,adhesion for a heavy wall climbing robot,i have come across a number of methods for developing wall climbing robots   suction chemical adhesion gecko like hair adhesion electroadhesion  which method would be the best for heavy robots   kg    are there any other methods that i have missed  ,mobile-robot
963,simulated kinect rotation around x  gazebo bug  ,i asked this question on answers ros org and gazebo ros org but still haven t got any answer  i m posting my question here with the hope someone can help me  in our robot  the kinect can be mounted on the side of the arm  as shown in the screenshot below  when running the simulation in fuerte  i found this weird behaviour  as you can observe on the image  the point cloud does not match the robot model  we see a partial image of the hand arm at the bottom left of the screenshot  which should be on the robot model    as soon as i rotate the kinect against its x axis  so that the kinect is horizontal as you can see on the second screenshot   then the point cloud and robot model are aligned properly   the kinect xacro and dae are the one from the turtlebot  i m simply attaching them with a rotation   the code can be seen on github  any help is greatly appreciated  ,kinect ros simulator
964,extended kalman filter using odometry motion model,in the prediction step of ekf localization  linearization must be performed and  as mentioned in probabilistic robotics  thrun burgard fox  page      the jacobian matrix when using velocity motion model  defined as  is calculated as    does the same apply when using the odometry motion model  described in the same book  page       where robot motion is approximated by a rotation   a translation  and a second rotation    the corresponding equations are    in which case the jacobian is   is it a good practise to use odometry motion model instead of velocity for mobile robot localization  ,localization kalman-filter
965,firmata over nrf  ,i m having some technical problems    i m trying to use firmata for arduino but over nrf    not over serial interface  i have tested nrf   communication and it s fine  i have also tested firmata over serial and it works   base device is simple  serial relay   when it has data available on serial  read it and send it over nrf   network  if there is data available from network  read it and send it through serial  node device is a bit complex  it has custom standard firmata where i have just added write and read override    read override id handeled in  method in this way  while firmata available        firmata processinput        handle network data and send it to firmata process method while network available          rf  networkheader header      uint  t data      network read header   data  sizeof uint  t        serial print data  dec   serial print           firmata processinputoverride data       blinkonboard         currentmillis   millis     firmata processinputoverrride is little changed method of processinput where processinput reads data directly from firmataserial  and in this method we pass data down to method from network  this was tested and it should work fine  write method is overloaded in a different way  in firmata cpp i have added an method pointer that can be set to a custom method and used to send data using that custom method  i have then added custom method call after each of the firmataserial write   call  firmata h     size t   firmataserialwriteoverride  uint  t        void firmataclass  printversion void      firmataserial write report version     firmataserial write firmata major version     firmataserial write firmata minor version     firmata firmataserialwriteoverride report version     firmata firmataserialwriteoverride firmata major version     firmata firmataserialwriteoverride firmata minor version      i have then set the overrided write method to a custom method that just writes byte to network instead of serial  size t ssignal uint  t data        rf  networkheader header basedevice       network write header   data  sizeof uint  t       void setup         firmata firmataserialwriteoverride   ssignal         all stages pass right  i guess  and then i don t get any response from node when i request pin states       f   a  f  f  f      f                     a b c d e f f     analog mapping   f   d   f     sysex request pin   state and value   f   d   f     f   d   f        f   d    f     and i wait for response     there is no response  any ideas why would that happen  node receive all messages correctly and code for handling pin states exist  ,arduino serial c++
970,do magnets affect imu values ,im in the process of making a robot which requires     x  mm cylindric magnets for the construction  they are   mm from the center of the robot where i plan to have the imu   i was thinking about using mpu       do magnets affect the values  if yes  is there a solution for it  like maybe i could have a shield or something around the imu  ,sensors imu
975,why do space probes need heating ,i know that temperature influences the characteristics of semiconductors and other materials  but we know how and can take that into account  furthermore  lower temperatures makes electronics more efficient  sometimes even superconducting  i remember reading somewhere that engineers building curiosity even considered low temperature electronics for the motors driving the wheels but still decided against it in the end  why is it  apparently  so hard to build components with operating temperatures matching those on mars  europa  or in space  edit  none of the answers address my question thus far  i know that all parts  both electronic and mechanical  and greases and so on have relatively narrow working temperatures  my question is  why don t we build special cold metals and cold greases and cold chips that have their narrow operating temperature band at      c or whatever  valid answers could be  it s too expensive  insufficient science has been done to determine materials appropriate for such cold  such cold materials cannot be manufactured in the sweltering heat of planet earth  ,heat-management cooling
976,what is a good approach to a quadruped gait ,i have a small quadruped with three degree of freedom legs which i have been working on   dof mini quadruped  my original code for it was a simple servo controller on the arduino  and scala code which would send servo commands over the wire   i did all the inverse kinematics and gait logic in scala  and got it to walk   dof quadruped first gait  my gait logic in scala was somewhat naive  it depended on the legs being in the right position at the beginning  one side extended fore and aft  the other side in toward each other    the logic was simply translate all four feet backward by  mm along y  and whenever a coxa angle became excessively rearward  stop and perform a little routine where that foot is lifted   mm in z  then translated forward   mm along y  and set back down   naive  but effective  now  i have rewritten my ik code in arduino c  and i m trying to decide how to move forward with the gait dynamics   i ve had a hard time finding good  easy to understand resources about gaits   i do have some knowledge about the difference between dynamically stable gaits  like creep gaits  where the body is a stable tripod at all times and dynamically unstable gaits  walking  trotting   where two legs are off the ground at a time and the body is essentially falling forward into the advancing leg  i had some thoughts about state machines and trying to calculate whether the body center falls within a triangle made by the remaining feet to decide which foot was safe to lift  but i m not sure if these are ideas worth exploring  i know this is kind of an overly general question  but i m interested to see how other people have attacked this problem  and about all i ve been able to find are research papers  ,mobile-robot walk
979,one bec for multiple esc  quadcopter ,i m building a quadcopter and have discovered that most esc have a built in bec  but i was wondering if it wouldn t be better to use only one  what if i delivered power to my four esc with a unique bec   would that work   i think this would be easier to configure  you have to set it up only once for the four esc  and it would prevent each esc from having it s own behavior  am i doing it wrong   here is an image of what i m talking about   edit   trying to find the original image and upload it  given the answer by ian mcmahon it appears that this schema is not the right thing to do  since i had misunderstood the role of becs  so would the right schema would look like this   edit   trying to find the original image and upload it  i m still not sure if i m getting it  do i need   escs with integrated becs and connect all three cables to flight controller   ,electronics quadcopter bec esc
984,does anyone know what might be giving me this error coming from an i c device,here is the background  i am trying to write a service for the hitechnic prototype board   using the appendix   from the blue tooth developers kit from lego s site i am able to understand what is going on with this service i am trying to build however the response i get is always        xdd    communication bus error  or       x      pending communication transaction in progress    i figured out that the hitechnic prototype board is using i c address  x   so i modified the brick code to use that address instead of the standard  x    it goes out and configures the device  i get a response and then it does an lswrite which seems ok then i get a get an error when it does the lsgetstatus   i know this thing works   i can bit bang it all day long with an arduino but i only did that to test it out   see this link i am not sure what else to try  here is how i am setting it up in the connect to brick handler    i have also tried setting anyport as well so that it will hit the testportfori csensorhandler that just does what i explained before   it seems to set the mode fine and then gets an error when it tries to read the device information   here is the data    this first part is the set input more   both the message and response   you can see it is totally fine   send command data                  receive command data    commstate serialport read receivedata     packetsize              then it does an lswrite   everything still seems fine    you can see i have modified the nxtcomm code to use  x   instead of  x   which it would normally use  then the last byte is also  x   which is the starting address of the manufacturer  it s asking for    bytes which would be the manufacturer and sensor type  like i said   i know that works i can print that info out using the arduino                            i c address     i assume this is what address i want to read from   got response  true error code success                          sendcommandhandler  nxtcomm                            requestresponsehandler  nxtcomm                            commsendimmediatehandler  nxtcomm                        send command data   then it tries to get the status            here is the response                      it s either    or      it s making me nuts     if anyone has anything that might help me out i would so much appreciate it  at this point i am running out of ideas  i can see what is going on  i can understand the entire transaction but can t seem to figure out why it just errors out like that   also   just for grins i tried  x   which is what they tell you on the hitechnic website  that gets a response of          from the nxt brick   that would indicate there is no data but as i pointed out i can get data using the arduino  how could i have two different i c device addresses   ,nxt i2c
985,which is easier cheaper  hbridge vs esc for controlling a motor ,i was able to find a small esc for about    bucks for an esc that connects to simple pulse wave interface     sign me up   or would you think         and be done with it   my robot in particular actually has two motors and therefor     to control the two of them   but the interface is really easy  plus has the added advantage of being r c vs computer controlled with a simple change of connectors  which way would you go  ,design electronics wheeled-robot
987,problem in serial communication between pc and atmega      avr ,i have written code to send data from controller to pc through serialport using interrupt but it echos garbage value exactly   times back   edit  function used to set baud rate    define fosc            clock speed  define baud       define myubrr fosc    baud     void usart init  unsigned int baud        set baud rate    ubrrh    unsigned char  baud      ubrrl    unsigned char baud     enable receiver and transmitter    ucsrb       rxen      txen      set frame format   data   stop bit    ucsrc       usbs      ucsz       ,serial avr
989,local localisation with particle filter,i am doing local localisation with sonar  particle filter  i e all particles are initially with robot pose   i have grip map of environment  when i execute algorithm in environment  where doors are closed open   particles are not able to followup the robot  i don t have random particles since i know the initial position of the robot exactly  adding random particle will change the pose of robot  i am find median of particles as robot pose   any idea methods how to improve local localisation  i want to know  do i need random variable if i am doing local localisation  and how do i improve localisation if there are many changes in the map without adding random particles  ,mobile-robot localization odometry particle-filter
993,conventional land vehicle dynamic models for gps ins augmentation,i am looking to augment a gps ins solution with a conventional land vehicle  car like  model  that is  front wheel steered  rear wheels passive on an axle   i don t have access to odometry or wheel angle sensors  i am aware of the bicycle model  e g  chapter   of corke   but i am not sure how to apply the heading velocity constraint on the filter  so my questions are   are there any other dynamic models that are applicable to the land vehicle situation  especially if they have the potential to provide better accuracy  are there any standard techniques to applying such a model constraint to this type of filter  bearing in mind i don t have access to odometry or wheel angle  are there any seminal papers on the topic that i should be reading   ,gps dynamics
994,chaining kalman filters,my team is building a robot to navigate autonomously in an outdoor environment  we recently got a new integrated imu gps sensor which apparently does some extended kalman filtering on chip  it gives pitch  roll  and yaw  north  east  and down velocities  and latitude and longitude  however  we also have some encoders attached to our wheels  which provide linear and angular velocities  before we got this new imu gps sensor  we made our own ekf to estimate our state using the encoders and some other low cost sensors  we want to use this new sensor s on chip filter  but also incorporate our encoders into the mix  is there any problem with chaining the filters  what i mean is  we d use the output of the imu gps sensor s on chip ekf as an update to our own ekf  just as we use the data read from the encoders as an update to our ekf  it seems reasonable to me  but i was wondering what is usually supposed to be done in this case   ,kalman-filter imu navigation
997,how do we make our robot work ,as a holiday project we are building a surveillance robot that is capable of transmitting live images using a webcam and is also capable of lifting small objects    it uses a cc     module for communicating with the robot   the interface is designed in visual basic   and it allows us to set the port of the computer to which the transreceiver is connected  it is connected via a usb to rs    port  usb side is connected to the computer   we tried the settings as shown below and we get an error that the config is unsuccessful  we have tried the same settings in   different computers so far and it did not work     circuit diagram for the robot   it is designed using an atmel   s    please tell us what settings to try to make it work ,electronics computer-vision wheeled-robot robotic-arm
998,motors response different with high frequency pwm,we are making a junior soccer robot and we just got our brilliant motors from maxon  setting the pwm timer to low frequencies  around   khz or     khz   the robot acts as expected  but this produces some problems    it puts a heavy current on batteries  around    a for   motors which is far too high   the high current causes our motor drivers  l      to heat up very quickly and even heat sinks won t help them  the motors make such a bad sound as they are screaming and this is not normal   in contrast when i configure the timer on high frequencies  such as      khz or       khz  the current drops off to    a which is ideal and the sounds quit down  but this causes a problem that our   motors when set to run on their highest speed  pwm set to      don t run by the same rpm  like one of them runs slower than others making robot turn to a specific side and so our handling functions fail to work correctly  asking someone he told me that the drivers don t respond the same to frequencies thus resulting in different speeds and because on low frequencies the difference is very small i won t notice it but on higher frequencies the difference becomes bigger and noticeable  so is there any workaround for this problem  or i should continue using low frequencies   ps  i m using atmega   as the main controller with a    mhz external crystal   ,pwm avr
999,for servos  can it be implied that  holding torque   operating torque      like with steppers ,i am following a guide that recommends using stepper motors and it has an approximate holding and operating torque  it says that if you don t know the operating torque  it is often half of the holding torque  i am adapting this to use with a servo and i was wondering can this same formula be used with a servo  my servo has approximately  of torque so does that mean that i can estimate the operating torque would be    kg cm  a couple of things   i know operating torque and holding torque are different  this is just a estimate it isn t an exact science  i know servos are harder to find their location     degrees  etc   than to use a stepper and assume that it worked  i have external means of finding the location   ,rcservo stepper-motor
1005,controlling the power of a solenoid,i am trying to control the force of a solenoid  my current system has a bank of capacitors connected to a relay  in order to control the force  how hard i am trying to hit the object  i am increasing or decreasing the the time the relay is on  the problem is this works but it either hits with too much force or way too much force  i can turn the relay on for   ms or more  if i try to turn it on for   ms it does not even respond   i am using a mechanical relay   i would like to have more control on how much of the energy i discharge so i can control how hard soft the solenoid moves  say discharge only    percent of the total energy stored so it hits slower   while searching i found out about solid state relays which according to wikipedia can be switched on an off way faster that mechanical relay  of the order of microseconds to milliseconds   so my question is am i on the right track  or is there something better to achieve what i am trying to achieve  ,control
1006,taylor series expansion for ekf,in probablistic robotics by s  thrun  in the first section on the extended kalman filter  it talks about linearizing the process and observation models using first order taylor expansion    equation      states   i think  is the state estimate from the last time step   my question is  what is     also  the ekf algorithm following this  on table      does not use the factor  anywhere  only    so after being confused about   i m left wondering where it went in the algorithm  ,kalman-filter theory ekf
1011,charging multiple lifepo  batteries at the same time ,i m looking to use   of these    v lifepo  batteries  i intend to have   pairs of   in series in parallel  so two    v battery packs in parallel  because my setup will be run off of this  it will also be easiest to recharge the batteries using the same setup  to accomplish this  i m looking to charge all the batteries at once using this    v lifepo  smart charger  from a simplistic standpoint  the resulting voltage should be correct and this should work fine  however  i know  from a previous question  that lifepo  battery chargers are a bit more complex then a basic voltage supply and check  would the setup i ve described work correctly  and in general  will a lifepo  smart charger be able to charge several batteries of the correct voltage at the same time so long as it doesn t try to charge them at too high an amperage  or does a lifepo  battery also have a minimum amperage cutoff point to charge such that trying to charge more than one battery at a time will cause problems  any other issues i didn t mention  thank you much  ,battery
1014,how would i go about making an art drawing robot like this ,i saw this art drawing robot on youtube   what do i need to learn in order to build something like that  what are some beginner oriented projects that could lead up to building something like this  i m an experienced programmer but i have very little hardware experience  ,robotic-arm
1018,connecting multiple different voltage servos to the same controller,i am using the pololu micro serial servo controller connected to an arduino and multiple other servos    total  to make a robot arm   two of the four servos require     volts  while the other   require      volts  so i am planning on powering all the servos separate from the pololu  i have the arduino and pololu connecting to each other correctly  flashing green led   but the servo s  don t move when plugged in to the control pins   all the servos work correctly when plugged into a servo tester  i think that this problem could be fixed by connecting the grounds of the servos to the ground of the pololu  but would like advice because i am not sure if it will work  or will end up frying one of the parts  we already fried a pololu   would connecting the grounds of the batteries to the ground of the pololu help  or damage the parts    but i couldn t figure out how to show the micro serial servo controller  ,rcservo
1020,how to make an  invisible line following robot  ,i would like to build a robot which follows a virtual path  not a visible path like a  black line on a white surface   etc   i m just enthusiastic by seeing some sci fi videos which show robots carry goods and materials in a crowded place  and they really don t follow a physical line  they sense obstacles  depth  etc    i would like to build one such robot which follows a specific  virtual   path from point a to b  i have tried a couple of things   using a magnetic  hall effect  sensor on the robot and wire carrying current  beneath the table   the problem here was that the vicinity of the hall effect sensor is so small     cms  that it is very difficult to judge whether robot is on the line or off the line  even using series of magnets couldn t solve this issue  as my table is   inch thick  so this idea flopped  p using an ultraviolet paint  on a line  and using uv leds on the robot as sensors  this will give more zig zag motion for the robot  and due to potential threats of using uv light source  even this idea flopped  p  i finally thought of having a camera on top and using image processing algorithms to see whether robot is on the line or diverging  is there any better solution than this  really looking for some creative and simple solutions     ,mobile-robot localization wheeled-robot industrial-robot line-following
1021,looking for a miniature joystick  but in reverse,does anyone know if small mechanical actuators exist which can be controlled electrically  sort of like a miniature joystick  but in reverse   instead of it picking up mechanical movement and outputting electrical signals  i want it to generate mechanical movement controlled via my electrical input signals   i ve searched for   electromechanical actuators  not finding what i need  think of a pencil attached to a surface which can pivot to point anywhere in its half dome   i m thinking small  on the order of an inch   it will not be load bearing   my goal is to programmatically control the normal pointed to by a small flat surface attached to the end of each joystick rod   accuracy is more important than speed   from across a small room  say     by      i d like the surface normal to accurately point to arbitrary objects in the room  say a person walking across the room   if i can cheaply buy build such mechanisms to control the movement of these small flat surfaces  i would like dozens places across the walls of the room  its for an electromechanical sound project i m planning   ,control actuator
1023,servo motor considerations for a quadruped,i m building a quadruped and i m not sure of the features i should be looking for in a servo motor  e g  digital vs analog  signal vs dual bearings  some of the ones i m considering are here ,rcservo walking-robot
1025,cant see kinect data in ros,i am working on this project that involves using the kinect for xbox    s with ros  i did all the steps mentioned in the ros tutorials to have openni installed and the prime sense and other drivers  and when i go to openni samples i see a output  but in ros i do a roscore and in another terminal do a roslaunch openni launch openni launch  and it loads with the regular calibration warnings and service already registered errors  then in another terminal i open rviz which gives a error   rviz display config does not exist  and even though i accept the error and go ahead i see a black window which shows no output  even if i do all tasks mentioned at the rviz tutorials  also i tried running  rosrun image view image view image   camera rgb image color  and it shows up a blank window with no output  how do i resolve this and get ros to show my kinect data   i need to run rgbdslam and use this kinect later  i am on ubuntu       and ros fuerte  well when i launch the openni launch it starts as usual except for the errors  tried to advertise a service that is already advertised in this node  and when i run a rostopic it just says subscribed to the  camera depth registered points and cursor keeps blinking  even subscribing to the rectified topics just says subscribed and nothing more happens  ,kinect ros
1032,how is piv control performed ,i m considering experimenting with piv control instead of pid control  contrary to pid  piv control has very little explanation on the internet and literature  there is almost a single source of information explaining the method  which is a technical paper by parker motion   what i understand from the control method diagram  which is in laplace domain  is that the control output boils down to the sum of   kpp  integral of position error   kiv  integral of measured velocity   kpv  measured velocity   am i correct  thank you   ,control servos pid
1033,what is the actual physical actuated quantity when controlling the position of a servo ,i m trying to learn about servo control  i have seen that the most generic position control method for servos is pid  where the control input is position error  however  i am not sure about what is the actuated quantity  i am guessing that it is one of   voltage applied to the motor current applied to the motor  i am then guessing that the actuated quantity gets turned into one of   torque that the motor exerts angular velocity that the motor runs at  i haven t been able to get my hands on and explicitly control a physical servo so i cannot confirm that the actuated quantity is any of these  i know very little of the electronics that controls the motor  it might well be that the controlled quantities are different for different series servos   my bet is on torque control  however  assume that the servo is holding a weight at a distance  so it is acting against gravity   which means an approximately constant torque load  in this case  if the position error is zero and the servo is at rest  then each of p  i and d components are zero  which means the exerted torque is zero  this would cause the weight to sink  which is countered by the error in its position causing p i components to increase  wouldn t this situation cause the lifted weight to oscillate and balance at a constant position which is significantly different from the goal position  this isn t the case with the videos of servos i have seen lifting weights  or is this the case and friction is smoothing everything out  please help me understand   ,servos pid
1036,web mapping that can be used for autonomous vehicles robots,is there web mapping tool that allows developers to use it to plot gps data of autonomous vehicles robots   forbids it  see      c  google earth terms of use link jumps to the same page  bing maps looks the similar  see      g    what i want is a internet based tool that shows either both satellite images and or map  which can overlay plot using its api  i m making a generic gps plotter on ros that could be used both for slow robots or fast vehicles cars  thanks  ,gps visualization
1037,building a balancing robot with differential drive,i ve already built a two wheeled balancing robot using some continuous rotation servos and an accelerometer gyroscope   i upgraded the servos to some geared dc motors with   bit encoders with the goal having the robot drive around while balancing     i m kind of stuck on how to program it to drive around while still balancing   i think one way would be to just have the control input to the motors act sort of like pushing it   so the robot would be momentarily unbalanced in the direction i want it to travel   that seems kind of clumsy to me though   there must be a better way of doing   i think i need to combine the dynamic model for the balancer with the differential drive but this is a bit beyond the control theory that i know    update  from anorton s answer i have a good looking state matrix now   now about pole placement   the a matrix will will have to be  x  based on the new state vector   and b will then have to be a  x  matrix since i can only control the left right wheel torque  u    x  vector     i may need to read more about this but is there a systematic way to determine the a matrix by pole placement   it seems to me for this example and even more complicated examples  determining a by guess and check would be very difficult    update    after a bit of reading i think i understand it now   i still need the dynamics of the robot to determine the a matrix   once i have that i can do the pole placement using matlab or octave     ,mobile-robot control dynamics
1039,resetting position of e puck in webots using supervisor node   problem with getting a handle to the robot,i am writing a method  java  that will reset the position of e puck in webots  i have been following tutorial on supervisor approach  i have two controllers in my project   supervisorcontroller extends supervisor   responsible for genetic algorithm and resetting e puck s position epuckcontroller extends robot   drives the robot  robots are communicating via emitter and receiver  and everything works fine but the position reset  this is what i m doing in supervisorcontroller   and as a result i get this exception   supervisorcontroller  exception in thread  main  java lang nullpointerexception  supervisorcontroller   at supervisorcontroller initialise supervisorcontroller java       supervisorcontroller   at supervisorcontroller main supervisorcontroller java       epuck variable is null  i tried calling different methods on epuck  and they all resulted in nullpointerexception  the name of e puck matches the world file   def epuck differentialwheels     translation                                  rotation                                         children                      name  epuck    controller  epuckcontroller    axlelength         wheelradius          maxspeed        speedunit            i would appreciate any advice on how to get a handle to the robot or where to look for issues in simulation code  ,mobile-robot simulator
1046,overview   what skills are needed for sensor fusion ,i want to make a list of what knowledge is necessary for sensor fusion  since it has a wide array of possible applications  it is not clear where to begin studying  can we please verify add topics that are in scope  and specify to what extent    digital signal processing   course   probability   course  machine learning   course at coursera from stanford university programming robotic car   course at udacity knowledge of matlab and simulink   tutorials on mathworks webpage and offline help  basic knowledge about integrals  matrices operations  differential equations   ,sensors sensor-fusion
1047,source to learn kalman fusion  explanatory code snippets,currently i am reading a book of mr  thrun  probabilistic robotics  i find it really helpfull to understand concept of filters  however i would like to see some code in eg  matlab  is the book  kalman filter for beginners  with matlab examples  worth buying  or would you suggest some other source to learn the code snippets from  ,kalman-filter books
1049,is it possible to interface android mobile as gsm and gps module with arduino based robotic applications ,i want to built a robot and i need bunch of modules to track it like gsm gps wifi and camera if i try to buy each of module separately it will cost me     dollar each aprox in pakistan  on the other hand an android enable phone can be purchased on just      having all of them  i was wondring if it is possible to interface android phones like  huawaii or google nexus  with   bit microcontrollers or arduino  the only port available with android phones are usb and arduino supports usb  it is possible to some how attach both of them  ,arduino usb
1050,how do space rovers survive at very low temperatures ,for example  if a rover has working temperature range of     to      celsius  how does it survive and then restore itself if the temperature drops to      degrees for several months  ,electronics ugv reliability
1051,what are human friendly terms for mobile robot orientation and relative direction of non robot objects ,within robotics programming  orientation is primarily given in terms of x  y    z coordinates  from some central location   however x  y  z coordinates aren t convenient for rapid human understanding if there are many locations from which to select  e g                                                          is not particularly human friendly  and is highly prone to human error    yet more common english orientation descriptors are frequently either too wordy or too imprecise for rapid selection  e g     front facing camera on robot   s right front shoulder  is too wordy  but  front    forward  is too imprecise   is the camera on the leading edge or is it pointing forward   in the naval and aeronautical fields vehicle locations are generically talked about as fore  aft  or stern   port  and starboard  while  direction of movement that is relative to the vehicle is frequently given in reference to a clockface  e g   forward of the the fore would be  at      rear of the aft would be  at     while right of starboard and left of port would be  at    and  at     respectively    this language supports rapid human communication that is more precise than terms such as  front  and  forward    are there equivalent terms within mobile robotics  ,mobile-robot control design localization navigation
1056,perfecting tripod gait   building a r hex robot,i need help with figuring out the following things  i m developing a hexapod r hex type model with a tripod gait  however  the angles obtained during the robot s walking in real life are not perfectly aligned  because of this the robot often collapses and falls even on perfectly straight terrain  my configuration is       rpm dc motors for each leg h bridge motor drivers for each dc motor atmega    should i change the gait type  or is tripod sufficiently stable  are dc motors providing fine enough control or do i need servos  do i need a dc motor with an encoder   what will be its benefits  what could be done to improve performance of the robot  added  would a stepper motor work as well  instead of a servo  ,motor wheeled-robot gait
1060,self learning maze solving robot using  bit microcontroller ,i want to know if there is best algorithm and technique to implement self learning maze solving robot in   bit limited resource micro controller  i was looking for some well optimized algorithm and or technique  maze can be of any type  of course first time it has to walk all the way and keep tracking obstacles it found   i think best technique would be neural networks but is it possible to do this in such a short resources of  bit  any example online with similar kind of problem   my wall detection is based on units  well  i have counted the wheel turns and it is almost     accurate in integers  for sensing the walls ultrasonic range finding is used  wheel can remeber its current position in let say    feet staight    feet right  etc  ,algorithm machine-learning mapping micromouse
1064,prototyping a device with        small dc    v motors  is arduino a good fit ,i want to prototype a therapeutic device that will have a lot of tiny mobile phone type vibration motors like this one in it  and i want to be able to activate them in any configuration i want   i m going to need analogue control  and support for logic like perlin noise functions and so on   i m not really going to need sensor data or any other kind of feedback beyond a few buttons for control   i just need fine control over lots of little motors   depending on what results i can get out of  say     motors on the initial prototype  i may decide that i m done  or that it needs more motors   i also don t have an enormous budget  so the question is  is arduino a good fit for a project like this   is it feasible to get that many motors working off the same controller   i know some of the arduino boards have up to    something serial outputs  but from what i can tell  that may only translate to    or so motors  so i d need a way to extend the board with more serial outputs if i wanted to try more  additionally  if arduino isn t a good fit  what would be better   could i try something directly out of a serial port on my pc   i ve never tried to home cook a robotics application before  so i m not really aware of the options  ,arduino motor
1066,how to invert d h parameters,i currently have a working kinematic chain made by a set of ten links in d h convention  with usual parameters       but my task currently requires the inversion of some of them  basically  i would have a part of the chain that is read from the end effector to the origin  using the same links  and thus the same parameters   is it possible  how to do so   please notice that this is not related to the inversion of the kinematic chain  it s more basic  i want to find the dh parameters of the inverted forward kinematic chain  let s put it simple  i have dh parameters for a   link planar chain from joint   to joint    so i can compute its direct kinematics  but what if i want to compute the direct kinematics from joint   to joint    given dh parameters      i can retrieve the transform matrix with this formula   this is the transform matrix from the i th link to the  i    th link  thus  i can invert it to obtain the transform matrix from the  i    th link to the i th link  but the problem is that this is not working  i believe that the reason is related to the fact that the dh convention doesn t work any more as it is  any help  ,control inverse-kinematics kinematics
1068,mindsensor motor multiplexer jump on run unlimited,i am trying to run a nxt motor using the mindsensors motor multiplexer at a slow speed   when i turn it on  it tends to jump approx    to    degrees before moving at a slow speed   has anyone seen this behavior  i am using nxt     with firmware down loaded from    sample code in nxc  i am using bricx command center as my ide  is as follows  mmx run degrees  sensorport  addr  mmx motor    mmx direction reverse       mmx speed slow       mmx completion wait for  mmx next action brake   wait        mmx run unlimited  sensorport  addr  mmx motor   mmx direction forward         the jump happens here  while sensor in     sensorthreshold    ,nxt mindstorms not-exactly-c
1069,is there a way to use a single dc motor output for two different loads ,is there a way to use a single dc motor output for two different loads  by using gears  relays etc    please see the illustration below   to clarify the illustration  i get the dc motor power at  output    gear which is extended over an idler gear to output   gear  all three are in contact  though the picture doesn t quite show it   load   and load   are two separate gears connected to different loads  wheels etc  and initially not in contact with the bottom gears  on switching on the relays        the load bearing gears  move towards the output  and output  and mesh with them to drive load       ,motor
1072,is it possible to make kite flying robot ,this question was asked in electronics stackexchange  i want to know if is it possible to make a robot that can fly kites  is this idea practical  i was thinking that making a kite is just like making some flying quadcopter or helicopter  i just want to know is this idea really implementable   is there an example or similar work in reference to this       ,control quadcopter radio-control
1074,how to assemble brushless motors and propellers ,i m building a quadcopter and i ve received my motors and propellers  what s the right way to assemble those together  i m not confident with what i ve done  as i m not sure the propeller would stay in place on a clockwise rotating motor  i mean  if the motor rotates clockwise  will the screw stay tightly in place  even with the prop s inertia pushing counter clockwise  here s what i ve done  of course i ll tighten the screw        ,brushless-motor
1078,how do i measure the distance that a cord  string  has moved ,for a pet project  i am trying to fly a kite using my computer   i need to measure how far a cord extends from a device   i also need to somehow read out the results on my computer  so i need to connect this to my pc  preferably using something standard like usb  since the budget is very small  it would be best if i could get it out of old home appliances or build it myself  what technology do i need to make this measurement  ,wheel usb encoding
1082,stabilizing a robot arm at a specified height,i have a   bar linkage arm  or similar design  for a telerobot used in the vex robotics competition   i want to be able to press buttons on my ps  style controller to have the arm raise to certain angles   i have a potentiometer to measure the   bar s angle  the potentiometer measures the angle of one of the joints in the shoulder of the mechanism  which is similar to this   what type of control should i use to stabilize the arm at these angles  ,mobile-robot control arm
1083,assigning frames and deriving link parameters,the textbook i m using doesn t have the answers to the practice questions  so i m not sure how i m doing  are the following dh parameters correct given the frames i assigned  the original question is as follows  the arm with  dof shown below is like the one in example      except that joint   s axis is not parallel to the other two  instead  there is a twist of    degrees in magnitude between axes   and    derive link parameters and the kinematic equations for   where b means base frame and w means wrist frame   link parameters   begin array  ccc      const           and                                   angle           distance                          i    alpha  i       a  i       d i    bf  theta i                                              theta                               l                 theta                               l                 theta            end array  frame assignments   ,inverse-kinematics kinematics forward-kinematics
1086,increasing the rotation range of a servo motor,how do i increase the rotation range of a standard servo  most servos have a rotation range of       degrees  i would like to access the entire     degree range on the servo  partially because i would be attaching the servo s shaft to the robotic wheel and would like it to be able to make full rotations  or is that not possible   i would not like to however lose the  encoder  part of the servo which allows me to clearly specify which angular position the wheel should stop at   if i use gears in order to transform this system range  would it lead to loss of precision  in addition  would such a transform allow the wheels to continuously rotate in one direction  from what i understand  this won t work  would a stepper motor with an external encoder or a dc motor with an external encoder work  ,motor rcservo
1089,how to perform this reference system transformation ,i have two quaternions that indicate the initial orientation of a four wheel robot  each one in relative to one reference systems   the robot s orientation given by a quaternion q is not the same in the two reference systems  for one reference system the quaternion q  might refer to the robot looking at positive x while the same quaternion components q  in the second reference system might refer to the robot looking at the negative x  i have two matrices which indicate the position of the robot in time in its correspondent reference system  i want to find the correspondent points of the first matrix in to the second reference system  each matrix is built with a different sensor  so the results will be similar but not exactly the same  i think i should find the transformation from the first reference system to the second and then apply it for each point of the first matrix  how can i find this transformation  the translation part i think is clear  but the rotation not at all  edit   wildcrustacean the solution proposed does not solve the problem  i think that the reason is because each system represents the robot in a different way   in the initial one  a  the robot moving forward with no rotation would increase in the x axis  in the goal referential system  b  the robot moving forward with no rotation would increase in the z axis   see figure for more details    i think i have to apply an extra rotation to change the initial quaternion that belongs to the first system to be in accordance with the second system before applying the transformation of your post  one rotation of     degrees around x followed by one of    around y  would rotate from a to b  this is how i tried to solve it    quaternion to adjust reference system first quat   make quaternion unitary x  pi    generates the quaternion that rotates pi around x  second quat   make quaternion unitary y  pi        generates the quaternion that rotates pi   around y  composed fs q   first quat second quat     quaternion to rotate from one reference system to the other quaternion ini a   quaternion ini a composed fs q a b quaternion   quaternion ini b  quaternion ini a inverse     a b quaternion is the quaternion that i use for the rotation but still doesn t perform the right rotation  any idea  ,mobile-robot localization odometry
1091,python libraries for image processing and feedback control on raspberry pi,i m building a motion detection and object recognition camera with feedback control for a hexy robot  fortunately most of the servo control is handled by the analog servo controls and the high level logic can be implemented in python on a raspberry pi  what s the right combination of python modules to implement   a daemon service to trigger and execute image capture and processing a daemon service to regularly update the hexy with the latest motion plan and servo setpoints the image processing for recognition and tracking of objects from the webcam  i m currently using python daemon for the services and comparing the various pypi opencv libraries to see if any of them look promising  anyone have experience with these on a raspberry pi or arm processor in a robotics application    remotecv                    remotecv is an opencv server for face recognition ctypes opencv               ctypes opencv   a python wrapper for opencv using ctypes pyopencv                    pyopencv   boost python and numpy opencv cython               an alternative opencv wrapper cvtypes                     python opencv wrapper using ctypes tippy                       another toolbox for image processing  based on opencv  these each depend on a deep list of low level libraries and or compilers like boost  numpy  gfortran or cython  gcc or ctypes  i m concerned about compatibility and performance of these lowlevel libraries on raspbian and an arm processor  anyone with a known working architecture for image processing and real time control in python on an arm processor will get their answer upvoted and or accepted  ,raspberry-pi real-time
1092,numpy alternatives for linear algebra and kinematics in python ,are there any decent python numerical package libraries besides numpy for python  numpy relies on gfortan which itself must be compiled correctly for your platform to avoid hidden insidious numerical errors in numpy   i need a matrix algebra package to do kinematics  path planing  and machine learning in python that isn t sensitive to  gfortran version and compiler options  ,kinematics python
1097,at which stage should filtering be applied to the sensors data ,shall i filter  kalman lowpass  after getting the raw values from a sensor or after converting the raw values to a usable data  does it matter  if so  why   example  filter after getting raw values from imu or  filter after converting raw values to a usable data eg  flight dynamics parameters  ,kalman-filter imu
1100,why are industrial machines called robots ,the definition of a robot is as follow   a robotic paradigm can be described by the relationship between the three primitives of robotics  sense  plan  and act   an example could be the famous  kuka robots   the kuka robot is preprogrammed and does mainly one loop over and over again  some of them could have measurement sensors but that is all  they do not think or plan nor do they make decisions   an automatic door opener  used in a building is not a robot either but according to the robotic paradigm definition they are more a robot than a kuka machine  they actually get some data from a sensor followed by planning and acting   so why are kuka machines called robots  ,industrial-robot
1110,robots minimum distance,i am trying to implement a mechanism to make robots avoid being too close  say in a distance less than    i am not familiar with those systems and i have to implement a strategy to avoid robots being too close to each other  could anyone recommend me some readings for such a problem or a set of keywords to search for  i don t know yet how to start  ,algorithm movement
1113,torque in kg cm ,i was looking up the motor parameters for some stepper motor where they listed the torque of the motor at different current voltage but the torque they listed was in kg cm  how is kg cm even a remotely acceptable unit for torque  how do i calculate the torque in nm from kg cm  clarity note  its not kgcm which represents        kilogram force     nm   website where this happens  ,stepper-motor torque
1117,how to obtain stereo correspondences and what exactly is a disparity map ,i am currently reading into the topic of stereo vision  using the book of hartley zimmerman alongside some papers  as i am trying to develop an algorithm capable of creating elevation maps from two images  i am trying to come up with the basic steps for such an algorithm  this is what i think i have to do  if i have two images i somehow have to find the fundamental matrix  f  in order to find the actual elevation values at all points from triangulation later on  if the cameras are calibrated this is straightforward if not it is slightly more complex  plenty of methods for this can be found in h z   it is necessary to know f in order to obtain the epipolar lines  these are lines that are used in order to find image point x in the first image back in the second image  now comes the part were it gets a bit confusing for me  now i would start taking a image point x i in the first picture and try to find the corresponding point x i  in the second picture  using some matching algorithm  using triangulation it is now possible to compute the real world point x and from that it s elevation  this process will be repeated for every pixel in the right image  in the perfect world  no noise etc  triangulation will be done based on  in the real world it is necessary to find a best fit instead  doing this for all pixels will lead to the complete elevation map as desired  some pixels will however be impossible to match and therefore can t be triangulated  what confuses me most is that i have the feeling that hartley zimmerman skip the entire discussion on how to obtain your point correspondences  matching   and that the papers i read in addition to the book talk a lot about disparity maps which aren t mentioned in h z at all  however i think i understood correctly that the disparity is simply the difference x  i  x  i  is this approach correct  and if not where did i make mistakes  ,computer-vision stereo-vision
1120,has a robot ever taken a complete iq test ,and if so  what was the highest score so far  some news articles suggest only parts of tests were aced   update since people censored this question and closed it  there was an ai that has taken an iq test and scored similar to a   year old    the ai system which they used is conceptnet  an open source project run by the mit common sense computing initiative    results  it scored a wppsi iii viq that is average for a four year old child  but below average for   to   year olds  abstract  we administered the verbal iq  viq  part of the wechsler preschool and primary scale of intelligence  wppsi iii  to the conceptnet   ai system  the test questions  e g    why do we shake hands    were translated into conceptnet   inputs using a combination of the simple natural language processing tools that come with conceptnet together with short python programs that we wrote  the question answering used a version of conceptnet based on spectral methods  the conceptnet system scored a wppsi iii viq that is average for a four year old child  but below average for   to   year olds  large variations among subtests indicate potential areas of improvement  in particular  results were strongest for the vocabulary and similarities subtests  intermediate for the information subtest  and lowest for the comprehension and word reasoning subtests  comprehension is the subtest most strongly associated with common sense  the large variations among subtests and ordinary common sense strongly suggest that the wppsi iii viq results do not show that  conceptnet has the verbal abilities a four year old   rather  children s iq tests offer one objective metric for the evaluation and comparison of ai systems  also  this work continues previous research on psychometric ai     update  a robot has passed the japanese college entrance test and has an     chance of being accepted  since it scored more than the average  that would make the iq        especially since college applicants have an iq greater than average  and especially since japanese are smarter than average humans    the wall street journal reports that the program  developed by japan s national institute of informatics  took a multi subject college entrance exam and passed with an above average score of     points out of a possible       the national average is       with scores like that  it has an   out of    chance of being admitted to     private institutions in japan  and    national ones   ,artificial-intelligence
1128,why is this electro motor going slower ,from an old dust buster i ve got this electro motor  the included battery pack and the charger    i ripped everything apart  the dust buster was broken  and the motor still works  after playing around with it for a while and letting it lying around for about two weeks it suddenly revs a lot slower  i supposed the battery pack was drained so i hooked up the battery pack to the charger and let it charge for a night  unfortunately the motor still turns very slow  since i want to use this motor for my first home robotics project  making a kite fly with my computer   off i went to the local electronics store where they measured the charger to give   v  even though it says   v  and the battery pack to give about  v  i then hooked up the motor directly to the charger  but unfortunately it doesn t even move an inch then  so now i wonder   why doesn t the motor spin at all when hooking it up to the charger   could that be because the    ma is too low   why doesn t the battery pack charge at all   this bothers me the most    all tips are welcome  ,motor battery
1130,what is the name of this mechanical linkage , i am trying to find a joint like these for a robot i m building  it is often called a swivel joint or a universal joint  but with a modified spider  i can t find one anywhere and would prefer not to make it  searching for  universal joint  returns the standard automotive type  any help would be appreciated ,joint
1132,how should i choose an educational robotics kits for beginner programmers ,i am a high school student  doing a research project in ai and robotics  how should i choose a robotics kit  for example  will it be better to learn the basics by using a hexapod or robotic arm   i know c at good level  ,arduino artificial-intelligence beginner
1143,how do i interface a tlc     with small motors ,this is a follow up to this question   prototyping a device with        small dc    v motors  is arduino a good fit  i ve decided based on the answer that sending the control signals through multiple tlc     chips  then sending the pwm signal to the motors is the best way to go   what i need to know is how to turn the pwm signals into something of the required power  since the tlc     s won t be able to drive the motors by themselves  i m guessing an amplifier is what i ll need to make  but what s the best way to boost that many signals  ,motor power pwm
1145,what would be the best way to handle food grains ,i m trying to handle food grains like rice  wheat in an automated way  to cook simple dishes   for this i have to transfer grain from a larger container to a weighing scale  i know i can use solenoid valves for liquids but all solid handling valves seem to be too big  gate valves etc  and for larger applications  is there any better way to do this    ,automatic
1148,dynamic programming algorithm aka bellman equation in robotics ,the dynamic programming algorithm refers to the bellman equation  an open loop control decides movement at the initial point while a closed loop control decides control during the movement  now most robotic application looks like closed loop control  in every point  it checks how it is doing with respect to some reward function  this is my thinking  now most participants in threads such as how mature is real time programming in robotics  do not differentiate their scope  perhaps they haven t thought about it  anyway  i am interested to know  how is dynamic programming used in robotics  is there any research about dp usage in robotics  ,research dynamic-programming
1153,when should fpgas be used in robotics ,fpga has good points such as a lot of io points but then again you need to think things on very low level with flip flops and pioneer on areas where things are not yet mature    for example see this question here about development tools on fpgas    this is my understanding currently  now fpga has been used to create excellent dexterity in robotic hands like here  now some people market fpga for fast prototyping and  forward looking  designs like here  i don t fully understand them  if you don t need a lot of io points for things such as sensors  why to choose fpga for a robot  so when should fpga be chosen for a project in robotics  ,design research logic-control
1158,equation to limit rate of change of end effector in x and y coordinates,some vector math is involved here so prepare yourself  i am developing a robotic arm that moves in two dimensions   it is a rotary rotary design which looks roughly like the picture in this post  building robotic arm joint i am now trying to limit the speed of the end effector   i am using simulink and believe that the best way to limit the speed is the limit the rate of change of the x and y coordinates that i tell it to move to    now  i also want the end effector to be able to move in a straight line and believe that i can accomplish this by defining functions that calculate the maximum rate for movement in the x or y direction based on the distance the arm is trying to travel   the equasion i came up with is this    so basically  xrate  distance in x   max between distance in x and distance in y   now  for the actual problem   because this limits the speed in both x and y  the end effector can travel  for instance    in  sec in both directions at the same time   meaning that it is travelling at over   in  sec overall   if  however  it is only moving in one direction then it will only move at that   in  sec speed because there is no second component   it boils down to the fact that the max speed the arm can move is  sqrt     and the minimum is      my main question is   given that i need to calculate a max xrate and a max yrate  how can i limit the overall speed of the end effector  secondarily  is there a way for me to implement a rate control that will limit the overall rate instead of limiting x and y independantly using simulink  ,design
1160,can i use the raspberrypi to receive the gamecube remote s rf signals ,i have an old gamecube that doesn t work and i want to gut it and fill it with arduino boards and or raspberry pi if necessary   i want the project to eventually have some kind of ai aspect  but i m also toying with the idea of using a wireless gamecube remote and wavebird to issue commands at the push of a button    i guess this would be mostly good for testing purposes  but i m mostly curious if and how i would go about making my raspberrypi understand gamecube remote input   furthermore  would this kind of idea be feasible  ,control arduino raspberry-pi
1163,how to know when a li po battery is discharged ,i m building a quadcopter and i ve seen that a li po battery must not be entirely discharged  otherwise it could damage it  how do you know when you have to stop your quadcopter or robot in order to prevent damages  since the voltage doesn t drop  which part should control the battery charge  escs  bec  flight controller  ,battery
1167,can the rate of peristaltic pump s flow be accurate across changes in fluid viscosity ,i m building an arduino controlled pump system to be able to move fluids around  i need this to be fairly accurate  but extreme precision isn t required  since there will be a variety of liquids moved through the pump  i ve determined a peristaltic pump the best fit  but i don t think i fully understand them  and had a few questions    since i ll need to purge the system    can a peristaltic pump push air  let s assume you have a  m of tubing  and you pump a bunch of water through it  can you remove the tube from the water reservoir so it is open to the air  and effectively purge the system of any remaining water  since i want to fairly accurately measure flow  could i simply count milliseconds instead of using a flowmeter      will a peristaltic pump always pump at a constant rate  regardless of the viscosity of the fluid  that is  will maple syrup come out at the same rate as water  shopping question  ignore i suppose     anyone know where i may find a fast high flow peristaltic pump  i m looking to be able to pump  at a minimum    oz sec would be determinant upon        what sort of relay would i want for toggling this on off with an arduino   ,arduino
1170,where does gazebo set the gazebo model path environment variable ,i m starting out with gazebo       at the moment and am following a tutorial off the internet  in order to get gazebo to find the model  the author advocates manually exporting the  environment variable via  export gazebo model path       models  ld library path  export ogre resource path  usr lib i    linux gnu ogre          this line is needed while we re relying on ros s urdfdom library export ld library path  opt ros fuerte lib home  gazebo models  so it must be set somewhere  i guess i could probably simply add gazebo model path to the setup sh script  but since it is set somewhere  i d still like to know where and whether it is better practice to set it in there  ,gazebo
1174,pid tuning to make my balancing robot better,see the video below of my balancing robot  balancing robot i was having trouble getting it to balance on hard surfaces but finally got it after playing with the pid gains a lot   previously it was balancing just fine on carpet    i set the pid gains by just picking a kp  then increasing ki until the robot oscillated very badly and tried to smash it s self into the ground   then increasing kd until it was finally stable  here s the gains i m using in the video   it will sit in one spot balancing without any problem   you can see in the video that it can even stop from falling after i give it a pretty good kick   the problem is that it stops from falling over but then greatly overshoots the other direction   in the video you can see when i give it just a small tap it runs the other way for a while before finally becoming stable again    any suggestions on what to try next  ,pid
1175,minimum speed controller refresh rate,in a quadrotor we need to change each motor s speed depends on its position in space  more frequency will result more stability   i mean if we can change motor s speed     times per second instead of     times per second we may stabilize our uav quadrotor far better    now my question targeting people who made a uav quadrotor before or have any information about escs  i wanna know whats the minimum refresh rate for escs in a quadrotor to make it stable   for example may an esc with   hz refresh rate enough for stabilizing quadrotor or not   i m asking this question because high speed escs are more expensive than lower speed ones  i have this one  may it work   ,quadcopter esc
1178,how can i calculate processing speed of microcontroller,i need a microcontroller that can process minimum  mb data per second  how do i determine what processors will be able to do this  also how can i calculate the processing speed in per second of any microcontroller  i am very much scared with my college project and i need help  ,microcontroller
1180,information filter instead of kalman filter approach,i read many sources about kalman filter  yet no about the other approach to filtering  where canonical parametrization instead of moments parametrization is used   what is the difference   other questions   using if i can forget kf but have to remember that prediction is more complicated link  how can i imagine uncertainty matrix turning into an ellipse   generally i see  area is uncertainty  but i mean boundaries   simple addition of information in if was possible only under assumption that each sensor read a different object   hence no association problem  which i posted here  ,kalman-filter algorithm sensor-fusion
1181,object level sensor fusion for multiobject tracking,i want to fuse objects coming from several sensors  with different  sometimes overlapping   fields of view  having object lists  how can i determine whether some objects observed by different sensors are in fact the same object  only then i can truly write an algorithm to predict future state of such an object   from literature i read those   steps   plot to track association  first update tracks estimates and then associate by  acceptance gate  or by statistical approach pdaf or jpdaf  track smoothing  lots of algorithms for generating new improved estimate  e g   ekf  ukf  pf  track initiation  create new tracks from unassociated plots  track maintenance  delete a track if was not associated for last m turns  also  predict those tracks that were associated  their new location based on previous heading and speed   so basically i am questioning point    acceptance gate  for a single sensor i can imagine it can be just a comparison of xy position of object and sensor measurement  velocity with heading eventually  my case is however  i have already ready object lists from each sensor in every cycle  there are some algorithms how to merge informations about an object collected by different sensors  great source is e g  here     but question is how to decide which objects should be fused  and which left as they were  fields of view may overlap partly  not totally  ,kalman-filter algorithm sensor-fusion
1182,shedding light on  cyber physical systems ,these days  one often hears of cyber physical systems  reading on the subject  though  it is very unclear how those systems differ from distributed and or embedded systems  examples from wikipedia itself only make them look more like traditional distributed systems  for example   a real world example of such a system is the distributed robot garden at mit in which a team of robots tend a garden of tomato plants  this system combines distributed sensing  each plant is equipped with a sensor node monitoring its status   navigation  manipulation and wireless networking   obviously  any distributed system consists of sensing  actuations  which can easily include navigation  and networking  my question is  how exactly does cyber physical systems differ from traditional distributed systems  is it just a fancy name  or is there something considerably different with it  ,distributed-systems embedded-systems
1192,fastest maze algorithm for robot,i m planning on programming a prebuilt robot to solve a maze as fast as possible   the robot has forward obstacle sensors  no side sensors  and   axis accelerometer   i m planning on using the wall following algorithm   is this the fastest possible algorithm   also  since there are no side sensors  the robot needs to continuously turn to check if there is a wall on its side  so is there a clever way to use the accelerometer and sensors  ,mobile-robot
1195,where can i get a  poster size of mars exploration rover spirit opportunity ,i am looking for a  size poster of mars exploration rover spirit opportunity for robotic education    gives a little postcard size of the mer along with its components on board when you buy the toy  but this is not large enough for classroom purpose  does anyone know where to buy a  size poster of these mer for robotic education  ,wheeled-robot
1198,dynamic braille interface,i m a newbie in robotics  and i m doing a project on dynamic braille interface  basically it s a     array of pins  which can be either totally up or down  how to use least motor as possible  i m thinking of using arduino for easy interface with computer  ,design
1200,what is the wire used for hand movement of robot called   where can i find it online  ,i am looking for a specific name of the wire used for the robotic arm movement control and where can i find some of this online  i want to control it using the micro controller so please suggest some good development kit  ,microcontroller robotic-arm movement
1202,problem with vibrations in air bearing,we have an air bearing for a planar xy motion  today it consists of four pockets according to picture    in the current design there are no sealings around the peripheries of the pockets and we suspect that is the reason we get vibrations   in the current design we control the pressure  same for all for recesses  the flow is adjustable individually for each recess  in practice it is very hard to tune it  for the non recess surfaces we have used slydway as we need to be able to operate it without pressure occasionally  to try to solve the problem we plan to develop a prototype where we can try out the effect of using sealings around the periphery of the pockets  the idea is something like this   questions  is the idea with adding sealings good   sanity check  suggestions for sealings   i m thinking a porous material like felt or cigarette filter   of course all suggestions are welcome   edit i m going to try and add grooves around the recesses to evaquate the air that leaks  my thinking is that this will give us a more defined area under pressure  ,linear-bearing
1205,plastic shaft supports,i would like to prevent a shaft from being pulled through it s bearings   that is  press a plastic ring around it on either side   what are these rings called  they re not bearings or hubs   and where can i find them  ,mechanism
1207,read multiple channels of rx tx with arduino,i have a   channel rf rx tx and want to connect   motors to it   i am able to connect channel   with motor   but unable to connect channel   with motor   simultaneously with arduino  here is the code i am currently using   ,arduino
1209,how to stabilize a quadcopter,today was my quadcopter s first  flight   i m running megapirate on a crius aiop v  with a turnigy talon v  frame  i only touched the throttle stick on my remote  nothing else  when i felt the quadcopter was about to take off  i pushed the throttle just a little bit more  and the quadcopter oscillated   or   times and the just flipped over  landing on the propellers  so  i broke   props  my frame feels a bit loose  i ll probably have to tighten the screws  i hope      how can i tune the software so it will stabilize nicely after take off  edit   i don t know if it was true oscillation or just random air flows making it unstable  i made some more tests yesterday and it was quite ok  even if i crashed a few times   this time  it was really oscillating but it was quite windy outside and the quadcopter managed to stabilize after all  so i ll probably have to tune my pids and find a way to do it without crashing  edit     after some pid tuning  i managed to stabilize my quadcopter pretty well but it s still oscillating just a little bit  i guess i ll have to slightly change the values to get a perfect stabilization  ,quadcopter stability
1211,what kind of sensor do i need for knowing that something is placed at a position ,i have a small device that s picking up small rocks from a pile and moving them to another place  its a kind of crude way of trying to push the whole pile onto a bigger gear and hoping one of them are pushed to one of the spaces between gears and taken around and falls off on the other side of the spinning gear  here i want to know if the machine successfully got a rock here  if not it should spin the gear until it turns up a single rock on the other side of it  if a rock is present at the spot  the gear should stop spinning until the rock is taken care of by the rest of the machine   what kind of device can i use to sensor if i successfully succeeded in getting a rock on the other side of the gear    this is just a part of a bigger system  to sum up  i need the sensor to signal when a rock is signalled out and separated from the rest so it can continue work on that single rock  i am building this using an ardiuno to move the gear around  so the sensor need to be something that can be controlled by an arduino ,motor sensors
1214,space elevator  what is still needed  apart from the cable and propulsion ,in order to build and operate a space elevator moving crafts and people into space  there are two big challenges that have not been solved yet   finding a cable with enough tensile strength  moving stuff along the cable at a reasonnable speed   apart from those two ones  what are the other technical challenges to solve  especially things that do not exist yet in robotics  and need to be invented  ,mobile-robot research
1218,how do i adjust objects on a conveyor belt into the proper orientation ,this is part two of my larger robot  it follows up what happens with the small rocks here  what kind of sensor do i need for knowing that something is placed at a position  now i am taking the rocks down a tube for placement  in the case they need to be altered so they always will stand up before they enter the tube  obvioulsy a rectangular rock wont fit if it comes in sideways  the dimensions here are pretty small  the rocks are about    mm x    mm  the tube i use is actually a plastic drinking straw  and the material i use for the rest of the robot is lego powered by step motors which draw the conveyor belts to move the rocks  the control is arduino    sorry for the lousy illustration  if you know a good paint program for mac like the one used to draw the picture in my other post  please tell me      the rocks will always enter one at a time and have as much time they need to be adjusted to fit and enter the tube so the fall down  the question is  how to ensure all rocks are turned the right way when they get to the straw  im not sure if using lego when building the robot is off topic here  but a solution involving lego is preferable  and it has to be controlled by an arduino   general tips in how to split a complex task into subtasks robots can do is also good  is there any theory behind the most common sub tasks a job requires when designing multiple robots to do it  ,arduino motor microcontroller motion
1219,drone targeting,imagine a  drone  and a target point on a  d plane  assuming the target is stationary  there are eight parameters   the drone s job is to get to the target as fast as possible  obeying max torque and max thrust  there are only two ways to apply the torque  since this is only in a  d plane  thrust is restricted to only go in one direction relative to the orientation of the craft  and cannot be aimed without rotating the drone  neglect any resistance  you can just pretend it is floating around in  d outer space  let s say the drone checks an equation at time interval t  maybe something like every     seconds   plugs in the parameters  and adjusts its torque and thrust accordingly   what should the equations for thrust and torque be   what have we tried  we know that the time it takes for the drone to reach the target in the x direction has to be the same for the same time in the y direction  there is going to have to be some integral over time in each dimension to account for the changing thrust based on total thrust  and total thrust in each direction given the changing angular position  i have no idea how to tie the torque and thrust together in a practical way where a function can just be called to give what thrust and torque should be applied over the interval t unless there is some other technique  ,design algorithm kinematics navigation
1221,quadrotor control using arduimu,we are using arduimu  v   as our quadrotor s inertial measurement unit   we have a separate board to control all motors  not with arduimu itself    as mentioned here   the output rate of this module is only at about  hz   isn t it super slow to control a quadrotor   i m asking because as mentioned in this answer a quadrotor needs at least    hz of control frequency to easily stay in one spot  and our escs is configured to work with    hz of refresh rate  any working pid controller i saw before for quadrotors used at least        hz of control frequency  i asked similar question before from ahmad byagowi  one of the developers of arduimu   and he answered   the arduimu calculates the dcm matrices and that makes it so slow  if   you disable the dcm output  you can get up to     hz gyro  acc and so   on   so  what will happen if i disable dcm from the firmware   is it really important   we did a simulation before and our pid controller works pretty well without dcm  ,arduino quadcopter imu pid
1227,connecting more than six analog input pins to arduino,i m in the planning stages for a project using the arduino uno to control   distance sensors  and have run into a little road block  the uno only has six input pins  so i m wondering  is there any way for this to work  if so  how  ,arduino microcontroller input
1229,limits of pwm  timers and interrupts ,i have a robot with two wheels motors and each has a quadrature encoder for odometry   using the wheel motor encoder combo from pololu  i get    transition changes per rotation and my motors give me a max of    rpm   i ve found it seems to miss some of the encoder state changes with the pololu wheel encoder library  would i run into issues or limitations on my arduino uno using interrupts to track the quadrature encoders while using pwm to drive my motors through an h bridge chip    ,arduino pwm encoding interrupts
1232,how can i use the arduino pid library to drive a robot in a straight line ,i would like to create an arduino based robot with   wheels  quadrature encoders on each wheel  a h bridge driver chip  or motor controller  and a caster   i want to use the pid library to ensure the speed is proportional to the distance to travel    at a conceptual level   assuming the motors do not respond identically to pwm levels  how can i implement the pid control so that it travels in a straight line and at a speed proportional to the distance left to travel   ,arduino pid driver encoding
1235,how does rocker bogie keep the body almost flat ,how does rocker bogie mechanism keep the body flat   keep the solar panel almost flat all the time  i know there is an differential system that connect both rocker bogie  left and right  together  but how does it actually work  edited  please provide relevant references  ,wheeled-robot
1246,using an xbox controller to fly a quadrocopter,so i have a quadrocopter  it does come with a remote but i intend to run certain modifications to the copter  like installing a camera  a mechanical manipulator  and other random modifications  the remote that comes with the copter isn t flexible enough to help with such functions and plus it lacks any more buttons   i was wondering if i could somehow program the quadrocopter to respond to my xbox controller  i was planning on using my laptop s bluetooth connection to talk to copter  the xbox controller which is connected to the computer would be then used to control the quadrocopter  so my question is  how exactly do i program the controller  how do i go about making all of this possible   i understand this question is really vague and that there are too many options out there  but i do need help figuring this out   ,quadcopter
1249,would the strength and speed of a robot skeleton be a danger to its wearer ,expanding upon the title  i am querying the use of robotic skeletons to augment human strength and speed  if such a robot had the capacity for example to bear weight   times heavier than the wearer and move its robotic limbs twice as fast as the wearer  is there not a danger because such powerful and sharp movements could break their bones and seriously injure them because it moves beyond their human capabilities  the robots means of producing movement i would think is important here but unsure how so  the nature of passive or actively powered movement and when each mode is used will also determine performance of the exoskeleton  i am not well versed in this area so will appreciate any feedback  ,mobile-robot
1253,what is the difference between task level and joint level control systems ,while doing a literature review of mobile robots in general and mobile hexapods in particular i came across a control system defined as  task level open loop  and  joint level closed loop  system   the present prototype robot has no external sensors by   which its body state may be estimated  thus  in our simulations and experiments  we have used joint space closed   loop   proprioceptive   but task space open loop control   strategies   the relevant paper is a simple and highly mobile hexapod what is the meaning of the terms  joint level  and  task level  in the context of the rhex hexapod  ,mobile-robot control walking-robot hexapod
1257,how can i get windows kinect working on angstrom on beaglebone ,i have tried following a number of guides on the internet but most of them fall down as libfreenect does not exist in opkg  which is the apt get of angstrom  has anyone got it working and if so what is the method  ,kinect
1259,how to measure and dispense a finite amount of powder or liquid,i ve been watching too much how it s made  and i ve been wondering how they build devices that spray inject dispense a finite amount of liquid  to within some amount of error    i wanted to try this for a hobby project  i m working on that dispenses dry goods in the amount i specify  do i use some kind of special nozzle valve which can open and close at high speeds  how can i dispense a known quantity from a reservoir of a fluid substance onto each individual unit passing along an assembly line  or an amount specified by the user into another container  ,mechanism manufacturing
1263,what is the easiest way to install ros on osx mountain lion ,the latest osx documentation i found on the website is from       and the latest build is from over a year ago  i m a complete n  b to all things ros and wanted to start playing with it  what is the easiest way  edit  this version of the installation instructions is more recent  april        but it says that  osx is not officially supported by ros and the installation might fail for several reasons  this page does not  yet  contain instructions for most higher level ros packages  only for the base system  this includes the middleware and command line tools but not much more    does not contain instructions  also means it doesn t work  what do osx users who work on ros usually do  run it on an ubuntu vm  install it just fine on their own on osx  even though there aren t detailed instructions on the website  ,ros
1266,what reward function results in optimal learning ,let s think of the following situations   you are teaching a robot to play ping pong you are teaching a program to calculate square root you are teaching math to a kid in school  these situations  i e  supervised learning   and many others have one thing  among others  in common  the learner gets a reward based on its performance  my question is  what should the reward function look like  is there a  best  answer  or does it depend on the situation  if it depends on the situation  how does one determine which reward function to pick  for example  take the following three reward functions    function  says   below a certain point  bad or worse are the same  you get nothing there is a clear difference between almost good and perfect  function b says   you get reward linearly proportional to your performance  function c says   if your performance is bad  it s ok  you did your best  you still get some reward there is not much difference between perfect and almost good   intuitively  i d think a would make the robot very focused and learn the exact pattern  but become stupid when dealing with similar patterns  while c would make it more adaptable to change at the cost of losing perfection  one might also think of more complex functions  just to show but few   so  how does one know which function to pick  is it known which behavior would emerge from  at least  the basic a  b and c functions   a side question is would this be fundamentally different for robots and human kids  ,machine-learning
1270,how to detect when a stepper motor has stalled ,how can i detect when a stepper motor has stalled  a google search led me to some people who say that when the stepper motor stalls  the current spikes up  which is easily detectable with a hall sensor   or  i suppose  by any of the other current sensors mentioned at  how can i sense the motor s current      however  i measured the current through  one of the   wires of  my stepper motor  and it s always within a few percent of     a  whether my stepper driver is holding one position  moving it normally  which in my application is very slowly   or the stepper driver thinks it is telling the stepper to move normally  but the motor has pegged out against the hard limit  measuring the current in the    v power supply going to the stepper motor driver  also seemed to give a fairly constant current  this may be because i turned down the current limit to that amount on my  chopper  stepper motor driver  am i missing some key detail in the  measure the current  approach  a google search led me to some other people that measure the back emf  bemf  in one coil of the stepper during the time the stepper driver is only driving the other coil  but that only seems to distinguish between  a motor moving quickly  vs  a motor stopped   and doesn t seem to distinguish between my case of  a motor moving slowly  vs  a motor stopped   is there some way to apply the bemf approach even in a system where i always drive the stepper slowly  and never spin it quickly  i m currently using a stepper driver board with the ti drv     chip on it  and i hoped the  fault  pin would tell me when the stepper motor has stalled against my hard stop  but it doesn t seem to be doing anything    is it supposed to tell me about a stall  but i just have it wired up wrong  is there some other chip or drive technique that detects when the stepper has stalled out against the hard stop  is there some other technique for detecting a hard stall that i can  add on  to a system using an off the shelf stepper motor driver   is there some other stackexchange site that is more appropriate for questions about motors and motor drivers   ,stepper-motor stepper-driver force-sensor
1274,how to connect an infrared remote control to pc or arduino or raspberry pi ,i bought my kid a robotics kit with several motors and an infrared remote control  you can steer the robot using ir remote control   now i want to take it to the next level and control the robots from a pc or a raspberry pi  what is the simplest approach to do this  i am thinking about   possible ways   find out the protocol the existing remote control uses and then emulate the ir signals using arduino  arduino is sending the ir signals   find a piece of hardware  which presses the buttons on the remote control and control it via to arduino  arduino is sending signals to the button pushers  the remote control is sending the ir signals to the robot    ,mobile-robot arduino raspberry-pi
1276,how can a load be balanced between multiple ac electric drive motors ,i have a three wheeled vehicle in a tricycle configuration attached to a fixed frame  each wheel is powered by an ac electric motor  the ac motors are fed by motor controllers that take a speed demand  the single main wheel  which is also steerable  has a lower gear ratio than the rear wheels so it has a theoretical higher top speed   when the vehicle drives in a straight line each of the motor controllers are given identical speed requests  unfortunately feedback from the controller indicates that some motors are pushing while some are pulling  in particular we have a common scenario where one rear wheel is pushing while the front wheel is trying to slow down  the third wheel will often have almost no current   what can be done to make all three motors work together and avoid situations where they fight   is there a way to change the request to the motor controller to encourage the drives to work together  do we have to switch from a speed request setup to a current control setup  if so what is the appropriate way to control the motors then   let me know if i haven t included any important details and i will update my question  ,control motor
1277,how can i convert rgb colors to cmyk for my airbrush robot ,i am developing a robot which paints using an airbrush   d painting   i intend to use several colors as a cmyk printer  but i do not know how to do the conversion of rgb colors in the computer to the dosage of colors in cmyk  ,robotic-arm
1279,how can i create a robot like the ez b using a regular arduino ,i am interested in building a robot like the ez b  sold by ez robot com  it comes with an sdk for visual studio and has direct scripting in runtime through a usb  bluetooth  wi fi  irc or https connection  if i get a regular arduino board  will i be able to control it remotely in the same way  from what i ve read  an arduino needs to hold the instructions in its own memory  but i would rather have the brain in the computer  feeding signals back and forth to the microcontroller  also  is arduino alone  a step down as the website niceley puts it  ,arduino microcontroller research machine-learning artificial-intelligence
1286,is there a benefit to using   imu units on a uav set at different sensitivities ,i noticed that some imu units are tuned to be sensitive to small changes  other to large changes and some that can be adjusted between different sensitivities  i am familiar with the use of a kalman filter to normalize readings  but i was wondering if my uav could benefit from a second imu where the two are set at high and low sensitivities to get even more accurate and timely information  ,kalman-filter quadcopter imu uav
1290,issues upgrading arduino code for kinect controlled arm from   servos to  ,i have arduino code for operating   servos  but we are using   servos and am having trouble getting the other   to talk   the program so far as i can make out is that the angles for the servos that are calculated by the processing side are being sent out one after the other  shoulder  elbow  wrist  wrist   then repeated  the arduino program gets this data and stores in into an array and then is written to the pin of the appropriate array segment  so   is shoulder    is elbow    is wrist and   is wirst    i can easily get   servos to run with no problem   but when i try and add   or   more we get no response   can anyone please help me to get the other   servos to work   my knowledge on this code is rather limited  so any help is appreciated    processing data being sent to the arduino   arduino code   include  servo h     declares the servos  servo shoulder  servo elbow  servo wrist  servo wrist      setup servo positions  int nextservo      int servoangles                define pins for each servo  void setup         shoulder attach        elbow attach        wrist attach        wrist  attach         serial begin           void loop       if serial available            int servoangle   serial read           servoangles nextservo    servoangle        nextservo           if nextservo                  nextservo                   shoulder write servoangles          elbow write servoangles          wrist write servoangles          wrist  write servoangles             sorry for the lengthy post but have been stuck for a while   ,arduino kinect robotic-arm
1294,what are the mechanics of translational drift ,concerning robots which rotate at high speed by spinning the drive motors in opposite directions  while still being able to simultaneously move in a direction  translate   as far as i know this originated with competitive fighting robots  where it is known as  melty brain  or  tornado drive   according to wikipedia  and is based on alternately slowing down the motors on either side as they revolve around the centre of mass  however  with the whole body spinning so fast how is the current  heading  of the robot established and maintained  ,navigation movement
1299,send arduino sensor data to server with gprs shield,i m trying to send arduino sensor data to a server using a gprs shield  sim    shield from geeetech   i have this particular set up because the data will be updated to a website and the device will be roaming  i can t use  because to the best of my knowledge that only updates every    minutes  i need to update about every      seconds  in order to connect i tried the code below to form udp connection but it does not get sent through to the receiving ip and port  i don t know why  no errors occur on the arduino side  and the server side has been shown to work with an iphone app that sends a udp message   the server side is as follows  written in python   import socketserver  portno       class handler socketserver datagramrequesthandler       def handle self           newmsg   self rfile readline   rstrip       print  newmsg          self wfile write self server oldmsg          self server oldmsg   newmsg  s   socketserver udpserver     portno   handler  print  awaiting udp messages on port  d    portno s oldmsg    this is the starting message   s serve forever    i can see a possible solution might be to change it to a tcp connection  but i don t know how to do that    ,arduino sensors raspberry-pi programming-languages python
1301,what are the signs that a servo might be broken ,i just got a kit and im not sure if its me or not but it appears one of the continuous servos might be broken  what happened first when i plugged it into the microcontroller  it made a humming sound when i sent it commands  the second continuous servo didnt work at all i played around with different ports on the aurdino based board  and to no avail  just a hum  then i removed the humming servo altogether and just placed the second servo alone  the second continuous servo started to move in whatever direction i asked it to   i plugged the first one in  only the second moved  then i tried spinning them by hand  the second has much resistance  while the first one has dramatically less resistance  maybe     easier to spin by hand  is this something i can fix  has anyone experienced these problems before  thanks in advance  you guys are great  ,arduino microcontroller servos wheeled-robot
1302,rotation ratio between left rocker and right rocker in rocker bogie system,following  the previous question  i am trying to calculate how much one rocker would rotate when the other is being rotated  i attached my calculation here  i am trying calculate the rotation of gear b that connects to right rocket  given gear a rotates at      rad  what is the rotation of gear b in rad  gear ratio a d is      and d b is      at the end  i ended up with rotational gear a   gear b  this somewhat puzzles me  is my calculation correct   ,wheeled-robot
1305,controlling robots through serial,i recently have been working on a little project  unfortunately  i ve ran into a bit of a road block with controlling servos using serial commands  the servos do appear to move when i put in any character into serial  but only a little  when i type in say     characters of random gibberish  both servos connected to my arduino move several degrees  here s my code   any help would be much appreciated  edit  another note  nothing is printed in the serial monitor  also  these are micro towerpro rc servos  ,arduino rcservo serial c++
1306,why are the irb      s servos running even when the joints are not moving ,i was jogging the abb irb     and i noticed that the servo motors are humming even when the joints are not moving  the motor cuts off only when the guard switch in the flex pendant is released  what kind of mechanism which require the drive motors to keep running even when the joints are not moving   i went through the manual but no luck  i suppose the holding torque is provided by some braking mechanism so i think i can rule it out  ,industrial-robot servomotor
1314,visualizing and debugging an ekf,i am currently debugging and tuning an ekf  extended kalman filter   the task is classical mobile robot pose tracking where landmarks are ar markers  sometimes i am surprised how some measurement affects the estimate  when i look at and calculate the numbers and matrices involved  i can work out how the update step got executed  what and why exactly happened  but this is very tedious   so i wonder if anyone is using some technique  trick or clever visualization to get a better feel of what is happening in the ekf update step  update     will be more specific and show first approximation of what i have in mind  what i am looking for  is some way to visualize one update step in a way that gives me a feel of how each component of the measurement affects each component of the state  my very first idea is to plot the measurement and it s prediction together with some vectors taken from the k matrix  the vectors from k represent how the innovation vector  measurement   measurement prediction  not plotted  will affect each component of the state  currently i am working with an ekf where the state is  d pose  x y angle  and the measurements are also  d poses   in the attached image open it in new page tab to see in full resolution   the  scaled  vector k         matlab syntax to take a submatrix from  x  matrix  should give an idea how the first component of the ekf state will change with the current innovation vector  k        how the second component of ekf will change  etc  in this example  the innovation vector has a relatively large x component and it is aligned with vector k          the second component of the state  y coordinate  will change the most  one problem in this plot is that it does not give a feel of how the third component angle  of the innovation vector affects the state  the first component of the state increases a bit  contrary to what k        indicates   the third component of the innovation causes this  but currently i can not visualize this  first improvement would be to visualize how the third component of the innovation affects the state  then it would be nice to add covariance data to get a feel how the k matrix is created  update    now the plot has vectors in state space that show how each component of measurement changes the position  from this plot  i can see that the third component of the measurement changes the state most   ,ekf visualization
1315,non vision based target tracking,i am building   wheeled  knee high robot with music and speakers on top that will follow a target person as the target moves around  i would like some help with the setup for tracking the target  the most obvious solutions are ultrasound or infrared sensors or some kind of vision tracking  but for this application  i don t want to use them   imagine that the robot is placed into a crowded area and asked to move towards a particular person in the area  for the sake of simplicity  assume the person is less than   meters away  but could be obscured by an object   ideally  if someone walked between the target and the robot  the robot would not lose it s path  as would happen with vision based sensing   thanks  ,sensors computer-vision navigation
1318,robotics location following and tracking ,i am building a robot that will follow a target as the target moves around  i would like some help with the setup for tracking the target  the most obvious solutions are ultrasound or infrared sensors  but for this application  they won t work  imagine that the robot is placed into a crowded area and asked to move towards a particular person in the area  for the sake of simplicity  assume the person is less than   meters away   is there some kind of radar or radio solution to this  or anything  ,mobile-robot sensors electronics
1320,problem uploading to roboduino atmega   ,i bought a new roboduino atmega     board  basically roboduino is a modded version of arduino uno made by robokits co in  the problem is  on windows plaform  when i tried to upload a simple blink program that s listed in the examples of arduino ide        i got error that  avrdude  stk    getsync    not in sync  resp  x   i chose the correct com port after verifying it with the device manager  i installed the prolific drivers for the board  i selected the board as arduino uno in arduino ide  the complete verbose for the upload is as follow   when i plug in the board the power led is on  the    pin led blinks once  when the ide shows uploading the    pin led blinks     times and then the error appears on the screen  in between also sometimes it blinks randomly for     times  i also tried other example programs but the same follows  i m using    bit windows   ultimate and the baud rate is set to       on ubuntu        i downloaded the ide from software center  i was added to the dialouts group on  the first run  after connecting the board to my pc i ran two commands lsusb which returned following output  bus     device      id    b      prolific technology  inc  pl     serial port bus     device      id  d b      linux foundation     root hub bus     device      id  d b      linux foundation     root hub bus     device      id  d b      linux foundation     root hub bus     device      id  d b      linux foundation     root hub bus     device      id  d b      linux foundation     root hub  and then dmesg  after this when i tried to upload the same program of blink  it gave me following error avrdude  stk    recv    programmer is not responding  i m using    bit ubuntu       and selected arduino uno as the board  thank you for reading this long  please provide me suggestions for the problem  ,arduino
1324,additional power to dc motor via second power source,how can i provide more power to a dc motor that is in series behind a receiver circuit hacked out of a cheap rc car without burning up the receiver board  the board runs off two aas at about  v  i m replacing the stock motor with a slightly larger one    v  taken from a printer  and remounting it on a chassis for a homebrew robotics project    just messing around to learn more  i imagine i could go safely to    v or even  v with the receiver but i don t want to go much higher since half the stuff is epoxied and i can t really tell what s in there  what i d like to be able to do is add an additional two aa batteries behind the receiver to run the receiver system at  v but add another two  v    a batteries to have the motor at   v with the ability to run with the higher current draw due to the heavier load the motor will handle on its fancy new chassis    but without pulling that current through the receiver circuit  my first thought is to simply connect my    as negative to the motor and positive to a common ground    but i m really not sure and i want to be careful to not damage the circuit or batteries  my next thought is to simply build a single power supply out of my    as and use a current divider but i ve only read about them and never actually tried so  i ve been doing some of those kiddie  electronic playgrounds   a few books and probably cost google an extra few bucks in energy costs and i m still kinda at a loss  ,motor power
1327,how do i interpret these specs for a motor and motor driver ,i ran into confusion while reading about motors  consider a motor with these specs   maximum motor voltage    vdc no load current      ma max  stall current   around  a  i am considering using the texas instruments l   d  with these specs   output current       ma per channel peak output current       a per channel  if i use the l   d to run   motor  back and forth   is this safe   what would happen if my motor requires more than    ma   does this simply mean i need different driver ic  also  the specs say that if i want to drive   motors then i ll need to compensate for the current  is it current from my power supply or from the motor driver  ,mobile-robot motor
1329,battery pack discharged,i used a turnigy     mah  s   c lipo battery pack with turnigy balancer   charger  s  s for about a month  yesterday i left the battery plugged into four escs of my quadrocopter  today i ve found the battery totally discharged  when i tried to charge it  the charger showed it as faulty  after replugging it to the charger it showed it as fully charged  how can i charge it now  p s  i ve got a multimeter  but i do not know what and how to measure    the battery pack has two plugs  one is connected to the charger and the other to the escs    ,battery
1332,multicopter odd or even,i would like to ask which is better to design the multicopter with odd or even number of propellers  and why  ,quadcopter
1334,arduino controlled rc car  what now ,i bought an rc car about a year ago  a few days later i integrated an arduino nano into the vehicle  the only thing the arduino does is to receive the rc signal and pass it on to the esc servo  so  basically it just does a big amount of nothing    right now the wiring looks like this    remote      rc receiver      arduino      servo esc lights   i added lights and i did some experiments with distance sensors and i will try to integrate car control via xbee   processing  this works via serial already  what else could be possible with a setup like that  here are some of my ideas   perhaps some sort of autonomic driving  the car is built for offroad and the suspension is not too bad but it is pretty fast     km h  so a crash would be fatal  fpv  first person view  driving  i could add another servo to move a small camera   swarm intelligence   i have built two of those vehicles  both feature the arduino nano  a zigbee and led front lights  steering correction  i could integrate a gyro sensor to check if the car is not driving straight when it should  telemetry to another arduino  i could build some sort of arduino zigbee handheld that shows me some information for both cars like motor temperature  current speed  uptime  battery voltage  sensor values etc   any ideas  anyone  right now it is just driving like it normally would  i integrated an arduino into an rc toy that does an awesome amount of nothing  makes me feel pretty stupid  ,arduino sensors radio-control automatic
1336,association of multiple measurements to multiple objects,i have a matrix of m measurements and n objects  each cell contains a cost of assignment a particular measurement to the object  i want to assign them optimally  as the condition  only one measurement can go to one object  and one measurement can go to only one object  i want to set some cost threshold  in effect there may be some measurement or object  which is not assigned at all  how can i do it  i was recently thinking of the auction algorithm  which however will never leave any unassigned measurement or object  if that is false  correct me please  or help with some alternative solution  thanks for your time  ,artificial-intelligence sensor-fusion
1339,permission to fly uavs,okay  this might sound like a stupid question but  is there some sort of a permission in the us i might require to fly a quadcopter or a uav for that matter  i couldn t find much help anywhere else    ,quadcopter
1342,open source  sci fi  like robot projects irl,i m looking for a robot that is capable of moving around and has arms that can get objects in one place and drop in another  something akin to what we see in most sci fi movies  though much simpler  it may run on legs  wheels or tracks  it may have claws or hands  i m looking for open sourced design  schematics  specifications of the parts  coding   the whole package  it may be specific cases or projects initiatives with a growing collection of robots  as long as it can take out the trash  it s perfect   d ,mobile-robot
1344,aluminum vs carbon fiber,so building a quadrocopter from scratch has a lot of decision making  and i need some input on the material choice   i have short listed aluminum and carbon fiber for the arms and support of the quadrocopter   i am a little short on cash to experiment with both of them   so considering that i have enough money to buy either of those  and assuming that i have access to general tools like a table saw  horizontal band saw  cnc router and a water jet   what would be a better material to work with edit  i will be deciding the specs around the frame so as to allow me some design liberty  so right now  my goal is to assemble a very durable  as light as possible frame  which can withstand a lot of experimentation on the electrical side  ,design quadcopter
1346,upgrading the motors on a seaperch rov   more torque  or more rpms ,i am looking to upgrade the motors for seaperch underwater rovs so we can carry heavier payloads and more equipment    my question is  should i look for motors which have a higher rpm and lower torque  or with lower rpm but higher torque to gain a substantial power increase  if the latter  what threshold of rpms should i stay above to maintain speed    we are currently running jameco  motors with         props  same setup as here   they are mainly run at max power as our esc currently consists of a fuse and a toggle switch    ,motor underwater
1348,single camera vision and mapping system,some time ago i saw a demo of a small  toy tank  with a single camera mounted on it  this tank was able to drive around the floor and detect objects and then move steer to avoid them  the interesting part was that it used a single camera vision system and as far as i remember was taking advantage of the floor being flat  and then using the rate a feature was moving in the scene relative to the motors and directions of travel to evaluate and hence map the scene  can anyone send me pointers what to search for to get some more information on this  or some pointers to codebases that can do this  the reason i ask is that this was a single camera system from a number of years ago      and therefore  from what i remember  was a relatively low compute load  i was intending to try this out on a raspberry pi to build a car tank that maps a room or set of rooms  ,raspberry-pi computer-vision
1349,working of autonomous lawn mower alm  in an unbounded area without a perimeter wire,i have an autonomous lawn mower alm  which can mow a certain lawn area when that area is bounded by a perimeter wire  even when that perimeter wire is removed  it has to mow the above mentioned area accurately without slipping into a neighboring area  constraints and problems   the alm is an open loop system  differential gps was tried  but it did not yield proper results  any iterative pattern of area coverage can be used provided the error in each iteration is not added cumulatively which can result in unpredictable error in the end   i do not expect full fledged solution  but i need a starting point to understand motion planning particularly for unbounded robotics to solve this problem   i searched on internet to know about the knowledge sources about motion planning but could not get good results  can anyone guide me to know about such sources preferably books and articles on internet which can help me to solve this problem  edit  addition of information    the above picture shows the irregular lawn area which does not have any enclosures and perimeter wire   the red mark shows the center point of lawn     the grey area is the initial scaled down area which resembles in shape to the larger area  i could not draw the grey area which exactly resembles the larger green area     the grey lines are the contours which from the tracks to be followed by the lawn mower idea description    using planimeter app for onetime   the shape and dimension of the lawn area  green area  can be known link    center of polygon can be found by using the method in the following link    calculation of area of grey shape in the above figure       grey shape is the least possible area which can be grazed by the alm   grey shape is similar to the green area shape and it is formed when green area is scaled down to determine the scale down factor which is a numerical value   n   n     where grey area   n   green area once the grey area is known   the number of contours or tracks to be grazed by alm have to be determined manually   the width of contour is equal to the distance between the blades on the either end i e  the width which can be grazed by alm in a single stroke   green area   grey area   area of track     area of track     area of track                  area of track n   once the lawn mower is switched on  it should reach the center of the lawn  red mark showed in the above figure    then  alm should graze the least possible area or grey area     after that alm should switch to contour circumscribing the grey area   it should continue circumscribing in each track till all the tracks are completed  decision has to be made by validating against the calculated and preset value   no of tracks  in alm     in this way entire lawn can be mowed without the need of perimeter wire and also alm would not mow the neighbor s lawn  challenges   a  enable alm to reach the center point of the lawn a  to make alm mow the grey area accurately b  to make the alm switch from one track to track   c  to bypass the obstacle in track and return to the same track   when i mentioned this idea to my colleague  he mentioned the about possible cumulative addition of error in each iteration resulting in an unpredictable error in the end   i intend to minimize the error and fix the boundary as correct as possible   in fact this deviation should be predictable before it can be corrected   ,motion-planning
1350,building a autonomous pesticide spraying system using swarm robotics based on odor  volatile organic compounds  detection,visible worms  pests  and diseased parts of plants emit a unique odor  volatile organic compounds with different concentrations   i understand that sensors which can quantitatively detect these compounds development are being developed  my idea is to build a swarm of robots which can spray pesticides by detecting vocs on three targets present on plants across the fields   target    visible worms  pests  larvae  may these can be mechanically eliminated  target    invisible pathogens on certain areas of a plant  target    areas where pesticides have to be sprayed to prevent disease   for these targets  pesticide has to be administered in the correct concentration  this idea can optimize the use of pesticides and treat the plant properly  questions   is swarm robotics still sci fi or did any one implement it  are the  any specific scenarios where implemented swarm robotic systems  are coming to help and establish the ease     which is the implemented system or idea in conception that can help in formation of solution for the above problem   how much time is required approximately to realize this idea   hope this question does not sound sci fi and is practical and the intention is to solve a definite problem  how can i work by following some steps to further  make this idea concrete ,sensors research
1356,can i use ziegler nichols s rules to find pid parameters for a non linear system,i m trying to use a pid to stabilize a system described from the following difference equation  y  k      a y k  sqrt    y k        b y  k       c u k can i use ziegler nichols s rules to find pid parameters in this situation  to be more precise  my system is an apache http server  in particular i m trying to model how the cpu load can change in function of keepalive parameter  when keepalive grows the cpu load should decrease  so  cpu  k      a  cdot cpu k  sqrt    cpu k        b  cdot cpu  k       c  cdot keepalive k obviously the cpu load is a scalar     is just a time and the  parameters are known to me through experimental data and multiple regression on them  ,pid
1367,prop orientation on a multirotor,while looking up information for the right propellers for my quadcopter  i realized that they had different orientations i e  clockwise and counterclockwise  on further research i found that all multi rotors have different combinations of these orientations  so my question is why  how does it matter if the propeller is turning clockwise or anti clockwise     ,quadcopter multi-rotor
1369,instantaneous center of rotation for a differential drive robot,i want to find the instantaneous center of rotation of a differential drive robot  assuming i know that the robot will travel with a particular linear and angular velocity  i can use the equations  given at a path following a circular arc to a point at a specified range and bearing  which come out to be  x c   x       frac v  w    cdot sin  theta    y c   y       frac v  w    cdot cos  theta     i m using the webots simulator and i dumped gps points for the robot moving in a circle  constant v w        and instead of a single  and  i get a center point for every point  if i plot it out in matlab it does not look nice   the red points in the image are the perceived centers  they just seem to trace the curve itself   is there some detail i am missing  i m really really confused as to what s happening   i m trying to figure out the center so i can check whether an obstacle is on this circle or not and whether collision will occur   ,mobile-robot motion
1370,prop orientation for tricopters,this question stems from previous question  where i asked why does the prop orientation matter so much for a multirotor  but on further research  i found that these reasons need not apply to a tri copter  and then again  why   are these reasons general for all multi rotors with odd number of motors  or even rotors    this forum talks a lot about tricopters and prop orientations but nothing really answers the question   ,multi-rotor
1378,how to tell when an ardupilot has finished initialising its gyros  without referencing telemetry  ,using ardupilot software  fixed wing  arduplane   i know that after i boot up i need to keep the system sit still while the gyros initialise  when i have ground station in the field it s easy to know when it s safe to launch because the telemetry message tells me  but i don t always fly with a ground station  in these situations i currently just sit and wait for a while before arming  then again before launching   is there some reliable rule of thumb  information in the blinking of the arming switch or buzzing that i haven t worked out yet  this uav has px  autopilot hardware  with both px fmu and px ioboard   including with buzzer and illuminated arming switch  the leds on the board are obscured  but i could make light channels from them if required    note  i m asking this question here to test the theory that robotics stack exchange night be an appropriate forum for these sorts of questions  which has been suggested a couple of times in response to the area   drones proposal   ,uav
1383,software for robot parts interaction modeling,i m robotic engineer  using openscad to model robotic components  gears  pulleys  parts  etc   but i need an application to model the physics and interaction of the components  for i e  how will robot move if i rotate a given gear   so  is there any software i can use for modelling interactions in linux  google sketchup is good  but i can t use it in linux  ,software
1388,programming pan tilt unit with c,i am trying to write a c code for a pan tilt unit model ptu d   using visual studio      in windows    but i can t find any tutorial or reference on how to do so  all the user s manual mentions is that there is a c programmer s interface  model ptu cpi  available  but it doesn t say where to find it nor how to use  i looked for it on google but couldn t find anything  there is a command reference manual along with the user s manual  but it only shows the different commands to control the tilt and does not explain how to make a c program that connects to the tilt controller and sends queries to it   does anyone please have an idea of where i should look or if there are any open source programs for that  i m not trying to make a complicated program  i just need it to connect to the tilt controller  the computer is connected via usb cable to the host rs    of the tilt controller  and makes it nod to say  yes  and  no    ,c
1391,creating a robot from ez b or regular arduino,does anyone have experience with this ez b  it is sold by ez robot com and comes with an sdk for visual studio it has direct scripting in runtime and through usb or bluetooth  wifi  irc  https my question is  if i get a regular arduino board  will i be able to do the same  from what ive read  arduino needs to hold the instructions on its own memory  but i rather have the brain in the computer  and feed signals back and forth to the microcontroller also  is arduino alone  a step down as the website niceley puts it thanks for your help in advance ,arduino microcontroller
1392,why does my lsm    magnetometer reading not change in a while loop ,i am using a lsm    sensor to compute a heading and i want to turn my robot to a heading  i have the simple code here   in a function called with a speed and angle  heading   the trex part tells the motor controller to turn on a point and the while loop should test for when the desired heading is reached  however  testing using a couple of instances of serial println mag   i have determined that once inside the while loop  mag never changes which just means the robot turns indefinitely   i have no idea why this would happen  perhaps someone here does  thanks  ,arduino
1393,what is the cheapest   easiest way of detecting a person ,i d like to know if anyone has had success detecting a warm bodied mammal  ie  human  using standard off the shelf  inexpensive sensors    ideally  i d like to use an inexpensive sensor or combination of sensors to detect a person within a room and localize that person  i would like the robot to enter a room  detect if a human s  is are present and then move to the detected human  the accuracy does not need to be       as cost is more of a factor  i d like the computational requirements of such a sensor to be such that it can run on an arduino  although if it s impossible  i d be willing to utilize something with more horespower  such as a raspberry pi or a beaglebone black  i have a few thoughts  however  none of them are ideal   pir sensor   can detect movement within a large field of vision  ie  usually     degrees or more    might be the closest thing to a  human  detector that i m aware of  however  it requires movement and localizing triangulating where a person is would be very difficult  impossible   with such a large field of vision  ultrasound   can detect objects with good precision   has a much narrower field of view  however  is unable to differentiate between a static non living object and a human  ir detectors    ie  sharp range sensors  can again detect objects with great precision  very narrow field of view  however  it is again unable to differentiate objects  webcam   opencv   possibly use face detection to detect human s  in a room   this may be the best option  however  opencv is computationally expensive and would require much more than an arduino to run   even on a raspberry pi  it can be slow  kinect   using the feature detection capabilities of kinect  it would be relatively easy to identify humans in an area  however  the kinect is too expensive and i would not consider it a  cheap  solution     perhaps someone is aware of a inexpensive  heat detector  tuned to body heat and or has had success with some combination of        above and would like to share their results  ,sensors sensor-fusion
1394,qt ros tutorial issue,i am working on a robotic application under r o s  groovy galapagos  i would like to make a tutorial about how create a template app with catkin create qt pkg  i m unable to call the script  from my catkin workspace  i found it at the root     opt ros groovy qt ros qt create script  but even if i try to execute it as sudoer i got an error   importerror  no module named qt create  i m unable to determine what i have to do to make it work  why  ,c++ ros
1399,wearable accelerometor,i ve worked with wiimote accelerometer  but i think now i want to move past that  mostly because i want to have a wider range of available gestures and i think that using only one accelerometer has too many limitations for what i want to do  i m looking for something compatible with arduino or rpi  does anyone have recommendations on how i should do this  ,control sensors accelerometer
1400,stream real time video with environmental data overlaid,i want to embed environmental data collected from sensors into a live video stream from a camera  has anyone done this or know how i would go about doing something like this  is there a library available for the arduino or rpi  ,sensors cameras
1408,pushing buttons remotely over ethernet,so i want to program something that will simply push a button  but controllable over ethernet   i m new to robotics so i don t know where to start   what s the best way to control an actuator over a network connection  ,arduino actuator
1413,is a raspberry pi processor powerful enough for a mobile chatbot ,in general  is a raspberry pi processor powerful enough for a mobile chatbot  i want to make a small mobile robot that is like a chatbot  is a raspberry pi processor powerful enough for any type of ai robotics  as far as a mobile robot  i want to make a wheeled robot about one foot in every dimension  the chatbot abilities will be from programpy sh  a new chatbot program that uses xaiml databases  the chatbot works by looking through a database for a match of the user s input  vocal or text based   it then acts according to the instructions given by the xml like database  ,mobile-robot raspberry-pi artificial-intelligence
1414,pid conundrums for legged robots,i am currently working on a legged hexapod which moves around using a tripod gait  i have two sets of code to control the tripod   set    time based control in this code set  i set the tripod motor set to move at their rated rpm for a required amount of time before shifting to the other tripod motor set  pid control would be based on counting the number of transitions using an optical speed encoder  calculating the error based on difference between actual speed and required speed and then adjusting the error with fixed kd and ki values  set    transitions based control in this code set i count to the number of transitions required to complete one rotation of the leg tripod motor set  before starting the other leg tripod motor set   pid control would be time based  calculation of error would be the difference in time taken for individual motors of the motor set  query  the set   shows promising results even without pid control  but the first set does not why so  the motors are basically set to move   rotation before the other set moves   would the speed differences between the motors cause it to destabilize  how often do i update the pid loop  my robot seems to drag a little bit  how do i solve this  ,mobile-robot pid legged walking-robot hexapod
1416,building robots with high reliability  durability  and battery life,i m involved in research on psychologically plausible models of reinforcement learning  and as such i thought it d be nice to try and see how well some to the models out there perform in the real world  i e  sensory motor learning on a mobile robot   this is already been done in some robotics labs  such sutton s implementation of the horde architecture on the  critterbot   however  these implementations involve robots custom build by robotics experts in order to deal with the trials and tribulations of learning on a long time scale     the robot has been   designed to withstand the rigors of reinforcement learning   experiments  it can drive into walls for hours without damage or burning out its motors  it can dock autonomously   with its charging station  and it can run continuously for   twelve hours without recharging    unfortunately i m no expert when it comes to designing robots  and don t have access to a high quality machine shop even if i did  i m stuck with whatever i can buy off the self or assemble by hand  are these constraints common enough for amateur robotics suppliers to cater to  or should i expect to have to start from scratch  ,mobile-robot battery reinforcement-learning
1417,what is the best way to go about building a robot hand that can type on keyboard  move  click  mouse  swipe touchscreens ,how would you go about building a robot that can use a computer  type on the keyboard  move   click mouse  i am talking about physically manipulating the hardware inputs  and the robot would be able to see the screen  not connected to anything  it s purely autonomous  my hope is that this will replace human qa testers  ,wheeled-robot artificial-intelligence robotic-arm
1419,how can i improve the map in my mobile autonomous robot using kinect,a little background of my aim i am in the process of building a mobile autonomous robot which must navigate around an unknown area  must avoid obstacles and receive speech input to do various tasks  it also must recognize faces  objects etc  i am using a kinect sensor and wheel odometry data as its sensors  i chose c  as my primary language as the official drivers and sdk are readily available  i have completed the vision and nlp module and am working on the navigation part   my robot currently uses the arduino as a module for communication and a intel i  x   bit processor on a laptop as a cpu  this is the overview of the robot and its electronics      the problem i implemented a simple slam algorithm which gets robot position from the encoders and the adds whatever it sees using the kinect  as a  d slice of the  d point cloud  to the map  this is what the maps of my room currently look like    this is a rough representation of my actual room   as you can see  they are very different and so really bad maps   is this expected from using just dead reckoning  i am aware of particle filters that refine it and am ready to implement  but what are the ways in which i can improve this result     update  i forgot to mention my current approach  which i earlier had to but forgot   my program roughly does this   i am using a hashtable to store the dynamic map    grab point cloud from kinect wait for incoming serial odometry data synchronize using a time stamp based method estimate robot pose  x y theta  using equations at wikipedia and encoder data obtain a  slice  of the point cloud my slice is basically an array of the x and z parameters then plot these points based on the robot pose and the x and z params repeat  ,arduino slam kinect odometry
1427,controlling a quadrotor from a pc,i need to control quadrotor from a pc  without using a joystick  i have got a mini beetle quad v    beetle   axis  and also have this nrf  l    wireless transceiver module chip     ghz transceiver  is it possible to write an arduino program to make them speak to each other  i did some research and found that the quad v    model uses flysky protocol and only works with a     nrf  l      ghz transmitter chip not the one which i mentioned above are there any other better ways of controlling the quad from pc or arduino board  ,arduino quadcopter radio-control
1429,pan and tilt bracket for a stepper motor,currently  i m using a pan tilt bracket that works with the servos i have  spark fun product        and are generic to all servos  however  servos aren t accurate enough  i m looking at other options  but have limited knowledge about them  what would you recommend  an important consideration is that i need my motor to tilt in two dimensions  to any random  coordinate accurately  to do this  i think i ll need some sort of attachment to the motor shaft  like the pan tilt bracket  what motor and bracket would you recommend i use to go to any random  coordinate  ,servos stepper-motor motion
1435,laser scanner distance,i m looking at laser scanners and i see a huge range of detection distances   the furthest i ve see are   m if you exclude the very expensive ones that claim up to    m   my question is what is the reason for the huge difference in range price   i would think that with a laser it wouldn t be that difficult to detect something at distances greater than   m   what s the physical limitation that makes it so much more expensive to go above   m for a laser scanner or is there one  ,localization
1437,most material efficient quadcopter frame,i haven t made or flown any quadcopter  but i am fascinated by them  but when looking at the frame of a lot of designs  after whachting this video i wondered why a lot the frames are in an x shape  since the most efficient shape would according to the video be something like this      where each corner is       i also did a quick search on the internet and found this blog which stated the same  however he did not mention the exact angle  and said   even though this is not entirely a new idea  it has not yet been widely accepted by the community   ,design quadcopter
1440,trapezoidal vs sinusoidal commutation,how do you know if a commercial driver is working with trapezoidal or sinusoidal commutation  if you measure the   phase voltage applied to the pmsm by means of an oscilloscope  will you see a difference  ,brushless-motor
1443,learning about embedded systems,the last robotics project i worked on involved autonomous outdoor navigation  using a microcontroller for lower level control and a computer for image processing and decision making  i worked more with the higher level software and another guy on the team did the electrical and embedded systems  i would like to be capable of doing everything  including stuff with embedded  but i m not sure where to look for information  if i were to have done the project from scratch on my own  i d need to know   what microcontroller to use what motors are required  what motor controllers to get  and how to interface with the controllers what encoders to use for motor feedback  and how to write drivers for them what batteries to use and how to safely power everything   if i were trying to learn about higher level software  i d probably take a few courses on udacity  are there any good resources out there like that for this kind of low level stuff  ,microcontroller power embedded-systems
1445,how to get data from ardupilot through serial port,i m doing a project related to telemetry  and i want to make ardupilot  programmed with arduplane       send through a serial port the sensors informations such as height  gps position  etc   i have tried to use ardustation  but i could not change its firmware to do what i want   the idea would be to read the ardupilot s serial port using an arduino uno  and then saving it in a sd card in real time  so ardupilot needs to send data without any user input or something like that  i ve already tried to manipulate arduplane source code to do that  but i couldn t either  has someone here did something like that before  i need some advice  ,arduino ardupilot
1448,maze solving algorithm for mazes with loops,i am trying to implement a line following robot that can solve mazes similar to the pololu robots you can watch on youtube  my problem is the maze that i am trying to solve is looped and therefore simple left right hand rule can not solve the maze  i have done some research and think either flood fill or breadth first search algorithm will be able to solve these looped mazes  solving the maze is reaching a large black area where all the sensors will read black  when the robot is following the line some of the sensors will read white and the central ones black  is there any other algorithms that can solve looped mazes  i understand how the flood fill algorithm works but am unsure how it could be implemented in this situation  my robot has   sensors on the bottom  the one in the centre is expected to always read black  the black line it follows  and the sensors on the right and left are expected to read white  while following a straight line  and then black once a junction or turn is reached  my robot has no problem following the line  turning etc  i need to find an algorithm that can solve looped mazes  that is  find a path from an entrance to an exit   ,mobile-robot motion-planning line-following routing
1449,how are units of noise measurement related to units of a sensor s data measurement ,i m trying to understand how noise is represented for accelerometers  gyroscopes  and magnetometers so that i can match the requirements of my project with the standard specs of these sensors   i want the output of a   axis inertial sensor to be values in meters sec sec  gauss  and radians sec for each axis  and noise to be represented by a range around the true value  so x as in     x m s s  gauss  and radians sec  for accelerometers  magnetometers  and gyroscopes respectively  switching out gauss for teslas  meters for feet  radians for degrees  etc  would all be fine  after looking at a few datasheets  i m surprised to find that      accelerometer noise is measured in  lsb rms  and   g  hz      gyroscope noise is measured in    s rms  and    s  hz     magnetometer noise is measured in   t rms  and  gauss  hz        what do these units mean  and how do they  or can they  translate into what i want  ,imu accelerometer gyroscope noise magnetometer
1450,how would i go about interfacing the raspberry pi and arduino ,i want to do a project where i control motors  and the arduino seems ideal for that  however  i m going to need to do quite a bit of processing on the back end first  connecting the arduino to a computer isn t an option  because it has to be quite mobile  does anyone have any experience controlling arduino with raspberry pi  ,arduino raspberry-pi
1454,motor and ethernet shields together,i was wondering if it is possible to plug a motor shield on top of an ethernet shield  even though the direction pins on the motor shield would be connected to the same pins as the spi bus   i was thinking that it would work if  in the coding  i disabled both chip selects on the ethernet shield before i used the motors  ,arduino
1455,help with adaptive fill algorithm for water color painting robot,tl dr  can anyone point me to a good adaptive path fill algorithm  hey there  my name is james  and my daughter built an awesome painting robot with her friends over at evil mad scientist labs  even brought it to the white house  very fun stuff  anyways  i m a web programmer by day  and though it might be fun to try and write some software to get the robot to do some cool stuff  and for some crazy reason i decided to do this using standard web technologies like svg and javascript  and   it actually works   see the project at   but there s a problem  to fill in colors for given shapes  it requires some kind of path filling algorithm using a given size shape to cover every part of the shape internally  not to mention it has to take into account overlapping paths and occlusions  i have successfully created  fake  fills  by following known paths like spirals and back and forth hatch lines over paths  while detecting occlusion using browser internal functions for detecting what object lies at a given x y coordinate  but these fill functions fall incredibly short of doing anything other than simply following paths  and can be incredibly inefficient at filling certain paths  like filling borders  letters  or u shaped areas   the question  i need an adaptive path filling algorithm  i know they re currently being used in similar cnc setups for milling  and similar algorithms are used by the roomba and  d printers to figure out coverage in the most efficient way possible  the issue comes in that i don t think any have ever been done in javascript  using native svg paths  anyone out there know where i should look  i m not too afraid to attempt to port something over to js  or possibly even use it as is for a native node js module  all my work will be sure to go back to the community and become open source as well  thanks for the help  ,algorithm motion-planning motion cnc
1457,is this a good quadcopter build , d cad   after some editing  i m building the frame myself from aluminum and polycarbonate  edit  all frame is polycarbonate except of the arms  and all screws   nuts   washers    they are form aluminum covered in polycarbonate  the total length  from one motor to another  is exactly   cm approximate mass        kg what i thought to put in   battery  zippy flightmax     mah  s p   c  changed from this     mah battery  motors  turnigy aerodrive sk             kv pdb  hobby king quadcopter power distribution board esc  hobbyking ss series      a esc core  arduino nano imu  invensense mpu      propellers    x    sf props  pc standa   heading   rd rotation   pc rh rotation  changed from  x    ones   i m gonna program it myself  or atleast try to   i want to use it as a uav  self controlled  questions   is this a good setup  it costs to much for me  any way to keep the frame and change the parts to be cheaper and yet a good quadcopter  does the propeller fit the motor  any place to buy these for cheaper  is it a good frame  am i missing some parts   thanks alot  dan edit   i checked it using this site and it gave no errors  guess its a good sign   the camera on the image is just for the picture  no camera is intended there    ,arduino motor quadcopter
1463,does more  power   w  means better motor ,if a motor has more power  w  from another it means that it is better  ,motor quadcopter power
1466,quadcopter application underwater,just out of curiosity  can the concept of a quadcopter be applied to an rov  would it work the same way underwater as it would be in air  if not what kind of modifications it would take to implement that idea  underwater  ,quadcopter
1475,pros cons of common robotics  kits  at the high school level,i am interested in starting a robotics club at my high school next year  since we don t have one  and i want to know what the pros cons are of common kits  i already have a vex kit since my uncle is one of the regional suppliers for indiana  but i m not sure that vex is the best choice  what are the pros cons of the other kits out there  note  i looked at lego mindstorms  and have used them when i was learning robotics  but do not want them for this  also  i own a raspberry pi  ,raspberry-pi mindstorms beginner children
1483,optimal time trajectory in  d and  d with simple constraints,i m trying to find the optimal time trajectory for an object  point mass  from point  with initial velocity v  to point p  with velocity v   i m considering a simple environment without any obstacles to move around  the only constraint is a maximum acceleration in any direction of a max and optionally a maximum speed of s max  this is easy to work out in  d but i struggle with the solution  d and  d  i could apply the  d solution separately to each dimension  but this would only limit acceleration and speed in a single dimension  the actual acceleration might be larger in multiple dimensions  are there any textbook  closed form solutions to this problem  if not  how can i solve this in a discrete event simulation  ,control motion-planning
1489,automatic sorting with barcode identification inside a refrigerator,i m endeavoring to prototype a challenging sorting mechanism inside a fridge and would appreciate any constructive tips on how to get from the specs to a plausible design  problem the aim of the game is to identify and sort food items in the limited space of a fridge     such that a user would push their unsorted shopping into a chamber at the top of the enclosure     and the machine inside would then try to identify the contents with help of bar codes  first big problem      and then sort and move the items according to their identities into different chambers below  second big problem    solution  are there any existing devices that already serve such functions  automatic bar coding and sorting   the designs of which could perhaps inform the mechanics of the device i m planning to construct   i m thinking maybe manufacturing plants or packing factories with conveyor belts etc may use systems that already solve such problems   or filtering mechanisms in candy dispensers  mechanized lifting forks   textbook engineering mechanisms   ,arduino motor sensors cameras
1492,single power source for electronics and actuators,it seems popular to build robotic systems with separate supplies for the electronics and motors servos  but what would be involved in a circuit that powers both from one source  if it helps  here is my particular situation  i want to use a single    v li po pack to power an embedded system       v operating voltage input  max  a current draw  and up to    standard sized servos  hs           v operating voltage   this would be a hexapod  so it is unlikely that all servos would be stalling at once with normal gait patterns  ,electronics servos power legged
1494,how to build a liquid filling machine using piston ,my team developed a filling machine for liquids which uses a piston to measure and deliver volumes     to   liters into bottles  it is built mostly with mechanical parts and we d like to replace most of them with electronic ones  how do i build a machine to pull liquid from a reservoir and fills a bottle using a piston  with electronic parts such as stepper motor  linear actuators and sensors  i understand this is somewhat vague  any aligned response is appreciated  update  this machine should  at its max speed  fill a   litter bottle with water in   seconds  to deliver    bottles per minute   higher viscosity liquids may take longer  it should not spill so liquid needs some filling acceleration control  you may assume two operation modes  with bubbles and without bubbles  the first is a plus  i d like to be able to change the volume electronically  via a lcd menu   i thought of a single main valve that switches between the reservoir and the bottle  that should be controlled electronically too  i could use two valves too  ,sensors stepper-motor mechanism
1496,on the ardupilot board  what is the difference between a     a   ground pins and the pwm ground pins ,i m looking for an electrical explanation of the statement here   warning  do not connect power  red     black    from the rc    a        rc    a    connectors to the servos  just use the signal lines  power   the servos via the pwm outputs connectors  these solutions will avoid   the scenario that can possibly happen when the pan tilt servo draw too   much current and cause the apm to brownout  reset   i examined the apm    board drawing and schematic here and the grounding is a little unclear  on the schematic  they all just go to gnd  but on the board drawing some of the ground pins appear unconnected to traces  i checked for continuity  and there is no continuity between the pwm grounds and the a   a   ground pins  by the way  my power setup is that i have j  enabled and i am using an esc to power the board  can anyone figure out  electrically  what is between these two sets of ground pins  ground pins appear unconnected to the traces   pwm ground just connected to gnd   analog output ground also connected to gnd   ,power ardupilot
1500,lithium thionyl chloride batteries to generate   a       v,i am building a robot where power density is critical  and looking into using lithium thionyl chloride  socl   batteries  i will be drawing around   a constantly and need between    and   v  the batteries i have found so far are aa sized and designed to deliver    ma     v     ah  and weigh   g each  i could picture a pack with   blocks of these batteries in series  where each block has    batteries in parallel  that would mean   ah  which is way more than the    ah that i need  and     kg  which is more than i would like the robot be carrying  so  the question is  is there a way to achieve   ah at   a and     v  i e  for   hours  using socl   carrying much less weight than     kg  ,power
1503,python  modules for motor movement,are there any python  modules used to program robotic movement by declaring a device or component and then providing the instructions  i am not looking for modules that test the components  ,python
1514,reducing motor speed without jamming up,so i built three little bots so far   one with a raspberry pi    v motors   one with an arduino    v motors   and another with an arduino but a hacked remote car   ish  volt motors      the problem i have with all these is that the motors spin so fast the car just bumps into something in a few seconds   i have a small house  i tried to use pwm to control the speed  but at a little less than full throttle       they jam up and they can t take the weight i put on them  should i buy one of these chassis that slow the motor down and give it torque with a gearbox  or is there anything else i can do  ,motor pwm
1515,building a non rotating persistence of vision device,i m looking for a way to create a non rotating persistence of vision device  i have all the electronics set up but i m stumped with the mechanical design  i tried these two designs  but these didn t work so well  everything shakes violently and it doesn t go nearly as fast as i need  about    swipes per second  any ideas on how i can build this  ,motor mechanism
1517,light pattern is flashing intermittently using rviz openni with two kinects,i have two kinects  each on its own usb card  whose cameras i m watching in rviz through openni  and the structured light pattern of one is flashing intermittently   it s only there for a short flash every two seconds  obviously  the structured light depth calculations only work if the pattern is always projected when the camera is looking at it  what causes this  and how do i fix it  edit  i was also having this issue with a single kinect  for which i discovered the issue  as detailed in my own answer  however  the problem persists when two kinects are plugged in  with one kinect flashing and the other functioning normally  ,ros kinect openni
1518,how do visual obstructions impact the ability to localize using lidar ,if a street is extremely crowded to an extent that the terrain is not visible from the point of view of the lidar  e g  in google s self driving car   can it still manage to localize itself and continue to operate  i recall sebastian thrun saying that google s car cannot navigate through snow filled roads since the onboard lidar cannot map the terrain beneath the snow  e g  here    edit   based on the comments  clarifying the context  here  not visible  means there is an obstacle between the lidar and the terrain ,ugv lidar
1519,px  communication,does anyone here know px  software  i m using eclipse to program it and i want to open a new uart door and write on this  i m doing the following commands     but this is not working  anyone have any idea why  ,microcontroller communication
1524,line follower optimization,i m working on building a line follower robot and want to optimize its performance  it was suggested that i use a pid algorithm  i read a lot about pid but am confused a bit regarding following  i ve calculated the error value using  but regarding the change in the motor speed i m confused as to what to use during comparison the difference  i e  currentposition   setpoint  or the errorvalue  that is should i use   or  if  error value          code for changing appropriate motor s speed using error value    also is there any specified range for the values of the constants    and   i m using a differential wheeled robot for my line follower  also i would be happy if someone suggests me any other advanced optimization algorithm for improving the line follower robot  ,arduino pid line-following
1525,how to implement bounded angle vision in particle filter ,i have built a particles filter simulator and i wanted to add the following functionalities   limited range vision  robot can see up to    meters  limited angle vision  robot can see within a certain angle w r t its current orientation   e g  if the current orientation is    degree then it can see in the range from   to    degree    i have managed to add the limited range vision functionality but unable to add limited angle vision  method to sense the landmarks distance within the range  method to calculate the probability of this particle  override public double measurement prob double   measurements        double prob            int c          double   mymeasurements   sense false       for  int j      j   measurements length  j              if  measurements j                      prob    util gaussian mymeasurements j   sense noise  measurements j                c                        if  isboundedvision              if  c                       increase the probability if this particle can see more landmarks             prob   math pow prob        c             else               prob                            return prob     coordinates are relative to the robot and for distance calculation i am using the euclidean distance method and my robot gets localized correctly   ,localization particle-filter visualization
1530,how do you dim    volt leds ,i was considering using a raspberry pi controlling a usb relay to dim   v led lights  but i m having trouble finding a solution that isn t a simple on off   what type of device would i need for dimming  ,raspberry-pi
1538,how to convert vertical motion to horizontal,i am interested in using this miniature motor  squiggle micro motor  to create very tiny horizontal movements  however  due to very limited space  i can only place it vertically within my project  assuming this motor is placed as follows  how can one adapt it to simultaneous movement at a right angle   ideally with the x axis movement matched to the y axis movement as well as possible    ,motor motion movement driver linear-bearing
1544,arduino c c   progamming tutorials,i have no problem in reading circuit schemes  connecting wires  resistors etc   basing on for example instructables com   but i ve only tried to learn java  a while ago  and it s difficult to me to find out what s going on with all this c code stuff  are there any tutorials that are focused on the programming part  thanks ,arduino
1547,how can i simulate a changing environment with non rigid objects ,many robot applications  actually   the most practical and appealing ones  include the robot s reaction to  and impact on  the evironment  e g  due to stochastic nature of the environment  e g  when robot should handle non rigid objects like clothes  or due to the variability of environment  e g  harvesting robots should be prepared to pick fruits of different sizes and shapes   the question is   is there a robotics simulator that can simulate not only robot but also the environment as well  e g  that can simulate the response of robots action on cloth folding or fruit picking and so on  i guess that such simulator is really non trivial but maybe there is some ongoing project for it  ,simulator industrial-robot
1552,use of automated tricopters instead of quadcopters ,hy  i just found useful to post my idea here   i ve seen videos about automated quadcopters   and    i surfed pages from the companies presenting this research and other information on the internet  but i haven t found why they use quadcopters specifically   i understand  how accelerating  rotating and rolling works in those quadcopters   it s simple  but they claim that quadcopters have minimum number of working parts to fulfill their needs  which i don t agree and i think that tricopters are better in this  duocopters can t rotate horizontally  but tricopters can by inclining and then powering the remaining left or right propeller    i rode forums  calculated and draw drafts of both tri and quad and found  that tri is much more efficient just in everything than quad with same props and battery when taken in account that best properties has the smallest copter with the largest props so       moving parts  no vectored yaw in tri          size  building y instead of x construction take far less material           lesser maximum power input      better power efficiency makes longer flight time and tricopters have also improved agility over quadcopters   the only disadvantage i see is a bit complicated horizontal rotating in tricopter without vectored yaw  which can be problem in man controlled machines but easily solved by simple algorithms in automated machines    it s not a real disadvantage  just a small work to be done  i was thinking about doing that in my bachelor thesis  but for now i am looking for your opinions  thanks  edit  maybe the torque is the problem  because on tricopters you can can have all   props in   direction or   in   direction and   in the opposite and it s symmetrical in neither way  but i m not sure if this is the main problem    ,quadcopter multi-rotor
1554,track a moving object,if this has already been answered  by all means please point me to it  i am in the process of building a quadcopter which i eventually plan to run autonomously by allowing it to track an object and take a video feed of it moving  gps is one of the options i ve considered  basically   gps antena on moving object  person  car  bike  surfer  gps antena on quadcopter radio to transmit coordinates from moving object to quad copter  some of the challenges i can foresee are  line of sight for camera  how does the camera know exactly where to point  angle  how can i pre program the quad to always record  say      m to the right of the moving object  or even better  program a set of angles to record from whilst keeping up with the object gps accuracy  what happens if the gps lock is weak   what are some of my other options  i saw this ted talk where the quads are following a ball shaped sensor  i believe it uses kinect cameras and lots of them which is not really an option for this challenge  so i m open to hearing some ideas before i start research and development of these features  ,arduino quadcopter gps
1562,if you can create pure yaw motion with a quadcoptor then why won t this work with a tricoptor ,an answer to the question why do quadcopters have four propellers   besides the name   said   you need   degrees of freedom to control yaw  pitch  roll and thrust  four props is therefore the minimum number of actuators required  tricoptors require a servo to tilt one or more rotors which is more mechanically complicated   in a comment  i asked   how do you get pure yaw motion with a quadcoptor and if that s possible why won t this work with a tricoptor  i don t understand how can you get yaw motion with any system where all rotors are in a plane without first tilting and moving  i would have thought that the main difference between quadcopters and tricoptors would be the kinematic calculations would be more complex   another answer explained   you get pure yaw in the following way  north and south motors rotating the same speed but collectively at a higher  or lower  speed than east and west motors which are also at the same speed    this explains why it works with a quadcopter  but doesn t explain why it won t work with a tricopter  is it simply the fact that the asymmetry means that you can t imbalance the torque effects to provide yaw movement while still keeping the thrusts balanced to keep pitch and roll constant  ,design quadcopter uav
1564,roslaunch include file remotely,i am trying to launch a file from remote computer but i could not success  actually i can connect to remote computer but i think the problem is with including a file from remote computer  in other words  i am looking for a machine tag for include  here is the my code   ,ros
1567,h bridges and stall current,for a dc motor with a stall current of     ma  what should the h bridge s current rating be   what will happen if we use our h bridge l   d whose max  output current is     ma  ,motor electronics h-bridge
1570,accelerometer bias removal,i found a good explanation on how to remove accelerometer bias  when on flat table only one axis should show values  the other two should be     i ve calculated s and b factors  page      record           and  in eeprom or flash memory   and use these values in all subsequent calculations of acceleration to   get the corrected outputs   i don t know how to incorporate these into the final calculation of accelerations  i guess the bias should be substracted from my sensor reading  what about sensitivities  s   ,accelerometer calibration errors
1571,how to raise drop a spider,for halloween  i d like to build a spider that drops from the ceiling when it detects motion  and then rewinds itself back up to scare the next kids  i already have a lightweight foamish spider from hobby lobby that i d like to use  but i need help adding the smarts to it to scare the kids    ideally it d be able to detect how tall far away the kid is to drop to a custom height each time  but i d settle for a standard dropping height if that s too much  i even had an idea of having a motion sensor and having it shoot silly string webs in front of people   i have a very technical background  but i m a total n  b when it comes to robotics  so ideas as to what components and considerations i d need would be greatly appreciated  ,motor rcservo
1579,accelerometer calibration   how to get cross axis sensitivities,i ve already asked a related question  accelerometer bias removal  here on robotics and got a bit better results on corrected accelerometer output  to get even better results i found the calibration equations   th    th paragraph  from vectornav which are just a bit enhanced than the solution in the linked question    however  six more variables are needed   sensitivity of sensor x axis to y axis inputs    sensitivity of sensor x axis to z axis inputs    sensitivity of sensor y axis to x axis inputs    sensitivity of sensor y axis to z axis inputs    sensitivity of sensor z axis to x axis inputs    sensitivity of sensor z axis to y axis inputs     below it is also stated   ieee std                 provides a detailed test procedure for   determining each of these calibration parameters  however  after searching through the           standard  especially page     in google docs  i didn t find any clue on how to calculate the  values  also   and  values from vectornav equations is not explained anywhere  can someone point me further  ,sensors accelerometer calibration errors
1581,choosing motor and battery for a robot,i have a project which requires a robot to move around a room with a flat surface  concrete floor   the robot must carry a laptop  i estimated that the total weight would be    kg  including motors  battery  laptop  motor controller board and other mics items   i would like it to move at about the same speed as a roomba moves  the robot will have two motors and a castor  i have tried doing the calculation to determine the type of motor to use  but i m very confused  can someone advise me on the type of motor and type of battery  lipo sla  to use  ,motor wheeled-robot battery
1582,interference between     mhz video transmitter and     ghz control radio,i m starting to attempt to fly fpv on my quadrotor  i am using a frsky d r ii     ghz frequency hopping diversity receiver  two antennas  for control and recently added a no name     mhz     watt analog video transmitter for fpv flying   when the video transmitter is powered up  my control range drops from about    km to under   m  i m surprised that the     mhz video channel affects my     ghz control channel this way  is this sort of interference expected  is it because my transmitter is low quality  what changes are recommended   should i switch to a uhf control radio  or a different frequency  eg     ghz   for the video radio  or just try moving it a few more inches  they are already about  in apart   ,multi-rotor
1584,how to deal with sonar crosstalk,our robot has a circular array of    sonar sensors that looks like this   the sonar sensors themselves are pretty good  we use a low pass filter to deal with noise  and the readings seem pretty accurate  however  when the robot comes across a flat surface like a wall  something weird happens  the sonars don t show readings that would indicate a wall  instead  it appears like a curved surface   the plot below was made when the robot was facing a wall  see the curve in the blue lines  as compared to the straight red line  the red line was produced by using a camera to detect the wall  where the blue lines show filtered sonar readings    we believe this error is due to crosstalk  where one sonar sensor s pulse bounces off the wall at an angle and is received by another sensor  this is a systematic error  so we can t really deal with it like we would with noise  are there any solutions out there to correct for it  ,sonar sensor-error
1589,existence probability of an object in fusion,i want to compute an existence probability of an object in a sensor fusion on the high level  having from each sensor list of objects already filtered with e g  kalman filter   there are these formulae  lr g   old     frac p ex  out    old       p ex  out    old    alpha    frac p ex  in    old   p ex  in    old       p ex  in    new    lr g   new    lr g   old     alpha p ex  out    new     frac lr g   new       lr g   new   where  is the probability of existence and  is the likelihood ratio    the idea is that  is some probability existence of local object  which was fused into the global   and its probability influences that global one    would mean values from previous cycle   how do you condition that computation to avoid situations of dividing by zero  obtaining   or inf  also  if  is almost    then  will be huge  increasing output  and increasing it enormously in each later cycle  so that the object will live forever  how to prevent it  ,sensors kalman-filter sensor-fusion
1590,what is the name for the transfer function  gh,what is the name for the transfer function  gh  in a simple feedback control system like y  frac g    gh u what do you call g  what about  g    gh    i am confused by the fact that that   open loop transfer function  and  loop transfer function  are used to mean gh by different people  which is academically correct or widely accepted  there are several terms   closed loop transfer function   open loop transfer function   overall transfer function   loop transfer function   loop gain   loop ratio  thanks ,control
1595,measuring gears for servo motors,i m quite new to mechanical engineering and not familiar with gears and motors  a few days ago  i bought a second hand gws servo motor for my project  and it didn t include gears  can someone help me understand the correct measurement of my motor so i can buy the correct gear to fit on my servo motor  specifically  the measurement of the gear hole   ,rcservo
1598,making a robotic arm that can draw a circle,i am software engineering student and don t know much about hardware  i recently have started a project in my ai course  the project is playing a  x  tic tac toe game between computer and a human   in a tic tac toe board  suppose you play first and you put a cross mark in a certain place  in tic tac toe board your position is          now my computer will take a picture with webcam and analyse this picture with help of opencv it is a open source c   library for image processing  for details opencv org   after finding the position of your cross mark it will find the optimal position with the help of my algorithm at which it will put a circle  for output it will just speak out the position  now  i want to make a robotic hand that can draw this circle as output  would anybody please help me to find the hardware and other materials that needed to make that robotic hand  it will be very helpful if anybody suggest me some tutorials  i googled and found many many suggestions  but i am confused about what to choose   ,robotic-arm
1602,how to design a differential steering mechanism ,i want to give my robot a differential mechanism for the system of turning and steering  considering the case of turning a right angled corner  the robot will achieve this by following a gradual circular arc through the intersection while maintaining a steady speed  to accomplish this end  we increase the speed of the outer wheel while slowing that of the inner  but supposing i want the turn to be within a definite radius  how do i calculate what ratio the   speeds have to be in  can someone give me an insight into this   what ive done is this  although i have my doubts  if the speed of the right wheel is  and the speed of the left wheel is   then the ratio of their speeds while turning will be equal to the ratio of the circumferences of their corresponding quadrants  therefore v r  v l   frac r a  r  is this right  i have a sinister feeling im missing something out    ,kinematics
1603,how to implement the wavefront algorithm,i am thinking of creating a robot that can navigate using a map  it is controlled from a pc  an   bit controller performs low level tasks and the pc is doing the image processing  i plan to implement it in a single room where the robot is placed and the robot and environment are tracked by a camera from a height or from the ceiling of the room  first  the robot needs to be mapped  like this  to do   track the robot from some height  using camera following the wavefont algorithim to locate robot and obstacles   procedure  just my idea  the camera will give image of the robot surrounded by obstacles in the random places   using some opencv technique draw some grind over the image    locating the  grid which contain  robot by having some colored symbol over the robot  and locating the grids containing the  obstacle  now the grids with obstacle is thought as wall and the remaining is the free space for the robot to navigate  robot is going to get  the goal place which should be reached is given from the pc may be like point the place to reach in the image by mouse click    unknowns    mapping the room and locating the robot  how  to do that  the robot should know where it is in the map or the image  we cannot believe only the camera is enough to locate the robot  so i thought of adding triangulation mapping like placing two irs in the room and a receiver in the robot  the doubt i have in this is how an ir receiver can know from which direction it is receiving the ir signal  from left or right    i think it knows only that it receives ir not the direction  then how is the triangulation going to happen if i don t know the angle and direction   coming to the image processing  how can i implement the wavefront    algorithm that is capture the live vedio and draw grids over it to    find robot and the obstacles    i have hc    bluetooth module  arduino  bluetooth dongle  chassis with dc motors and driver  and a dc supply  ,algorithm mapping
1607,do servos stop at their limits automatically ,i m moving from controlling a robot arm with basic time based motors controlled using a raspberry pi and python to a more advanced robotic arm that has servos  e g hs    bb   with the time based motors i must constantly keep track of the arms position  guess work  and make sure it doesn t over turn  do servos automatically stop if you give them a position that is outside of their boundaries rather than grinding the gears  ,rcservo
1610,how to make a motion sensor circuit  that can communicate with my lan ,i m a newbie to electronics  robotics  but i love to do it as a hobby   so i want to build a circuit  a really small in size would be much better  with a motion sensor that can communicate data  basically when it sense a motion send a signal  to my computer over wifi  is this something possible   if so how do i do it  may be a schematics diagram  or someway to start the project would be a grate help  thank you     ,sensors wifi communication circuit
1613,motor driver selection,i am building a   wheel robot to carry  kg of load  i used this link to get the torque required for each motor which is   kg cm  so i choose   of these motor which has   kg cm  x more  torque  i noticed that the stall current is   a   can i use adafruit motor shield for arduino which is rated  a peak current capability  if not what current rating driver should look into  thanks   ,motor driver current
1614,arduimu noisy output in quadrotor,we are using arduimu  v   as our quadrotor s inertial measurement unit   we have a separate board to control all motors  not with arduimu itself    now we have a problem with arduimu s sensors output  when we put our quadrotor steady on the ground with motors on  instead of getting   degree in roll and pitch we have a noisy output something like the image below     to   degree error     delta t      s we are sure that this isn t a mechanical problem  because we checked the mechanical joints and everything  i should mention that with motors off everything is going well  also we checked that if we vibrate the device slowly on yaw axis or any other axis  it still shows the noisy output  we are using dcm filter inside arduimu  also we tested with kalman filter but no difference  we also tested fri low pass filter  results is good but there is about   seconds delay in the output  we also checked that if we separate the arduimu s power from our circuit  it still no difference  what s the problem with arduimu and how we can get rid off this noisy output   update   we think that the problem with our pid controller is because of these noises     is this a true assumption   we can t tune our pid parameters   using ziegler nichols method   when we have noisy data  we tested ziegler nichols method when we have low rate noises and we successfully tuned our pid but when noise appears we are unable to tune pids  is there anyway for us for tuning our pid in such situation   is this problem is because of the noises or the pid itself can get rid of them   ,arduino quadcopter noise ardupilot
1615,why can humans single out audio in a crowd  what would it take for a robot to do the same ,i was at a robotics conference earlier today and one of the speakers mentioned robots not being able to function as well in a crowd because they can t single out audio like a person can    why can people single out audio so well   and what would it take for a robot to do the same  i m aware of active noise reduction  anr  like on bose aviation headset  but that is not what i m talking about   i am thinking about the ability to take everything in but process only what you feel is important   ,artificial-intelligence
1618,beaglebone black power draw,what is the minimum amount of power that a beaglebone needs to start up  this would be with no   peripherals attached besides host usb  the getting started guide claims that it can run off of a computer s usb power  but makes no mention of how many amps are actually needed  i saw a mention of older kernels limiting current draw to    amps when working off of usb  although that was all i could find   could one start a beaglebone black off of    amps  if not  how many  ,microcontroller
1622,how do i motorize the elbow socket and other joints in a powered exo skeleton ,how would you motorize the joints in an iron man suit  you need something fairly shallow  i would think  probably dual servos sitting on either side of an elbow or knee joint or either side of your hips  but how do you get motorized action there without dramatically adding to the thickness of the joint   bicycle style chain drives wouldn t work  i would think  since the length of the chain would need to vary depending on what position you re in for at least a lot of joints  how would you motorize the joints  ,design mechanism
1627,why do quadcopters use brushless motors,i ve been thinking about starting a quadcopter project  maybe building it from scratch  one of the main barriers to entry for me is the motors  it seems like most quadcopters use brushless motors  i have some experience with dc motors and using pwm signals to regulate speed  but no experience with brushless motors  as i understand it  brushless motors are more expensive than the typical dc motor i would use on a land robot  and they also require electronic speed controllers  escs   which seem to make them  from my perspective  even more expensive and more complicated to use  so  my question  what is it about brushless motors that make them useful in a quadcopter  is it more torque  less weight  something to do with efficiency  and would it be significantly harder  or even possible  to achieve lift using dc motors instead   ,quadcopter brushless-motor
1630,controlling a conveyor belt with a time based motor,i have some crude time based motors taken from a robot arm that we upgraded to proper servos  i want to be able to power a conveyor belt with one of them and i was wondering how i would go about the following setup  a ball drops through a hole onto the conveyer belt hitting a lever switch on its way through  this switch triggers the motor to start  when the ball gets to the top of the belt and falls off it hits another lever switch that turns the motor off  i could handle this logic by hooking it up to my raspberry pi and using python to start and stop the motor depending on which gpio pin received input  top or bottom lever   or i could use a single lever and set a constant time interval to stop the motor  i would prefer to use both to handle any change in scale construction  i was wondering however if this could be done with the breadboard alone  using logic gates or similar  ,motor raspberry-pi
1633,how can i get data from my kinect ,whenever i try using   it works normally  however  when i try viewing an image using the kinect s rgb or depth camera  or even recording a simple bagfile with data from the kinect  i am unable to see any picture and rosbag does not record any data  and after a few seconds of running image view or rosbag record  i got this error  terminate called after throwing an instance of  openni wrapper  openniexception    what     virtual void openni wrapper  opennidevice  startimagestream      tmp buildd ros groovy openni camera        precise               src openni device cpp         starting image stream failed  reason  xiron os got an event timeout   camera nodelet manager    process has died  pid       exit code     cmd  opt ros groovy lib nodelet nodelet manager   name  camera nodelet manager   log   home rosbotics  ros log   b      e      e  ac            aa  camera nodelet manager   log   log file   home rosbotics  ros log   b      e      e  ac            aa  camera nodelet manager    log  after searching around and trying various fixes  i figured it might be a problem with openni and started using freenect  however i encountered the same problems  i could not record any data using bagfiles or see any images from the kinect  using rviz or image view  then someone asked me to use something completely unrelated  freenect glview  however that too gave me a black screen  lsusb shows that all   parts of the kinect are connected and i ve been able to control the kinect s motor through ubuntu so i know that there is at least a connection established between both  additional info   i run ros on ubuntu using virtualbox v        and windows   with usb   ports i am using ubuntu       and ros groovy  all up to date  i ve had the exact same errors on my mac osx lion when i try using rviz with the kinect  virtualbox crashes all together  i would appreciate anyone s help on the matter  ,ros kinect
1634,how to control velocity ratio when turning angle is   ,im designing a differential steering mechanism for my robot  supposing my robot is going in a straight line and i want it to change it direction by a certain angle   in the diagram   what should the velocity ratio be of the   wheels so that it gradually turns and starts moving along a line that is  degrees to the initial line of movement  if there s any ambiguity in the question please take a look at my earlier question which is similar  how to design a differential steering mechanism   ,kinematics
1637,paper work before i do make my own line follower robot,i am a graduate student trying to make my own line follower robot for my minor assessment  i ve all hardware parts and all data sheets with me  i ve attended a workshops of robotics and studied a lot on line follower robot  i have a good knowledge of c programming and embedded systems  but the problem is i ve a very limited amount of time   days   please help me to suggest a good paper work about my project   line follower robot  where should i start from   i am getting myself confused should i start from programming or should i first do circuit simulations as i know it is not a better approach to use directly hardware   please suggest me a fine paper work or some links videos so that i can make my robotics projects fast  any help would be really appreciated  thanks  ,mobile-robot
1638,why are there no operating torque specifications on steppers ,i have been looking online for a while  and i cannot seem to find any steppers without any torque ratings   operating torque  not holding torque   i even looked on hobby sites that usually have all the ratings  including adafruit and sparkfun  i only have found one ever that said the operating torque  however  it didn t seem that reputable and it didn t have holding torque  so it might be likely that it s a mistake  i might contact them and ask  am i missing something  can i calculate what it will run at with certain factors   how long in between each step  etc   the reason that i say that is i found a tutorial saying how much torque  didn t specify which kind  but i kinda assume it isn t holding  you need for a cnc machine  what i m building    equation  from this site    also on the page   by the way  we are talking about torque during a continual turning motion  not at a holding position   that seems like operating torque  but what makes it the most confusing is they sell steppers and they only list the holding   what am i missing  ,stepper-motor cnc
1642,how to speed up robotic arm ,i need  my robotic arm to ring a desk bell  i one on the maplins site  usb robotic arm  it does seem very slow   what can i hack on it to boost the downwards and upwards speed  i need it hit the bell tip platform quickly once or twice   this is purely a lol project for work  ever time we get an order we want the arm to ring the bell       edit this is the gearbox assembly   and it much much to slow   what can i change in here to speed up one gearbox by at least   times  the grabber gearbox is different though  the gear marker p  is white and seems to move the grabbers at a faster speed   ,robotic-arm
1644,what is rotor torque ,on my stepper s datasheet  it has the category  rotor torque   labeled in n cm   what does that mean  is this the torque it has can supply when turning   hopefully  ,torque stepper-motor
1649,how can i manipulate real time sonar data from my arducopter in arduino ,i have a apm  dr quad with a  dr radio telemetry kit   i would like to send real time sonar data to my laptop  running windows    in order to manipulate it in an additional arduino sketch    the sonar sensor is connected to an analog in channel on my arduino  that data is processed for altitude calculations  and i would like to send this altitude data to some sort of ground station on my computer through the use of a telemetry kit     dr radios    on the quadcopter and   on my computer   i am not quite sure how to go about this task   is there a way that i can modify the source code  gcs h or gcs mavlink pde  in conjunction with mission planner mav     ground station to do this   or would i need to write a python module to accomplish this    ,quadcopter python sonar
1653,calculate position of differential drive robot,how do you calculate or update the position of a differential drive robot with incremental sensors  there is one incremental sensor attatched to each of the two differential wheels  both sensors determine the distance  resp   their wheel has rolled during a known time   first  let s assume the center between both wheels marks the position of the robot  in this case  one could calculate the position as   x    frac x  left  x  right         y    frac y  left  y  right        deriving  those equations under the assumption that both wheels rolled in a straight line  which should be approximately correct for small distances  i get    frac  delta x   delta t     frac       left   frac  delta left   delta t     frac  delta right   delta t  right cos  theta      frac  delta y   delta t     frac       left   frac  delta left   delta t     frac  delta right   delta t  right sin  theta   where  is the angle of orientation of the robot  for the change of this angle i found the equation   frac  delta  theta   delta t     frac    w   left   frac  delta left   delta t     frac  delta right   delta t  right   where  is the distance between both wheels  because  and  depend on   i wonder whether i should first calculate the new  by adding  or if i should rather use the  old     is there any reason to use one over the other  then  let s now assume the center between both wheels does not mark the position of the robot  instead i want to use a point which marks the geometric center of the robot s bounding box  then  and  change to   x    frac x  left  x  right        l   cos  theta    y    frac y  left  y  right        l   sin  theta    deriving  the first gives    frac  delta x   delta t     frac       left   frac  delta left   delta t     frac  delta right   delta t  right cos  theta    l  sin  theta    frac  delta  theta   delta t   now there is a dependance on   is this a reason to use the  new     is there any better method to do simulatenous update of position and orientation  may be using complex numbers  same approach as with quaternions in  d   or homogeneous coordinates  ,mobile-robot kinematics motion two-wheeled forward-kinematics
1654,what is the difference between a robot and a machine ,what is the difference between a robot and a machine  at what point does a machine begin to be called a robot  is it at a certain level of complexity  is it when it has software etc   for instance  a desktop printer has mechanics  electronics and firmware but it is not considered a robot  or is it   a roomba has the same stuff but we call it a robot  so what is the difference  i have always believed that a robot is a robot when it takes input from it s environment and uses it to make decisions on how to affect it s environment  i e  a robot has a feedback loop  ,industrial-robot
1658,implementing slip compensation into a half size micromouse,i would like to know if there are any other solutions to implement slip compensation into a half size micromouse other than the conventional method  i have spoken to a few japanese competitors  and they told me that the only solution they have to such a problem is creating a table of predetermined values and using these values to increase or decrease the before turn after turn distances  the values used are determined by the mouse s intelligence  due to the fact that this method has too many limitations  i would like to hear more suggestions from people who are familiar with this matter  ,micromouse
1660,how to protect the milk in a homemade vending machine ,i am working on a homemade vending machine project that serves milk and cookies  using arduino and some basic servos and stuff  the problem is  i really have no clue on how to protect the milk to last long  or how to even know if the milk is still ok to drink   all i really know is that air is bad for the milk  and the cookies   so here is what i came up with   two solenoids that activates at the same time  to allow air in  and milk out  all of this should be inside a  slightly  colder place  i m sure this design might sound stupid to some of you  but this is where i need your help please  do you think this design can work    would that solenoid on top make any difference to protect milk   how to improve it to make the milk last as long as possible   i v heard about the big guys making machines that keep milk fresh for weeks even months  while i m probably sure my milk won t stand a couple of hours   any idea or any information  link  or clue would be greatly appreciated  thank you  ,arduino
1666,classify if two adjacent surfaces belong to same object,i have a box  cuboid  lying on floor or table  so there are   surfaces of the box and   surface of the floor  if i take each pair of surface such that the surfaces are  adjacent  to each other  i get two kind of pairings     two surfaces of the box  the surface normals of the surfaces diverge from each other       surface of the box   surface of the floor   the surface normals converge and intersect at an angle of    degrees     o to     degrees  if we want to add some tolerance   i want to distinguish these two cases by representing through a function  what function can distinguish between these two situations  in both cases  the the normalized dot product of the surface normals is    since the angle b w them is    degrees  so this is not the right solution    ,kinect computer-vision machine-learning
1670,moldable rubber for  feet ,i m trying to inject some kind of rubber around an aluminum strut to form  feet  for a robot  i ve already milled the mold  but i m having trouble finding an inexpensive and readily available rubber compound that will cure without exposure to air  ideally it should cure to about the consistency of a silicone o ring  i ve tried silicone gasket maker  the automotive stuff   however a week later it hasn t cured in the mold  as there is no exposure to the air   is there anything out there with a similar consistency to silicone  but doesn t require air to cure   or is there a way to get what i m currently using to set up without waiting a millennium   there aren t any real mechanical requirements  i m just trying to clean up the look of the robot and prevent its legs from scratching my table   ,cnc
1676,funny behaviour or what   dc motor control,i m trying to control the speed of this motor  with this motor driver and pic  f      pwm in my program  starting with     duty cycle the motor doesn t run  but moving from say      to      i e  program my pic with     duty cycle  and then re program it with       the motor will run at      of course at a lower speed   i consider this funny  anyone to explain this  my motor powered by  v  ,motor
1678,smooth servo movement for a crawling robot,i made a small crawler robot a little while ago that had two legs with two degrees of freedom each  so   rc servos total  while i was programming the movement of the legs i noticed that they moved rather stiffly  it makes sense that the rc servo s internal controller would have a very quick response to position commands  but i wanted my crawler to move in a way that seems a little more smooth and life like  my solution was create a cubic function of time that describes the path of the servos  and then set their position in small time increments  resulting in more smooth motion  essentially what i did was solve for the  coefficients in a cubic equation using the time interval  starting and ending position of the servo  and starting and ending rates the servo should move  which is just the derivative of the position   solve for       and    position t    a     a  t   a  t     a  t     rate t    position  t    a      a  t    a  t    given         i set the rate of the servo between a pair of movements to be zero if the movements were in opposite directions  and positive or negative if the movements were both in the positive or negative direction  respectively   this worked pretty well  but this solution is limited in a few ways  for one  it s difficult to decide what exactly the rates between movements that go in the same direction should be  i used the average of the slopes ahead and behind of a particular position between movements  but it isn t clear to me that is optimal  second of all  cubic curves could take the servo to a position outside of the range of the positions at the beginning and end of a movement  which may be undesirable  for example  at some point during the time interval  the curve could cause the servo to go beyond the second position  or below the first position  thirdly  curve generation here does not consider the maximum rate that the servo can turn  so a curve may have the servo move at a speed that is unrealistic  with that  a minor concern is that the maximum turning rate depends on the response of servo s internal controller  and may change depending on the size of the position interval   neglecting that last concern  these issues may be solved by increasing the degree of the polynomial and adding constraints to solve for the coefficients  but i m now starting to wonder    is there a better way than this to make servo movement smooth and seem more life like  ,servos kinematics
1680,management of asynchronous commands,i am working on a robotics project with c    drawing signs on board   on crs catalyst  arm  i have faced a problem  i have many methods move in different directions  gotolocalizations  etc  but the problem is that when i run many of them in main without sleep   function between each function they does not run properly  i think that the first one needs time  the time of robot movement  but when i put sleep        between them  i guessed that    seconds are enough for the movement  all is ok  this is very ineffective and slow solution  would you like to give me some solutions to avoid the use of sleep   ,activerobot
1682,does a vehicle with defferential gear still move straight ,i am in the concept phase of a driving robot  the two wheels on the front axle will be powered  while the rear will be dragged along  the rear is also responsible for steering but this has noting to do with my question  since the robot is required to make relatively sharp turns at high speed  therefore i have two options to compensate the different speeds on both sides  on the one hand  a differential gear in the front axle could be used  it would be powered by one motor then  on the other hand  i could simply use two motors directly powering each a front wheel  this way i could simulate the differentiation in software  i d like to go for the first approach  using the hardware differential  but i have the one concern with it  would a robot vehicle with differential gear still move straight  without explicit steering applied  my imagination is that  with those wheels not being solidly connected  the robot would move in random curves which i d have to compensate with a lot of steering then  i know that for real cars  differential gears are standard and do their work  but now i am talking about a small robot measuring about   inches  ,motor wheeled-robot motion wheel
1684,wind force impact on torque mechanical arm,i ve got an arm attached to a shaft  the arms dimensions are   x  inches the arm weights about    lbs  if i have a wind acting on the side of the arm  how would i translate the wind force into torque on the shaft  to give some more information  i m rotating the arm using a stepper motor  and i would like to know how to size the motor depending environmental conditions  what should my formula look like in order to arrive a required oz in of torque given my requirements being   i need to be able to accelerate the arm from   to    rpm in     seconds the wind speed can be as high as    mph  using the formula p          x      i find the wind pressure per square foot being       using the formula f   a x p x cd for calculating force  i get       x       x          so i know that the wind force on my arm is     lbs  but now how do i translate this to torque on my arm    source   ,force torque
1687,can gps modules work inside plastic enclosures ,i m going to be embarking on an autonomous robot project and i was going to be using gps to navigate to waypoints  i m aware of the margin of error when it comes to localization with gpd but i live in a lovely area with many open fields    i was going to use adafruit s ultimate gps breakout board with my raspberrypi  and i was wondering how i should protect or mount the gps to protect it from the elements  do all gps units need to be face up and unobstructed  ex  wood or plastic  in order to work  if so  how can i still protect a gps unit from the outdoors  ,gps protection coverage
1693,do   motors require   individually assigned batteries ,for the dagu wild thumper   wheeled platform  or any multiple motor system  do i really need   battery for each motor  or should i just buy   for either side of the platform  in addition  for larger motors like the ones on this platform  how do i deal with the power generated from a coasting motor  i want to jump into the deep end with robotics  as i already hold all the programming skills  and i realize a platform of this magnitude may be a difficult endeavor  recommended motor voltage is         volts  so should one use two    volt batteries for the left and right side  or six     volt batteries  ,motor battery
1695,help with pid  units  in a quadcopter control system,i m in the process of writing my own simple quadcopter controller for experimental use  and i m having trouble getting my head around how to convert from the degrees which my pid controller demands to an appropriate  k  k range for pwm output  for example  take the roll axis on a     configured  copter  pseudo code    how do i take the roll demanded by my pid controller and convert it to a value useful to the motors  that is to say  where does rollpwm come from  my first instinct is to use a simple linear relationship  i e   rollpwm   scaletorange demandedroll  minvalue receiver throttle    maxvalue      receiver throttle     don t let it go beyond     of throttle on low end  and the esc s max on the high end    however this seems far too simplistic to work  or should i be doing more calculations before everything goes through pid control  any help would be great   ,pid motion multi-rotor
1697,mpu        arduino nano   logic converter or not ,i bought this mpu       link according to the manufacture site  the sensor logic level is    v  though the ebay page says   should i use a   channel bi directional logic level converter  like this one  for the sda  scl  int channels  or can i connect it directly to my arduino nano  i saw some places that says i should use it with a logic level converter and some who say it s ok without it   i guess it depends on the sensor board  so please take a look  link above  current setup  sda     llc     a  scl     llc     a  int     llc     d  vcc    llc     v  arduino  gnd    llc    gnd  arduino   i still don t have the parts so i can t test it  and i m probably going to use jeff rowberg library to communicate with the sensor  i c  ,arduino sensors quadcopter logic-control
1707,build an wifi ip camera with webcam,i have a usb webcam and a wifi module which it can convert serial data to wifi and vice versa  the question is can i simply convert the data coming from the webcam to serial with a usb to serial ic  like ft   r   and then hand it over to my wifi module  update  the wifi module datasheet is here ,cameras wifi usb
1711,approach to using pid to get a differential robot driving straight,consider a differential drive robot that has two motorized wheels with an encoder attached to each for feedback  supposed there is a function for each dc motor that takes a float from    to   and sets the pwm signals to provide a proportional amount of power to that motor  unfortunately  not all motors are created equal  so sending each motor the same pwm signal makes the robot veer left or right  i m trying to think about how to drive the robot straight using the encoders attached to each motor as input to a pid loop  here s how i would do it  i would take the difference between the left and right encoders  bound the error between some range  normalize it to be from          and then map it to the motor powers   to    so if i and d were zero  and we get an error of    so the left motor has turned much more than the right motor   then left motor would be set to    and the right motor set to    causing a hard left    are there any issues with this  what is a better approach  ,pid differential-drive
1712,what is the difference between rc motors for cars and helicopters ,i am working on a robot with focus on speed  at the moment i am looking for a suitable motor but it world help if i understood the difference between the various options  to provide some background  i have not worked with rc model components before  but i think this is the only place for me to find the components needed for my robot  such as the motor  i have already figured out how much power the motor needs to accelerate my robot as desired  taking energy conversion efficiency and tractional resistance into account  it s about     watts  depending on the final weight  to limit my search further  i need to decide on either using a rc car motor or a rc helicopter motor now  but i don t understand the difference between these options  focussing on brushless motors  if that matters   what are the differences between rc car and rc helicopter motors which might need to be taken into account when choosing between them  ,motor brushless-motor
1717,how to determine the parameter of a complementary filter ,i know that the complementary filter has the functions of both lpf and hpf  but i think my understanding on the principal behind it is still unclear  i am quite new on digital signal processing  and maybe some very fundamental explanations will help a lot  say i have a complementary filter as follows  y  a cdot y    a  cdot x then my parameter  may be calculated by a  frac  text time constant    text time constant   text sample period   where the  is simply the reciprocal of the   the  seems to be at my own choice  my questions   what is the theory behind this calculation  how do we choose the  properly   note  i also posted this question on stack overflow  as the answers there are likely to be slightly different in emphasis  ,gyroscope magnetometer
1724,off the shelf micro fluid dispenser,need a way to dispense micro liter amounts of water  lets say     ul   only thing i ve found is piezoelectric dispensers and they are        any suggestions   i can build  but preferably would be an off the shelf component  ,electronics
1728,what is an effective distribution of grayscale sensors on robot,i m working on a robotics project  and i am using grayscale sensors to automatically follow a black line  turning    degrees  going round in a circle  and passing through gaps in the lines etc   i was wondering what is an effective way to detect the colours and move it through the lines  with five or six grayscale sensors    thank you very much  ,mobile-robot sensors automatic line-following
1729,how do slam algorithms handle a changing environment ,i m doing some groundwork for a project  and i have a question about the current state of slam techniques  when a slam equipped device detects an object  that object s position is stored  if you look at the point cloud the device is generating  you ll see points for this object  and models generated from it will include geometry here  if an object is placed in a previously empty space  it is detected  and points are added  subsequent models will feature geometry describing this new object  how does the device react if that object is removed  as far as i ve seen  slam systems will tend to leave the points in place  resulting in  ghost  geometry  there are algorithms that will disregard lone points caused by transient contacts  but objects that remained long enough to build up a solid model will remain in the device s memory  are there any systems that are capable of detecting that previously occupied space is now empty  ,slam
1730,how to correctly compute direct kinematics for a delta robot ,i m trying to put together a simple simulation for a delta robot and i d like to use forward kinematics  direct kinematics  to compute the end effector s position in space by passing   angles  i ve started with the trossen robotics forum delta robot tutorial and i can understand most of the math  but not all  i m lost at the last part in forward kinematics  when trying to compute the point where the   sphere s intersect  i ve looked at spherical coordinates in general but couldn t work out the two angles used to find to rotate towards  to e x y z    i see they re solving the equation of a sphere  but that s where i get lost   can someone please  dumb it down  for me   also  i ve used the example code to do a quick visualization using processing  but the last part seems wrong  the lower leg changes length and it shouldn t   ,kinematics forward-kinematics
1737,h bridge using atmega  microcontroller,i want to use my atmega  uc as a h bridge  can anybody give me the source code using c  so that the microcontroller acts as an h bridge  ,microcontroller c h-bridge avr
1743,at command in sim   a gsm gprs module to find out originating address of an sms,i am using sim   a for some purpose and want to know the number of the sender from where a message comes  i am unable to find the specific at command related to receiving message which give me number from where latest message comes  i had used at cnmi  it corresponds to notification regarding latest received message   but am unable to find sender number  i had seen at cmgl  stat    mode   will give you a string which will have oa i e  originating address and once that is stored in a string i can easily parse it out  but when i had data format of that string  need help or any suggestion if somebody can help me out with any other possible solution  ,arduino microcontroller
1745,what modelling tools are available to design a robot,i am planning to build a robot     what free or low cost robot modelling tools exist  ,design
1750,design calculations   mathematical modeling of tricopters,i have been studying about building a tricopter   but i couldn t find the design calculations or mathematical modeling of the tricopter any where over the internet   what are the mathematical relationships or equations of motion and forces in tricopter   how do i calculate the requirements of the structural design and the energy requirements of the motors  ,design
1753,assigning serial number and guid to a microcontroller,this might be a out of league question and may seems to be very odd i am using multiple arduino uno boards over network and want to assign a guid and serial number to each board so that when ever they send any data to a central server  server is able to find which device it is if we have assign name for each device   first way to do this is to assign guid and serial number of device before each message that is send to central server manually while programming and then burn that hex to arduino   now is there any way out that we can burn a program that always give a output as a string  guid serial number of device  like we program eeprom for this and then burn our main code in arduino which pick the guid serial id combo from eeprom and write it before every message which arduino is pushing to central server  or my another way of asking is can we program eeprom with a different program and our arduino separately like   files running in parallel or is it not possible  is there any other way of doing this  ,arduino microcontroller communication
1755,any globally unique signature in ardupilot hardware  or arduino in general ,i have several apm     boards and need to identify them based on some globally unique hardware signature that does not change with programming  arduinos and atmel avr chips in general do not have  also this thread  an accessible serial number  however  it seems that the ardupilot has so many integrated sensors and other ics that one of them must have something unique i can use   see schematic    i will be checking datasheets for mpu       hmc    l tr and ms      but in the meantime  if someone has already figured this one out  please answer  ,arduino ardupilot
1757,laser   photosensor pair or similar,i m looking for a laser   photosensor pair  or product of similar function  for detecting when a beam is interrupted  no more than  ft apart  probably more like  ft   i d like these to run off of  v  since i m using an arduino  my main requirement  however  is that these parts have nice housings  ideally with some mounting screw holes or something along those lines  this is going into a project where sturdiness and durability are important  i don t know how to search for parts like what i am looking for  could you please point me either to some good product sources  give me some better keywords for searching  or link me directly to potentially useful products  ,arduino sensors
1758,polling or timer interrupt ,we hope to build a simple line follower robot and we got a problem when we were discussing about pic programming  we planed to write a endless loop  check the sensor panel reading and do the relevant stuff for that reading  but one of our friends told us to use a timer interrupt to generate interrupts in definite time periods and in each interrupt check the sensor panel reading and do the relevant stuff for that reading  but we can t figure out which is best  the endless loop in main method or timer interrupt method  what is the best way  and why  ,sensors microcontroller interrupts
1765,place for gps antenna on autonomous vehicle,i used to think that the higher gps antenna position the better until i read the following on gpsd faq   one common error is to place the gps or antenna as high as possible    this will increase multipath effects due to signal bounce from the   ground or water  which can cause the gps to mistake its position and   the time signal  the correct location for a boat gps antenna is on the   gunwale rail or pushpit rail  close to the water and as far from the   mast as possible  to reduce signal bounce from the mast   if you re   outside or in a fixed location  put the gps antenna as far from   buildings as possible  and on the ground  if you re in a car  don t   put the gps antenna on the roof  put it on the towbar or some similar   location  if you re driving in a heavily built up area  you re going   to get signal bounce off buildings and reduced accuracy  that s just   how the physics works  note  however  that as your velocity goes up it   becomes easier for the convergence filters in your gps to spot and   discard delayed signal  so multipath effects are proportionally less   important in fast moving vehicles   does anyone has experience placing gps antenna on a towbar of the car as suggested  does it give reasonable effect  my concern is that placing antenna there will not reduce an error that much  but will expose the device  antenna  to possible mechanical damage  so  are there any better positions apart from roof and towbar  thanks ,gps ugv
1766,how to model unpredictable noise in kalman filter ,background  i am implementing a simple kalman filter that estimates the heading direction of a robot  the robot is equipped with a compass and a gyroscope  my understanding  i am thinking about representing my state as a  d vector   where  is the current heading direction and   is the rotation rate reported by the gyroscope  questions   if my understanding is correct  there will be no control term   in my filter  is it true  what if i take the state as a  d vector   then does my becomes the control term   will these two methods yield different results  as we know  the main noise source comes from the compass when the compass is in a distorted magnetic field  here  i suppose the gaussian noise is less significant  but the magnetic distortion is totally unpredictable  how do we model it in the kalman filter  in kalman filter  is the assumption that  all the noises are white  necessary  say  if my noise distribution is actually a laplacian distribution  can i still use a kalman filter  or i have to switch to another filter  like extended kalman filter   ,localization kalman-filter gyroscope compass
1767,what to do when the control input of the kalman filter is unknown ,i am implementing a simple kalman filter that estimates the heading direction of a robot  the robot is equipped with a compass and a gyroscope  say at time   the compass reports a reading   and the gyroscope reports a reading   then i assume from time  to   the rotation rate can be regarded as a constant  thus  my current heading direction is  theta  t   theta  t dt   omega  t dt  cdot dt as can be seen  the  can be easily time updated  but what about my   the robot is not at my control  so its rotation rate at next moment is unpredictable  how should i do the time update in this case  ,kalman-filter gyroscope compass
1774,in slam  how does a laser range finder produce pseudo segments from dynamic objects ,in this paper  the author says that during slam process  pseudo segments that appear from any momentary pause of dynamic objects in laser data would make the map unsatisfied  how is this caused    if the dynamic object moved  won t laser data update and eliminate the segment of dynamic objects  ,sensors slam
1775,how to control the position of a pneumatic piston ,how can i control the position of a pneumatic piston  the only way i know about is using a magnetic reed switch  magnetic sensor  with a matching piston and use some type of control algorithm  like pid for instance  to keep the piston where the sensor is  the problem with that is that it gives you only limited control of the position  it just adds another  state   open  closed  sensor position  and not full control  for example i want it to be     once and     the other time  but without using a sensor for each position because i would like all the  options  to be available  i mean that the percentages aren t pre defined  this is an example of the pistons i use   this is a good example of what i want   ,sensors control pid movement
1776,running uwsim commands in ros,where can i find a good documentation about the uwsim in ros  actually having the source files is not enough and it is actually hard to follow all the functions  for example  how can i use these command correctly     rosrun uwsim gotoabsoluteposition               i know that there is a node  gotoabsoluteposition  in the package  uwsim  and i knwo the variables  but i cannot set the two topics properly  ,ros
1777,tracking with accelerometer and gyro versus multiple accelerometers,i m building quadcopter and most of the control systems use one accelerometer and gyro  i ve read few papers and usually accelerometer is used as reference to the ground because gyro slowly drifts away in time  but if quadcopter does some crazy maneuvering when force direction from accelerometer does not have to point to the ground than accelerometer data is useless  as well there is problem with centripetal force if the accelerometer is not directly in the centor of mass  i was thinking about using multiple accelerometers  to fully determine position and motion of quadcopter one would need three accelerometers if i have done the math right   this would kind of solve the problem with centripetal force so i would like to know if anyone tried to use multiple accelerometers for better orientation estimation   ,quadcopter imu accelerometer gyroscope
1782,actuator design  plausible ,so i got this idea waay back when i was in highschool as a kind of electromagnetic analogue to a biological muscle  it is basically a long stack of thin electromagnets connected in parallel      when current is applied gaps between electromagnets shrink thus providing contraction of the whole chain   i am pretty sure it can work  it can t offer great contraction range  up to     i would guess  but it has potential to provide good speed and be compact so that multiple chains can be combined to form stong and fast linear actuators  the thing is  i never heard of this type of actuator being used  so what is the catch  is there a better alternative  is there a design flaw  too much heat generated making them unpractical  ,actuator
1787,how do i send text to a torobot usb device ,i m trying to get the  torobot  usb servo controller to work with angstrom linux on a beagle board xm  the servo controller registers as a usb device  the device just takes simple text commands  but there is no tty associated with it  so i m not sure how to send commands to it  can i just send data like this  assuming that         is the device    or do i need to associate it with the generic usb device  if so  how do i do that  ,control microcontroller rcservo usb embedded-systems
1790,motor controller with micro usb interface,i am a robotics enthusiast and planning to make a small and simple four wheel car whose motors are supposed to be controlled by an android device housed inside the car by means of the micro usb port of the device  the car has to move forward or backward only as directed by the signals from the android device  so my assumption is that there should be a circuit board which accepts the signals from the microusb usb of the android device and controls the power to the electric dc motor  also the power for the motor will be supplied from a battery pack inside the car  could anyone suggest me a cheap motor driver circuit which supports micro usb or usb  and where can i get the parts for this online  i did a lot research but very confused with the technical terms which i am not familiar with  ,mobile-robot motor wheeled-robot
1791,how to control a brushless motor ,i consider using a brushless outrunner motor  designed for helicopters  in my driving roboter  how can i control such a brushless motor with my micro controller  of course i ll have a separate power source  the roboter should be able to move forwards and backwards  so i need to control the motor in a way to determine direction of rotation  too  i think this isn t related to the question  but i need to ensure high acceleration  specially  i am talking about this motor which is listed in a german shop   ,motor control microcontroller power brushless-motor
1795,localizing a swarm of robots,i have a    cm x    cm room with a   cm high ceiling  yes twenty five centimeters   it contains    small wheeled robots  about   cm x   cm   a central computer will orchestrate the movements of the robots  using a wireless network to send position commands to them  the robots will perform their own closed loop position control to save wireless bandwidth  the robots have    bit arm microcontrollers  they have wheel position sensors  and the ability to do accurate wheel control   problem  the robots can t actually do this yet because they have no way to measure their position in the room  question  how can the robots be given the ability measure their position and orientation to an accuracy of better than   mm  i am looking for an accurate and robust solution  which is not affected by occlusions  and doesn t require a high power pc on each robot  whatever sensors are necessary for localisation can easily be added to the robots  the microcontrollers can easily be changed for more powerful ones if the localisation solution demands it  ,localization wireless swarm
1797,how do i calibrate analog thumb stick ,outline  i m trying to work with an arduino and analog thumb stick to get values for a simple differential drive robot i m working on  the keyes sjoys arduino joystick module i have in my possession is giving me some strange numbers   following axises data i have   x axis range of   to a shaky         with a center value of     y axis range of a solid   to solid      with a center value of       problem i haven t used analog sensors before but it seems pretty obvious that my x axis ranges should feel somewhat similar to the y axis but they don t  in addition  the x axis hits zero way way before even coming close to the edge for its operating range  is my sensor broken  it s new   or is there some way i can recalibrate the potentiometer  note  i also asked this over on electrical engineering stack exchange  ,microcontroller
1806,gears modeling in google sketchup and sketchyphisics,i m trying to make differential in google sketchup using this tutorial  for gears modeling  but i have problem  gears don t collide with any objects  and other gears   what s wrong  how to fix this  how to make a bevel gear placed at    degrees relative to each other and conical cylindrical gears joints  p s  is there something like sketchup and sketchyphisics in linux  ,design mechanism 3d-printing
1808,tiny high torque actuator sensor design,i need to assemble a small  about  cm x  cm x  cm maximum   actuator with as much torque as i can get at that size  it will be driving a small reel and pulley  reel is      cm     mm center diameter   and needs to respond to load  eg  stop if the load increases beyond a certain threshold   power to the actuator will be provided via a common bus line  so the space limit isn t further limited by the size of the battery  my thought is to use a worm drive for this  for torque  and watch for change in current voltage  for load   but i m not sure if that is mechanically sound  it seems like the mechanical advantage provided by the worm would make it hard to detect a change in load  plan b i could add another sensor that would gauge the force being exerted  i d prefer to avoid adding too many points of failure to the system  but if i did what sort of sensor would i use  how should i approach this  ,sensors control actuator
1811,localising a robot swarm non optically,this question is further to localizing a swarm of robots  in summary  i want to create a swarm of robots which can each measure their own position in a  x m room with a   cm high ceiling  to an accuracy of   mm   there were some good answers  but most of them were optical methods  i would be interested to hear some non optical localisation ideas  so i will impose the following further constraints   localisation method cannot use optical means  either visible or invisible  nothing can be added to the floor or ceiling  there s no appreciable gap between the top of the robots and the ceiling  there are no walls  and equipment can be added around the perimeter of the room   i look forward to hearing some creative ideas  ,wireless swarm
1813,software for designing mechanical systems robotic parts,which software can be used to prototype design robot parts  mechanical parts  body  gears  etc   i have some crazy idea i would like to try  quadripedal walking robot  animal like   but i d like to design the mechanism and test  to some degree  the mechanism in some kind of simulator before i start wasting money on parts materials  what tool could i use for that   i m only interested in mechanical design  chassis   servo motor placement   cogs gears   not in electronic design  i m not interesting in robot control software  because i ll be probably able to slap something like arduino onto it and program behavior i want  experienced programmer  details  what i d like to see    should work in  d  i e  finished system should be viewable in  d  i should be able to cut materials like plywood metal  drill holes  place gears on it  etc  it would be nice if it had some kind of part catalog so to place a gear cog i wouldn t need to design it from scratch  it would be nice i could test if parts can actually move  i don t need full blown simulation  just to see if gears can turn or if they ll get stuck  not interested in electronic circuitry  just need mechanical parts  but should be able to place servos  it would be nice if it could produce blueprints  cheap inexpensive  if possible   basically  i should be able to construct robot mechanism in it  by placing connecting parts like gears cogs  motors  springs   or some kind of clock  and test  to some degree  if it actually works  i know that i could use blender d for that  but it wasn t exactly designed for this purpose  i also heard that solidworks could be used for designing mechanical parts  but it is too expensive  especially for one time project   any recommendations  ,software
1815,roller screw drive   axial movement instead of friction,i need an equation or a some hints to solve the following problem  imagine a roller screw drive  i apply a torque of  to translative move my load mass m  i assume my screw has an efficiency of      now an additional axial force affects my mass in the opposite moving direction  is this force completely transformed into torque  of course considering the efficiency  or is it possible  that my whole roller screw is moving  because it is not fixed  i just found papers books articles for movable slides loads  but fixed shafts  but in my case motor and shaft are part of an osciallation system  i m not a mechanical engineer  so i m sorry if the answer may is trivial  i made a little sketch now  the process force fp is pushing my mass  most of the force is transformed into a load torque tp which acts against my drive torque td  some of the energy is lost by friction  the question is  if there is also a partial force tp  which is affecting the bearing and therefore exciting my chassis  ,movement torque differential-drive
1826,why do      rpm and    rpm dc motors cost the same ,today i was going to buy a motor online  and saw that    rpm and      rpm dc motors cost the same  how is it possible to change the rpm without requiring any additional parts cost  ,motor
1831,quadcopter parameters calculations for simulink model,i want to make a mathematical model of quadcopter in simulink  i have studied quadcopter  although i am new and not build any flying robot before  i studied so far that i have to use four brushless dc motors pid speed control  two motors will rotate clock wise and two anti clock wise  i want to make very simple mathematical model   the input of the model will be the xyz locations on  d space  copter will always fly from       path   so far i decided that i will increment the coordinates step by step for example if i want the next location of the to be x     y     z     then i will increment in these locations and input to a flight control block   my question is how can i decide the speed of motors according to x y z next location and how to convert that speed into yaw pitch and roll and finnally convert the yaw  pitch and roll into x y z coordinates   i need the convertion formulas that can be easily implemented into simulink   please provide help thanks  ,quadcopter simulator
1835,effective motor type for robotic arm ,i am trying to build an arm that will have about   by   by maybe   or so centimeters of room for a rotary motor capable of lifting it  the joint will basically allow the arm to rotate in a single degree of freedom in a circle that is perpendicular to the ground the rest of the arm will probably be around    centimeters long and weigh around a minimum of   kilograms before it lifts anything   what kind of motor type would give it the best chance of lifting the arm quickly  and reasonably accurately ddagger      raising from straight down to out    degrees in around   to    seconds maximum   ddagger  at least a centimeter at the end of the arm which means probably at the very least     positions for the motor  ,motor robotic-arm
1837,choosing a platform to start,i d like to start with robotics  but unfortunately i know very little about hw engineering  moreover i used to use such languages as python  c  and java  and do not have much experience in c  still i want very much to be able to program a robot  and i have very big interest in computer vision and ai  are there any platforms kits that you can buy  and with little time spent you already can program them  preferably in high order languages  i d prefer something wheeled  something flying would also be nice  but it may be too hard to be the case for a first robot   with a camera and some additional sensors  would be also nice to have there something  that could help to avoid obstacles  like laser distance sensor or ultra sonic sensor  ideally i would like to build a robot that can navigate in the room without the help of operator  i d like to look at slam some time in future  but for now i just need something to get familiar with the robotics  also it should probably be not very expensive  at least not before i will be very sure that i am ready to go deeper into robotics  something for          would be awesome  can somebody suggest kits platforms tutorials any other info  ,beginner
1838,how yaw  pitch and roll effect the flight of quadcopter ,i am doing simulation of quadcopter in simulink  i want to know how yaw  pitch and roll effect the flight of quadcopter  and how these are different from a single rotor helicopter   mainly how to change the rpm to change the x y z coordinates of the quadcopter   is there any differential equation that can convert the rpm to yaw pitch and roll  please help  ,quadcopter
1839,what frame of reference is used during visual servoing ,i m new to the whole visual servoing area  i m now reading the tutorial visual servo control  part i  basic approaches  and i don t understand something fundamental   what information is available to the robot   is the  d location of the tracked features in the current frame known  is it known for the desired frame  is it known for both   if it s known for both   then what would be the best thing to do   would it be to compute the current and desired  d location and orientation of the robot  and plan an optimal path accordingly  essentially knowing everything in advance  also  in what sense could a control law  i e translation   rotation path  be optimal for a visual servo  ,localization research visual-servoing
1844,stabilizing a quadcopter with optical flow,my quad copter can balance itself in the air using data collected from mpu      with the sonar sensor  it can hover at a specific height  but it  moves on the horizontal plane in a random direction   if i put an object below it  it will ascend to keep the distance between the sonar senor and the object  now i want to make it have the ability to hover stably  is it possible to add a downward facing camera to calculate the speed of optical flow in order to keep it hovering on the same point in the horizontal plane   could i use a forward facing camera to stabilize its vertical speed  ,sensors quadcopter cameras visual-servoing
1853,digital servo shaking,i need your advice if someone experienced something similar  i try using digital servo but when i tried to connect it to board by this tutorial  servo motor only shakes for first ten cycles but after that turns normally  i have no idea why is that but in every article i read that controlling digital servo is same as analog with no need to program them after unboxing  thanks for any idea ,raspberry-pi servos
1856,need suggestions for object recognition,i am tasked with creating a system that will recognize fish pulled out of a lake  the system should be able to identify the type of species of fish  typically  i turn to arduino for projects like this  however  based on what i ve read about image processing  it s sounding like arduino doesn t have the processing power  does anyone have any suggestions for development boards and cameras that can easily interface with the board  i ve look at this option    it seems like it would be a nice all in one type of thing  has anyone used anything like this  thanks  ,arduino microcontroller raspberry-pi cameras
1857,transducer for underwater applications  passive sonar ,i m kicking around the idea of building a small passive sonar for an autonomous submarine  i ve looked through the net for parts and finding a good transducer for converting the sound underwater into an electrical impulse  after looking at parts i got into the piezoelectric materials used for doing this such as barium titanate or lead zirconate titanate  from what i ve read on the web  some of these materials are toxic   my question is  are there piezoelectric materials that one could to build a sensor from scratch that does not possess the toxic qualities  something that could preferably thrown in a pool w  my kids and not give them or me any defects  ,sensors
1858,why do   axis accelerometers seemingly have a left handed coordinate system ,careful inspection of page     figure     of the adxl    datasheet shows that under gravitational loading only  the chip uses a left handed coordinate system   my own experiments with this chip confirm this    i typically only use the chip to indicate the gravity vector   so when using this chip  i simply negate the values to get a right handed coordinate system   but this doesn t seem right   i assume there is a logical and mathematical explanation for the left handed coordinate system but i can t figure out what it might be    ,sensors imu accelerometer calibration
1861,question about car like robot localization based on dead reckoning,i have a question about car like robot localization using only dead reckoning  given    robot position  at current time step  in the form   theta is the heading  steering angle  distance traveled between two time steps  how can i estimate the position of the robot at the next time step  ,mobile-robot localization
1863,may i have some suggestion on inexpensive robotic arm ,i want to build some simple application  i need a   or   degrees of freedom robotic arm  the arm must have feedback  so that i can control it preciously  the arm must be able to handle at least   lbs  and the arm would be able to work    hours a day  my budget is usd       any suggestion  ,robotic-arm
1864,razor imu arduino interfacing,i was looking into the  razor imu from sparkfun  and realized that the only example code on sparkfun s website was for it was meant for hooking it up to a computer  the ahrs head tracker used a serial to usb chip   i looked on google and saw nothing but stories about how it did not work   is there any good way to hook up the  razor imu to an arduino uno  or any arduino without hardware support for more than one serial port   and if so does example code exist  ,arduino imu
1874,where i can learn algorithms or and find examples of code for controlling a rover ,i am a programmer by profession and new to robotics  i have studied ece  so know electronics  but not very familiar with mechanical aspects of robotics  i am working on a learning project with dagu rover   platform  i am trying to control the   dc motors with pwm and want to use the optical encoders for feedback  i am looking for some algorithms  example code in c to effectively control the rover  i know how to control the gpio  pwm and interrupts from the processor  i am more interested in learning the algorithm that controls the motors based on this  for now  i am working on a manual robot  controlled with up down left right keys  in future  i would like to add sensors  camera etc and work on autonomous aspects  any pointers would be helpful  for reference  i am working on the raspberry pi platform to control the rover  ,mobile-robot algorithm pwm c
1876,depth map with raspberry pi,is it possible to get two images from the raspberry pi camera mounted on a remote controlled bot and have them sent to a computer through wi fi and process the images in the computer to generate a depth map  all this is to be done in a very short time so that the robot can be helped with its locomotion without making it completely autonomous  ,raspberry-pi
1877,controlling bot using video and image processing,i am going to start a project on controlling robots using hand gestures  though i have used matlab for this purpose earlier  i realized it is extremely slow for any practical real time system  i am currently planning to use opencv for this purpose  i want suggestions on  if opencv is the best alternative  are there any other alternatives and if i use opencv  which language should i go for  c  c   or python  ,real-time
1881,should you learn assembly language for robotics ,i ask this since assembly language is really close to the micro controller hardware  and what micro controller would you reccomend  the bot has to search for object that i show it before and then i  lose  the object  note  i do not know anything about micro controllers  ,microcontroller software programming-languages
1884,blender a good robotic simulator for quadcopters   swarm simulations ,i m interested in simulating quadcopter control and swarm co ordinations  was wondering if blender or specifically morse was going to be good enough  according to the limitations of morse  it states    morse was never meant to be a physically accurate simulator  while we rely on a state of the art physics engine  bullet   do not expect to accurately simulate robot arm dynamics or fine grasping  other projects are doing that much better  like opengrasp for grasping   while on going efforts try to tackle this issue  we do not consider morse to have a good enough temporal accuracy and time synchronization capabilities for application like hybrid simulation  where some robots are simulated while others are physically operated     was wondering if anyone has experience in using blender for these types of applications  ,simulator
1895,arduino for simple data glove  should i go with mega or due ,first  i m a beginner in mcu robotic world  been working with atmega cvavr  but that s all   so please bear with me  i m making a prototype data glove  like keyglove  but much more simpler   it consist of   imu sensors  mpu       dof  all reading is fused with built in dmp     reads hand position and orientations minimum of   flex sensors    reads figer flexion mcu  well  arduino to be specific   the sensors are plugged in to the arduino and the reading will be filtered  e g low pass  kalmann  in the arduino before being transferred over serial to pc  the pc will then translates the data into virtual gripper to move an object  vr    initially i planned to use uno    pansenti s mpu     library in my code  then i realised the flash memory size left would be so tiny  i e mpu     lib code size is    k  uno has   k   my project is still in very early stage  so a lot things are expected to be changed and added  with so little flash memory left  i can only do so much    i immediately looking for mega as replacement     k flash  but i realised there is also newer due with faster processor   they cost effectively the same as for now    my main concern here is the robustness and compatibility when   designing  the hw interface to arduino  making circuits  addding shield  code development  available library  streaming and filtering the sensor readings  would    bit mcus helps  or it s overkill    i know this question might sound as too localized  but i believe a lot of projects that utilize multiple sensor reading   filtering similarly will also benefits from this discussion  i ll revise the question if it s needed  the main question is probably would    bit mcus perform significantly better in multiple sensor reading and signal filtering compared to   bit mcus  or in my case   should i go with mega or due  ,arduino imu
1897,mechanism for changing gears on a bicycle,i m looking to make an automatically shifting bicycle for my senior design project  along with some additional features tbd   however  i come from an electrical software background  not a mechanical one  so i need to figure out a decent way to shift gears  i was thinking of leaving the gear system in place as is and using some sort of motor  servo or stepper motor with worm gears  to pull and release the wire cable as needed  however  i have some concerns with this  namely the amount of torque needed to pull the wire and finding something with enough holding torque  perhaps my best option is to use the trigger shifters on as well and perhaps use a solenoid  my other concern  namely with the worm gear  is that it ll be too slow   so i would like to pick your brains here for a moment  thanks ,motor automatic
1899,making a brushless servo using hall sensors,i d like to assemble a prototype of brushless servo system using a rc brushless motor  heavily geared down   a sensored electronic speed controller for rc motors  and a microcontroller to do the pid control   i d add three hall sensors around the motor  and feed those signals into the esc and the microcontroller  the mcu will run a pid controller  and output an rc servo compatible pwm signal to the esc  question  is this likely to work  or will i find that the esc is trying to be clever  i have one rc car which only switches into reverse if you double pulse the reverse signal   note  the reason i m trying to get this working using an off the shelf esc  rather than designing my own proper one is that development time is much more expensive than parts cost at the moment   ,servos brushless-motor esc
1901,does monte carlo localization need a predefined map ,so i m doing some reading on monte carlo localization  and it sounds like the approach is based on using a predefined map  but i just need to make sure  because i haven t read anywhere that it absolutely needs a predefined map   i just want to make      sure that my understanding is correct  does it absolutely need a predefined map   maybe i need to add the below stuff as another question  but here goes nothing  and what other localization approaches are there that don t need a predefined map  so far i ve only read about slam  which sounds to me like a general approach instead of a specific implementation   thanks in advance  ,localization slam mapping
1903,is finished plywood a comparable prototyping substitute for polyoxymethylene ,i m working on a robot with a team  and we re building our robot out of acetal polyoxymethylene  pom   specifically  delrin  plastic  however  we d like to prototype the robot before we build it out of pom  as pom is somewhat expensive  there are several critical areas that plywood would be used in place of pom   over sliding surfaces around gearboxes  under weight stress  we d like to take into account the friction coefficients  smoothness  and rigidity of the materials in deciding whether plywood is a valid prototype substitute  the material will be      thick  what differentiates plywood from acetal pom with respect to the relevant points  ,design
1904,strafing of mecanum wheels,i am part of my college robotics team  we are participating in robocon      and are thinking about using mecanum wheels  we have done our research but one thing id like to clarify is  does the number of rollers in the mecanum wheel effect its strafing  if yes then how  ,wheeled-robot
1909,arduino isp bootloader burning,in earlier versions of the arduino ide there was a option to burn a the bootloader using an arduino as the programmer  as of current there is only a burn bootloader option  was the burn using a arduino as a isp integrated into the still existing one  or did it disappear  ,arduino
1910,use computer to throw a small switch,would like a product that enables me to use my computer to throw an small dc on   off switch  seems like a stupidly simple thing to do  but for the life of me i can t seem to find such a device when i search online  is there a device floating around out there that i can order  or is there some kind of term i should be searching for  thanks so much  ,control
1911,how are the optical encoders used in platforms like rover   ,i just got my rover   chassis with   motors and   quadrature encoders and i am trying to utilize the optical encoders  i know the encoders generate pulse signals which can be used to measure speed and direction of the motor  i want to know how   separate optical encoders add value for the controller of rover   like platform  the controller normally uses pwm to control the speed of the motor  if two motors are running at same speed then the encoder output will be same  so  why should the controller monitor all   encoders  ,mobile-robot motor control
1918,installing morse simulator on ubuntu      ,i ve been having trouble installing morse  i am trying to install it on ubuntu       and on a virtualbox with ubuntu        i don t need it on a virtualbox  i m just trying to make something work    on ubuntu       i get the following errors at the cmake stage   on a fresh vmbox with ubuntu        after  morse check  succeeds  i try  morse create mysim  and get  adminuser adminuser virtualbox    morse create mysim usage  morse   h    b base     name name    c     reverse color    g geom             v            check edit run   scene      morse  error  argument mode  invalid choice   create   choose from  check    edit    run    any suggestions  update  i ve managed to install morse on ubuntu        make sure your blender was compiled with the same version of python  i e python        that morse was compiled in  i used this blender    ,simulator
1919,how can we manage stepper motor cables ,i need to actuate   or   cnc like nema       n m torque  stepper motors  i would like some cable solution to connect easily the motor to the motor driver   i have not yet bought anything  i have searched various robotic stores and ebay  but did not yet found a triple  motor  cables  driver  which would be  plug and play    as stepper motors usually have   to   cables  and there are multiple motors  manual soldering everything would be too time consuming  error prone and messy  is there a standard way to deal with cables for stepper motors   ,stepper-motor wiring
1924,any ideas for a robot ,i am in the fll  first lego league   and while we are waiting for the competitions  we want to work on a robot  anyone have any ideas  ,sensors
1925,performing the proper coordinate system transformation,i could use some guidance regarding a coordinate system transform problem  my situation is this  my system begins at some unknown location  which i initialize the location  x y  and orientation  roll  pitch  and yaw  all to zero  i establish a frame of reference at this point  which i call the  local  coordinate frame  it is fixed in the world and does not move  at system startup  the body frame is perfectly aligned with the local frame  where body  x points forward   y to the right and  z down  the body frame is fixed to my system  and travels with the system as it moves  i have an estimation routine that provides me with the x and y position  as well as the roll  pitch  and yaw of the system  yaw is rotation about the z axis of the local frame  pitch and roll are with respect to the body frame  i e  if the robot pitches up  i always get a positive value  if it rolls right  i get a positive value   how can i take the known roll and pitch values and transform them to be with respect to the local  fixed  frame  ,mobile-robot kinematics
1927,dc motor direct loading,i found many tutorials and online calculators for the selection of dc motor to drive wheel  i understood how the torque affect the driving of wheel  but what happen when i change the orientation of motor and load  what is the main criteria for a dc motor to work when i want to rotate a plate which is vertically mounted on motor s shaft  when the motor is placed vertically also  as shown in the picture    i am not an engineering student so please provide me an answer as simple as possible  ,motor torque
1931,is a thrift store a good place to get a servo motor ,i m trying to learn about a very basic motor  the servo motor   can these be found a thrift stores like goodwill in old toys   are these  robotic  quality   what toys or other kinds of things would i scavenge   all i want to do is get a motor   after that i want an arduino and make it  work    nothing complex  ,servomotor
1934,field oriented control of brushless motors,if i was controlling a normal brushed motor as a servo  i would measure the motor s position  and adjust the pwm signal to control the voltage  this way i could achieve a precise velocity position profile if my control was good enough   when doing field oriented control  foc  of a brushless motor  there are two parameters i can control  the voltage angle  and the voltage magnitude  there are three things i can measure  the current angle and magnitude  and the rotor position  i want to achieve a precise velocity position profile including good control down to zero speed and reverse  question  how can i calculate the correct voltage field angle  or phase lead  and magnitude   do i need two pid algorithms  phase lead    calcpid           voltage mag   calcpid            assume i can take any reasonable measurements of the motor state  including rotor position and winding current  ,servos pid brushless-motor
1935,how to open a sliding window ,i live in an apartment that has sliding windows in it  the apartment is naturally warm because we live above a mechanical room  such that we either opened the windows or ran the air conditioning through the winter  i want to create a device than can open and close the windows in the apartment depending on temperature  the software and electronics are already figured out  i just need to figure out how to move the windows   this is a sample of the window  it takes about   lbs of force to pull it open  and they only open   inches since i m    stories high   ultimately  i want to make this cheap enough that i could replicate it on   windows  my first thought was a linear actuator  but most of the ones i have seen are designed for moving     lbs and cost several hundred dollars  pneumatic actuators are cheaper  but i d have to run a network of air lines and solenoids  and would have a compressor that would randomly kick in  a double winch system would be very complicated to set up and prone to failure  lastly  i was thinking of a cheap metal gear servo dealextreme has   kg cm servos for under          but it would be somewhat difficult to use a series of turnbuckles and arms to translate into   inches of linear movement  any help would be appreciated  ,design actuator
1944,arc welder for  d printing,has anybody experimented with gmaw for additive manufacturing  the thing is  welding wire is so much cheaper than abs or pla filaments and  well  it is steel you are printing in  not some flimsy plastic  i imagine the arc deposition printhead would be constructed similarly to one used in plastic filament printers  except there is no need for the heating element  so  even simpler   welding often requires fast z speed  to finely control the arc  so i think delta  deltamaker  chassis would work best  gmaw calls for some sort of inert gas to insulate heated metal from oxygen  it would make sense to seal off most of the interior of the printer and fill it with heavier than air inert gas during printing   i would highly appreciate any pointers on existing  d printer designs employing this deposition method as well as flaws in design i outlined here  ,3d-printing
1946,what is the most appropriate slam algorithm for quadrotors with rgb d camera ,i have been researching on slam  i came across ekf slam which uses odometry to measure the robot s initial position in the map and as well as landmarks which helps the robot s position to be more accurate  based on the slam for dummies  it has a problem of loop closure  in another journal  it was compared to fastslam and ekf has a big o function of  where  is the number of landmarks while fastslam has   it was also said that the most promising slam algorithm from the journal  the vslam algorithm for navigation in natural environments   is fastslam  however  the vslam used by an experiment done by the university of pennsylvania is the occupancy grid slam  i want to ask what would be the most approriate slam algorithm for vslam given an unmanned aerial vehicle like the quadrotor and rgb d camera   imu  also are there any algorithm that can be extended to support co operation  ,localization slam quadcopter mapping
1947,i want my stepper motor to switch speed while traveling  not acceleration wise ,i have this project i m working on where i ll need the speed of the stepper motor to change set speed at a certain distance  i just can t figure out a way to do it  i m using arduino and a stepper motor  this is the current code   what i want it to do basically is to first moveto        at the current speed     then after      i want it to increase speed to      after it has moved      it turns and moves back to position but that s implemented already  ,arduino control stepper-motor
1949,in ekf slam  why do we even need odometry when there is a more reliable sensor also  are all slam algorithms feature based ,in the book of slam for dummies  why do we even need the odometry when the robot would use the data retrieved from the laser scanner which is more accurate than odometry  why not just rerly on the laser scanner and do away from the odometry  is there any contribution by the odometry that the laser scanner does not have  also  are all slam algorithms feature based  ,localization slam mapping
1954,is it possible to use hc sr   ultrasonic range sensor to indicate thickness of a material,the hc sr   is directly connected to an arduino board with the receiver end echo  connected to analog pin   and the transmitter  trigger  connected to digital pin    i am wondering if i can use the sensor to sense the change in saturation from when object block its path  the receiver and transmitter will be positioned like this   the line in the middle is supposed to be a paper  i ll be using it to see the difference between one paper and two paper when they travel trough the two   now i m not sure if this is possible but the way i see it working is kind of similar to an ir led arduino program connected to an led  where when one paper passes trough the light gets a little bit weaker and with two it takes a heavier hit  is this possible  ,arduino sensors
1955,choosing path planning and obstacle avoidance algorithm for  d space,i am working on a  d space where my robot needs to follow a trajectory while avoiding some obstacles  i ve read recently about methods for path planning as  vector field histogram  and the  dynamic window approach   is it worth to use these kind of algorithms for a  d space or should i go with something as potential fields or rapidly exploring random trees  ,mobile-robot motion-planning
1959,will wiring a unipolar stepper to a bipolar stepper driver decrease the holding torque ,i have read that you can wire a unipolar stepper to a bipolar driver  which i have  by ignoring the two extra wires  one concern i have is whether connecting a unipolar stepper to a bipolar driver will cause it to lose torque  holding or operating    will it be the same  increase   i ve read that bipolars are more bang for your buck energy wise  and since you can  transform  a unipolar stepper to a bipolar good enough that the driver will still work right  i would think that it might run more efficiently  is this true  ,torque stepper-driver stepper-motor
1965,what is telemetry used for ,i m pretty new to the world of uas after a ten year holiday from rc flying  i m looking at ardupilot and am wondering what purpose telemetry serves  is it just to get in flight data back to a ground station or can it also be used to program the system in flight  are there other capabilities that i am missing  ,uav ardupilot
1966,public training data for vehicle detectors in computer vision ,this question is to anyone familiar with object  specifically vehicle  detection research  i m new to computer vision and am confused about training object detection classifiers  specifically  the objective is vehicle detection  i ve been reading through vehicle detection literature for weeks now  but i m still a bit confused  what i m confused about is evaluation  for the evaluation of a system  the research community usually has a benchmarked dataset which can be used for testing data  but the performance of a system also depends very much on the data that was used to train it  no   so aren t there any training datasets out there  too  that would make for far more uniform method comparisons  i seem to keep finding papers using benchmarked datasets for evaluation  but making no mention of where they got their training data from  ,computer-vision
1974,autonomous car steering using ir sensors,i want to steer a rc car in a straight line the car has   sharp ir sensors on each corner of the car to help it steer the corridor the corridor is irregular and looks something similar to the picture below  the car needs to be stay exactly at the middle shown by lighter line  and take help of the ir sensors to correct its path  the car has a servo on the front wheel to steer and another that controls the speed  i tried running it using a algorithm where it summed the values on each side of the car and took the difference the difference was then fed to a pid control the output of which went to steer the car the greater the value from the pid  on either sides   the greater the value of the steering angle till it reaches the middle  it works for the part where the walls are at similar distance from the center and even then it oscillates a lot around the center and fails miserably around the bumps in the corridor  i need to make changes to the algorithm and need some help in steering me  in the right direction  the ir sensors are too finicky and is there a way to filter out the noise and make the readings more stable  any help regarding the changes that needs to be implemented is much appreciated  currently the car only uses   ir sensors to guide i can also use   ultrasonic sensors   ,mobile-robot sensors
1976,usage of multibeam  d imaging sonar for auvs  testing them in the pool environment,i belong to an auv team at my university  we are planning to have a multibeam  d imaging sonar  the blueview p     for our auv to detect obstacles underwater  i have the following questions to ask on the feasibility of testing implementing such sonars on auvs   as we know that these multibeam sonars have multiple reflections arriving at different times from various surfaces while testing in a pool  is there any recommended way to filter these noises in the image obtained from the sonar pings  are such sonars in use test by any other team organization anywhere else who do pool testing other than a ocean reservoir testing where multiple reflections are almost zero except the reflections from the obstacle s   also i would like to know the recommended image processing algorithms that can be implemented used to detect obstacles from the sonar images   ,sonar
1978,accelerometers error  bma    and bma    ,recently i am working with two accelerometers  bma    and bma     i will try to explain my problem using bma    as example because it is less accurate therefore problem is more visible  when i hold my acc in neutral position i get correct average result    g  now i turn my acc upside down but this time my average result is      g  the same problem occurs for other axis  for bma    problem is less visible    g in normal position and      g upside down   do you know why accelerometer behaves like this   ,accelerometer
1979,how to retrieve parameters from mavlink  tlog using pymavlink ,i ve been able to use pymavlink mavutil to read telemetry from a  tlog created by missionplanner  to do this  i create a  like this  mlog   mavutil mavlink connection  mylogfile tlog   now i want to read the flight parameters  settings  from the  tlog   the method mavlogfile param fetch all   appears to be designed only to work with a live telemetry link rather than a log  it sends a parameter request command  which obviously has no result when you are linked to a log rather than an actual aircraft  i know the parameters are in the  tlog    how do i get them out  ,python ardupilot
1981,  cm accuracy radio rangefinder ,i need to track a point in space  the point is less than   m away  it has to be passive  no batteries  and no charging  i don t always have a line of sight  i need to pinpoint it to about a centimeter  i need to sample it at a frequency of    hz or more  can it be done at all  does such a solution exist  ,sensors
1983,can you have a career in robotics if you hate mechanics ,i m a first year electronics engineering student  i love almost all the aspects of robotics   the electronics  algorithms  control theory etc  i can t stand the mechanical aspect of robotics though  can i have a fulfilling career in robotics if i hate mechanics but love all other parts of robotics  i m ready to learn mechanics if i absolutely have to  but would strongly prefer not to learn anymore than the absolute basics  thanks  ,software electronics mechanism
1985,slam without landmarks ,first  is it possible to build map without landmarks for a robot in  d  let s say we have an aisle surrounded  by two walls  the robot moves in this environment  now is it feasible to build such a slam problem  or landmarks must be available to do so  ,mobile-robot slam
1991,are time of flight cameras like the swissranger affected by outdoor fog ,i m looking to build an outdoor robot and i need to know if time of flight cameras like the swissranger  sr     work in fog  does anybody have some experiences on that  ,mobile-robot cameras
1992,jacobian of the observation model ,the state vector is    textbf x     begin bmatrix  x    y    v  x     v  y   end bmatrix  transition function is    textbf x   k    f  textbf x   k      delta t     begin cases   x  k      v  xk   delta t    y  k      v  yk   delta t    end cases     and  the jacobian of the observation model    frac  partial h   partial x      begin bmatrix   frac  y  x     y         frac    x     frac y  x                                      frac x   sqrt  x       y          frac y   sqrt  x       y                  end bmatrix   my question is how  the jacobian of the observation model has been obtained  and why it is  x   the model from kalman filter  ,kalman-filter
1995,pre built pid motor controller,i lead a university robotics team that needs pid controllers for four drive motors and two additional motors that are used in a secondary system  i would strongly prefer to buy pre built pid controllers that provide just about any reasonable interface for setting pid constants  motor velocity and direction  as the controllers are not remotely central to the difficult  interesting problems we re trying to solve  to my astonishment  the internet doesn t seem to be saturated with such controllers  talk about reinventing the wheel   hundreds of tutorials but almost no pre built solutions  did willow garage build their own pid controller for the pr       does anyone have recommendations experience  preferably pointers to such controllers   i ve googled around quite a bit  and so far this is the best option i ve found  it s a cape for a beaglebone black  which is the board we re using   the problem is that the python library is not finished   it resets pid constants at every call  it doesn t support changing the direction of the motor  and it seems to only support setting motor power  not velocity  which gives me the impression that it s not actually using the pid controller at all  additional details   the stall current of our drive motors is  a  they are brushless dc motors with quadrature encoders  the secondary motors are much smaller  and we re building our own encoders for them  our code base is in python  and we re running on a beaglebone black using the latest debian image from robert nelson  that guy s awesome    our batteries provide     v  and we already have    v and  v rails  our robot is fairly small  about  x x  feet  and weighs about   pounds  this info is meant to give perspective with regard to scale       or so is the comfortable top range of what we could spend to get all   motors pid controlled   any help would be greatly appreciated  ,motor pid brushless-motor
1997,is there a way to determine which degrees of freedom are lost in a robot at a singularity position by looking at the jacobian ,for a  dof robot with all revolute joints the jacobian is given by    mathbf j      begin bmatrix   hat z     times   vec o     vec o        ldots    hat z     times   vec o     vec o        hat z       ldots    hat z     end bmatrix   where  is the unit z axis of joint  using dh params    is the origin of the coordinate frame connected to joint   and  is the origin of the end effector   the jacobian matrix is the relationship between the cartesian velocity vector and the joint velocity vector    dot  mathbf x     begin bmatrix   dot x     dot y     dot z     dot r x     dot r y     dot r z   end bmatrix     mathbf j   begin bmatrix   dot  theta       dot  theta       dot  theta       dot  theta       dot  theta       dot  theta       end bmatrix     mathbf j  dot  mathbf  theta    here is a singularity position of a staubli tx  xl  dof robot     mathbf j      begin bmatrix                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     end bmatrix   you can easily see that the  th row corresponding to  is all zeros  which is exactly the lost degree of freedom in this position  however  other cases are not so straightforward     mathbf j      begin bmatrix                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     end bmatrix   here you can clearly see that joint   and joint   are aligned because the  th and  th columns are the same   but it s not clear which cartesian degree of freedom is lost  it should be a rotation about the end effector s x axis in red   even less straightforward are singularities at workspace limits     mathbf j      begin bmatrix                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     end bmatrix   in this case  the robot is able to rotate  but not    there are no rows full of zeros  or equal columns  or any clear linearly dependent columns rows    is there a way to determine which degrees of freedom are lost by looking at the jacobian  ,robotic-arm inverse-kinematics industrial-robot
2000,maintaining positive definite property for covariance in an unscented kalman filter update,i have an unscented kalman filter  ukf  that tracks the state of a robot  the state vector has    variables  each time i carry out a prediction step  my transfer function  naturally  acts on the entire state  however  my sensors provide measurements of different parts of the robot s state  so i may get roll  pitch  yaw and their respective velocities in one measurement  and then linear velocity in another  my approach to handling this so far has been to simply create sub matrices for the covariance  carry out my standard ukf update equations  and then stick the resulting values back into the full covariance matrix  however  after a few updates  the ukf yells at me for trying to pass a matrix that isn t positive definite into a cholesky decomposition function  clearly the covariance is losing its positive definite properties  and i m guessing it has to do with my attempts to update subsets of the full covariance matrix   as an example taken from an actual log file  the following matrix  after the ukf prediction step  is positive definite   however  after processing the correction for one variable  in this case  linear x velocity   the matrix becomes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               the difference between the two matrices above is                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               as you can see  the only difference between the two is the value in the location of the variance of linear x velocity  which is the measurement i just processed  this difference is enough to  break  my covariance matrix  i have two questions   updating a subset of the filter doesn t appear to be the right way to go about things  is there a better solution  alternatively  am i missing a step that would keep my covariance matrix as positive definite   thanks  edit  it looks like i m not properly placing the values back into the original covariance matrix  simply copying the values back isn t sufficient  i need to track the correlation coefficients for the covariance matrix  and make sure that when i update a variance value  i update all the values in its row column to maintain the correlation coefficient value  i have to do some more testing to verify that this is my issue  but some initial analysis in matlab suggests that it is  if i m correct  i ll answer my own question  edit    given the response below and after trying it  i can see that my original edit idea won t fly  however  i have one more question  as this is a ukf  i don t actually have jacobian matrices  i think i see how i would make it work within the ukf update equations  but even in an ekf   and i ask because i have one of those as well   my state to measurement function  is going to end up being the identity matrix  as i am directly measuring my state variables  in the case  i take it my  jacobian  would just be an  matrix with ones in the  location  where  is the index of the measured values in the measurement vector  ,kalman-filter
2009,ekf partial state update question,this is a follow up to  maintaining positive definite property for covariance in an unscented kalman filter update    but it s deserving of its own question  i think  i am processing measurements in my ekf for a subset of the variables in my state  my state vector is of cardinality     i am directly measuring my state variables  which means my state to measurement function  is the identity  i am trying to update the first two variables in my state vector  which are the x and y position of my robot  my kalman update matrices currently look like this  state   just test values     left  begin array  ccc                   end array   right    covariance matrix   pulled from log file      left  begin array  ccc                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               end array   right    measurement   just test values     left  begin array  ccc         end array   right     jacobean      left  begin array  ccc                                                                                                     end array   right   measurement covariance   just test values     left  begin array  ccc                     end array   right   kalman gain     left  begin array  ccc                                                                                                                                                                                 end array   right    is   x   meaning that my innovation   and therefore both measurement and current state   would need to be  x  in order to have a   x  result to add to the current full state   where  is a vector containing only the parts of the full state vector that i am measuring   here s my question   yields   left  begin array  ccc                                                                                                                                                                           end array   right   does it make sense that this vector  which i will add to the current state  has non zero values in positions other that   and    the x and y positions of my robot   the other non zero locations correspond to the robot s z location  and the x  y  and z velocities  it seems strange to me that a measurement of x and y should yield changes to other variables in the state vector  am i incorrect in this assumption  incidentally  the covariance update works very well with the jacobean in this form  and maintains its positive definite property  ,kalman-filter
2011,how to calculate the right and left speed for a tank like rover ,i am trying to control the rover   robot using an android app with a touch based joystick control in the app ui  i want to calculate the speed of the left and right motors in the rover when joystick is moved  from the joystick  i get two values  pan and tilt  i convert them into the polar coordinate system with  and theta  where r ranges from   to     and theta from   to      i want to derive an equation which can convert the  r  theta  to  left speed  right speed  for rover  the speed values also are in the         range  now  here is what i have figured out till now  for any value of r   if theta     then left speed   r  right speed    r  turning right on spot   if theta      then left speed   r  right speed   r  moving forward at speed r   if theta       then left speed    r  right speed   r  turning left on spot   if theta       then left speed    r  right speed    r  moving backwards at speed r   for other values  i want it moving and turning simultaneously  for example  if theta      then left speed   alpha r  right speed   beta r  moving forward while turning right   so  basically for any  r  theta   i can set speeds as   left speed  right speed     alpha r  beta r  i need to formulate an equation where i can generalize all these cases by finding alpha and beta based on theta  how can i do this  is there is any existing work i can refer to  ,control kinematics movement
2018,arduino uno r  or roboduino atmega    or arduino mega      r  which board is better for small robots,i am new in robotics  may be this question looks like too naive but i want to know which is a better board among arduino uno r  or roboduino atmega    or arduino mega      r  for my purpose mention below     a simple robot with wheels  can move around  can have ir sensors and camera  is powerful enough to deal with computer vision computations   arduino mega      r  looks more powerful than the other too  i just want to know if my purpose can be solved with other two boards too  thanks ,arduino
2021,telemetry with ardupilot    ,i m using the telemetry kit from  dr robotics     mhz  to interface with ardupilot mega      controlling a quadcopter  the mission planner  v        by michael oborne works well with the telemetry kit  transmitting flight data  imu  compass  gps etc   from the quadcopter to the gcs and displaying them in their gui  however  i would like to see the same data in the hyperterminal  windows system   the radio receiver on the gcs connects to my pc through a usb drive  i have tried calling the remote radio station using all possible baud rates  starting from     to         including         i ve set the data bits to   and stop bits to     none  for parity and flow control  however  all that i ever get on my terminal is either gibberish or no data at all  i also tried burning this software to the radio receiver and tried using at commands on the radio   it connects ok with        but keeps returning error for at   att etc  please give me an idea about how to get flight data at the hyperterminal  thanks  ,quadcopter ardupilot
2022,how will the currently evaluated computer technology influence robotics and embedded systems in the forseeable future ,this is my first question on this site  might be a little subjective    there is an ongoing process of many cool cyclonic changes of technology in the electronics and software industry  concurrency and parallelism what will be the implications of gpgpu  multi core  and  programming in the large  model in the specific case of embedded software  and how will it influence the styles and conventions in the community  single board multicore hardware like soon to be released parallela can be an example  programming language research the results have been excellent  functional programming has supposedly started reaching the masses  it was late night previous weekend when i briefly skimmed through an example of functional reactive programming to solve real time problems  ai people are also suggesting that we should be programming our robots in declarative domain specific languages soon  it would be nice to know the implications on the robotics community   there has been a tremendous growth of frameworks like ros and urbi too   that should be the region to look upon    most of the robotics  embedded and high performance ai codebase directly depends on c c     and though languages like rust and d are bubbling up  wouldn t it take massive amount of time to adopt the new languages  if ever adaptation begins   ai correct me  but it seems like a lot of time has passed and there are not many major production results from the ai community  i ve heard about cognitive architectures of old like act r and  caps  they seem to be in hibernation mode   there seems to be a lot of work lately on otherwise intelligent systems  solved problems  like computer vision and data mining  but these problems cater to supercomputing and industrial crowd more  could there be any possible shift towards low powered systems soon  thanks ,software artificial-intelligence programming-languages beginner embedded-systems
2024,roboticize an old netbook ,i have an old beat up netbook that is currently collecting dust  i ve also only taken stuff apart  without having to worry about putting it back together  so please bear with my possibly stupid questions   a  i imagine it s possible to wire this baby up to servos  breadboards  and all that good stuff  am i correct   b  i d like to start with some simple raspberry pi like projects  think automating my irrigation system  feeding the dog from work  etc   obviously barring the energy expenditure  wouldn t a netbook be more apt than a raspberry pi for handling this type of thing  c  i have basic python experience  but i wouldn t mind picking up more as i go  would that be sufficient  cheers  ,raspberry-pi python
2027,ros amcl does not need odometry data ,i m reading amcl document on ros wiki  in its subscribed topics there is not odometry topic  why  it works only with laser  subscribed topics   from ros wiki  scan  sensor msgs laserscan  tf  tf tfmessage  initialpose  geometry msgs posewithcovariancestamped  map  nav msgs occupancygrid  and my next question is how can i use  in gazebo simulator for turtlebot  any tutorial available  ,slam ros navigation
2028,is it possible to run multiple loops at the same time   arduino ,i ve got a code where i have a motor running back and forth and buttons connected to a scanner  when i press the buttons it causes the motor to stop  and over rides it  i would like them to run parallel to each other so the codes don t interrupt each other  here is my code  ,arduino stepper-motor c
2031,calculate covariance matrix from x y z data,in ros i ve recorded a bag file from a custom robot  in real world  that does not provide covariance matrix and i want to use  to feed an ekf  but covariance matrix is    how can i calculate it  note  covariance matrix is needed by ekf to estimate position  it s a sample of  odom  pose     pose       position         x              y              z          orientation         x            y            z                        w                   covariance                                                                                                                                                                                       twist     twist       linear         x              y            z          angular         x            y            z                    covariance                                                                                                                                                                                        ,localization ros odometry
2032,rocker bogie suspension stability,from the designs usually shown of rocker bogie systems  the whole weight of platform seems to be supported by only one rod  be it differential bar or gear  isn t this a bit unstable system because if we have arms of rover at one end we will have a high torque about that rod  is my understanding such rocker bogie systems correct  if so  are there any solutions to this problem which don t sacrificing the functionality of rover  to clarify  i want to know how rovers like curiosity are designed so as to balance such a heavy platform with a differential bar mechanism  i am trying to make a small rocker bogie myself and i want to avoid this anticipated problem  ,mobile-robot design wheeled-robot
2034,cheapest  d printer for gears ,it would be incredibly useful if i could print my own gearing solutions  even if i have to print the gears one at a time   however  i do not know how the market s cheapest printers will accommodate this task    the gears need be     inches in diameter  and they will bear only a very light load  much less than   foot pound   so the material need not be strong or machinable     the tolerances need only be sufficient for the teeth to mate robustly  preventing any hang   unfortunately  i do not have a sense of what tolerances will allow gears to mate properly     if the machine is precise enough to print a hole to statically mate with a shaft of a specified dimensions due to friction  excellent   if not  i can probably improvise a tiny shaft hole with adhesive     because this may be used in close proximity to pavement  a melting temperature in excess of    f is desirable but not required      because any given element will interact kinetically only with other elements that have also been  d printed  except a metallic shaft   compatibility with external resources is not required    i would be grateful to anyone who could shed some light on this issue  ,wheeled-robot
2036,making high can baud rates work,i m dealing with a board that no matter what i do i can t seem to make can work over     kbit s  i ll give some detail about the board on the bottom  but i m going to keep this question generic  first of all  regarding hardware  from what i ve gathered  there isn t any need for a pull up resistor on the tx of can  is that correct  it may perhaps be chip specific  but wherever i see  it seems that the tx rx lines are directly connected to the transceiver  second  regarding bit timing  using different calculators  for example  kvaser or the one from microchip  i can see the following configuration  for    khz input clock    i ve seen this from more than one source  furthermore  the numbers fit to the formula in the datasheet of the microcontroller  however  only the configuration for     kbit s works for me  i m using canreal to monitor the messages  i ve tried different configurations for the can  for example with    time quanta instead of   as well as changing my microcontroller s clock to    mhz and using again different values  regardless of all that  speeds higher than     kbit s result in only errors and warnings in canreal  which are taken from the can driver   note that the same can board  driver and software works with   mbit s with some other hardware i have  this all is made harder since  as soon as i put a probe from my oscillator on the tx line  it becomes a continuous     alteration like the following                                                                                                                                                                                                                                                                                                                                                                                                                     which is not something i would be outputting by software  in fact  as soon as i remove the probe  the messages start arriving  again  only at     mbit s   so basically  i don t seem to be able to have any oscillator debugging available  back to my  first of all  regarding hardware   the shape of the signal suggests a pull up resistor may be necessary  but i haven t seen the need for that in any datasheet i found  furthermore  my microcontroller configures the pin when used as can  so i don t have control over making it push pull  since it looks like it s open drain   not to mention the microcontroller doesn t even have a configuration to make the pin push pull  is there any hidden parameter somewhere that should also be set  is a pull up resistor necessary after all  why would the oscillator probe cause such a behavior   details from the board   mcu  p  f  k    can is connected to its default rb  and rb   can transceiver  iso       compiler  mikroc  ,microcontroller can
2039,quadrotor experimental identification,i want to model the quadrotor using experimental method  i have not built it yet  what i want to do is  turn only one motor at a specific speed  then plot the x y z and the angles then identify the transfert functions from the plots x w  y w      and so on  but i don t know if it s possible or what graphs i will have so if you know about the subject or maybe tried something like that  and feel free to add anything you think might be helpfull ,control quadcopter brushless-motor uav
2042,choosing correct power supply for stepper motors,i am building a machine and need   stepper motor for that  the motors are driven using by a    v arm device  i have made the following selections regarding the stepper motor  stepper motor driver and the power supply  power supply    volt power supply       amp single output stepper motors stepper motor  unipolar bipolar      steps rev       mm   v      a phase stepper motor driver drv     stepper motor driver carrier  high current i tried my best to research the compatibility and came up with these  is this a good selection considering the fact that the power supply will be driving   of these motors  i will be running the motors at      step for high resolution as far as the speed is concerned it s going to be pretty slow but they will be running continuously for hours in end basically what i am trying to do here is make a v plotter as far i can tell  there will be loads of start stop motion in the motors though  ,stepper-motor power stepper-driver
2045,questions about irobot create,i m interested in getting a create for a project i ll be working on  and wanted some information about it from somebody that already has one   how much weight can it safely carry  i talked with irobot s tech support and they told me the maximum is  lb  but searching on the internet it seems like this limit is actually not as strict as it appears to be  i m asking because i d need to put a  kg laptop on top of it  which would mean       kg if you also consider the kinect and eventual supports for both  i guess i could use a netbook and send the data i need to another computer  but i wanted to avoid the additional overhead of the wireless link  for how long does it run using aa batteries  i m inclined on not getting the battery pack  since i d be using the robot in europe  so i d also need a transformer if i went with the battery pack option   thanks  ,mobile-robot irobot-create
2048,encoder based speed control for rover  ,i am trying to get precise control over the speed of rover   based robot  it has four pwm controlled motors and   optical quadrature encoders  i am using   channel motor controller with rover   chassis  i am using arduino nano for control  i am able to read encoder int output and change pwm based on pulse width to control speed  but  as a result  i am getting heavy oscillations in the control output  that makes  the robot to move in steps  as pwm is changing constantly  i need an algorithm which can minimize this ringing and have a smooth moving robot  here is my arduino code snippet   here req speed is between      to      where sign indicates direction  please consider all undefined variables as globals  i experimentally measured that  when motor is running at full speed  the pulse width is around     us  encoders  int outputs  xor of a and b  are connected to a  thru a   motor pwm is connected to d   d   d   d   please let me suggest any improvements to this code and advice me about what am i missing here  ,arduino motor pwm
2053,odd l   d behavior  pin    seems to act as enable,i have a chip that is labeled l   d with a small  st  logo  which does not behave like i believe a l   d should  i have the chip on a breadboard with pins        and    connected to the ground rail  the positive rail gets  v from a battery pack  a motor is connected to pins   and    pin   is connected to the positive rail  now  when i connect pin    enable    to the positive rail  the motor spins  which is expected  the weird thing is that if i connect pin    instead of pin   to positive  the motor spins  as well   also  with the motor connected to    and     and    connected to positive  the motor spins if i connect pin   or pin    to positive  but not if i connect pin    which should be the enable pin for that side   does any of that make sense  am i missing something here  thanks  ,motor h-bridge
2056,bluetooth module hc    giving error     ,i am working right now with arduino uno and hc    bluetooth module i followed the instruction given on this link for wiring  so there are   mode of working with this hc    module  simple serial communication working in at command mode so as to change the parameters of hc    module  as long as i work in simple serial communication mode  everything works fine but when i tried to change the parameters of module  it didn t work out  for working in at command mode  pin no    of hc    module needs to be high which i had taken care of  lately i found that in mu module they had knowingly not connected the berg strip to pin     so i connected the pin directly  even though i am not able to change the parameters of module and when i write any command on com port of arduino ide  i get this response  i think that garbage is due to my code here is my code   include  softwareserial h   softwareserial btserial             rx   tx  void setup       pinmode    output       digitalwrite    high     serial begin          serial println  enter at commands       btserial begin              void loop       uint  t x    char commandfromserial            char responsefrombluetooth              if   serial available          if serial available             for x   x    x            commandfromserial x  serial read          btserial println commandfromserial                if   btserial available          if btserial available            for x   x    x            responsefrombluetooth x  btserial read        serial println responsefrombluetooth          i am not able to figure out what i am doing wrong  i used this command on com port  at r n and many other commands but every time i get the same response  did i mess up with my bluetooth module unknowingly  ,arduino c communication serial
2062,guidance for compensating internal forces on closed loop chain,i m working on a legged robot and generating joint torques  basically the robot seems to be statically stable to some extend  the robot goes instable if the center of pressure moves to the border of the feet  i m looking for some method to move away the center of pressure  from the feet edges after having calculated my joint torques  in sentis thesis        it is mentioned that he somehow manages to cancel out the internal forces to keep the feet flat against the supporting surfaces   does anyone has got experience in dealing with internal forces  as far as i understood the literature one can modify the nullspace of the calculated torques to achieve that the cop remains in the geometrical center of the considered foot  i m looking for methods apart from the virtual linkage model as it did not seem to work for me or someone with whom i could discuss the virtual linkage model described in      as i might not have it understood it correctly  ,stability legged
2063,unable to read pushbutton press properly in arduino,i am trying to use a push button in order to know and print number of time a push button is pressed using a counter but everytime i press the button   counter get incremented to sometime   and sometime   and some time counter does start      and continue  i had preferred the this link for wiring push button with arduino  and here is my code  i dont know why count is coming absurdly and unevenly  ,arduino c serial
2068,my raspberry pi is losing power in a surge,i have an rc car  the battery provides power to the esc and then the esc provides   v back out to the receiver  instead of the receiver i have a raspberry pi  which uses the   v  steps it down to   v and provides power to the raspberry pi  the problem every time we go full power   there is a lack of voltage and the raspberry pi seems to hard reset    by full power we mean direct to      and not ranging from       i am not an expert in electrical circuits  but some of the suggestions are to use a capacitor to provide the missing   v in the interim  how do i prevent the raspberry pi from dying in the event of full power  ,raspberry-pi electronics esc
2074,omron g v   relay no pins not working,i could swear that it was working for a while  i got back to my desk  tried it again  and it s no longer working  could i have fried the no pins on both sides  this is a dpdt relay  everything works normally on the nc pins  i have never applied more than  v  i do hear the relay click when i apply  v to the coil  but when i measure voltage on the no pins  i get  v  has anyone else seen this  i have two of these relays and i can t seem to get voltage on the no pins with either relay  i should clarify that i m expecting the same  v power source to power both the coil and the common pins  if the nc pins work then i don t see why the no pins shouldn t  in both cases the  v is shared between the coil and any load attached to the nc no pins  i did try driving the entire circuit off a  v power supply  but that did not change the results  and that does contradict my earlier statement that i ve never applied more than  v to this relay   my circuit is based on charles platt s  make  electronics   p      here s a pic of the schematic i am following  except that i am using a  v relay and a  v power supply  usb port  and i am using piezo buzzers without resistors instead of leds   ,electronics
2075,particle filter implementation in ros,i m looking for particle filter implementation in ros to use in mobile robot localization  but it seems the only available package is amcl  adaptive monte carlo   i m not sure is it possible to use it as particle filter or not  and if it s feasible  how  note  the robot  wheeled robot  provides odometry data and another data source is   that provides visual odometry data using fovis  ,mobile-robot localization ros particle-filter
2077,recommendations for system to repeatedly force contact between head and desk,i frequently bang my head on my desk after performing a task poorly  i would like to eliminate the unnecessary middle step of actually performing a task poorly  as such  i would like to design a system to hold my head and repeatedly strike it against my desk  alternatively  a system that holds the desk and repeatedly strikes it against my head would be acceptable  requirements are at least   strikes per second maximum with    cm travel  can anybody make any recommendations for a system to base this device off of  denso products  while small and affordable  do not have the required load capacity  some users may have a rather large head  and involuntary resistance is to be expected    at least near the start of the cycle   i am thinking of something more industrial  perhaps   ,robotic-arm
2081,soft led protection material,i am looking for some material to build a soft clear protective covering for rgb leds  the material needs to be close to transparent to allow light to shine through  be soft and compliant but sturdy enough to withstand someone standing on it  the ultimate goal is to have a floor of these leds that someone can jump in barefoot and change led colors   i have tried gel candle wax and silicone but neither worked very well  i am looking for other material ideas and this was the most relevant of the stackexchanges that i could find   ,arduino
2083,arduino uno getting a type of  hanged  while runing samll code of switc debounce and serial print,i am using arduino uno to read a push button every time it is pressed earlier i was simply reading the digital io pin to read the count and then i faced the condition of switch debounce regarding which i had asked a question here and get to know that i must use interrupt instead of reading a digital io pin but even after using interrupt  i was facing the problem of switch debouncing  so i used this link and code given on this link  and change   long debouncedelay        to    means read any thing ina time gap of    mili second  as the code says now what is happening  code is running on the board and after some time my board get hang and led stop toggling on any press of push button and then i had to manually reset my board i also want to add upon a thing that i am also using a serial port in between when led toggles or switch is pressed  i am totally confused why this is happening there can beone possibility that this is happening because i reduced time gap between two consecutive events to    from    miliseconds and that might be making avr get hanged and thus require a manual reset  ,arduino c serial communication
2084,fake localization using bag file in ros,i have a bag file that contains couple of topics needed for localization  odometry data  kinect data and   what i want is watching robot s movement path in rviz after initializing robot position  even i don t know how to initial it   any help  all topics   scan  tf  clock  map  odom  ,localization ros
2087,which kinect to a movement base ,i am making a mobile base for a robot with wheels  i want to use a kinect like a movement sensor  to avoid obstacles  recognition of people  etc     but i read that there is   models  the     and the developer  which kinect works well for my job  and another thins  its there another thing that can i use like a movement sensor  to see diferent posibilities  ,mobile-robot wheeled-robot kinect
2088,powering down servos completely in robotc tetrix,for a certain robotic application  actually for the ftc challenge this year  our team is performing an operation where a servo driven arm could potentially be forced into an unknown position  we are using nxt tetrix  since this could damage a powered servo working against this forced position  servo holding arm weight on fixed base is now trying to move heavy base relative to fixed arm   we are thinking about somehow de powering our servos  or servo controller   in order to get the servos to  relax  and accept the mechanically forced position  originally  we were thinking of having our robotc code determine the physical position of a given servo and set its desired position to there every loop  limiting how much a servo would try to fight the movement  but to our dismay   actually gives us the setpoint  and not the physical location  due to the servo being unable to provide this information   we also considered setting servochangerate fooservo  to   the minimal value  but this only changes the rate of the target location changing relative to the previous target  so  we re concluding that the only way to really do this is to fully depower the servos  is this possible on nxt tetrix with robotc  a few notes   i realized as well that one could suggest to rig an encoder associated with a tetrix motor that does not need an encoder  onto the rotating area  that actually would not work for mechanical constraints  i looked into setting pwm enable as shown here but am not sure how to send the i c commands needed  if someone could clue me in to how these commands would be sent in terms of c code  that would be very helpful   ,power rcservo nxt robotc
2089,compiling code for ey   ,i recently purchased at ey    from electrodragon  ey    all in one   axis motion sensor  gyro   acceler   magneto   baro  i am having a hard time compiling the example code on my arduino   this is what is happening   so far  i am only copy and pasting the code   any help   i am somewhat new to programming  so don t fully understand all of the code  ,arduino sensors gyroscope
2090,wifi to pass through aluminium,i am about to make an rc car which uses a wifi connection  the body for the car would be made from aluminium and the wifi receiver will be placed inside this aluminium casing   how do i make sure that this will work  would i be forced to change my material or can i just make an extension for the receiver and make sure it is out of the casing   if so   would that really help me  ,wifi
2091,how to use arduino for esc control ,i am using an arduino uno to control an esc for my  in progress  quadrocopter   i am currently using the servo library to control the esc  which works great  except   a count of     is max speed  meaning i only have    speeds between     stopped  and      motor at full power  to correctly run my quadrocopter  i would like to have many more speed options   any ideas   i m having a hard time using a pwm signal  i might not be doing it right though  my current code is here   ,arduino control quadcopter esc servomotor
2096,using armatures in morse robotic simulator,i m trying to add my own robot in morse      using ubuntu         i am struggling to add an armature actuator and armature pose sensor to an existing robot  can someone please explain how this can be done  preferably with some sample code and using the socket interface   thanks   ,mobile-robot sensors robotic-arm simulator python
2098,are there any gps sensors that provide data at  hz or faster ,i searched for gps devices that provide   sec updates to server  but i have not found any  i found this   t   s module has sent a monitoring data packet  after    seconds the   server sends an acknowledgement  in    seconds later  t     s  module   sends the next monitoring data packet  are there any products that take less than this time  why do gps devices take this much time to send data  ,sensors gps
2101,do i need an accurate flight model for a uav ,as i understand it  a kalman filter uses a mathematical model of the robot to predict the robot s state at t    it then combines that prediction with information from sensors to get a better sense of the state  if the robot is an aeroplane  how accurate realistic does the model need to be  can i get away with simple position and velocity  or do i therefore need an accurate flight model with computational fluid dynamics  ,kalman-filter uav
2104,how to calculate probability of particle survival for particle filter ,i m trying to figure out a way that i can calculate the probability that a particle will survive the re sampling step in the particle filter algorithm  for the simple case of multinomial re sampling  i can assume that we can model the process like a binomial distribution if we only care about one sample particle  so if the particle has a weight of w that is also the probability that it will get selected in a step of the re sampling  so we use     p k  p  n  where p is the binomial distribution  k is    we did not select the particle in all our tries   p is equal to w and n is equal to m  the number of particles  what is the case though in the systematic re sampling  where the probability of a particle being selected is proportional but not equal to its weight  ,particle-filter
2105,    degree ultrasonic beacon sensor,basically  i want to detect an ultrasonic beacon in a radius around the robot  the beacon would have a separate ultrasonic emitter while the robot would have the spinning receiver  are there any existing ultrasonic sensors that would meet this use case or am i stuck hacking one together myself  is ultrasonic even the best choice  i was hoping that the beacon would be kept in a pocket  so i figured optical sensors were out  edit  the beacon and robot will both be mobile so fixed base stations are not an option  ,sensors
2106,what happened to butler s car ,having read the article  this car has electric brains  in popular mechanics  august      i have some questions  how practical were his methods  was his work acquired by a car manufacturer or some other company  were his methods developed further  how did his corner navigation work  i don t think he needed to know the distances of road segments  i think he could have used sonar or radar to detect a corner but if cars were entering the corner before him  he could misinterpret those cars as a wall and the absence of a corner  additionally i think he d need two sonar radar systems on both sides of the cars which aren t mentioned  all that s mentioned is a set of relays  what is the compensator that is mentioned  it s said to function as a gyroscope   i cannot find any information on this device  that i m sure is relevant   ,design navigation
2109,pomdps in robotics,pomdps are used when we cannot observe all the states  however  i cannot figure out when these pomdps can be useful in robotics  what is a good example of the use of pomdps   i have read one paper where they used them  but i didn t find it obvious why pomdps should be used  what would be good projects ideas based on pomdps  ,algorithm artificial-intelligence
2110,rc transmitter quadcopter with arduino,i have a wl v    quadcopter and i want to control it using arduino instead of the joysticks on the transmitter  i opened up the transmitter and saw that each joystick has   potentiometers on the pcb and that the voltage for each pot goes from      v  i used arduino s pwm and a low pass filter and connected the output of the filtered output to the potentiometer s analog pin which is connected to the pcb  i cannot desolder and take out the pots from the pcb  but even with this  going onto the analog pin  my transmitter s display gave       now i am really confused and frustrated because i don t know how else to control this transmitter other than attaching stepper motors to the joysticks and manually controlling the transmitter but this is really my last resort  can someone help me with this  i have spent hours and hours trial and error but i am getting nowhere   here is the pcb of the transmitter    ,arduino sensors radio-control wireless
2111,have bloodstream nanobots been approved in any countries ,a google search on  bloodstream nanobots  yields thousands of results and just on the first page  many results of blog posts that date back to       it is nearly   years later   i ve had no luck in finding any information on actual approval of these bots  are there any countries at all who have approved this  people seem to have talked about it like crazy   years ago  yet  we re still not seeing anything  ,microcontroller
2114,sending and receiving parameters to ardupilot,i am interested in getting an arducopter with an ardupilot apm   i read through the documentation and from what i understand  ardupilot is the low level hardware and firmware that directly controls the motors of the arducoptor   i would like to know if there is a higher level programmatic interface to the ardupilot  the mission planner provides a user interface to control the ardupilot  but is there a programmatic interface to control it  in other words  would it be possible for a user written  linux process  to receive and send sensory data to and from the ardupilot respectively  ,quadcopter ardupilot
2117,defining frames for  dof robotics arm,for examples if i have this robotic arm  example  for the base rotation   th dof in the clip at        we know that the z axis for that joint will be the same as the z axis for the base frame     but i don t know about y and z axises of the base rotation respects to the base frame  should they be the same or not   and one more thing  for defining the frame of the base rotation  at      in the clip   the vertical arm pitch  at      in the clip  and the horizontal arm pitch  at      in the clip   it s pretty easy  but i don t know how to continue for defining the frame of wrist roll  at o    in the clip  and wrist pitch       in the clip  since the angle between the z axis of wrist roll and the wrist pitch is now   o   thank you very much  ,localization kinematics robotic-arm
2119,deburring robot  plastic box ,for a university course i have been asked to design a rough  specification  for a system that will deburr a plastic box that appears in a workspace  due to irregularities in the boxes edges i cannot use simple position control and must use force control  i have so far decided on  using an ir sensor to detect the box has appeared in the workspace  use an epson   axis robot to move around the work piece use an ati   axis force sensor to maintain a constant force against the edge of the box as the deburrer robot moves around it  is there a simple means of detecting the end of each side of the box   a  n force value would indicate reaching the edge of a box but it could also mean a breakage in the box which was also specified  how can i distinguish between the two   also does my work so far sound sensible   thanks for any help ,control
2121,resampling attitude states  quaternions  rotation matrix  in a particle filter,suppose i have a particle filter which contains an attitude state  we ll use a unit quaternion from the body to the earth frame for this discussion    what methods should or should not be used for resampling  many resampling schemes  e g  this paper  seem to require the variance to be calculated at some stage  which is not trivial for   or  the variance is required when performing roughening  are there any good papers on resampling attitude states   especially those that re sample complete poses  e g  position and attitude   ,particle-filter pose
2124,image retrieval through a multibeam imaging sonar,i would like to know if anyone here has used the blueview sdk  linux  for retrieval of images from the pings obtained by a multibeam sonar  p     p     etc     if so  i d like to know why would anyone get a null head when i trying to retrieve the head  eventually for the pings to be converted to an image  using the  method  my snippet for retrieving the image from a  son file  some son data son  is given below  int main         bvtsonar son   bvtsonar create        bvtsonar open son   file    some son data son         if  null    son  cout     son not null     endl      bvthead head   null       bvtsonar gethead son      head       return       ,auv sonar
2127,where can i learn electronics from intro to advance digital,i d like some well put video series of like    videos  or anything but it needs to thorough and in easy english   less mundane  so far all resources i have found either go upto resistors code or of projects that tell you do this and this and this and tada you got this  is there really no online resource for people to learn electronics  i want further master analog and do move on to digital cause it s better to spend      cents     than  spend     on components and get the whole thing on tiny chip  please bare with me like six months i have been searching for legit source  material that is meant to teach you  i like pictures and colors   ,electronics
2130,transform image using roll pitch yaw angles  image rectification ,update  this exact problem has been solved in stackoverflow  please read this post there for further explanation and a working solution  thanks  i am working on an application where i need to rectify an image taken from a mobile camera platform  the platform measures roll  pitch and yaw angles  and i want to make it look like the image is taken from directly above  by some sort of transform from this information   in other words  i want a perfect square lying flat on the ground  photographed from afar with some camera orientation  to be transformed  so that the square is perfectly symmetrical afterwards   i have been trying to do this through opencv c    and matlab  but i seem to be missing something fundamental about how this is done  in matlab  i have tried the following   where r z y x are the standard rotational matrices  implemented with degrees   for some yaw rotation  it all works just fine  r   r z     r y    r x      which gives the result   if i try to rotate the image by the same amount about the x  or y  axes  i get results like this  r   r z     r y    r x        however  if i rotate by    degrees  divided by some huge number  it starts to look ok  but then again  this is a result that has no research value what so ever  r   r z     r y    r x             can someone please help me understand why rotating about the x  or y axes makes the transformation go wild  is there any way of solving this without dividing by some random number and other magic tricks  is this maybe something that can be solved using euler parameters of some sort  any help will be highly appreciated  ,computer-vision cameras
2131,line following robot with ev  colour sensor,i am trying to build an advanced coloured lines following robot with the ability to differentiate between many different coloured lines and follow them  i am looking for the right sensor that will help my robot achieve its objective  as i was researching i came across the ev  colour sensor which can detect up to   colours  is this sensor suitable for my project  what other sensors can i use and how  thank you ,mobile-robot sensors line-following
2132,what dependencies do i need for usb programing in python with pyusb ,i am trying to get the  command to work properly in a python script i m writing on angstrom for the beagleboard  here is my code     usr bin env python  import usb core  import usb util  import usb backend libusb   as libusb   pyusb debug level    debug    find our device   bus     device      id              idvendor            x        idproduct           x       dev   usb core find idvendor  xfffe  idproduct  x        imanufacturer             torobot com  dev   usb core find idvendor  x      idproduct  x      backend libusb get backend      i don t know what s missing  but here is what i do know  when i don t specify the backend  no backend is found   when i do specify the backend usb backend libusb   i get the following error   root beagleboard   servo    pyservo py traceback  most recent call last     file    pyservo py   line     in  module      dev   usb core find idvendor  x      idproduct  x      backend libusb get backend       file   usr lib python    site packages usb core py   line      in find     return  interop  next device iter k  v     file   usr lib python    site packages usb  interop py   line     in  next     return next iter    file   usr lib python    site packages usb core py   line      in device iter     for dev in backend enumerate devices      file   usr lib python    site packages usb backend libusb   py   line      in enumerate devices      check  lib usb find busses      file   usr lib python    ctypes   init   py   line      in   getattr       func   self   getitem   name    file   usr lib python    ctypes   init   py   line      in   getitem       func   self  funcptr  name or ordinal  self   attributeerror  python  undefined symbol  usb find busses  what am i missing so that this will work properly  thank you  ,rcservo python usb
2133,turning a differential drive robot to a specific angle,given a robot with   wheels with radius r on one axle with length d  i want to set the wheel speed so that it turns to an angle phi as fast as possible  the timestep t is    milliseconds  i thought the wheel speed could be set to v     desired heading actual heading    circumference wheel trajectory     pi   t   wheel radius   this will converge to a somewhat right angle  eventually  but its very slow and becomes slower as i approach the angle i want to be at  is there an alternative better way to do this  ,kinematics
2135,algebraic and geometric in inverse kinematic,i m just wondering that is there any case that when algebraic way can t solve the problem while the geometric can   cause i m working on a  dof robotics arm this one  i know the length of l  and l   location that i want for the end effector  then i tried calculating the angles by using algebraic but it gave me cos alpha       but when i tried solving with geometric  i can find the solution  so is it because i use a wrong way in algebraic    thank you very much  ,localization kinematics robotic-arm inverse-kinematics
2138,move atrv robot to specific distance using ros,is there a node or package that can send commands to  to move atrv jr like   meters forward or turn it    degree to right left  i don t want to tell the robot to move with specified speed  for example when i use this command rostopic pub  cmd vel geometry msgs twist                                 the robot starts moving forward until i send another command or send break command  ,mobile-robot ros navigation
2145,another sdk like openni,i am taking information for my project and i need to see libraries ans sdks  searching in the web i found that openni has a lot of functions and when i try to found another sdk  i dont find any other  i am working with a kinect and a xtion so i need an sdk who works in both   is there any other sdk o set of libraries that works well in both  thanks  ,kinect openni
2146,apm accelerometer calibration,i am trying to manually calibrate the on board accelerometer of an apm     controller  i am using the following code  i found this somewhere  don t remember where  with arduino        in windows environment  to fetch the accelerometer and gyro data   my objective use to calibrate the accelerometers  and gyro   so that i can use them without having to depend on mission planner  i m reading values like  acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z    acc x       acc y        acc z       gyro x      gyro y    gyro z     from what i understand  spiread          returns an analog voltage value from the data pins of the sensor  which happens to be proportional to the acceleration values  right  my question is  how do i go about calibrating the accelerometer  what i ve tried till date  i ve tried the  place horizontal    place nose down    left side  right side  technique used by mission planner   basically  when placed on horizontal position  the sensor is experiencing   g on it s z axis and  g in x and y axis  left right side provides   g on y axis and nose down up provides   g on x axis   now for every orientation  i ve passed the raw sensor data through a lpf and then computed the mean  median and sd of this sensor data over     iterations  i store this mean  median and sd value in the eeprom for each axis  one for   g and one for  g   now  when i use the sensor  i load the stats from the eeprom  match the mean median and standard deviation with the current reading of     iterations   here i m working under the assumption that the values between  g and   g  and anything above  g  can be interpolated extrapolated from the data using a linear plot    is this the correct approach for calibration  can you suggest a better way  i noticed that the maxima minima for each axis is different  is this the expected outcome or is there something wrong in the code  what do i do with the gyro  how to calibrate for angular acceleration   ,arduino accelerometer ardupilot
2147,how can i interface my cmos camera module to an arduino ,i am totally new to the camera interface and usage in an embedded project  and would like to use a cmos vision sensor like this this project further will be used to power a small robot with on board video processing power using processors like arm    i do have a limitation that until now i have worked only on   bit micro controllers like the atmega           and on the arduino platform  i think that for better processing we can use arduino due  with the data sheet for the cmos camera above  we can build its breakout board  but what next  i haven t i found any useful resources while searching  all i need to do is to capture a small video and store it in a sd card  i have seen these links but they haven t proved to be very useful as they don t provide me the required form factor  i am looking to interface this module to a customized board  so what so i need to understand about what commands they accept for their proper functioning like starting to take video and posting them out on a output pin  if we get a video on a output pin  to which pin should i take that output to on my controller  i e  on uart or i c or spi  ,arduino microcontroller computer-vision cameras c
2148,continuous or discrete,i am new to robotics and control and i have been thinking about how to deal with problems in real life  i have passed a course in control  but i do not have any idea about control for discrete digital systems  there are a lot of robots and in general dynamic systems which are controlled by microcontrollers or computers with some software  i e  simulink  usually there are sensors which send feedback to the microcontroller or the computer and the controller sends a signal w r t the input signal from sensors  i was wondering how we decide if the system is discrete or continuous  how one can decide if he should use discrete or continuous blocks in simulink to control a dynamic system  does it really matter which one we use  after all computers are digital and i think it is easier to work with digital signals and also  do we really have continuous signal  i have not passed any signals course  so my questions might be really easy  i did not find any other place for my question  ,control microcontroller
2149,extended kalman filter with laser scan   known map,i am currently working on a project for school where i need to implement an extended kalman filter for a point robot with a laser scanner  the robot can rotate with   degree turn radius and drive forward  all motions are piecewise linear  drive rotate drive   the simulator we are using does not support acceleration  all motion is instantaneous   we also have a known map  png image  that we need to localize in  we can ray trace in the image in order to simulate laser scans   my partner and i are little confused as to the motion and sensor models we ll need to use   so far we are modelling the state as a vector   we are using the update equations as follows  we thought we had everything working until we noticed that we forgot to initialize p and that it was zero  meaning that there was no correction happening  apparently our propagation was very accurate as we haven t yet introduced noise into the system  for the motion model we are using the following matrix for f   as its the jacobian of our update formulas  is this correct  for the sensor model we are approximating the jacobian  h  by taking finite differences of the robots    and  positions and ray tracing in the map  we talked to the ta who said that this would work but i m still unsure it will  our prof is away so we can t ask him unfortunately  we are using   laser measurements per correction step so h is a  x    the other issue where having how to initialize p  we tried          and they all place the robot outside the map at           when the map is only   x    the code for our project can be found here   any advice is greatly appreciated  edit  at this point i ve gotten the filter to stabilize with basic movement noise but no actual movement  as soon as the robot starts to move the filter diverges quite quickly and exits the map   ,mobile-robot ros kalman-filter ekf
2151,what micro controller should i use ,i am planning on building a robot with wheels  later legs  if possible   that can move around the room and analyze certain things  using a couple sensors  in the later steps more functions such a grabbing are the things i want to add  could you recommend me a micro controller  my concern about arduino is that there aren t enough slots  raspberry pi seems like it constantly needs a screen for the user  i am a complete amateur when it comes to robotics  however  i am quite familiar with the computer languages java and python  since i wrote a fun app for android for myself i would love the robot to be compatible with android  too  ,arduino raspberry-pi beginner
2156,how to calibrate an industrial robot ,i am testing an industrial robot  abb irb       using three simple micron dial gauges to get x y z values at particular point by varying speed  load and distance from home position   my questions are  whether these three parameters influencing the repeatability or only the accuracy  using dial gauges  without any relation to the base frame  is it possible to measure accuracy  is any other cost effective method to measure the repeatability and accuracy like above method  ,industrial-robot calibration
2158,making a tiny robot by using a remote brain,i d like to build a robot as small as possible and with as few  delicate  parts as possible  the bots will be bashing into each other   i was wondering if it was possible to use a small chip that could receive bluetooth ir wifi commands to move the motors  and in turn  send back feedback based on sensors such as an accelerometer  to detect impact   i can probably achieve something like this with the picy   however this is slightly bigger than i d like  due to the size of the pi  and i m not sure how long the pi would last taking continuous impacts  i d therefore like to try to offset the brain  the pi  to the side of the arena and just use a small chip to receive move commands  and send back data from the accelerometer  do you have any recommendations for such a chip  wifi would be my choice but if it impacts the size i could try bt edit  after further research it seems an arduino nano with a wifi redback shield might do the job along with something like this for the motors   ,raspberry-pi rcservo accelerometer
2159,computer aided rc airplane combat, is from      swarm and shows rc aircraft or combat wings trying to hit each other in the air   scoring a hit is pretty rare  and i d like to increase a pilot s chances by using a computer targeting system   it would be an offline system that gets data from sensors on the airplane  what sensor s  would work for this application  ,mobile-robot sensors
2165,spp bluetooth profile compatibility with phone,i m building a project that uses a cell phone to control a microcontroller via bluetooth  i ve decided to use the hc    bluetooth module  hc    manual   and the phone i m using is the nokia c      series       the hc    module uses the spp bluetooth profile while my phone only supports dun  ftp  gap  goep  hfp  hsp  opp  pan  sap  sdap profiles  but to my knowledge the phone api utilizes rfcomm  question is  can i use this bluetooth module with my phone  thanks in advance and my apologies if my question is too trivial as i m quite new to bluetooth   shaun  ,microcontroller
2167,quadcopter instability with simple takeoff in autonomous mode,i m trying to get a quad rotor to fly  the on board controller is an ardupilot mega      being programmed by arduino        i m trying to fly it in simple autonomous mode  no radio controller involved  i ve done a thorough static weight balancing of the assembly  somewhat like this    and the propellers are balanced correctly  i m trying to get the quadcopter to lift using this code   but the issue is  as soon as the quadcopter takes off  it tilts heavily in one direction and topples over   it looks like one of the motor propeller is not generating enough thrust for that arm to take off  i ve even tried offsetting the weight balance against the direction that fails to lift  but it doesn t work  and i snapped a few propellers in the process    is there something wrong with the way the escs are being fired using the servo library  if everything else fails  am i to assume there is something wrong with the motors  do i need to implement a pid controller for self balancing the roll and pitch just to get this quadrotor to take off   edit       thanks for all the replies  i got the pid in place  actually  it is still a pd controller with the integral gain set to zero   here s how i m writing the angles to the servo  motor  write  int  val    kp   perror     ki   ierror     kd   derror         front left motor  write  int  val    kp   perror     ki   ierror     kd   derror         rear right motor  write  int  val    kp   perror     ki   ierror     kd   derror         front right motor  write  int  val    kp   perror     ki   ierror     kd   derror         rear left   ki is zero  so i ll ignore that  with the value of kp set somewhere between         to          i m getting an oscillation of steady amplitude around a supposed mean value  but the problem is  the amplitude of oscillation is way too high  it is somewhere around         degrees  which looks crazy even on a tightly constrained test rig       edit    how i calculate the term  perror    simple linear thresholding   i ve a precomputed data of the average readings  mean and sd  coming out of the gyro when the imu is steady  based on the gyro reading  i classify any motion of the setup as left  right  forward or backward   for each of these motion  i increase the perror term for two of the motors  i e  for right tilt  i add perror terms to motors        for left tilt  i add perror term to motors       etc   check the comment lines in the code snippet given above    the magnitude of error i assign to the perror term is   abs current gyro reading    abs mean steady state gyro reading   this value is always positive  therefore the side that is dipping downwards will always have a positive increment in rpm      as i crank up the derivative gain to around        to         the oscillation dampens rapidly and the drone comes to a relatively stable attitude hold  but not on the horizontal plane  the oscillation dies down  considerably  but not completely  only to give me a stable quadrotor tilted at          degrees with horizontal   i m using only the gyros for calculating the error  the gyros were self calibrated  hence i do expect a fair amount of noise and inaccuracy associated with the error values    do you think that is the primary reason for the high amplitude oscillation   one other probable reason might be the low update frequency of the errors  i m updating the errors   times a second    could that be a probable reason it is taking longer to stabilise the error   and  for the steady state error after the wild oscillations dampen  is it necessary to fine tune the integral gain to get rid of that  please help   edit     i cranked up the frequency of operation to      hz and what i get now is a very controlled oscillation  within        degrees    i m yet to tune the derivative gain  following which i plan to recompute the errors for the integral gain using a combination of gyro and accelerometer data    edit     i ve tuned the p and d gain  resulting in       degrees oscillation approx   i can t get it to any lower than this  no matter how much i try  there are two challenges about which i m deeply concerned  after   to   seconds of flight  the quadcopter is leaning into one side  albeit slowly   a  can this drift be controlled by tuning the integral gain  b  can the drift be controlled by using accelerometer   gyro fused data  c  given that my drone still shows       degrees oscillation  can i consider this the optimal set point for the proportional and derivative gains  or do i need to search more   in which case  i m really at my wits end here    ,arduino quadcopter pid ardupilot
2173,visualizing kinect data on rviz,i am a beginner of ros  kinect and ubuntu  what i want is to visualize kinect s data on rviz environment then run object recognition on it  i ve tried a few tutorials but had no luck  all i got was an empty rviz world  since i am a beginner i would appreciate any step by step instructions  preferably for hydro or groovy   i would also like to note that i ve managed to get visual from kinect so the device is working fine  ,ros kinect
2180,lawn mower robot  type of cutter ,if not all  but major types of lawn mower robots are rotary mowers  i presume  that reel mower is more efficient  and is said to leave a better lawn health and cut  so  why industry go to the other option       i m assuming the efficiency  as electrical rotary mowers have at least    w universal motors or induction motors  and a manual reel mower is capable nearly the same cutting speed  ,motor mechanism
2182,what should i use for speech recognition ,i was wondering  my team and me are working on a robot communication oriented and we wanted to add speech recognition on it  what technology should i use   ,software
2186,understanding arduino bootloader,that is what i came to understand while reading here and there about flashing a new bootloader understanding what a bootloader is etc etc the bootloader is supposed to be the first thing that runs when i power up my arduino duemilanove  or micro controllers in general   it does some setup then runs my app  it also listens to the usb cable so that if i upload some code it erases the old one and run the new one  there are   sections in the memory  one for the bootloader  s   and one for the app  s    code on s  can write to s  but not to s   or strongly discouraged i don t remember   there are things that i don t understand though    if i upload some new code while my app is running  the upload works  what happened   i thought that the bootloader gave hand to my app how can we flash a new bootloader   if the bootloader is the thing that runs on section    s   and can only write to s  and if the bootloader is the only thing that listens to new code uploads       can you help me correct my thoughts and answer my questions   many thanks   ,arduino microcontroller
2189,what autopilot to purchase apm     or pixhawk ,i m a newbie in uav stuff  your advice would be very helpful  i want to start mapping using fixed wing uav  but my main choice was apm      but after some researches  i found that apm     won t be actively maintained in the future because the future releases will be pixhawk  i wonder if i should choose apm     for its stability  on the other side i don t see the benefits of pixhawk apart having long time support  or being a newbie i should start with something experimental like apm        cheap chinese version for apm   thanks in advance ,uav
2192,how can i build a   cm    cm ir range sensor ,everybody here is probably aware of the sharp distance sensors  gp y  series  e g  gp y a  yk f   they use a diode to emit infrared light and measure the angle of the reflected light with a psd  i e  they do triangulation   they seem to be the only producers of this technology  i am only aware of a few similar but incomparable devices  sensors of ambient light and distance or proximity like si   x   which other comparable products are out there  another way to ask this question   what are the different ways to build a   cm      cm range low cost ir range sensor  and what is an example of each of those ways   ,sensors manufacturing
2195,re calibration of an articulated industrial robot,we are planning to recalibrate abb irb      robot and conduct series of accuracy   repeatability tests using faroarm  my questions are i  is there any physical identification marker on the robot which can be used to identify the location of base co ordinate frame  ii  if locating the base frame is not possible  can accuracy be measured from fixed arbitrary point in space  ,industrial-robot calibration
2196,robots without microcontrolers  beam robots   are they technologically limited ,beam robotics seem to be a good approach to teach learners about electronics in robotics  but can these robots be like regular programmed  cognitive  robots  can these robots  with just analog circuits  take us to the level of robotic assistants  worker robots and other kinds of self sufficient autonomous robots  i specifically want to know that  when creating mission critical robots       what are the areas in robotics which are practically impossible without a real time software system     what areas of the field can be done without programming  if yes  are these areas feasible without an onboard software system     could an intelligent space rover  work without a cpu in the future  ,control software electronics artificial-intelligence embedded-systems
2197,how can i make a boat,i m having an event for a boat race simple boat has to be made all i have is   days the restriction is   v motor not more than      rpm what best material and shape will you suggest to make a boat i know basic circuits we have to make a boat with a wired circuit that circuiting i can do but what can be an ideal shape for boat with maximum speed it can achieve   ,activerobot
2205,low speed control of bldc motors,i m having a problem with controlling my bldc motor when starting up and when running in low rpm  i have a custom board to measure rotation of the motor using an optical sensor and send servo pwm commands to an esc  the problem is  that i can t start the motor smoothly  when i slowly increase the control signal  it starts stuttering and then jumps directly up to about     rpm  is there a way to improve this situation without using a sensored motor esc combo  ,motor control brushless-motor
2209,what are the different types of electric motors ,i am beginning to learn about the hardware aspect of robotics  and in order for a lot of this new information to be useful to me  whether on this site or elsewhere  i will need a basic understanding of the terminology  one thing that comes up repeatedly is different electric motors  servo  dc motor  brushless motor  step motor  gear motor    etc is there a comprehensive list  or at least a list of the most common ones  and their descriptions   differences  ,motor
2215,how do robotics startups work ,in software engineering startups  you generally go to a room with a computer or bring your own laptop  and write code  i m interested in how robotics startups work  is there a separate location for designing the robots  take for example  anki  do they have separate research labs for designing robots  how does a robot get from a single design to being manufactured  i couldn t find a better place on se to post this  the startups business section is defunct   please link me to another se site if there is a better place to ask this question  ,manufacturing
2216,what method should i use for putting rubber bands on wheels ,i have a boe bot pbasic  stamp based robot that came with rubberband  tires  for the wheel  however  they are very tight and i can t figure out how to get them onto the plastic hubs  the furthest i ve gotton was mostly covering the outside  but when trying to make it less crooked it came off again  is there some trick to getting those pesky tires to stay on  ,wheeled-robot
2217,access denied during pic programming in windows xp,i m programming a pic  f   with propic   which communicates via serial port  as i don t have this port in my pc  i used serial to usb adapter  i m using icprog in windows    i ve proggrammed it before but it was in windows xp using the driver who specifies in  and worked perfectly  but in this os the only difference is the adapter  the program gives some errors while loading the driver    error occured  access is denied  while loading the driver    privileged instruction   ,microcontroller
2218,what is the purpose of electronic braking in motors ,i have a micro magician v  micro controller  it has a a     dual fet  h  bridge motor driver built in  in the manual it states  electronic braking is possible by driving both inputs high    my first question is  what is the purpose of these brakes  if i set the left right motor speed to    the robot stops immediately anyway  what advantage is there to using these brakes  or am i taking the word  brake  too literally  my second question is  the driver has  motor stall flags that are normally held high by pullup resistors and will go low when a motor draws more than the    ma current limit  connect these to spare digital inputs so your program will know if your robot gets stuck   but when my robot hits a wall  the wheels just keep on spinning  slipping if you will   i take it these stall flags can be used on a rough surface where the wheels have more friction  ,motor h-bridge
2222,i am an entrepreneur and i want to start building robots for businesses  where do i start ,over the last couple of years i ve had good success with my technology startups and now looking to enter into robotics  i was interested in robotics and automation ever since i was a kid  yes  that sounds nerdy   so my question is  where to get started  what to build  and how to sell  and lastly  how difficult it is to sell in this industry  ,industrial-robot
2224,udoo board   kinect sensor ,i am wondering if it would be possible to get kinect to work with udoo board  quad   i have found that there is now support for ros   udoo  also saw a question asked about xtion   udoo which shows some more interest  it would really be great if it could be possible for kinect udoo  was hoping to implement perhaps a miniature version of turtlebot  i wish someone could give some insights on this matter  thanks  ,ros kinect arm embedded-systems
2227,quadcopter configuration,i m building a quadcopter  it will be controlled by a beaglebone black with several sensors and a cam  i new to the quadcopter stuff  therefore it would be nice if someone could have a look at my setup before i buy the parts   frame  x   f      mm battery  turnigy nano tech     mah  s      c lipo pack motor  ntm prop drive      s    kv      w brushless motor esc  skywalker  x   a brushless  this sums up to    kg  giving me still some room for about    g payload  what do you think  did i miss something important  better ideas for some parts  ,quadcopter
2228,zero crossing events with brushless dc motors,i would like to ask a question about zero crossing event in a trapezoidal commutation on a brush less dc motor  here is a waveform that shows that the zero crossing event occurs every     electrical degrees in a sinusoidal commutation   but what about trapezoidal commutation  here is the waveform that i found about the trapezoidal commutation   so as you see  the zero crossing occurs    electrical degrees after the previous commutation and    electrical degrees before the next commutation  in a motor with one pole pair  we would have    electrical degrees      mechanical degrees  so we would have this waveform   you see that the zero crossing in phase a occurs when the magnet faces the phase c  or in other words  after    electrical degrees from the last commutation  my question in why does the zero crossing happen at that moment  why not after    electrical degrees  or    electrical degrees  is it related to some law s of induction  what are those law and how do this law s appear in this motor  can someone explain to me this with some pics  ,brushless-motor
2234,zero crossing events in trapezoidal commutation,i would like to ask a question about zero crossing event in a trapezoidal commutation on a brush less dc motor  here is the waveform that shows that the zero crossing event occurs every     electrical degrees in a sinusoidal commutation   but what about trapezoidal commutation  here is the waveform that i found about the trapezoidal commutation   so as you see  the zero crossing occurs    electrical degrees after the previous commutation and    electrical degrees before the next commutation  in a motor with one pole pair  we would have    electrical degrees      mechanical degrees  so we would have this waveform   you see that the zero crossing in phase a occurs when the magnet faces the phase c  or in other words  after    electrical degrees from the last commutation  my question in why does the zero crossing happen at that moment  why not after    electrical degrees  or    electrical degrees  is it related to some law s of induction  what are those law and how do this law s appear in this motor  can someone explain to me this with some pics  ,brushless-motor
2236,computercraft  minecraft mod  navigation  collision avoidance and path planning finding in  d  d space,i m programming lua for controlling computers and robots in game in the minecraft mod computercraft  computercraft has these robots called turtles  that are able to move around in the grid based    world of minecraft  they are also equipped with sensors making them able to detect blocks  obstacles  adjacent to them  turtles execute lua programs written by a player  as a hobby project i would like to program a  function for my turtles  some turtles actually have equipment to remove obstacles  but i would like to make them avoid obstacles and thus prevent the destruction of the in game environment  i have no prior experience in robotics  but i have a b sc  in computer science and am now a lead web developer  i did some research and found some basic strategies  namely grid based and quadtree based  as i have no experience in this area  these strategies might be old school  note that turtles are able to move in three dimensions  even hover in any height   i could share the obstacles as well as obstacle free coordinates in a common database as they are discovered if that would help me out  as most obstacles are stationary once they are placed  what are my best options in this matter  are there any easy fixes  where do i look for additional resources  thank you very much in advance      edit  thank you for your feedback  i started reading the book artificial intelligence  a modern approach   rd edition to get up to speed on basic theory as suggested by ian  pointers to other educational resources are appreciated  also  i started developing a basic navigation algorithm for moving in unexplored areas  similar to what cube suggested  the priority for me is as few moves as possible  as it costs time and fuel cells for each additional move  approx      seconds and   fuel cell per move in either direction   i plan on using the euclidean heuristics function in a greedy best first search for computing a path that is expected to be quite optimal in reducing the number of moves to reach the goal  if enough data is available from the shared database from previous exploration  each time an obstacle is reached  i plan to use the following very basic algorithm  exploiting the fact that turtles are able to move vertically     calculate direct horizontal path to the goal     turn to the direction of the next step of the path     if an obstacle is detected in front of the turtle go to    if this is the  th time that an obstacle is detected in front of the turtle after moving up  go to       move forward  go to       if no obstacle is detected above the turtle  move up and go to    else go to       backtrack to the coordinates the turtle was in before moving upwards     turn left  go to     when using this algorithm  records are kept of the explored coordinates and uploaded to a shared database  however  there are some cases  that i did not consider    when should it move down    what if the goal is not reachable from a coordinate directly above it    if no horizontal move in any direction is possible  how long should it backtrack    how to detect unreachable goals  obstacles can then be removed if requested   maybe if enough exploration data of the area is available  a jump point search is performed to calculate an optimal path  however this assumes a  d map  how can i take the  rd dimension into account  also  what would be a good data structure to store the exploration data  ,mobile-robot navigation
2244,how to know the desired orientation of a quadcopter ,i am trying to simulate a quadcopter model on simulink  i want to implement a pid controller for each of x y z and phi theta  psi angles  pid gets the error  as input  which is to be minimized  for the x y and z  the desired values are entered by the user and the actual values are calculated from the accelerometer data  hence  the error is the desired set value   actual value  for phi theta and psi  the actual values may be obtained from the gyroscope and accelerometer  sensor fusion  but i don t actually know how to calculate the desired values for each one of them since the user is usually interested in giving the position values x y and z as desired not the angle values  the absence of the desired values prevents me form calculating the angular error which is needed for the pid controller  ,design pid quadcopter
2245,kalman filter and the state noise vector ,i m reading probabilistic robotics by thrun  in the kalman filter section  they state that   x  t   a  t x  t      b  t u  t     epsilon  t   where  is the state noise vector   and in  z  t    c  t x  t     delta  t   where  is the measurement noise  now  i want to simulate a system in matlab  everything to me is straightforward except the state noise vector   unfortunately  majority of authors don t care much about the technical details  my question is what is the state noise vector  and what are the sources of it  i need to know because i want my simulation to be rather sensible  about the measurement noise  it is evident and given in the specifications sheet that is the sensor has uncertainty   ,kalman-filter noise
2250,finding inverse kinematics algorithm for a specific manipulator,i need to find a way to solve invrese kinematics for comau smart   robot  could you give me a few hints where to start looking  i have no idea about robotics and i couldn t find an algorithm for this specific robot  ,inverse-kinematics
2251,difference between rao blackwellized particle filters and regular ones,from what i ve read so far  it seems that a rao blackwellized particle filter is just a normal particle filter used after marginalizing a variable from  p r t s t   y t  i m not really sure about that conclusion  so i would like to know the precise differences between these two types of filters  thanks in advance  ,slam particle-filter
2256,flipping an old manual switch  physical one ,i have an old audio amplifier that has those switches to turn it on   i m looking for the simplest motor robotic arm  or any other relevant component  to control this switch   eventually via raspberry pi   are there any options   ,motor raspberry-pi robotic-arm
2261,how to gyroscopically measure number of rotations on one axis when there is concurrent random motion on another axis,can a gyroscopic sensor  comparable to the type that are typically used in smartphones  that is embedded in this black object    that is rotating around the x axis measure the number of rotations around the x axis if the object may or may not also be rotating at the same time in random ways  number of partial or full rotations  speeds  and directions  around the z axis  if so  is the z axis rotation irrelevant  or is there special mathematics involved in filtering out the affects of the z rotation on the measurement of x axis rotation   or does another measurement such as acceleration or magnetism need to be used to solve the problem  is there any impact in using a   axis vs  a   axis gyroscopic sensor for this measurement scenario  ,sensors gyroscope
2262,how to choose wifi signal strength detecting sensors,we want to create robot that will localize itself by the signals of wifi routers  which sensors should we buy to detect strength of   wifi signal  which of following is necessary for us   or can be any other more suitable variants  we are using arduino as a platform  ,arduino sensors localization wifi
2263,quadcopter position measurement  accelerometer  gps or both  ,i previously thought that an accelerometer on a quadcopter is used to find the position by integrating the data got from it  after i read a lot and watched this youtube video  specifically at time        about sensor fusion on android devices  i seem to get its use a little correct  i realized that it s hard to filter out the considerable noise  generated from error integration   to get useful information about the position  i also realized that it is used along with the gyroscope and magnetometer to for fused information about orientation not linear translation  for outdoor flight  i thought of the gps data to get the relative position  but is it so accurate in away that enables position measurement  with good precision   how do commercial quadcopters measure positions  x y and z   is it that gps data are fused with the accelerometer data  ,quadcopter accelerometer navigation sensor-fusion
2264,are artificial intelligence and robotics different ,i need help in differentiating between ai and robotics  are ai and robotics two different fields or is robotics a subject in ai  i want to pursue a career in ai and robotics  so i need your valuable suggestion  i searched the web and also some universities that i want to apply and i cannot find any such thing that i am searching for  ,artificial-intelligence
2273,unwanted arduino reconnect  servo   arduino   python  raspberry pi ,i am having difficulty sustaining a connection between my raspberry pi  model b running raspbian  and my arduino  uno  while sending signals from the raspberry pi to a continuously rotating servo  powerhd ar      hb robot servo  via python  i m not sure if there is a more efficent way of sending servo instructions via python to the arduino to rotate the servo  i m attempting to communicate signals from the raspberry pi to the arduino via usb using what i believe is considered a  digital serial connection   my current connection    servo connection to arduino     signal  orange    pin      power  red       v    ground  black    gnd  on the raspberry pi i have installed the following  although not all needed for addressing this problem    xboxdrv pyserial python arduino command api pygame lego pi arduino  the sketch i ve uploaded to the arduino uno is the corresponding sketch provided with the python arduino command api   again  i m not positive that this is the best method means of driving my servo from python to arduino  to the servo   from the raspberry pi  i can see the arduino is initially correctly connected via usb  pi raspberrypi   python arduino command api  lsusb bus     device      id           standard microsystems corp  bus     device      id  d b      linux foundation     root hub bus     device      id      ec   standard microsystems corp  bus     device      id    e      microsoft corp  xbox     wireless adapter bus     device      id  a        terminus technology inc  fe       port hub bus     device      id  bda      realtek semiconductor corp  rtl    cus       n wlan adapter bus     device      id    d c  b logitech  inc  unifying receiver bus     device      id           arduino sa uno r   cdc acm   from the raspberry pi  i m able to rotate the servo as a test clockwise for one second  counter clockwise for one second  then stop the servo  with the following python script     usr bin env python from arduino import arduino import time  board   arduino       port   dev ttyacm     board servos attach      declare servo on pin   board servos write         move servo to full speed  clockwise time sleep      sleep for   second print board servos read      speed check  should read       board servos write         time sleep    print board servos read       should read         board servos write        print board servos read    board servos detach     the output via the raspberry pi terminal reads            although this only performs full speed in both direction  as well as the calibrated  stop  speed of      i have successfully alternated from a full speed to slower speeds  for example  going from   up to    in increments of     from the raspberry pi  i m able to send input from my xbox controller to drive the servo with a small custom python script i ve created along with xboxdrv  which works flawlessly with other projects i m doing      usr bin python  from legopi lib import xbox read from arduino import arduino    to catch ctrl c import signal import sys    the deadzone within which we ignore inputs  approximately     of total possible input deadzone          def signal handler signal  frame       print  stopping wrapper      sys exit       capture ctrl c so we can shut down nicely signal signal signal sigint  signal handler   print  starting wrapper  print  press ctrl c at any time to quit   board   arduino       port   dev ttyacm    board servos attach    board servos write         for event in xbox read event stream deadzone deadzone       print  xbox event   s     event         if the rb button it s being held  rotate the servo counter clockwise at full speed        when the rb button is released  stop the servo      if event key   rb            if event value                 board servos write                     print board servos read            else              board servos write                    print board servos read            continue  this script runs  and i m able to control the servo using the rb button on my controller  however  it eventually fails   sometimes after minutes  sometimes after seconds  rapid and intermittent input seemingly having no influence on expediting a crash   input is no longer read by the script  the terminal comes to a halt  the servo freezes on whatever the last command given was  either spinning endlessly or stopped   and i m forced to ctrl   c out of the script  if i check to see if the arduino is still connected to the raspberry pi  it shows that it has reconnected itself to the raspberry pi as  ttyacm    from  dev ttyacm  to  dev ttyacm    pi raspberrypi   robotarm   dir  dev ttya   dev ttyacm    dev ttyama   why does the arduino reconnect itself  is there some other way i should be processing this information  distance to the wireless xbox receiver is not a factor as all of these pieces are adjacent to one another for testing purposes  it will prove impossible to use this servo as a wheel for my robot if i m constantly tending to this issue  ,arduino raspberry-pi servos python
2274,workable low resolution object target recognition pattern and library ,i ve spent quite some time researching this  but most of my google search results have turned up academic research papers that are interesting but not very practical  i m working on a target pattern recognition project   where a robot with a small camera attached to it will attempt to locate targets using a small wireless camera as it moves around a room  the targets will ideally be as small as possible  something like the size of a business card or smaller   but could be  less ideally  as large as  x   inches  the targets will be in the form of something easily printable  the pattern recognition software needs to be able to recognize if a target  only one at a time  is in the field of vision  and needs to be able to accurately differentiate between at least    different target patterns  hopefully from maybe a   x   pixel portion of a    x    image  before playing with the camera  i had envisioned using somewhat small printed barcodes and the excellent zxing library to recognize the barcodes  as it turns out  the camera s resolution is terrible      x     and grainy and not well focused  here is an example still image  it s not very well suited for capturing barcodes  especially while moving  i think it could work with  x   barcodes  but that s really larger than i m looking for   i m using this particular camera because it is tiny  light  cheap  and includes a battery and wi fi   i m looking for two things  a suggestion or pointer to an optimal pattern that i could use for my targets  and a software library and or algorithm that can help me identify these patterns from images  i have no idea where to start with the right type of pattern so suggestions there would really help  especially if there is a project out there that does something resembling this  i ve found opencv and opensift which both seem like potential candidates for software libraries  but neither seemed to have examples of doing the type of recognition i m talking about  i m thinking picking the right type of pattern is the big hurdle to overcome here  so any pointers to the optimal type of pattern would be great  being able to recognize the pattern from all different angles is a must  so far  my idea is to use patterns that perhaps look something like this  where the three concentric color rings are simply either red  green  or blue   allowing for up to    unique targets  or    if i use   rings  from about   feet  the capture of a  x  inch target  from my computer screen  looks like this which seems like it would be suitable for analysis but i feel like there should be a better type of pattern that would be more compact and easier to recognize   maybe just a plain black and white pattern of some sort with shapes on it  pointers to an optimal approach for this are greatly appreciated  ,software computer-vision artificial-intelligence
2277,once you understand motors  what s the next step ,i ve gone through tutorials on how to build circuits and control dc  stepper  and servo motors   i may not understand everything about them internally  but i have a good basic foundation    now i m at a loss for where to go from here   i m more interested in learning how to make mechanical devices with them than just the electronics behind the devices   while i know that they go hand in hand  i want to learn more about the mechanical aspects of using motors    i have in mind several ultimate goal projects that i want to work toward  like home automation  model rc vehicles  autonomous robots  etc     but i m sure that there is more to mechanics that i need to learn before i can jump into a project like that   he who will learn to fly one day must first learn to stand and walk  are there hobbyist mechanical starter kits or starter projects to learn how to make effective use of electric motors   i don t necessarily need a specific product endorsement  but rather a general idea of what important concepts to learn and materials   projects to help me learn them  my apologies if this question is too broad   i can refine it if deemed necessary  ,motor mechanism
2279, d path following robot  converting xy axis path to input on wheels,at the moment i am creating an android program  that will steer my simple    wheel    motors    for balance  robot to move online following the path drawn by user on his screen  the robot is operated through wifi and has   motors that will react on any input signals  imagine user drawing a path for this robot on smartphone screen  it has aquired all the points on xy axis  every time beginning with        still i have no idea  how to somehow  convert  just points  into voltage input to both motors  signals will be sent in approx    hz connection  so quite fast  maybe not every single axis point will be taken into consideration  there will be surely some skips  but that is irrelevant  since this path does not have to be done perfectly by the robot  just in reasonable error scale  do you have any idea on how to make the robot follow defined axis points that overall create a path  edit        the voltage will be computed by the robot  so input on both is between      and     and the velocity should increase or decrease lineary in those borders  additionaly  i would like to solve it as if there were perfect conditions  i don t need any feedback crazy models  let s assume that all the data is true  no sensors and additional devices  just xy axis path and required input  ommit wheel slide too   ,wheeled-robot wifi two-wheeled
2283,emulation of an orrery,orrery is a clockwork model of the solar system  i am trying to emulate one in  d  now  to emulate  i need to know what goes on inside  can someone please explain the basic principle behind the clockwork  or direct me to a resource that will explain all the machinery inside a simple orrery  ,motor design
2289,dynamics of parallel manipulator,my task is to apply forces to control   dof parallel manipulator  forces are applied to linear  actuators  friction is neglected   end effector of a robot is supposed to follow generated path  for this example  let it be a simple circle  so far i have made a simplified  d model of robot and calculated inverse kinematics   promoter of my engineering work don t really know how to do this  but he said that calculating forward dynamics is too complex and i shouldn t go that way  could you tell me what will be the easiest way to go   ,force dynamics manipulator
2290,kk    quad stablility,i m running a kk          a multistar escs     emax gf         motors     slow fly props after about a foot off the ground  the entire quadcopter starts wobbling like crazy  no auto level   any ideas  i ll add some video if needed  ,quadcopter stability
2295,power model for humanoids,i am in the process of creating a power prediction model for the hubo robot  the robot has    degrees of freedom and has a computer some sensors and motor boards  the motors are powered through motor boards  all these boards are powered through a main power board that exists at the robots chest  my model should be able to predict the power for any trajectory of the robot  say for instance if the robot raises its hand from   degrees to     degrees my model should be able to predict the power  heres an idea i came across  my idea was to equate the electrical torque to the mechanical torque of each joint  for instance if the right arm pitch moves from   to     degrees i can do as follows    however  i am not getting a proper prediction and the current value is way off than what we can read from a software installed in the robot  i know there are losses but even then its off  i was wondering if there are any other approaches or a fault in my approach  and after i do this i can add all the joint currents for a specific trajectory and then give a estimate for total power consumption  ,brushless-motor power inverse-kinematics motion-planning torque
2297,quadcopter pid tuning,in continuation of the question i asked here  quadcopter instability with simple takeoff in autonomous mode      i d like to ask a few questions about implementing a basic pid for a quadrotor controlled by an apm     module   i m using a frame from  drobotics  i ve stripped down the entire control system to just two pid blocks  one for controlling roll and another for controlling pitch  yaw and everything else    i d think about them later   i m testing this setup on a rig which consists of a freely rotating beam  wherein i ve tied down two of the arms of the quadrotor  the other two are free to move  so  i m actually testing one degree of freedom  roll or pitch  at a time  check the image below  here a  b marks the freely rotating beam on which the setup is mounted   with careful tuning of p and d parameters  i ve managed to attain a sustained flight of about    seconds   but by  sustained   i simple mean a test where the drone ain t toppling over to one side  rock steady flight is still no where in sight  and more than    secs of flight also looks quite difficult  it wobbles from the beginning  by the time it reaches         seconds  it starts tilting to one side  within    secs  it has tilted to one side by an unacceptable margin  soon enough  i find it resting upside down  as for the pid code itself  i m calculating the proportional error from a  complimentary filter  of gyro   accelerometer data  the integral term is set to zero  the p term comes to about      and the d term is at          i m not using the arduino pid library on purpose  just want to get one of my own pids implemented here   check this video  if you want to see how it works    yeh  the setup is pretty ancient  i agree      please let me know what could i possibly do to improve stability at this stage   ian  of the many tests i did with my setup  i did plot graphs for some of the tests using the reading from the serial monitor  here is a sample reading of roll vs  motor    motor    pwm input   the two motors controlling the roll    as for the input output  input  roll and pitch values  in degrees   as obtained by a combination of accelerometer   gyro output  pwm values for the motors  delivered using the servo library s motor write   function  resolution i resolved the problem  here s how   the crux of the issue lied in the way i implemented the arduino program  i was using the write   function to update the servo angles  which happens to accept only integer steps in the argument  or somehow responds only to integer input      and       produces the same result   i changed it to writemicroseconds   and that made the copter considerably steadier  i was adding up rpm on one motor while keeping the other at a steady value  i changed this to increase rpm in one motor while decreasing the opposing motor  that kinda keeps the total horizontal thrust unchanged  which might help me when i m trying to get vertical altitude hold on this thing  i was pushing up the rpm to the max limit  which is why the quadcopter kept losing control at full throttle  there was no room for the rpm to increase when it sensed a tilt  i observed that one of the motor was inherently weaker than the other one  i do not know why  i hardcoded an offset into that motors pwm input   thanks for all the support   source code  if you re interested  here s the source code of my bare bones pid implementation  pid source code please feel free to test it in your hardware  any contributions to the project would be welcome  ,arduino pid quadcopter stability
2298,how much accuracy could i get position tracking with a   axis accelerometer and gyro sensor  and compass  and how would i do it ,given a     x     field   m x  m   a reasonably cheap   axis gyro sensor and accelerometer  and compass  i plan to design a device capable of tracking its position to sub centimeter accuracy for a minute of motion or so  the device has a holonomic drive system  capable of moving any direction at a maximum of about  mph     m s   with a maximum acceleration of about  g s  however  there are some simplifying constraints  for one  the field is nearly flat  the floor is made of a tough foam  so there is slight sinking  but the floor is flat except for a ramp of known angle  to a few degrees   the device will  excepting collisions  not be rising above the floor  accuracy is preferred over simplicity  so any mathematics required on the software side to improve the system would be welcomed  before i definitively choose accelerometers as the method of position tracking  though  i would like some idea of how much accuracy i could get  and the best ways of doing it  ,kinematics accelerometer machine-learning
2299,where to start for the software side of robotics ,i am a computer science student entering my last year of college  i m pretty sure robotics is what i want to eventually be doing based on my interests in ai and embedded systems  i ve seen a lot of topics that covers robotics such as  control theory  signal processing  kinematics  dynamics   d simulators  physics engines  ai  big data with machine learning  i m hoping someone can point me in the right direction as to what i should be attempting to study in my interests of robotics  i am not sure what other topics i have not mentioned that would be relevant  i would like to deal with the software side of robotics  both ai and none ai  my other question is about machine learning  i ve seen researchers applying machine learning  deep learning unsupervised learning specifically  to robotics but how do they do this  is information and data transferred from the internals of the robot to an external computer that does the data processing  machine learning requires a lot of data to predict  is this the only way machine learning can be used in robotics  through an external computer   i hope someone can touch on some of the things i ve mentioned  thank you  ,mobile-robot software artificial-intelligence programming-languages
2304,system for determining occupied seats in an auditorium,i need an app that can do live monitoring of whether each seat in an auditorium is occupied   so visitors can load the app and see where to sit      the auditorium has a relatively flat ceiling  m high  and the seats are   m wide   the hardware cost per seat needs to be     i m looking for all solutions   web cams  preasure sensors  sonars  lasers  arduino  pi  intel edison  anything   obviously there cannot be wires that people could trip over   sensors on the ceiling could have wired networking   sensors on the seat or floor would need to have wireless communication   sensors on the ceiling would need to consider occlusion by people sitting in the seats  think  if there is an empty spot between   people  can the sensor see it as empty  in the end  the data needs to be collected as a simple list of which chairs are occupied open  possible solutions   rasberry pi s on the ceiling every   seats with a camera     pressure sensors under chair legs wired to pi s gpio drones flying around the auditorium     any ideas  update  more constraints    auditorium size is     seats installation costs should average    chairs per hour             hours    as the picture shows  chairs are cushioned regular maintenance should take no longer than    min  per   hour event eg  batteries  hardware should last     sessions for auditorium cleaning  it should be possible to  disconnect  and  reconnect  the chairs with   hours of labor   ,arduino sensors raspberry-pi computer-vision
2315,overcorrecting kalman filter,i m trying to get an extended kalman filter to work  my system model is   where lat and long are latitude and longitude  in degree  and  is the current orientation of my vehicle  also in degree   in my prediction step i get a reading for current speed v  yaw rate  and inclination angle    i use the standard prediction for the ekf with  being    being the prediction frequency   being the radius of the earth  modelling the earth as a sphere  my jacobian matrix looks like this    as i have a far higher frequency on my sensors for the prediction step  i have about    predictions followed by one update  in the update step i get a reading for the current gps position and calculate an orientation from the current gps position and the previous one  thus my update step is just the standard ekf update with  and thus the jacobian matrix to    being the identity  trying my implementation with testdata where the gps track is in constant northern direction and the yaw rate constantly turns west  i expect the filter to correct my position close to the track and the orientation to     degrees or so  what actually happens can be seen in the image attached  red  gps position measurements  green blue  predicted positions    i have no idea what to do about this  i m not very experienced with the kalman filter  so it might just be me misunderstanding something  but nothing i tried seemed to work  what i think  i poked around a bit  if i set the jacobian matrix in the prediction to be the identity  it works really good  the problem seems to be that   the covariance matrix of the system model  is not zero in  and   my interpretation would be that in the prediction step the orientation depends on the position  which does not seem to make sense  this is due to  not being zero  which in turn makes sense  can anyone give me a hint where the overcorrection may come from  or what i should look at   google for  ,kalman-filter gps sensor-fusion
2321,tracking  d positioning with imu sensor,i am using a miniature car and i want to estimate the position  we can not use gps modules and most of the tracking systems that i saw  are using imu senson with the gps module  in our car we are able to find our exact correct location with image processing but for some parts that dont have enough markings we can not do this  so we want to use the imu as backup for our positioning  so as long as the positioning is close is good for us  and we are only interested in our  d position since the car is on a flat ground  i am using a imu  dof sensor and i want to calculate my movement  i have seen some amazing works with imu for tracking body movements but no code or simple explanation is anywhere about it  so basically i have the reading from accelerometer  gyro and magnetometer  i also have orientation in quarternions  from the device i am getting also the linear acceleration but even when i am not moving it in any direction the values are not   which is really confusing  can you please help me how to approach this  thanks in advance ,sensors accelerometer gyroscope
2322,what can be the rating and specifications of dc motor used for making a quadcopter ,i want to make a quadcopter for my final year project and i am willing to use dc motors as the four rotors of the quadcopter  can any one guide me about the ratings for proper motor selection for my job  ,quadcopter
2324,kinematics of a   wheeled differential drive robots,i have a   wheeled differential drive robot  like the pioneer   at  there are only two motors  one for left wheels and one for right wheels  i want to send velocity commands to the robot  i m using ros and the standard commands are   linear velocity  angular velocity   i need to convert them into left and right velocities  from literature if i had   wheels i should do this    where  r  is the absolute value of the distance from the wheels to the robot  center   how should i take into account that i have   wheels  ,wheeled-robot inverse-kinematics wheel
2326,problem with simulated sensor in matlab ,i m simulating a sensor in  d  the sensor should determine    from the origin  where  is the rotation about z axis and  is the rotation about x axis  the sensor is given position of a point    this is what i did  now i need to get the cartesian coordinates     this is what i did      p theta phi    getmeasurement x  y  z       x    p cos theta  sin phi       y    p sin theta  sin phi       z    p cos phi     the sensor is working fine at the beginning but at a particular point it behaves strangely  i have the state vector to compare it with the measurement  i m guessing that  might be the problem    edit   i m sorry for this mistake  the aforementioned calculations based on the following picture  so  the point will rotate first about z axis    and then rotate about x axis    ,sensors sensor-error
2330,is it possible to achieve fully autonomous route following using px fmu module ,i have a quadcopter equipped with px fmu board  you may download its datasheet from here  i wonder whether it is possible to program the quadcopter to autonomously follow a path like circular motion without any human interference  are the built in sensors enough for this task  i also wonder how accurate the built in gps is  i read that it gives coordinates with a radius of  m as error  ,quadcopter
2331,what is the kalman filter in the basics of its aspects ,my question is very broad  however i would like a complete description to the very last detail in a way that a foreign exchange student would understand  i want to try my best to master the way the kalman filter works  please be as through as you possibly can  and more  ,kalman-filter
2336,learning  embedded  electronics,i am an aerospace engineer  currently in grad school  and i really want to get into  embedded  electronics  but i have this problem  i understand the theory fairly well  i took an edx course in circuits and had no problem  i can build projects from the internet  however  i have a very hard hard time connecting the theory with the practical part  understanding why projects are done the way they are done and i have a hard time to design my own projects  please help  i d appreciate the following   general tips  how did you learn it  how is your workflow  what should i do  which steps should i take   books  which hands on books and websites can you recommend  i am looking for books and website that are practical but also explain the why  kits  what kits can you recommend that combine the theory with the practical   anything you think is important thank you for your time  ,electronics
2337,monte carlo localization,i m implementing monte carlo localization for my robot that is given a map of the enviroment and its starting location and orientation  mine approach is as follows   uniformly create     particles around the given position then at each step   motion update all the particles with odometry  my current approach is newx oldx  odometryx   standardgaussianrandom   etc   assign weight to each particle using sonar data  formula is for each sensor probability  gaussianpdf realreading  where gaussian has the mean predictedreading  return the particle with biggest probability as the location at this step  then      of new particles are resampled from the old ones according to weights and      is uniformly sampled around the predicted position   now  i wrote a simulator for the robot s enviroment and here is how this localization behaves   i m very afraid that for a longer period of time the robot may get lost  if add particles to a wider area  the robot gets lost even easier   i expect a better performance  any advice  ,localization motion-planning sonar
2341,how do ultrasonic range finders detect objects at an angle ,as far as i can tell  an ultrasonic rangefinder works by reflecting inaudible soundwaves off of objects and timing their return   but if the object has a flat surface and is angled with respect to the line to the rangefinder  how does it detect that object   under what circumstances might it give a false distance or otherwise fail to detect the object  ,sensors sonar
2345,simple web interface with beaglebone black,this is actually a very simple question  but i m lost at the moment  i was using a beaglebone black for a school project  it controls a bunch of motors and actuators etc  we wrote everything in c    and made libraries of functions  when a main program calls them  the functions run just fine  recently we have been told to demo our progress so far  the main program is nowhere near done  so we were thinking of some sort of web interface that can execute the complied c   program on command  we were hoping to get the server hosted on the board  and access it via lan from other pcs  but i ve never done this before and have no idea where to start  does node js  with the  bonescript   going to be of any help  or is there a simpler way with basic html  i only have a few days to figure it out  so i didn t want to waste time looking at the wrong methods  ,embedded-systems
2347,the costs of using existing   axis kuka abb robots and existing vision systems in picking and placing tasks,i would like to use a kuka abb   axis robot and a machine vision system to pick and place a variety of metal drill bits in size ranges from    mm  ascending up    mm per cylinde  to   mm in metric and then      of an inch ascending to      of an inch  the machine would not have to differentiate between the bits  niether drill bit would weight more than  kg  crucially at the beginning and end of the picking and placing i would like to inspect the very tip of the cylinders to be inspected for a     degree chamfer on one end of the bit which should be present regardless of drill diameter of length   i am lead to believe that if the drill bits are placed end up on a conveyor belt and always the the same place its relatively low cost but crucially if the kuka   axis robot has to find the drill bits then the cost increases dramatically  is this true  ,industrial-robot
2348,what motor to use for reciprocating  reversive  movement,i want to make a copy of this machine fisher price soothing motions  glider and i m wondering what motor to use  simple dc motor with appropriate gearbox  slow rpm  or stepper motor  here is another instance of this idea  ,motor stepper-motor mechanism
2350,electronic noses for detecting dog urine,i have very limited experience with sensors or robotic components at all  and i hope you will excuse the lack of detail in this question   i want to set up posts around my yard with electronic noses that detect dog urine  i want to use this information to make a map of my yard from a dogs perspective  is it possible with todays technology  what would it cost  there may be information that is very relevant to me  but that i m not requesting  this is because of lacking insight  if there is something you think i should consider or research  please say so   ,sensors electronics
2356,line follower robot program,i am working on a line follower robot as part of my microelectronics project  and am confused over what sort of code to use to program the  pic  f  microcontroller i m using  can someone give me source code or a layout of the code and what should be in there  ,c line-following
2357,cons and pros of wireless technologies for rescue robot,robotics enthusiasts  i m a member of a team which has to develop a mobile rescue robot to cooperate with firemen  e g  on earthquake sites   the problem we have is connection of a commander post with the robot  the robot has to enter buildings  so it is desirable that the connection can go through several decimeters of walls and have a reach        meters  on the other hand  we need to send a lot of data  camera images  point clouds  maps  which can easily eat    mbps or more  at this time we use     ghz wifi for this connection  as for the speed  with direct visibility it seems to be sufficient  but only when a single robot is operating  we can use up to   non overlapping channels  so in theory   robots can work together  but usually you have the environment messed up with home routers   we need at least   robots to be operating simultaneousely  we have tried   ghz wifi  but it has problems with penetrating walls  so it can only be used for uavs  my idea was to use some mobile connection technology like lte  i found that lte can be run on     mhz  which could be great for the wall penetration performance  i also found that the lte s theoretical upload speeds  for clients  are    mbps  but nobody says if it is on     ghz and how would it be changed when running lte on     mhz  moreover  we cannot rely on some provider s coverage  i have found that you can build your own lte transmitter for about        which seems to be interesting to us  maybe it is possible to build it even cheaper  but we think both     ghz and     mhz are regulated frequencies  however  the cooperation with firefighters could persuade local regulators to give an exception to us to setup our own small lte base station  and now to the question  do you think such setup would give better results than using wifi  or do you know of any other technologies that would help us to either increase the bandwidth or the wall penetration performance  what are their cons and pros  ,wireless
2361,explanation of the kalman filter,i am a beginner in robotics  and i am learning about the kalman filter  i do not seem to get it  though  i am a mathematician  and so it would be helpful if the kalman filter could be explained in a mathematical method  ,kalman-filter
2362,actuator to control steam valve,i have a steam radiator at home and it has a valve similar to the picture below   please note that the valve doesn t have grooves on top to attach things to  i want to build something to turn it on and off depending on the temperature at certain points in the room  i have that taken care of but cannot find a way to attach a actuator actuator is the right word in the context i guess   to turn the valve in both directions  also it is a rented apartment so i would like to avoid making any modifications to the radiator itself  ,actuator valve
2363,building a mobile camera platform,i have zero experience with robotics  but i need to build a mobile platform for a streaming camera  the idea is that i ll plug in my android phone into the pan tilt unit on my wheeled robot and then drive and look around via wifi  i have already solved all of the software  interface and controller issues  but i would appreciate some advice on how to build the wheeled platform  my initial idea was to buy a cheap rc car  remove all electronics and replace them with my own  this approach almost worked  i purchased this new bright f     truck   the size is good and there is plenty of storage space    however  i quickly ran into a problem with this thing  i assumed that the front wheel would be turned by some kind of servo  instead i found this nonsense    that small gear shaft is not driven by a servo   it s a conventional motor  which spins until it is jammed at the extremes of travel  the wheels are straightened when power is removed by a small spring on the other side  this means that there is only one angle at which the wheels can be turned  and that angle is way too small for what i need  so using this rc car will not work  before i start buying more things  i would like to hear some opinions from more experienced people  am i on the right track  do i simply need to get a better rc car  or are they all designed like this  perhaps there are other options that would be more suitable for what i am doing  ,mobile-robot
2365,covariance matrix in ekf ,i m struggling with the concept of covariance matrix     sigma     begin bmatrix   sigma  xx     sigma  xy     sigma  x  theta      sigma  yx     sigma  yy     sigma  y  theta      sigma   theta x     sigma   theta y     sigma   theta  theta      end bmatrix   now  my understanding for     and  that they describe the uncertainty  for example  for   it describes the uncertainty of the value of x  now  my question about the rest of sigmas  what do they represent  what does it mean if they are zeros  i can interpret that if  is zero  it means i don t have uncertainty about the value of x    note  i m reading principles of robot motion   theory  algorithms  and implementations by howie choset et  al   which states that  by this definition  is the same as  the variance of   for   if   then  and  are independent of each other   this may answer my question if the rest of sigmas are zeros however  i m still confused about the relationship between these variables for example  and   when does this happen  i mean the correlation between them  or in other words  can i assume them to be zeros  another book namely fastslam  a scalable method     by michael and sebastian which states   the off diagonal elements of the covariance matrix of this   multivariate gaussian encode the correlations between pairs of state   variables   they don t mention when the correlation might happen and what does it mean  ,kalman-filter noise
2371,compensating for yaw in lateral quadcopter movement,i m trying to make a quadcopter move laterally at a certain angle  i ve been able to find the proper roll and pitch angles for this  that work with a yaw of      how would i adjust these values to compensate for a different yaw  ,quadcopter gyroscope movement dynamics
2373,using vision for monte carlo localization,from each step of my vision code i am able to get around     coordinates of where the robot thinks the walls are i want to integrate this into monte carlo observation step  i m storing the map of the maze as a set of line segments  what would be a nice way to implement the sensor update  i e  given the position  x y  of the robot what is the probability that it is found there given the above described coordinates of the walls   the main idea i currently have  transform points in polar coordinates  then for each point  from vision output  compute a ray with this angle and find the first intersection with the maze  now we have the predicted distance and real distance and we can compute the probability that this measurement is right   the main drawback is that this is slow  for each point from vision output i have to iterate over all line segments to find the one with the closest intersection  the line segments number is around     so it gets to o        particle number   ,mobile-robot localization computer-vision
2374,maximum angle between the camera pose to correctly estimate homography,i want to capture two views of same scene  the scene consists of a set of objects kept on a table  from the two views  i wish to calculate homography for image matching  i want to know what is the maximum angle between the two views  such that the homography can be accurately calculated  right now  i am capturing the images at around    degrees of angle  but unable to construct homography accurately  ,kinect computer-vision stereo-vision
2376,kinect for xbox  sdk selection,my application is basically about sound source localization and visual servoing  i selected kinect as the main hardware  i already know the basic differences between kinect for windows and kinect for xbox  i cannot access to windows version from my country  no reseller here in turkey   but the xbox version is there at the stores  i am not sure about problem specific software selection  i found out that the latest kinect sdk supports sound source localization  and beamforming  using the built in microphone array  can i use that sdk within the xbox version  or is there another sdk for xbox  having the same support  i am not sure because i also read that openni does not provide the best audio api  i will also apply some processing on image   depth outputs  so i will be using opencv  i also want to use qt for threading  gui etc  so  another question  is it possible to use the microsoft official kinect sdk within another ide  not visual studio  ,kinect
2379,water depth arduino sonar sensor,just like a fish finder finds the depth of the water directly beneath it  im trying to find a sensor that i can purchase for the arduino that does the same  would like it to check up to    ft at least  with high accuracy         or    cm  all the threads and info i ve been finding are water level sensors not for water depth  so does anyone know of a sensor like this and where i can find one  ,arduino microcontroller underwater
2382,motion model for holonomic robot,we are working with an holonomic robot equipped with three      degree shifted  omnidirectional wheels  the relative movement is estimated by dead reckoning using wheel encoders  to improve this estimation we installed an gyroscope to measure the change in orientation  furthermore the robot has a     degree laser range finder   in order to solve the kidnapped robot problem we implemented a particle filter  in every step each particle is updated according to the odometry and gyroscope readings  since these readings are distorted by noise we need a motion model to include these errors  as described in probabilistic robotics by thrun  page            there are two commonly used motion models  velocity motion model and odometry motion model   however these models seem to describe the behavior of differential drive robots not omnidirectional robots  i base this thesis on the fact that the error in relative y direction is proportional to the error in orientation as far as the motion models by thrun are concerned  this is appropriate for differential drive robots as the orientation and the heading of the robot are identical  for omnidirectional robots this assumption can not be made since the heading and the orientation are completely independent  even if we assume perfect information about the robots orientation we can still obtain error in relative y direction  i would like to discuss if my assumption   that the velocity odometry motion model fails for omnididrectional robots   is correct or not as i am not sure about that  furthermore  i am curious if there are any other motion models for omnidirectional robots that might fit better  ,mobile-robot localization motion particle-filter
2387,how can i start programming proto x quad,i have bought a really small proto x quad  it has a joystick which navigates the device  and i am looking for a way to send a signal to this thing from my computer   so can anyone point me how can i turn on one of the propellers of this quad using my laptop  i have a decent knowledge in python matlab c  but hardware is a completely new world to me   ,quadcopter programming-languages
2394,lidar solutions,i am surprised by the price range of lidar applications considering the simplicity of the design  i try to make a simple project that requires lidar for object recognitions etc  i wouldn t like to use visual recognition such as opencv   regardless of that i am trying to understand why lidar solutions are so expensive you can see that this   small lidar sensor goes for        but their performance is very bad   i hope you can answer what makes a lidar so expensive and what are some cheap systems a hobbyist can afford   ,arduino computer-vision lidar
2396,generic name for two motor wheeled tracked robots ,is there a generic name for the category of robots that move using two opposing wheels or tank like treads  ,mobile-robot differential-drive
2402,how to  attach wheel encoder to motor ,i have a couple of these dc motors  which have an extended motor shaft that sticks out the back and is  mm diameter   i m having trouble trying to think of the best way to attach an encoder disk to this shaft  i thought of getting a custom wheel  d printed and make the opening    mm so it will be a tight fit  but i don t know if is just to small  i also though of taking the encoder disks from a pc mouse and drilling a  mm      mm but its the same problem but with the added difficultly of trying to drill a small hole on a small thing  so i wondered if anyone knows a better way  or of a made disk to attach  as i just can t find anything for a  mm shaft ,motor
2409,connections on a baby orangutang b     board,i am new to robotics and planning my first purchase  i m looking at the baby orangutang b      here is information about the microcontroller    the pin headers come unmounted  so you have to do the soldering yourself  my problem is that i don t know what the pin connections are for  here is a picture of the board    could someone briefly tell me what the different connections are for  or link a website that does  ,microcontroller
2411,robotic part to dispense candy,i m a complete newbie trying to build a simple robot that dispenses candy  m m  skittles  etc    however  since i m not familiar with the field  i m having a hard time googling because i don t know the correct terms to search for   i m looking for a piece to build a robotic  trap door  of sorts that will open for a specified amount of time to release candy   what parts can i use and what is are called   i ve tried robotic lever  robotic door  etc with no luck  ,design
2413,why is analysis required to study robotics ,i am studying informatics and i am interested in doing a masters in robotics and i was checking out some unis and their courses and i saw that robotics contains analysis and a lot of math  why is that  ,software
2416,low amp fpv quadcopter motors,why do fpv quadcopter motors  usually the more expensive ones  draw lower amps than regular motors   and why are they more squat disk shaped  as opposed to normal motors which are about the same diameter and height  ,motor quadcopter
2418,quadcopter props  wood vs plastic vs carbon fiber,all the pro fpv builds and the more expensive quads don t seem to be using plastic props  any reason for this  ,quadcopter
2421,just run program on nxt  not download ,is there any way i can simply run a program on the nxt  but not download it   i have all my programs already downloaded  and i am connecting with a usb cable to a macbook pro using the nxt g interface   is there any way i can just run programs existing on the nxt from the computer  and not download them   it s really increasing my robot s run time     i am competing in robocross in science olympiad  and my event is at noon   thank you  ,nxt usb
2422,is configuration space same as joint space ,for robotic manipulator like the one on the picture   are the configuration space and joint space equivalent  i am trying to understand difference between the two    ,kinematics motion-planning forward-kinematics
2423,what do quadcopter propeller specifications mean ,i m trying to figure out the diameter of tri blade propellers  i found a  x x    blade  i m trying to understand the measurements  is the     the length of the blade giving the prop a       diameter  or is the   the total diameter  ,quadcopter design
2424,android phone   adk   arducopter apm     for autonomous quadcopter,for a project for a robotic lab  i d like to build an automous quadcopter able to follow a path and land on its own  i d like to use an onboard android phone to do the image processing and recognition part  so that i avoid to send the video stream to a control station  process it and send back the commands  as i need to use it in an indoor environment  so no gps coordinate   i need the phone to guide the quadcopter giving it relative directions like forward and after   sec stop  this is something a normal pilot would do via the rc radio  i already have a arducopter apm     and an arduino mega adk and i was thinking to connect the phone to the adk and then the adk to the apm to guide the copter  i think i have   options  either having the adk to generate ppm pwm signals as a rc receiver would do or use the mavlink protocol  which is the best easiest solution  other info   i have already read checked some uav related websites  but i couldn t find something close to what i want  in most of them  try to build a new type of controller  or use only ab android phone   adk  i d like to stick to something already tested and known to work  as the apm   arducopter software  and i don t want to use the phone as imu as i don t trust its sensors  i already have built the quad  a hexa actually   i have already set up the connection and protocol between the phone and the adk so i m able to send commands like  i e  forward  turn  hover etc     i have already checked the andro copter project and similar ones   i might consider other platforms than the apm     if there s something easier to use  it d be nice to keep the rc receiver in the loop to regain control of the quad if something goes wrong  ,arduino control quadcopter ardupilot
2426,how to programatically calibrate turningy esc ,i have a turnigy esc and i am controlling it from avr  now i need to calibrate it to set the range of the input  with a servo tester i managed to calibrate it without any problems  more or less by following the user guide  but when i try to do the same procedure from code  the esc starts beeping in some confused pattern and then enters programming mode  my code looks like this   where  servo range ticks is    ms pulse length   servo range ticks is    ms pulse length and   is    ms  the timeouts of   s were measured during the manual calibration with a stopwatch  i have checked with an oscilloscope that the output servo signal looks the way i would expect it       seconds of    ms pulses     seconds of    ms pulses and then    ms pulses  edit  i made a mistake here  see my answer  do you have any idea what to change to calibrate the esc  ,c calibration esc avr
2433,what is minimum torque required for cnc stepper motors and spindle for aluminium milling ,i am planning to buy cnc mechanical skeleton without motors  spindle and controller  i will be using the cnc mainly for aluminium milling  are there any specifications for minimum torque requirement for stepper motors and spindle to perform aluminium milling   ,stepper-motor cnc
2434,is it possible to make diy clone of makerbeam,is it possible to make clone of  of some easy accessible material like   wood plywood osb mdf hdf others  using any type of cnc machine to mill some holes and rails in those materials may give sufficient results e g  to make a prototype of  d printer of such  beams   of course it won t be as rigid and durable but for making prototypes it may be good idea  just for reference  when reading this  i ve found this   this  and this   and this   ,mechanism
2435,jsp container for embedded systems,there is this project i am working on which is using a beaglebone and we need a jsp container to run on it  i was thinking of tomcat but wanted to know if tomcat is suitable for embedded systems  is it too resource heavy  if yes  are there other lighter jsp containers  i know only of tomcat and jetty  ,beagle-bone
2443,how to link ends of timing belt into loop,when i buy some length of timing belt i don t know how to link ends of timing belt into loop  so far i ve found one way to do that  thanks to     any other ideas  ,mechanism
2445,transformation a robot in  d ,i m watching this video at       min  the guy gave an example but i m not sure what is the problem  he stated that if we want to move a robot then we should to the following  for inhomogeneous case    x    rx   t    r     begin bmatrix  cos theta    sin theta    sin theta    cos theta  end bmatrix    where  is the translation vector and  is the previous position   in homogeneous case    x      begin bmatrix  r    bf t      bf     t        end bmatrix  x  now  he gave an example in which   t     begin bmatrix           end bmatrix     x     begin bmatrix               end bmatrix   my solution is as the following in matlab  for homogeneous case    xn    r t          x       xn                                      both have same result  but the guy got another result  what exactly he did is     xf    r x          t       xf                                      why he did switch  and   i m aware of the issue that he is trying to calculate the velocity but in fact he is computing the position  this mistake in the notation won t affect the final result    second question  why he assumed that the forward movement of the robot in the above example should be  t    begin bmatrix      end bmatrix     he said that because the robot always in the forward movement move in  x axis  why this is the case  the movement in robot s frame is determined based on the direction of the robot and the distance the robot travels which is specified as hypotenuse length   ,mobile-robot
2446,rc helicopter connect with computer,i am planing to control my rc helicopter with my computer  i have experience of programming in  net  could we use  net to control rc helicopter   from where can i start this project  ,control radio-control
2453,quadrocopter first build  how to tell if components play well together ,i m building my first quadrocopter  and i m trying to come up with a parts list that is suitable for a first build   i will use this to learn how to fly a quadrocopter manually  lots of crashes    and to do some experiments with running ai for piloting it  a couple questions about the below list of parts   is this a good choice for a first build  are we missing any crucial parts  do these components work together  is this battery strong enough to fuel all the components that need power   here s the current list of parts   frame       mm propellers     x      two pairs motor   x       kv brushless outrunner motor  max current    a  esc       a  cell count  s  s lipoly electronic speed controllers   x      a constant current    a burst current  battery     s lipoly battery       mah lipoly      v    cell  constant discharge    c  peak discharge    c  charge plug  jst xh       mah x   c      amps  charger   lipoly    w   a    v power supply power supply   input  ac        v      hz  output  dc  v  a arduino board gyroscope for arduino accelerometer for arduino gps sensor for arduino  rc transmitter for arduino rc controller  ,arduino motor sensors quadcopter
2456,how are interference avoidance and collision avoidance different ,someone told me when explaining about a controller module named  that it only checks self interference and moves accordingly without detecting collision  to me both sounds the same  how are they different  thanks  ,untagged
2458,what should i study if i want to get into robotics ,i understand this is a broad question but i m taking the risk to ask anyway   robotics  from what i can tell so far  is a detailed  diverse  and thorough field  however  if there are better areas of research to invest time into  what would those areas be  ,research
2462,connecting a raspberry pi to a roomba via an ftdi cable,i have a raspberry pi with this ftdi cable and a roomba      the roomba has an sci port to allow for control of the roomba via serial  i installed the pyserial library on the pi and send valid commands to roomba  but the roomba doesn t respond  i have the txd of the cable attached to the txd of the roomba  the rxd on the cable wired to the rxd on the roomba  and a ground on the cable wired to the ground on the roomba  everything in  it s respective port   i do not have power going from the cable to the roomba or vice versa  what i can t figure out is why the commands aren t working  there s no error message upon running the python code  this is the information sheet for the roomba s sci port  code   ,mobile-robot software wheeled-robot
2465,alternatives to primesense depth cameras ,i m looking for low cost depth cameras  less than      usd  with a range of more than   meters  currently  i have found only softkinetic ds     that meets these requirements   here are some other low cost cameras that i found  but they have a short range   pmd vision  camboard nano softkinetic ds      and others with a long range but high cost  panasonic d imager pmd vision  camcube     swissranger sr     odos imaging real iz  k  ,sensors kinect computer-vision
2470,gps amplifier   is this reliable ,i m multimedia developer who is searching for a way to get gps signal inside buildings structures  is amplification a reliable way to fix this gps signal issue  will a  gps amplifier  work as perfectly as using gps outside  ,wireless gps
2476,benefits of the number of propellers,i am planning on creating a quad copter with my arduino that i have  i have created a few land robots before but no aerial vehicles  so this is all new to me  i was looking on the internet for different models  and i see that most robots have   propellers  i have also seen a few hexacopters     and octocopters but that many propellers can t get a but out of hand  does having   propellers the best and most efficient thrust to weight ratio  or will   propellers arms work better  ,quadcopter
2478,ros   android sensor driver,i try to connect android device and computer over ros    this tutorial explains good  i download the application on android device and set the ros master uri   when i run the application  the phone shut down and this node is not seen in  rosnode list  is there anyone who experience similar error  ,ros
2480,looking for a circular track and bearing with a spindle,i ve really tried to find something online that s suitable but what i m after is i ve two concentric circular rings  one of which has a diameter about   mm smaller than the larger   the rings themselves are in the region of    mm diameter  i m trying to find a way to connect the two together and allow the smaller to  slide  in a circular rotational way within the larger one  i m also trying to let the   rings pivot vertically in relation to each other   the intention being of producing a gyroscopic esque motion   what type of bearings tracks spindles would suffice  ,tracks linear-bearing
2481,writing a simple program for processing rgbd video with openni,i would like to write a simple program which processes the depth feed from an asus xtion depth sensor using openni  the sensor will be fixed like a cctv camera and count multiple targets moving around   the processing would involve some simple functions on each frame  background subtraction  level sets  connected components filter   and some multi target tracking across frames  i have searched the web  but it is hard to see how best to get started  and i m also quite new to programming in c    can anyone recommend any existing code that can help to get started   any libraries which would be suitable for this real time application  or perhaps there is some opensource code which already does such a thing  would really appreciate any pointers from anyone with experience  thanks  ,openni
2486,val language and velocity control of industrial robot,in my bachelor  i programmed cnc machines  now  working with an industrial robot arm  i learn that their programming languages are mostly similar  val is a typical example  for instance   most of the cases  control of a robot arm is similar to this example  cleary  move end effector to a point with a given pose  but    is there any way that i can control the end effector  ee  speed  an example is  move ee to p  with time duration t    or  move ee to p  with velocity v    i could have only seen defining for joint rotational velocity  in other way of speaking  i can command the ee to move from p  to p  but cannot control the duration of that traverse which is necessary in cases of ee velocity control this is the programming manual for my robot   the velocity control i m talking about is not joint velocity but end effector velocity  but ee screw   robot jacobian joint vel which means to control ee velocity  it resolves in control joint velocity  about the inverse kinematic  i ve already programmed a module to solve the robot the experienced in robotics programming and val please help  i ve stuck in this problem for months ,control manipulator
2488,can motion model noise be zero ,can i assume the noise of motion model to be zero  if so  what are the consequences of doing so  ,kalman-filter noise ekf
2489,vex   keeping arm at an angle,so my team made a vex robot for the toss up competition  but we need the arm up during the autonomous  the problem is that it s too heavy to stay up on its own  i was going to use encoders to count what angle the arm is at  i was going to use this code  but i m not sure if there s a better way   would anyone recommend a better solution or is this the best way  this is untested by the way  ,arm
2491,how are color sensors used for line following ,i have to build a line following robot that will be able to detect a selected colored line on the floor and start following it  how do color sensors do this after detecting the specific colored line  ,mobile-robot sensors
2494,slam for autonomous car,i am working on slam for autonomous car like vehicles with  d lasers and imu  deriving odometry   i would like to know how efficient is using the existing slam algorithms  for example  gmapping in ros based on rao blackwellized particle filter   till now i find map are high in volume and speed of vehicle is high and most importantly computational time compared to mobile robots  are there  any other important factors to consider for car like vehicles in using slam algorithm  thank you  ,mobile-robot localization slam
2498,forward kinematics two fixed standard wheels, what would the equations be for the robot s angular and linear velocity at p and also p   i think i m doing it wrong    wl   left wheels angular velocity wr   right wheels angular velocity for p i had for example the linear velocity         r wl          r wr am i on right track  ,kinematics wheel
2499,can inverse dynamics control be regarded as a function ,i know that inverse kinematics    p  desired pose of the end effector  q  joint angles  is not a function because there might be multiple joint angle vectors q that result in the same pose p  by inverse dynamics control i mean the mapping   u  required torques  i am not very experienced with these kind of problems  is the mapping a function  i e  for each triple  there is a unique solution u  my intuition says it is  but i am not sure  if there is not  would it always be possible to obtain a solution by averaging two or more solutions  ,dynamics
2504,jacobian method for inverse kinematics,i have big problem  i have to solve inverse kinematics for a manipulator with   dof using jacobian method  from what i know to do that i need to have matrix of transformation and denavit hartenberg parameters  which both i have  but i am not a mathematician  and descriptions i find on the web are not even a bit understandable to me  so i would love if you could give me an example of how to solve my problem  the denavit hartenberg parameters are            begin matrix           alpha   l    lambda    theta                          var                               var                               var                                 var                               var                              var                   end matrix   the values in theta are values to get the following matrix of transformation  and values i want to get with this jacobian method  and those values are in degrees  matrix of transformation            begin matrix                                                                                                                                                                                  end matrix   i would be most greatful  if someone could walk me through how to solve it in simple language  ,inverse-kinematics
2507,robotics as a beginner,i want to begin robotics so as a beginner what micro controller would be convenient arduino or pic what type of robots can be built with arduino or pic  should i start from just a line following vehicle   ,arduino microcontroller beginner
2508,looking for a way to scan cylindrical objects,can anyone recommend a commercial or solid  reliable diy solution for scanning cylindrical objects  i ve seen a couple of simple hacks for flatbed scanners  but i m looking for something i could make or buy for a commercial project that work reliably  many thanks ,stepper-motor
2510,slam and vision  good resources  ,i would like to know if there is a good source that combines slam problem with vision  from mathematical perspective  there are numerous resources that handle slam  however  i didn t find a good source that focuses on slam and vision    ,kalman-filter slam ekf
2511,find the difference between two consecutive sensor readings in real time in c,i am working on a micromouse and it has three sensors  call it s  s  and s   for now  i have to use s   the idea is this s  controls the left motor and s   the right motor  s  will detect wall in the front   anyways  i am trying to write a code in c for the dspic  f     mcu which would continuously read sensor values and after reading two consecutive values  it will compare the two values  read happens every    ms  the flow of the code is as follows   so if you look at the line with the    how do i compare two sensor values in real time every    ms   let me know if one wants to more info   ,c micromouse
2519,how to measure displacement  cheaply and without using an accelerometer ,motion is known to be confined in a sphere with radius of about    m  and resolution doesn t have to be very high   cm is enough   the device will actually be incorporated in a toy designed for kids  i tried implementing that with an accelerometer but the estimated displacement drifted away    s of meters per minute  is there some other solution  maybe involving electrical or magnetic fields  it s important that the sensor costs no more than a few bucks  edit  the device should not be attached to anything mechanical and its movement is in  d  a kid moves the toy freely   ,sensors imu
2524,how to calculate the power required to drive a fan,i need to specify a fan motor combination and wondered if there are formulas that can work this out  the fan we are using is a crossflow fan   so i m assuming the power required to drive it is derived from the number of blades  dimensions of blades  including angle of attack   dimension of barrel wheel and the speed in rpm  is this possible or does it need to be worked out practically with experimental measurements etc  hopefully this is the correct stack for this question  if not then mods please feel free to edit close   ,motor power
2526,neuromorphic engineering and robotics,i have been into a boggling paper research on neuromorphic engineering and its implications on robotics applications  lately  it is relatively a less applied field and full of academic papers and difficult to skim easily    there are many ongoing projects applying analog or digital circuitry design to implement neurosynaptic simulations of the brain  consumer oriented products like ibm synapse and qualcomm s zeroth focus on digital hardware whereas academic research like standford s neurogrid or etc zurich s human brain project focus more on actual brain study using analog hardware  if anybody is following this engineering field  can he she spread more light on it and explain it s implications  methodologies and toolsets to the community  in detail  ps   regarding toolsets  i m talking about the most feasible engineering methodologies to commit to the field  ,mobile-robot artificial-intelligence research machine-learning
2530,help sending serial command to roomba,i have a raspberry pi hooked up to a roomba     s serial port  while going over the spec  i noticed movement controls weren t as simple as i expected  i can t send bytes larger than      but  according to the spec  to go straight i have to send       how does this work  edit  my solution was the following three functions   ,mobile-robot raspberry-pi serial irobot-create roomba
2531,why is ros not a real time operating system ,ros is not real time os  after reading the architecture of ros  i am unable to realize why is ros not real time  what part of the architecture or what design decision is causing that  ,ros
2542,what do we call a coupling with infinite range of rotation,in most situations  range of motion is limited by the fact that we need to carry power or information past a joint  so  past a certain point there are either cables in the way  or the cables would stretch so much that they would either prevent further movement or break  however  if we situate the conductors in concentric rings around or within the rotor shaft  we can have a joint that can rotate forever while keeping in contact with any modules on the other side  what do we call this mechanism  does it even have a name  ,motor motion joint
2545,arduino serial mixing incoming commands,in my project i m aiming to control a quadruped robot from my android phone using raspberry pi as a middle device  web server   in order to make sure that the server on rpi working fine i googled and got an app that sends a specific character whenever a button is clicked and the arduino job here is simply to receive it from serial port and blink a led   so easy huh   but the problem here is that i noticed that some leds are blinking when i click a button not assigned with them  this can be a disaster if you are controlling a robot   does anybody know the reason of this and the solution   ,arduino serial
2552,best way to sense rubiks cube movements,i was wondering what was  in your opinion  the best way to study the different motions of a rubiks cube  i want to be able to recognize what face moved and in what direction   would i be able to get the direction and the face with accelerometers gyro and if yes how many would i need  if you have ever used a leapmotion or kinect  is it possible to achieve this using those  ,accelerometer motion
2553,capacitive touch input robot to remote access ipad,i d like to buy a capacitive touch input robot in order to remote access my ipad but i m having trouble describing a correct kind of robot   i would like to keep lag down to an additional   ms so that it is still a high quality interface   i would like to have a robotic arm equipped with a capacitive pen that moves to places on the ipad screen based on the mouse or i d like a array of capacitive pens that emulate the touch of a user   i guess i d use squires software reflect and the mirror function but i m open to using an shd camera with the robotic arm and a pixel sensor array with the array of capacitive pens   does this make sense  how could i improve the design  what materials would i need to build it myself  assuming ready built arm  how could i build an array of capacitive touch micro pens  ,robotic-arm
2555,any image transfer protocol for wireless serial transfer ,i want to send image over wireless serial communication  i am planning to capture images using either raspberry pi or stm   mcu using dcmi and then transfer image using wireless serial communication module such as xbee or  dr radio which can provide air data rate upto    kbps at baud rate of        i would like to know if there is any protocol which can send a jpeg compressed image as a wireless serial data  ,raspberry-pi serial communication wireless
2556,how to rotate covariance ,i am working on an ekf and have a question regarding coordinate frame conversion for covariance matrices  let s say i get some measurement  with corresponding  x  covariance matrix   this measurement and  are given in some coordinate frame   i need to transform the measurement to another coordinate frame    transforming the measurement itself is trivial  but i would also need to transform its covariance  correct  the translation between  and  should be irrelevant  but i would still need to rotate it  if i am correct  how would i do this  for the covariances between     and   my first thought was to simply apply a  d rotation matrix  but that only works for a  x  submatrix within the full  x  covariance matrix  do i need to apply the same rotation to all four blocks   ,kalman-filter
2559,are propellers dangerous ,aren t all propellers super dangerous  how are these startups like hex and pocket drone selling drones as  kid friendly  to consumers  what happens if a kid puts his finger in a propeller s movement space while its flying   ,quadcopter
2563,connecting wifi bee with xbee usb adapter,i started to follow  get started with the wifi bee  tutorial in wifi bee v    wiki page   i am using xbee usb adapter v    wifi bee rn xv mini usb cable as listed in tools needed  when i conneted the xbee usb adapter v  to my computer via mini usb cable wifi bee didn t light up  but usb adapter did light up   then i followed all the steps till number    which is   send at command   to the wifi bee and it will reply  cmd  to indicate that it enter the command mode properly   when i sent command  it didn t reply anything  i typed other commands like show net and  scan  it didn t reply either  when i tried arduino server example in the wiki page  wifi bee lighted up  but it gave me some strange ip address with port      and when i entered that ip address to my browser address  browser couldn t find the page  so my question is does xbee usb adapter need some extra power sources  or it just doesn t fit with wifi bee  i don t think the problem is with usb cable   cause my computer found the device   ,wifi usb
2564,how to use toa  time of arrival  to measure   axis location of a wireless device ,i need to read the location of my device within a  m radius sphere  with accuracy of     cm  the device is handheld and wireless  and currently communicates using a bluetooth v  chip  i could add an rf transmitter on the moving part and a few stationary receivers at the base  what components should i look into  what would be the cheapest way to triangulate it  ,sensors imu
2570,do servo motor specifications take into account the gear ratio inside ,i am looking at buying a servo motor for a an application that must be able to lift     lb at a rotational speed of approximately  rpm  the servo motor listed here  states a stalling torque of     oz in  is this torque rating at the horn of the servo motor or the torque rating of the actual motor before any gear reduction is done  is this motor sufficiently strong for my application  ,motor servos servomotor
2571,sensor for tracking relative position of human,i am making a robot that needs to continuously track the relative position of a human  up to    meters away and with at least     degrees coverage  currently i am using a hitechnic irseeker v  sensor and made a beacon wristband with   tv remote ir leds  but the maximum distance i can get is around   meters  i ordered some   watts ir leds to boost the power  but the size of the wristband will be a problem because it will not run on a cr     battery  i also bought some ir remote receivers  but i am not sure if the reflection from the wall will give false results  is what i am trying to do possible  is a beacon   m away feasible using this technology    if it is  then what do i need to modify in my current implementation  if not  are there any other technologies that i should be considering to track the relative position or direction of human     meters away with at least     degrees coverage   ,sensors
2575,pid control against sine wave error,i m writing a pid to control a toy car that follows a black line on a circuit  i ve tuned my pid and it works at high speed for all the circuit except the winding section  for that  the error signal looks like a sine wave  and the toy car steers too much  i would like it to go close to straight  is it possible  edit  my car sees     grey points in a line ahead  and the difference between the darkest point and the middle of the visual range is the error signal  my output is the angle of a servo on the front wheels of the car  while the speed of the back motors is constant  the desired performance would be to oscillate with an amplitude less than the amplitude of the winding road  and the actual performance is that the car steers close to the sine line for one period  and at the next max amplitude it under steers  sorry  i can t provide graphs right now but i ll try to add some in the next days  is there a formula for adjusting the pid constants for the desired pid bandwidth  ,pid
2580,fit robot simulator to robot,i have odometry data  of a real two wheeled robot  who received control commands   now i want to code a motion model  in c     ros   which should follow the same trajectory  given the same control commands  normally  the kinematics should look something like this     begin align   v  fwd     control  fwd     v  ang     control  ang     x    x  old        control  fwd    v  fwd old      cos angle    dt    y    y  old        control  fwd    v  fwd old      sin angle    dt    angle    angle  old        control  ang    v  ang old     dt  end align    and i thought about just setting     begin align   v  fwd     control  fwd    k   v  fwd old    k   v  fwd old      k   v  ang old    k   v  ang old       v  ang      text     analog        x  y  angle   text  unchanged   end align    and then just search the minimum of the squared distance of the computed trajetory to the real one   depending on the values of   this would mean either a good optimization algorithm or just brute forcing   randomly testing a lot of values  is this the way to go here  i tried the  nd approach  but the results so far are not that good   so  as you might guess now  i m pretty new at this  so any help is appreciated  ,wheeled-robot kinematics algorithm
2587,reading data from d  and d  pins of a usb,so i have this optical mouse with me  which has a pan    dl tj optical sensor  it has a usb interface and when i looked up the internet  all i could find was tutorials using a     or sensors in those lines and it has pins like sclk and sdi but i don t have them instead i have d  and d   i understand that these are the data pins so what i did was take two wires and plug them into my analog pins of my dspic  f     and read data from it  after setting up uart communication and transmitting data  all i get are numbers running continuously   what i want to do is to read coordinates over the analog pins as the mouse aka the sensor moves on a surface  i would use this for position control for my robot  so my question is how do i read coordinates from the optical sensor over the d  and d  lines through my analog pins   ,sensors
2588,robotics stackexchange vs ros answer,robotics stackexchange vs  ros answer  what is better and for what purpose  ,ros robotc
2591,denavit hartenberg parameters of a robot with spherical wrist,what are valid values for the denavit hartenberg parameters  and   sometimes called   of the last   links of a robot with spherical wrist  from this reference   a spherical joint can be represented by three consecutive rotary joints with intersecting rotation axes   so the retrictions should be     arbitrary                but in this exam i have found on the internet  it says that the kuka robot has spherical wrist  and  of the last joint is different to   would  in the last link still yield a spherical wrist  ,kinematics joint
2593,sourcing motors for larger robots,i have been wanting to build larger robots and r c cars for some time now  but one issue i have had is trying to find larger motors  in the range of electric wheelchair motor size  i found one set on ebay but i am trying to find a more reliable source for these  to make my question more clear  i am looking for a reliable source s  for medium size electric motors around the size and power rating of a typical electric wheelchair motor ,motor
2594,  v dc to   vdc converter,i have built a r c car that runs on     ah   v dc deep cycle batteries  the motors are   v motors that will each draw around   a at full power  my  motor controller can handle this  as well as reclaiming braking energy   this is my way of saying that i have a   v power system  now my issue is that i want to run a   v device on this   v service  i do not want to have the hassle of another battery to maintain so i would like to power it off the main batteries  all the becs and other converters that i have found only supply around   amp while the device i am looking at powering will take around    a   v dc  does anyone know of a device that will do this  ,bec
2595,control arduino firmata with hc   ,i m using the johnny five library to control an arduino uno running standardfirmata  i have a hc    bluetooth module that i want to use to wirelessly control firmata  but have yet to get it working  i used  to configure the board for       baud rate    i m able to send various at commands and read back the results in my serial monitor  i followed  to wire up the voltage divider  to make my arduino s tx operate at     going into the hc    s rx  i ve tried running the hc    in master  slave  and slave loop  it only makes a bt connection in slave  which is default  when i run my johnny five script  here s the output    node jf simple js               board connecting                  board    serialport connected waiting for board to be ready               standardfirmata a timeout occurred while connecting to the board  please check that you ve properly loaded standardfirmata onto the arduino               board closing  firmata  serialport  i ve more than triple checked everything  uploaded firmata many times  firmata works fine over  usb  also  i have been able to get this working in the past with an hc      am i missing something  what are some good debugging techniques to figure out why it won t connect to firmata   ,arduino troubleshooting
2596,atlas robot reference,boston dynamics keeps making great robots  however  i dont see any papers that they publish   although now i can find papers on people using the atlas robot  i can not find an original paper detailing the robot or its mechanics designs   is there a reference for the robot  should i use youtube videos  ,design mechanism humanoid
2597,software libraries for parsing sensor data,what software libraries are there for assisting the general problem of parsing a stream of sensor data  we use various sensors like lidars and gpsins units that provide messages in proprietary binary formats  and have to write drivers for each one  even though there s a lot of similar concepts used in each sensor  like a general purpose datagram for all messages  consisting e g  of start end sentinels  length specifications and a checksum  and then a variety of well defined message formats for the payload   it ends up being a lot of tedious work to develop a driver each time  i d love a solution where i can write out packet message specifications in some format  and have a library that finds   extracts valid messages from a stream  and provides them in a simple data structure format  i m not too fussed about what language  but basically want a general purpose datagram parsing library  there s a lot of customisation with sensors  maybe some odd format parsing  and probably some initial configuration to start the data stream  so this is really something i want as a library for processing the data in real time that can be used as part of a driver application  everything i find is either too basic  the low level tools for interpreting individual elements  so still lots of time spent extracting individual elements explicitly   or too specific  i e  parsers written specifically for one particular protocol   as a concrete example  consider nmea messages   there s a basic outer datagram  starts with  followed by message name  then comma separated data  and ends with    checksum and line terminating character  data is in ascii so needs to be parsed to binary for computational use outer datagram allows for validation and removal of incomplete corrupted messages message name   content would be further parsed for consumption field names can be specified for ease of use  a  gpgll  message might be turned from  gpgll         n          w           a    into a programmatic data structure containing latitude  longitude  utc timestamp and its validity  ,sensors software driver
2600,need troubleshooting help regarding arduino uno   hc    bluetooth connection problem,i just bought arduino uno and hc     i hooked up the connections    v bluetooth    v arduino gnd bluetooth   gnd arduino tdx bluetooth   rx    rdx bluetooth   tx      here are the pictures    my problem is that i cannot seem to search for the bluetooth connection on my laptop or on my phone  is there something wrong i am doing here  ,arduino
2604,differential drive trajectory following control,i have a robot platform with differential drive which knows it s position and orientation  lets say that the space through which the robot moves is known and it has only static obstacles  the task is to move the robot from point a and heading alpha  on which it currently stands  to point b and heading beta on the map  lets also say that i can obtain a reasonable trajectory  in relation to the turning abilities of the robot   as both the robot and the sensors are inert  what are some general approaches for controlling such a robot to follow the path  it should of course be kept in mind that the final task is to reach the point b without colliding with the obstacles and not the perfect trajectory following  i hope the question is not too general  ,control pid navigation differential-drive
2606,where to ask nxp lpc       arm cortex m  related questions,i am a beginner to robotics and embedded systems  consequently i have a lot of questions related to the toolchain and how things are going together like how to debug or how to connect a bluetooth module  i already tried  and it did not work out for me  any ideas where i can get help with my lpc     related questions  ,microcontroller arm embedded-systems
2609,arduino operational frequency,just wanted to clarify some pretty basic arduino concept  if i put this code into an arduino board      i see        value in my serial monitor  for the  counter  variable   however  the moment i put in some heavy calculation in  point a   the value drops to            this is expected  i guess  my question is  is the only way to push up the operational frequency lies in optimising the code calculation  or  is there some other way i can get faster execution  ,arduino
2610,function of pidcontrol  pragma config   directive in robotc,i am trying to sync motors on a vex cortex based robot and have had mixed success using the encoders with position control   i noticed that the motor setup directive  has a parameter  pidcontrol  but i cannot find any documentation as to what it actually does    i see on the encoder documentation page here that the encoder provides velocity output  but it is not apparently built into the api   so my question is two fold     what does the  pidcontrol  directive actually do     how can i use the encoder to control the speed of the motors  ,robotc
2613,what is a suitable model for four wheeled differential drive rigid body robots ,i found a model for   wheeled robots here  what is a suitable model for two wheeled robots  how should i adapt it to a   wheeled setting  ,wheeled-robot kinematics
2619,building a servo tester to measure peak stalled amp draw,since finding data on stalled and in use under load  not free  amp draw for servos seems impossible  i want to build create my own servo tester  all i really want to know is how much amps the servo is drawing at idle  at movement under load  and at stalled full position  i think that should cover all the bases relative to amp usage on the servo but if not  please let me know what i am missing  here are my questions   i am going to need a power supply for an exact    v and    v since that seems to be the standard measurement voltages   i ll need some way to accurately measure the amp draw  i ll need some way to control the servo movement   is that it  what am i missing and if anyone has any suggestions please let me know and thanks for the help   this seems to be uncharted waters for those in the rc hobby area but someone in the robotics field may have been down this path  ,rcservo
2620,how to explain bandwidth of a measurement to a noob ,i am working on a system which is measuring a force  the specification is to have a    hz bandwidth on the measurement   now i was trying to explain this    hz bandwith to my mom and i could not really explain it easily  what is the most easy way to explain the term bandwidth of a measurement to someone without control engineering background  ,control
2628,project idea for a ai related project,i am a computer science final year undergraduate student until now i used to shirk away from robotics as i believed that it is more related to electrical and mechanical aspects but my interest in robotics grew by seeing some demos and i seriously want to make a robot which involves ai by teaming up with interbranch students of college so what is the best project i can pick up as a beginner in robotics and ai and some experience in computer science so i can apply ai machine learning concepts so that it learns something how to start something  ,artificial-intelligence machine-learning
2631,quadrocopter build   do these parts look fine ,i am completely brand new to quadrocopter building  i am currently about to start building a quad  i have done a little bit of research and was thinking of buying the following parts   kk    hobbyking flight controller turnigy h a l quadcopter frame   x ntm prop drive              kv      w turnigy  x  ch turnigy plush   a esc slow fly prop left slow fly prop right quad power dist board turnigy  ah  s  c lipo  what do you think of these parts do you have any complete builds with instructions that you would recommend instead  thanks ,motor sensors quadcopter multi-rotor
2635,how much can realistically be drawn from a   c max   c battery ,i am using   brushless motors for an octocopter  each motor can be run at maximum   a  i use   batteries in parallel  how high c number is needed   frac                c when running the motors at      load  it will draw   c from each battery  can a   c with max   c be used  or will it run hot  additionaly  how many ampere hours can be drawn from a     mah battery before it s empty  many   v car batteries can only be drawn for     of their stated capacity before they need to be charged  ,battery
2637,what is meant by a speed profile ,when researching robots  micro mouses etc i ve often come across people taking about generating  speed profiles  and how to calculate them  also profiles for acceleration   deceleration   turning etc  also trapezoidal profile  but i can t seem to find exactly what is meant by this  the how or why also  so what is a  profile  in this sense and why you would need one  ,control
2639,raspberry pi for two wheel robot ,i want to create a two wheel remote controlled robot  i have worked out a lot of the logic with regards to balancing  i have started to read up on motor control and arduino vs beagleboard black vs raspberry pi  is the multitasking nature of a full linux os a problem i need to be concerned with for this application  i expect that i have to adjust the motors at least    times per second  but i don t think a slight variation in the update loop interval to be a problem  possibly  i will face problems if i need to do pwm myself  basically  the way i plan to make the robot work is by using an accelerometer to have a reference to where down is  the robot will autonomously work to keep the direction of the accelerometer down  the remote control will simply adjust the readings from the accelerometer  and the balancing loop will then react as if the robot is falling and accelerate the wheels  ,arduino control raspberry-pi real-time
2641,what is the response time of an arduino nano ,i want to make a circuit that powers a transistor when a sound above a set threshold is reached   trigger a flash for high speed photography   how long will the response time be  ,arduino
2642,what is the best way to fuse measurements from imu  lidar  and encoder information in some recursive bayesian filter ,i am doing slam with a four wheeled    wheel drive  differential drive robot driving through some hall way  the hallway is not flat everywhere  and the robot turns by spinning in place  then traveling in the resulting direction  the slam algorithm does not need to run online  the robot takes measurements from a strap down imu gyro measuring   where ax refers to acceleration the x direction and wx measures angular acceleration about the x axis  the lidar scans the hall way with a     degree arc and measures ranges and angles  however  so far as i know the hall way has no discernable features except when it corners i need to find the best way to fuse the proposed action measured by the encoder with imu and lidar data  it makes sense to me that i could fuse yaw from imu with encoder data to get a better sense of heading  but how should i incorporate lidar data   in essence  what is the appropriate measurement model and how should i incorporate noise into the motion model  beside just adding some gaussian noise at some        addendum this somewhat orthogonal to the question but just as confusing to me  currently i am using a particle filter to do slam  and i am a little confused about whether to represent uncertainty in angular acceleration in the particles themselves  i see two options   a separate navigation filter using ekf  or anything really  to find a vector of  best estimate  angular acceleration matrix first  then use this matrix as absolute truth for the particle filter  so that any drift in the particles is not from uncertainty in angular acceleration  incorporate the uncertainty into the particle drift themselves  this option appears more sensible but i am not sure what a principled way to do this is    ,kalman-filter slam particle-filter
2643,can a rigid prop quadcopter hover upside down ,most small quadcopters use rigid rotors with some fixed pitch  in principle  i can imagine it might be possible for such a rigid prop quadcopter to hover upside down  but that apparently requires reversing the direction of rotation of all   motors   this is very different from the way some  standard  single rotor model helicopters can hover upside down by continuing to spin that rotor in  the same direction   but moving the swash plate to give negative blade pitch   is it possible for a rigid prop quadcopter to hover upside down  when i build a quadcopter so it can switch from flying upright to flying upside down and back again in mid flight  what do i do differently than a normal quadcopter designed to always fly right side up   related   can you run a bldc motor backwards without damage     ,motor quadcopter multi-rotor
2644,dc motor with encoder,can anyone help me out here with this dc motor  especially the encoder part  i tried searching around for its datasheet but its as short as   page and the only spec i get are  encoder    pulse revolution it has   connection on the bottom  and i guess they are for driving the motor  but they say nothing about the   connections wires below   ,motor quadrature-encoder
2649,kinect point cloud   pcduino  will it work ,i m a newbie to mircroprocessors  pcduino  for example  and i wanted to know if kinect can be integrated with the pcduino  before i go and buy the board  i know in terms of connectors etc what might be required  my concern is regarding the hardware required to run the kinect  to elaborate more  i ll explain my current system  i have a system working on my laptop that uses a kinect to extract unorganized point cloud data using  processing  ide which interacts with kinect using openni drivers  my matlab code then processes this information to detect obstacles and specific objects  can also be done using c      i want to build such a system for a robot  but using pcduino as the processing module  this means that the kinect will connect to the pcduino using one of its usb ports  i ll power the kinect using battery and a converted power adapter  since pcduino can run linux  ubuntu  i  think i  can easily convert my laptop code into whatever the ubuntu requires  the only concern i have is if there were any problems associated with using depth sensors with mini pc boards in terms of hardware capabilities of mini pc boards  i know that mini pc boards are not as fast as a pc  so the processing would be slower  but i m not concerned with the speed  atleast for the time being  one problem i encountered while using kinect  even on a pc is that the point cloud drivers in openni won t initiate the point cloud data stream  unless there was a gpu in the pc  the exact same code runs perfectly on a pc with a dedicated gpu  however  i do know that pcduino has a gpu chip  opengl es      would the kinect work on this  i searched online but the closest thing i could find is this which does not elaborate how the integration of raspi and asus xtion works  i m not too picky about the boards  anything that would work with a kinect is fine with me  although i like the pcduino since it has arduino headers and built in wi fi etc   any additional pointers can also be helpful  please let me know if i need to elaborate on anything more  thanks in advance ,microcontroller kinect
2652,a few questions about my first quadcopter build,i m planning to order parts for my first quadcopter build and i had a few questions  here is my parts list  i m crossing my fingers that they are all compatible  and i m pretty sure they are  i have two questions   do i need a power distribution board and if so  what does it do  where on my flight controller do i attach my radio receiver    ,quadcopter microcontroller radio-control
2657,could piezoelectric sensors be crushed ,i have found some load sensors  piezoelectric  that measure relatively small weights  on the order of   grams   that s what i need  however    around my robot  there will occasionally be bursts of extremely high pressure  these bursts do not need to be measured    they just wash over  the pressure appears  to the sensor  to be a          kg  question  are these sensors likely to break or fatigue  i realize piezos do not measure via deformation  but still    that s a big load  maybe i should just order a few and try    ,sensors
2661,kalman filter when states are not observable at the same time ,i have a system that i can make a strong kinematic model for  but my sensors send readings at unpredictable times  when i say unpredictable  i am not just saying the order the readings will arrive  i also mean that sensors are able to sleep when they do not see a significant change  when an input arrives for any given sensor  that information can be used to infer the states of many other sensors based on my model  at first  it seemed like a kalman filter was exactly what i needed because i could make a prediction of all of the states of the system and then update those states when one piece of information comes in and repeat this process until a good estimate of the system as a whole was determined  however  after reading over kalman filters  it looks like they assume that every state will be updated on a regular basis  is there a way the kalman filter can be modified for when you are unsure about what input will come in next and you are also unsure how much time will elasped before the next input arrives  please note that in my case  once the information arrives  i will know the source of the input as well as the time that has elapsed since the last update  i just won t be able to predict these two things beforehand  ,kalman-filter
2667,wine yard robotics ,my friend has acquired a  small  wine yard to discover how much work it is tending and harvesting the grapes  now we are musing to enlist robotic help  the vine stocks are usually connected by a stiff wire  so some dangling machine might be feasible  we are looking for references inspirations for an agricultural robotic vine assistant  any ideas  ,mobile-robot robotic-arm
2668,removing quadcopter drift to the side,i wrote my own quadcopter firmware which is based on some older code  this code shall stabilize the copter to be always in equilibrium  the model is behaving relatively nice  i can control it with my laptop  however i noticed  that the copter is hovering to the side  if not manually controlled   likely because of wind  not well balanced or turbulence   my idea was maybe to fuse gps and accelerometer data to implement a function which shall help to hold the position  but this will likely only work if i have a hold altitude function  because changes in pitch or roll change the height  because the thrust is changed slightly  this is why i recently added a routine which shall allow to hold the altitude   is someone having experiences with this  i mean with avoiding side drifts of the model because of whatever by software  the problem is in my opinion  that i don t know whether the position change is wanted  by remote control  or not  additionally it is hard to localize the correct position and calculate the distance caused by drift from it  just with gps  but this is not precise    copter control     stabilise pids float pit stab output   constrain float  hal board m rgpids pid pit stab  get pid  float rcpit   vatti x                  float rol stab output   constrain float  hal board m rgpids pid rol stab  get pid  float rcrol   vatti y                  float yaw stab output   constrain float  hal board m rgpids pid yaw stab  get pid wrap    f targ yaw   vatti z                       is pilot asking for yaw change   if so feed directly to rate pid  overwriting yaw stab output  if abs rcyaw       f      yaw stab output   rcyaw    targ yaw   vatti z     remember this yaw for when pilot stops       rate pids int fast   t pit output    int fast   t constrain float  hal board m rgpids pid pit rate  get pid pit stab output   vgyro x                  int fast   t rol output    int fast   t constrain float  hal board m rgpids pid rol rate  get pid rol stab output   vgyro y                  int fast   t yaw output    int fast   t constrain float  hal board m rgpids pid yaw rate  get pid yaw stab output   vgyro z                   int fast   t ifl   rcthr   rol output   pit output   yaw output  int fast   t ibl   rcthr   rol output   pit output   yaw output  int fast   t ifr   rcthr   rol output   pit output   yaw output  int fast   t ibr   rcthr   rol output   pit output   yaw output     hold the altitude hold altitude ifl  ibl  ifr  ibr  rcalt    hal rcout  write motor fl  ifl   hal rcout  write motor bl  ibl   hal rcout  write motor fr  ifr   hal rcout  write motor br  ibr    ,arduino quadcopter
2671,compliance control for a single link robot in matlab,what exactly is active compliance control in robotics joint   why is it used    how can i write a program to simulate the compliance control in matlab for a single robotic link or single robotic joint   i have to develop an algorithm for torque control  i have to sense the torque and give feedback to bldc motor which is supposed to apply some controlled torque   i also have some unclear understanding of few things  lets say i have single joint two link systems  how would this system behave when i have applied the compliance control algorithm at the joint  how will i test it  i mean if i apply some external torque what should it do so that i understand that it is in compliance control mode  here is a related paper   ,control robotic-arm
2672,mcbl controller through rs   ,i m trying to use the mcbl controller by faulhaber to control my motor  i m trying to program some sort of driver on linux using the serial connection and libserial  but it does not seem to be working for now   i m using the usb to rs    converter like this one   i m wondering if it s well supported by libserial  i ve read that yes but does anyone have any experience with it  ,serial communication
2673,passive ego motion estimation vs active,i am doing research of ego motion estimation and positioning in  dof space  and i found that apparently all systems are based on active rgb d sensors  like kinect  i understand  that such sensors provide greater accuracy  and requires less computational resources  but if such systems will be used  for example  for augmented reality or robot navigation  how they are going to solve the problem of the interference of signals from different systems  operating in the same space  if many people will wear ar glasses with active sensors   they will interfere with each other  aren t they  are there big commercial projects  that use passive visual odometry with multiple camera units and imu sensors  i found some good papers on this topic  but i have not found commercial application of such technology  i am going to make research of passive odometry method for ar  but is it actually a problem with active depth sensors  that i described earlier  upd  the main question  is passive odometry  based on video flow analysis and imu  worth to make deep research in this topic  or active sensors   is our future  and the signal mix is not a big deal  and passive odometry is a dead end of such kind of technology  because it will be not very useful to make research in useless technology    ,kinect sensor-fusion odometry
2676,how can i measure the torque value of a servo ,i know there must be a  tool  that can measure oz in of torque   i do not want to trust what the servo manufacturers state on their site for torque values so i want to test them for myself  anyone know what tool i can use to do this   i have used fishing scales before  but i need something more sensitive than that and my units are pretty small such as around    oz in  thanks    ,servos
2677,autonmous surveillance vehicle,i am planning to build an autonomous all terrain surveillance robot using raspi  which is the better option computer vision or ultrasonic sensing to avoid obstacles   and i want to transmit the video recording to base station  ,raspberry-pi computer-vision ultrasonic-sensors
2680,how to decide about the length of a robotic arm  the base of it and the torque ,i am designing  a remote controlled robot which will have a base with three wheels  two of them will be simple wheels at the back of the base and the third will be a ball wheel at the front  it will have a robotic arm which will have a gripper to hold objects up to  kg  i have designed the arm like this  what i want to ask is how to calculate the length of the arm  the base of the  robot  the torque and also which motor to use  please suggest to me if there is a better solution for designing the robot i am a robot enthusiast and i am designing a robot for the first time  ,motor control design robotic-arm
2683,altitude hold for quadcopter with accelerometer and barometer,i wonder currently how to implement an altitude control for a quadcopter  i have atm just a barometer gps and an accelerometer   barometer and gps are relatively straight forward implemented  but not very precise and slow  for the accelerometer readout  i remove the constant      m s  acceleration by a low pass filter  then i take this data and calculate out of it the climb rate in cm per s   i know the speed approximation by this way is not so great  however i don t know a better approach so far  for the calculation of the motor speeds i use atm two pids  stab and rate    i coded the example shown below  without much testing so far  i believe it will not work out in a smooth and nice way  e  g  instead of the speed calculated of the accelerometer i could use the climb rate of the barometer  however for low altitudes and small changes i do need very likely the accelerometer   ardupilot seems to use somehow in a different way both with a third pid for the acceleration  i believe they calculate the height difference like me  then they use maybe for stab pid the barometer climb rate  not like me the accelerometer  and calculate with acceleration data another output  unfortunately i don t know how exactly  or whether there are other methods  does someone know the exact layout to implement with a barometer and accelerometer an altitude hold function  i mean i am really not sure whether my ideas would be correct  maybe i can post some options later  my pids   code for altitude hold     stabilizing code done before  float fcuralti cm          hal board get alti m         f            barometer and gps data float facclclimb cms       hal board get accel mg ms   z             accelerometer output in cm per s  gravitational const  corrected      calculate the difference between current altitude and altitude wanted float faltstabout          hal board m rgpids pid thr stab  get pid fcuralti cm    float  rcalt m              rate it with climb rate  here with accelerometer  int fast   t ialtoutput    hal board m rgpids pid thr rate  get pid faltstabout   facclclimb cms          modify the speed of the motors ifl    ialtoutput  ibl    ialtoutput  ifr    ialtoutput  ibr    ialtoutput   ,sensors quadcopter accelerometer ardupilot
2687,need help calculating the thrust on quadcopter motors,i m trying to calculate the lifting capability of my four quadcopter motors  i tried using ecalc but it doesn t have battery i m using  are there any equations to keep in mind for doing these calculations  here are some relevant details  battery      mah  s      c lipo esc    a motor      kv brushless propeller   x  any help would be much appreciated  thanks  ,quadcopter
2692,using  dr radio to communicate ardupilot data,i am trying to send some data over to my pc from the arduipilot  i used a normal usb connection to send over a recurring string like this    i receive the string just fine when i open a serial monitor with baud of       bits sec  but  when i remove the usb port and plug in the  dr radio module to the ardupilot and the pc  it gives me garbage  i know that the  dr radios use mavlink communication protocol  but i was wondering if it s possible to change this protocol and use a normal spi so that i receive the data in the same format i receive when connected via usb  if this is not possible  is there a way to convert this garbled data from the radio module to a useful string   it would be greatly appreciated if someone can help me with this  ,ardupilot radio-control
2694,set canopen node id of ingenia pluto dc servo drive,does anybody know how to configure the node id of an ingenia pluto dc servo drive  i ve got a request out to their support team  but perhaps somebody here is already familiar with these drive boards  i do have ingenia motionlab        but it does not ship with documentation and the motionlab user manual on the site is out of date  i had previously been looking through the hardware documentation  but it turns out the info was in motionlab documentation  although the instructions for previous versions no longer seem to apply to         ,control can
2695,what are the options for a thin light source  e g  led  ,i m looking to make or buy something resembling an led  that would be thin  about    mm or less  and cheap        in mass production   any suggestions  ,arduino electronics
2696,an architecture for testing autonomous flight and sensors,i m designing a simple autopilot software on top of ardupilot  my goal is to possibly interface an raspi on top of ardupilot mega  apm   i am stuck on setting up a simulation environment using either v rep or gazebo   the quadcopter will have basic sensors plus advanced sensors  basic sensors talks directly with ardupilot  while advanced sensors talks with my own autopilot software  i am trying to wrap my head around a feasible setup to test the software while using ardupilot mega in the hardware in the loop  i am planning on having three stages of simulation  stage    simulate quadcopter physics in gazebo v rep  run ardupilot software and my autopilot software in a vm  not sure if it s even do able  stage    simulate quadcopter physics in computer  run my autopilot software in a vm  and run apm in a hardware in the loop fashion  stage    deploy my autopilot onto raspi and interface with apm then run both hardwares in hardware in the loop fashion  ,quadcopter simulator
2698,random number generation for particle filter,i implemented a bootstrap particle filter on c   by reading few papers and i first implemented a  d mouse tracker which performed really well  i used normal gaussian for weighting in this exam   i extended the algorithm to track face using   features of local motion and hsv    bin histogram  in this example my weighing function becomes the probability of motion x probability of histogram   is this correct   incase if that is correct than i am confused on the resampling function  at the moment my resampling function is as follows  for each particle n        compute cdf generate a random number  via gaussian  x update the particle at index x repeat for all n particles   this is my re sampling function at the moment  note  the second step i am using a random number via gaussian distribution for get the index while my weighting function is probability of motion and histogram   my question is  should i generate random number using the probability of motion and histogram or just the random number via gaussian is ok  ,mobile-robot localization particle-filter tracks
2700,battery system with and without mains voltage attached,i m working on a project where mains voltage will sometimes be disconnected  and the system will have to run on battery for as long as possible before doing a  safe  shutdown   the desired behavior is exactly like a laptop battery system   when mains voltage is connected  charge the battery and power the system from mains when mains voltage is disconnected  power the system from the battery prevent the battery system from supplying current when the batteries are discharged below a certain voltage  to prevent damage    is there a name for this type of system  or a name for the feature s  that i should be looking for when i look at chargers    if it matters  this system will be   v  so i m looking at     v lithium battery options   ,power battery
2701, d map representation of gps coordinates in degrees,i want to implement my own gps navigation for a quad copter  i can calculate and filter the gps coordinates  latitude and longitude in degrees    i believe the easiest approach for me would be  to calculate the change of the heading of the quad copter from the current attitude to the destination point and let it fly straight on after turning   however i am not sure about the  d representation of the latitude longitude gps coordinates  for a round earth to a  d map system when calculating the heading change   how big is the expected error  or is there none  ,navigation gps
2702,how does one calculate the angular motion of each node in a robotic arm,a robotic usually consists of joints with sections of possibly varying width connected together  considering we know how much each is bent and the length of each section  and their location in  d space  not local coordinates  at time zero  how do we determine how much each joint should rotate to goto position b from position a  both a and b are defined in world cartesian coordinates  now each joint can move in terms or all at once  so should all joints move simultaneously or in turns  ,kinematics robotic-arm
2704,quadcopter forward speed,i am trying to better understand the dynamics of forward flight in multirotors  assuming i have a quadcopter with   motor propeller combinations capable  each  of a propeller pitch speed of  say  speedmax      mph  in forward horizontal flight  the quadcopter will pitch down at a certain angle  let s say alphap  from horizontal  if alphap is  say     degrees  and drag is neglected  wouldn t the quadcopter be capable of a max theoretical speed of sin       speedmax     mph  also  seems to me alphap cannot go all the way to    degree  quadcopter flying like a plane   as at that point the propellers would not produce any  upward thrust to maintain the copter aloft given there is no wing loading as available in a plane   if drag was to be neglected  what factors would the optimum alphap be depended on  and what would that angle be  for maximum speed  ,quadcopter
2706,how do i get started in computer vision ,i want to know how to write and run the correct code  i understand that i need to download opencv  which i have   but when i try to compile sample code   for example  blob detection   it doesn t compile  i am just very confused on the process of what you need to do to get something to show up on the screen   i know my question is really vague  but i have such a bad understanding of computer vision that i don t really know how to describe my problem  hopefully discussing more will be able to help me   please help me  i have been searching the internet for   hours now and i am just lost in a sea of information    ,computer-vision
2708,multiple position estimates fusion,i have a system in which i have two separate subsystems for estimating robot positions  first subsystem is composed of   cameras which are used for detecting markers the robot is carrying and which outputs   estimates of the robot s position and orientation  the second subsystem is a system which is located on the robot and is measuring speed on the two points of the robot  by numerically integrating those two i can get an estimate on the robot s position and orientation  because i am tracking two points at once   the first system is less accurate but the second system drifts  first system gives output about once a second while the second one gives output much more frequently          times per second   i assume there must be a better approach than to just reset the position with the first system s estimate  as it is not      accurate   but to also use the accumulated position from the second sensor system and fuse that with the new data from the first system  also  there is a question how to fuse   estimates of the first system  there must be a better way than pure average as it might happen that the two estimates are exactly the same and the third one is completely different  meaning that it is probably more wrong   do you have any fusion algorithms to recommend to use in such a system  i know about kalman filter  but i am having trouble figuring out how to use it as the two systems output data at different frequencies  i hope the question is clear enough  what is the best approach to fuse the estimates into a more correct and accurate estimate  thanks ,sensors localization kalman-filter sensor-fusion
2712,power issues involving raspberry pi,i have a raspberry pi  model b  attached to a roomba  i m using this part to bring the unregulated   v  power of the roomba down the  v  a of the pi  the problem is that the pi will randomly reboot and cause peripherals  such as the bluetooth adapter  to freak out and not work  we can sometimes drive it around for a little while before it reboots  other times it happens almost immediately  ,mobile-robot raspberry-pi
2713,how to connect arduino uno   l   d motor driver and   colour sensors together ,i am trying to build an autonomous multi coloured lines following robot  the parts i have bought so far include   arduino uno      colour sensors  taos tcs       l   dne motor driver  robot chassis including   dc motors    wheels and   caster wheel   i am trying to figure on how to connect all these components together  for example  arduino to the colour sensor  l   d to motor    how do i connect it in order for the motor to rotate in both directions   do i need to solder anything  ,mobile-robot
2714,precision we can expect of an ultrasound based localisation system,i m considering building an absolute  indoor robot positioning system based on ultrasound time of flight  transducers will be ordinary  narrow band     khz ones  based on your experience  what is the best exactitude and precision we can achieve with such a system  i m aware that the answer to such a question will depend on many factors  both hardware and software  if applicable   but i m not asking about the performance of one solution or another  but about the intrinsic limitations of the ultrasound technology  ,localization ultrasonic-sensors
2715,how to implement a distance proximity sensor with wider range,more in the line of robotics observing their environment  i m trying to implement a proximity sensor that can sense objects in front of it to a least up to  to    of it s direction of propagation  there are only two ways i can think of  multiple infrareds      con  more spacious fast motor   con  expensive in money and time complexity wise  i m currently using a proximity sensor with up to   ft distance capability ,sensors
2719,h bridge for rover,i am building a   wheeled rover  one set of   wheels will work together and other set of   wheels will run together  so current in each side may vary from  a   a blocked rotor  and  v i want to make a h bridge for controlling direction and speed i ll use pwm  so i will require two such h bridges  what is the copper track thickness i should use in proteus for making the design or else shall i go for manual soldering replacing tracks with wires  can anybody suggest a design which is relatively easy to design with some protection circuit in it  for mcu pins isolation  or suggest any suitable motor controllers from ti or any company which can be apt to my problem ,motor control
2720,what are the pros and cons of fictitious play,i ve been looking for articles and topics the fictitious play learning algorithms for my presentation i haven t found it s pros and cons is there a book or something that i can benefit from  thanks ,algorithm
2723,scara arm lead screw choices,i m thinking about building a scara arm to lift moderate loads  lbs  with a high degree of accuracy  i want a relatively quick and inexpensive z axis gantry  and i was thinking about using a lead screw with dual linear rail  trouble is i m not certain the linear velocity will be fast enough  what s the best method of choosing the lead screws and the associated nut  given a desired linear velocity of   inches second and a nema stepper motor driving it  ,robotic-arm mechanism
2724,what s a good pose estimation method for high precision    mm per axis  solutions at short range     cm  ,i m trying to get a  dof pose solution for an object that ll be between    and    cm from a fixed point  i want to avoid putting too much special hardware on the object  but extra hardware on the fixed side is fine  i ve been looking into two general methods   fiducial markers there are several software packages with different types of markers  but i haven t been able to find any information about them regarding precision or accuracy in short range pose sensing  ultrasonics i ve found some commercial systems that do  dof pose sensing  e g  hexamite   but they re expensive and require you to put transmitters on the object   ,sensors ultrasonic-sensors pose
2726,what s the difference between can s motor max velocity vs  profile max velocity ,can        provides max motor speed   x      x    and max profile velocity   x   f  x     in profiled motions  the maximum speed is limited to the lower of these two values  in non profiled motions  the maximum speed is limited to max motor speed  what is the intended purpose of max profile velocity  rather than only providing max motor speed and using that everywhere instead  ,motor control can
2729,is there an analytical solution for inverse kinematics of a   dof serial chain ,let s take a   dof robotic structure  it s consisting of the   dof global structure for the position   and the   dof local structure for the orientation of the endeffector  if the last   axis  of the local structure  are coincident in one point  the inverse kinematics can be solved analytically by decomposing it into a position  and orientation problem   but is it possible to solve the inverse kinematics analytically if the last   axis are not coincident in one point  i ve read several papers that claim that due to high non linearity of the trigonometric functions and motion complexity in  d space  a   dof serial chain cannot be solved analytically   does anybody know if this is right  ,inverse-kinematics
2730,how to use scan command in arduino wifibee,we want to find available wifi networks near  so in tutorial there is command scan  which is send from coolterm program from pc   now we want to write program to arduino which will do same operation  how it can be done  ,arduino wifi
2731,using robotic simulator for prediction step in probabilistic localization approaches,probabilistic localization approaches like kalman or monte carlo benefit from an accurate prediction step  the more accurate the prediction step  the more accurate is the belief of the robots pose  in most approaches probabilistic motion models are applied  mainly because robot dynamics are more difficult to model  still some approaches rely on dynamic models in order to increase the accuracy  therefore  i was wondering if it s reasonable to utilize a robotic simulator like v rep or gazebo for the prediction step  the advantages i see in doing so are the following   the robots kinematic is solved by default  simply through modeling it in the robotic simulator the robots dynamics are taken into account nonlinear behaviors like slippage or collision can be modelled up to a certain extend the robots workspace is taken into account  by modeling its environment  if the robot drives against a wall previous models would predict it behind the wall  which won t happen in a robotic simulator   with the shown advantages i hope to achieve a more accurate prediction  however there might be some problems using a robotic simulator  for a start it has to ensure real time behavior and there will be delay in the prediction due to the communication with the simulator  i was looking for some papers which pick up on that idea but couldn t find any  are there any approaches similar to my idea  if not  are there any reasons why nobody is using a robotic simulator for the prediction  what are your opinions about my proposal  ,mobile-robot localization motion simulator
2744,what different sensing approaches are used in the current batch of indoor  d cameras ,i m aware of the primesense camera powering the kinect  are more advanced sensor types available now in the        range  for example  has there been any sort of game changer in structured light techniques  do decent flash lidar cameras exist now  ,sensors kinect cameras lidar
2747,robot start up movement problems,i have created robot using a robot chassis kit from hobbyking  at first when testing the robot connected to usb power source and the wheels lifted above the ground everything seemed to be ok  then  when i tried to power the robot with batteries i encountered a problem with starting the movement  the robot hardly starts to move even when i power it with      of power   sometimes i have to push it a little bit in order to start driving  as a newbie i don t know whether it is a power source  battery  or motors problem   there are   motors with torque of    gf cm min in the chassis   the gear ratio is      and to power the motors  i used two serially connected li ion batteries and dc dc regulator which limits the voltage output to  v   the power is regulated with dual h bridge motor driver    according to specifications  the maximum free running current for a single motor is    ma and i have read that the stall current is    x running current  anyway  the problem is that the robot has problems with starting up driving and i don t know how whether the motors are even powerful enough to move the robot or it is a power source problem or perhaps the obstacle could be solved with appropriate power regulation  ramp    how can i solve this problem   ,motor battery movement
2748,maximum distance using ultrasonic sensor arduino,what is the maximum distance  of say   a car   you could measure using an ultrasonic sensor that would be compatible with arduino  is there any sensor ultrasonic or not  that could measure the distance of a car   say upto    meters that can be used with arduino  ,arduino ultrasonic-sensors
2754,what is the name of the part i m describing,i m looking for a part that will do a particular function   it has to be able to move along one axis and tell me the force that is being exerted on it  kind of how like a piston moves inside an engine  one axis of movement  except that something will be pushing at the top of the piston and i need to know how hard its pushing   another difference is that the piston won t be constantly moving back in forth  but needs to be able to receive commands like    and then remain stationary at its new position  i know to make this it would involved a sensor and something that can exert force but what is the name of the described machine  edit      response to matthew gordon the piston would have to move between     centimeters   the form factor would be small  ideally smaller than the palm of your hand    smaller better  the forces it would have to deal with are comparable to the forces exerted on a bicycle by its chain   i m a math cs person not engineering so i don t know technical terms for these kinds of things off the top of my head   it would have to be real time sensor reading  but the volume of data could be processed by a phone   would have to working in conjunction with wireless communication  probably bluetooth  but i d have to look into the latency requirements to be sure  ,sensors mechanism force-sensor
2758,what are the advantages of using the denavit hartenberg representation ,when one wants to model a kinematic chain and in particular define the frames attached to each body  it is common to use the denavit hartenberg parameters  what are the advantages of this representation  i can understand the interest of having a normalized representation but does it impact the algorithms performance  the algorithm is not trivial to implement  what gain can we expect from this instead of  for instance  just fixing reference frames by hands  i e  arbitrarily  like this is done in many robotics formats such as urdf  ,kinematics
2760,computing inverse kinematic with jacobian matrices for   dof manipulator,i m trying to calculate the inverse kinematic for an   dof manipulator  task  a target point  and the orientation  are given and i want to get the angle configuration  for my robot  method  for that i try to implement the jacobian method  with the transposed jacobian matrix  with this guide and followed the pseudocode at slide     but instead using the pseudoinverse of the jacobian matrix i used the transposed one  i ll try to compute the jacobian matrix numerically and analytically  but didn t get a solution  endless loop  for any of them  here s how i retrieve the jacobian   numerically    analytically  private void calculatematrixanalytically         var pematrix   calculatejointpositions        var zmatrix   calculatez         for  var column      column   this columns  column                  double   p p   new double             for var row      row   zmatrix rows  row                          p p row    pematrix m row  this columns      pematrix m row  column                      this m    column    zmatrix m    column    p p      zmatrix m    column    p p             this m    column    zmatrix m    column    p p      zmatrix m    column    p p             this m    column    zmatrix m    column    p p      zmatrix m    column    p p             this m    column    zmatrix m    column           this m    column    zmatrix m    column           this m    column    zmatrix m    column                 summary      calculate the positions of every joint        summary       returns the matrix with the joint coordinate for each joint   returns  private matrix calculatejointpositions         matrix jointpositions   new matrix           position pos       for  var joint     joint  this currentaxisconfiguration joints count    joint                  pos   this kinematic calculatedirectkinematic this currentaxisconfiguration  joint           jointpositions m    joint    pos point x          jointpositions m    joint    pos point y          jointpositions m    joint    pos point z             return jointpositions     private matrix calculatez             z  t z  t z  t     z  t      var ksend   kinematics translaterobottoworld        var zmatrix   new matrix             for  var column      column   this currentaxisconfiguration joints count    column                  for  var row      row   zmatrix rows  row                zmatrix m row  column    math round ksend m row                   ksend   ksend multiply              kinematics translatecoordinatesystem              robo theta column    this currentaxisconfiguration joints column               robo d column               robo alpha column               robo a column                            return zmatrix      here is the implementation of the pseudocode          do                       jacob   jacobimatrix getjacobi currentposition  currentaxisconfiguration               jacobitranspose   jacob gettransposematrix                    deltae    x  x   y  y   z  z   a  a   b  b   c  c                   deltae   position                  getdistancevector currentposition  targetposition                deltathetas   jacobitranspose multiply deltae                                       scale beta                for  var axis      axis   deltathetas rows  axis                     currentaxisconfiguration joints axis     deltathetas m axis                   currentposition   this calculatedirectkinematic currentaxisconfiguration             while  math abs position distance currentposition  targetposition     epsilon    where  and  problems  the transformation matrice should be fine  because it behaves good for the forward kinematic  in my opinion the jacobian matrix must be somehow wrong  i m not sure if it is correct how i put the orientation data in the numerical calculation  for the analytical computation i didn t have any clue what could be wrong  i would be thankful for any advice  an explicit example for calculating the jacobian would also be very helpful   ,inverse-kinematics manipulator
2761,is it possible to record only incoming data with realterm ,i am trying to test a sensor circuit i m working on  essentially  i am using realterm to send commands to the microcontroller and it is returning the value read by the sensor   when logging to a file in realterm  i noticed the commands being sent were showing up as well as the data being returned  i was wondering if anyone knew a way to record only the incoming data using realterm  and not the outgoing commands  any suggestions would be greatly appreciated  unfortunately  there is no way around using realterm specifically because of a company policy   ,serial
2767,nxt segway problem  need advice help,i m attempting to build a segway robot using a gyrosensor and accelerometer  i m having trouble getting the robot to remain standing  for some reason  and i can t identify the problem  here s what i know  the gyroscope api for the lejos nxt platform is here   by using timestamps and angular velocity  the project attempts to infer the angle of the robot   the api suggests that in order to be accurate  it must be polled     times per second  or every   ms on average   the problem is that simply polling the gyrosensor takes  ms  polling the accelerometer takes   ms  the dimensions of the robot  height    cm wheel circumference        cm radius of a wheel  given the circumference      cm the accelerometer is mounted on the top of the robot  at approximately   cm from the ground    cm from axis of rotation  in order to keep the correction amount linear  as opposed to trying to correct an arbitrary angle    i translate the angle of the robot to a distance to travel along the ground to  right  the robot   this might be a bit naive  and i m open to suggestion here   basically it s just the horizontal distance calculated using a right angle triangle with the angle of the robot at the top and hypotenuse of   cm  if that s not clear  it s essentially the horizontal distance from the top of the robot and the bottom of the robot  right now my main concern is the amount of drift the gyroscope seems to be experiencing   given the fact that with the nxt java software package  it s nearly impossible to poll     times per second  the amount of error accumulated by the gyroscope is fairly large  finally  i ve implemented a pid control system   the thing i m not clear about with respect to this system is the integral and derivative of error must be calculated given a set of values   say  the last    error measurements recorded  if the amount of past errors recorded is a variable  and the pid constants are variable  and the speed of the wheels is a variable  it seems this problem begs for some kind of automated optimization   but how to do it   if i set the speed to     rpm  roughly the max of the nxt servos  and take the past    errors for calculating the integral and derivative of the error  will it be possible to optimize the pid constants successfully   or must all   variables be tuned together  thanks ahead for any insight on the problem  ,accelerometer gyroscope nxt
2768,differential drive pid controller,i have a differential drive robot that works fine  good pd parameters  driving at say   m s  now  if it speeds up  to     m s  it starts wobbling again  what would be a good strategy for a controller that is able to cope with the whole speed range of       m s  edit   th of april  the robot is a line follow robot but i do not see how this would be related to my question since a robot following a trajectory would have the same problem   i recently talked to other developers of differential drive robots and they are facing similar issues e g  they told me that they need to adjust pid parameters once the battery is not fully charged hence the robot drives at a different speed  i do not know if you guys are into youtube  but if your are really interested in my robot this link would be helpful   pid parameters are  p       d       i      pid controller programmed using c   ,pid differential-drive
2769,how to turn a rover    degrees using wheel encoders ,i have a four wheel dc rover with two optical wheel encoders   i m executing rover turns by controlling the direction of wheel motion on either side of the rover   to turn left  all wheels on the left rotate backwards while all right wheels rotate forward   this allows to rover to remain relatively in the same position while turning   the directions are reversed to do a right turn    how can i use these two sensors to execute as close to a    degree turn as possible without fusing additional sensor data  ,sensors motion
2771,point tracking from a mobile robot,how can i track a fixed point   from a moving robot  coordinates of  are relative to the state pose of the robot  x axis looks forward the robot and y axis is positive on the right of the robot   suppose that the initial robot state pose is at   the next frame  namely after   with the applied control  the robot is at state   where  i set the axes as opencv        the question is  which are the coordinates  of the same point  relative to    as visible in the picture  i know the transformation from the initial state to the next state of the robot and the coordinate of p in reference to the initial state  t    begin pmatrix  cos  theta  r       sin  theta  r      x  r     sin  theta  r      cos  theta  r      y  r                  end pmatrix   please correct me if i made some mistakes  thank you  any help is appreciated  ,mobile-robot kalman-filter tracks
2772,quadcopter throttle and pid mixing to motor speed,i ve been writing some quad copter software and i am not sure what the best way is to map the throttle and pid inputs to esc power  my throttle range is     and my pid outputs are      my esc s have a range of     us to     us  i have mapped the motor speeds like this   this works but if my quad is perfectly level  i e  the pid outputs are    and i apply full throttle       then map this to esc power i will only get quarter power      us   how should i be doing this so that if my throttle is on max then i get max power  if my throttle is half       then i should get half power plus the pid values etc  can anyone help me with this  thanks joe ,motor quadcopter pid pwm esc
2774,datasheet for taos tcs     gy   ,can someone please post the datasheet for the colour sensor mentioned above  all i can find is for tcs     ,sensors
2781,how to know what motor esc propeller combination will work for a quadcopter ,i am preparing for my first quadcopter build and need to know how to tell what motors esc s propellers will work with each other  i also would like to know how to tell what the motors would be capable of carrying how much thrust they have  i would like to put a camera on this copter  i cannot find anywhere a straight answer to this question  the ones i currently think are the ones i want are  esc   motor   propeller    inch this copter needs to be able to carry a camera   go pro  tldr  how does one match esc s motors propellers  and how to tell if they can get the job done   esc   electronic speed control  ,quadcopter brushless-motor esc multi-rotor
2782,wire gauge for hobby robot question,so  i m making my second ever hobby robot i m     and am planning on soldering my own connectors for the battery  sensors  arduino  etc  it will be a small mobile robot  anyways  i was wondering what a good gauge of stranded hookup wire would be good for that purpose  thanks   ,mobile-robot
2787,position and object data tracking,for a class project  i m working with a weight stack   i m trying to simultaneously measure   the position of a moving weight stack the value of the weight based on a calibrated preloaded position in the stack  not via load sensor   e g  think a stack of plate weights where the sensor knows in advance that   plate     lbs    plates     lbs  etc    the weight stack and the base camp chip sensor laser would be within two feet of the weight stack  so i don t need anything overly strong  my requirement is that it is small unobtrusive and cost effective  i ve looked into a few options  but i m not an engineer so i m not sure if i am on the right track  how would you do this  is there any research that i could check out  ,sensors
2794,crimp or solder to lipo battery ,so  i m planning out my second hobby robot i m      i am planning on using a    v lipo battery and my idea is to solder on a   pin header to connect to the electronics  anyways  should i solder to crimp terminals and then attach it to the pack  or should i solder directly to the battery leads keep in mind i have a decent background in hobby electronics and am just starting with robotics  my soldering skills are also decent  thanks   ,battery
2798,why does irobot not sell the create in europe ,i m trying to find a good beginners platform to use ros with  and i came across the irobot create  to my surprise  they do not sell in europe  why is that  ,mobile-robot ros irobot-create
2800,pid output does not reach setpoint precisely enough,i m developing tuning a software pid for a quadcopter  for now i m only trying to stabilise the pitch angle using the front and back motors  and i m only looking at kp  the motors have a control resolution  input variations need to reach a threeshold to have any effect at all  the process output does reach the setpoint  but not precisely enough for my requirements  there is no steady state error  aka droop   the hunting range is centered on the setpoint  just too wide for my requirements  also the instability is not an oscillation  but more of a random drift which needs to be large enough before the pid attempts to correct it   with a lower kp the output needs to diverge from the setpoint significantly before the error is big enough for the pid to attempt to correct it  with a higher kp the pid oscillates   i could not find a reasonable compromise  i m thinking about applying the cuberoot function  or similar  to the error before feeding it to the pid  that way small errors should be significant enough for the pid to attempt to correct them  and large errors would be reduced and might not trigger oscillations  i suppose someone must have been through this before  is this a good solution  are there any better alternatives  this is not a steady state error  aka droop  or oscillation issue as far as i can tell  please don t suggest using ki or kd edit  i have clarified the problem description and suggested using cuberoot rather than logarithm which was a bad idea indeed  thanks  marc  ,pid
2801,what is the minimum number of rc channels required to control quad copter ,most of the blogs website say we need minimum of four channels  for a quadcopter  pitch  roll  throttle  yaw     one channel for throttle second channel for turning right and left  third channel for pitching forward and backward  fourth one for rolling left and right    but looking at the rc transmitter   i see that at a time you can change a maximum of two sets  data   left and right joy stick     even if you want to send rudder and throttle information at the same   can it not be sent in the same packet   my understanding is  two channels should be sufficient  to control quad copter  please provide more clarity on this  ,quadcopter radio-control
2802,radio control over dozens of kilometers and mountains,i am wondering what technology should i use to transmit data  enough for controlling the robot and receiving video  over dozens of kilometers and mountains   ,radio-control
2807,robot control law   control theory vs optimal control,for a robot  say path planning in particular  what are the pros and cons of choosing classical control theory or optimal control  lqr for example    ,control motion-planning
2812,role of neuromorphic computing and quantum computing in the field of robotics and ai,i asked a similar kind of question some time ago  neuromorphic engineering and robotics  since then  many things have come to the point of revelation  a road map for neuromorphic computing was revealed recently  it proposes the analog way of computation  to solve advanced computer vision problems  ibm and qualcomm are also working on the similar project though on the digital side  memristor technology is slated to come very soon  the question i am asking here is how is the robotics community working to adopt the technology  this question opens the domain for other pressing questions which have been answered cryptically since the     s  are neuromorphic computers good for mission critical precise robots  like that on mars  can we use neuromorphic systems on avionics systems  how is neuromorphic processing going to help us solve the problems on nlp  and knowledge processing  aren t quantum computers very similar to neuromorphic computers in ideology  if neuromorphic robots gain traction  will digital hardware still be required  it would be really nice if someone could explain all points  because answers in various but sparsely related research papers are very cryptic  ,microcontroller computer-vision machine-learning research
2822,robot kit suggestions,i want to develop a toy project that will allow me to move object around the house  because i am interested in the programming of the robot and not actually build it  i would like to use some sort of programmable  starter kits   like lego mindstorm  to get started  while i do not have everything figured out yet  here is a list of specs that i expect my ideal kit should have    the ability to lift object  object as big as     or    centimeters  the ability to distinguish objects by their colors  it should have some stort of color sensors  obviously it should be able to move on a smooth surface  obstacle detection  should have sensors for obstacle detection extra  maybe remotely controllable  can someone please suggests the cheapest kit i should use for this   thanks  ,mobile-robot kit
2826,how much should i expect a kalman filter to converge ,i am learning about kalman filters  and implementing the examples from the paper kalman filter applications   cornell university  i have implemented example    which models a simple water tank  filling at a constant rate  we only measure the tank level  and the kalman filter is supposed to infer the fill rate   according to the model  the fill rate is a constant  so i assumed that over time  the kalman filter would converge more and more accurately  and with less and less noise  on the correct fill rate  however  the amount of noise in the fill rate never seems to reduce after the first few iterations   this graph shows how the fill rate part of the state vector changes over the course of      iterations of the simulation  adjusting the measurement variance matrix seems to have very little effect on the fill rate noise  also  the kalman gain vector and state variance matrix seem to be constant throughout the simulation  i assumed that the state variance would reduce as the filter became more and more confident in its state estimate  questions    is this graph what i should expect to see    should the kalman gain vector and state variance matrix change over time in this situation  ,kalman-filter
2828,click button short vs long button presses arduino,i am using the clickbutton library from arduous and am having some problems implementing it  as it stand now the code just runs the servo clockwise and i m not sure what i did wrong  basically i want the servo if pressed for a short period of time to move according to an exponential function  and if pressed according to a long period of time to move at a regular pace   ,arduino
2829,differential drive robot on uneven surfaces,so i am building a differential drive robot and i want it to autonomously drive in a straight line on an uneven surface  i know i need a position and velocity pid  as of now  i am deciding on which sensors to buy  should i use optical encoders  accelerometers  or something else  i wanted to go with accelerometers due to the error encoders would face due to slippage  but i am not sure  some enlightenment would help  ,sensors control pid differential-drive
2832,servos power supply in quadruped robot,i m facing a problem while building my quadruped robot which is figuring out the efficient power supply needed for the    servos  i m using    mg    tower pro servos powered by   lithium batteries  x   v  about   volts  with      ma   i really don t know if that enough for the servos or something else is needed to be added i hardly fitted the   batteries into the robot s body   any suggestions please  ,power battery servomotor walking-robot
2834,dead reckoning on a car like robot with a gyro and only one encoder,recently i began to build a car like robot and i stumbled upon dead reckoning  i use one motor for steering and one for traction  i want to be able to get the position of the robot  from what i have read   encoders should be used  but i am curious if you can use only one encoder on the motor shaft to get distance  and a gyro   accelerometer to get the orientation of the robot  ,mobile-robot motor gyroscope encoding
2837,what kind of motor control can i implement if i cannot use an encoder ,every time i see a pid control for a motor  it involves an encoder  so the algorithm knows the real position of the motor or wheel  but with the robot i have  i cannot use an encoder  i only have one optocoupler per wheel which can count how many degrees the wheel has moved  i can use it to increment a counter  but the counter always increment  if the wheel moves forward or if the wheel moves backward   the first moment i saw it as an inconvenient was when i studied the arduino pid autotune library  in the first figure  i would not see decrements on the input   my objective is to move a little two wheels robot small segments driven by simple trajectories separated over time by a complete stop  straight    cm  stop  move right    degrees  stop  straight until detect obstacle     could you suggest me some kind of ideas  the first idea i have is to transform the pid position control to a speed control  which is more convenient for the feedback loop i have  and keep a counter of the traveled distance to inform the speed control when to stop  ,arduino motor control pid
2841,what approaches should i consider to create rotating a turret,first a bit of background  i am planning to make a highly maneuverable airship controlled by four thrust vectored propellers  i don t want to rely on a rudder and forward momentum for turns but instead be able to maneuver with direct prop thrust  i want to be able to point each prop anywhere within a half sphere dome  so two axis      degrees traversal for the forward back up down and     degrees for the left right  the nearest thing i can think of is a ball turret similar to this ball turret but instead of a gun  have a motor and propeller  the turret can rotate infinitely through     degrees  but the gun rotates through    degrees  my first thought was for a servo for both axis  but they are limited in range and i would like the     axis to be able to rotate continuously  this would allow for the turret to rotate to the desired angle using the shortest path   my question is  what do i need to be able to rotate the turret and still know what angles the turret is currently pointing  ,sensors servos
2847,accelerometer  gyro  and magnetometer sensor fusion in  d,i have not yet build this so this is basically a theoretical question  i am still wrestling with some c code to manage i c communication etc   when i originally said  i have not build this  i meant that the robot is in what could be called a  design phase   for the sake of my question lets assume for a moment that the whole robot consists of just one imu sensor  it moves magically  no motors that create a lot of noise in the sensor measurements   with theoretical i mean i am interested in the mathematics and algorithms involved in solving this problem  what i call imu sensor provides raw accelerometer  gyro  and magnetometer measurements  lets say our tiny robot travels on a snooker table       mm x      mm   i believe this is sufficiently small to call it  d  now  sensor fusion should be much easier  faster  consume less resources  than in  d  right   i would like to measure the velocity and if possible the position   with velocity i mean at a given point of time i need to know the current velocity of the robot moving over the snooker table  velocity is in the range of       m s  with position i mean at a given point of time i need to know the current position of the robot on the snooker table  x  y  heading   i hope this will be possible since the robot should be able to identify some landmarks and use this information to reduce position errors  when i originally said  i hope this will be possible  i meant to express that i already am aware of the fact that real sensor data is noisy and errors accumulate quickly  using landmarks i will   or will not be able to manage to reduce the error in the position estimates  but this is not part of my question  i am about to improve my linear algebra knowledge  so i am confident to manage some matrix multiplications  inversions and such  my question is for some ideas  references on measuring velocity and position in  d using an imu sensor like this one   a little side question  i just figured that this question is probably too theoretical for robotics se  if you know any forum that is more focused on mathematical   algorithmic side of robotics please let me know  ,localization imu sensor-fusion
2848,ctl port in a motor controller,when i look at my    a motor controller  it has a port that is called  ctl   what does ctl stand for  is that a sort of protocol like rs     ,motor
2849,our quadcopter goes forward instead of hovering in place  how to correct it ,i m trying to do a quadcopter with some friends and we have a problem  it goes forward instead of hovering in place  we made a video to explain it  you can see it here  as you can see  the quadcopter flight and go forward when i don t touch the controller  i need to correct it to go backward and it goes forward again  we use the kk         the hobbyking kk      multi rotor controller is a flight control board for multi rotor aircraft  tricopters  quadcopters  hexcopters etc   its purpose is to stabilize the aircraft during flight  to do this it takes the signal from the     mpu gyro acc  roll  pitch and yaw  then passes the signal to the atmega   pa ic  the atmega   pa ic unit then processes these signals according the users selected firmware and passes control signals to the installed electronic speed controllers  escs   these signals instruct the escs to make fine adjustments to the motors rotational speed which in turn stabilizes your multi rotor craft   we made some test  as you can see in the video  we placed the battery backward to be sure there is no weight against  when we check values in the debug mode  all values are at   when nothing is pressed  ,quadcopter uav multi-rotor
2850,need specifications to operate this stepper motor with rpi or arduino,here is the disassembled stepper motor that i m working with  contains the photo of the motor  and the label that s on the bottom of the motor    i need to identify this stepper motor that was retrieved from scrap for a project  budget constraints force us to use the scrap motor  i tried to drive this using a l    h bridge  but i couldn t find the right bit sequences to get this running smoothly  i also tried to search for a specifications sheet in the internet with the label  unsuccessfully  i m using either an rpi or arduino board to run this  i just need a pin diagram and the specifications of the motor  if you guys have seen this type before  ,arduino raspberry-pi stepper-motor
2852,how to get prevent twisting of cables,i am planning to create a motor turret described in this question  but to simplify the problem  i m thinking of a wind turbine with a generator in the main head that can rotate freely through     degrees to face the wind  how would i prevent the power and sensor wires coming from the head and down the shaft from twisting   ,sensors wiring
2854,create set of drones to fly in patterns,how would one go about making a number of drones fly in a preset pattern or formation  for example have them rotating around a point  something like this   ,quadcopter
2860,how long can a vex pneumatic arm be ,how long can a vex pneumatic piston be  ,robotic-arm arm
2865,simplest way to do object tracking with a  d range finder sensor ,my current class assignment is to program a robot through a course that includes two moving obstacles   other robots moving at constant speed around a region the one robot must get to  since the other robots are moving at a constant pace alongside a predictable path  my robot can just stop at the border of the region  wait until the others pass by and then proceed  the robot can use a  d laser range scanner to sense its surroundings  given these restrictions  what is the simplest object tracking algorithm i could use  i am thinking of something along these lines   collect two laser readings   d point clouds   and b with a suitable time gap between them  apply dbscan to a and b  producing the cluster lists a  and b    generate a list p of pair wise matches of the clusters in a  and b   maybe using the hungarian algorithm  discard from p any pairings whose difference falls within a threshold  calculate direction and magnitude of movements from the distance between the centers of mass of each cluster pair   the reason for choosing dbscan and the hungarian algorithm is that i already have both implemented and in use elsewhere  and the difference between clusters could be measured as the distance between their centers of mass  do you think this solution would work for my problem  do you have any suggestions on better and or simpler ways to solve it  ,mobile-robot sensors algorithm rangefinder
2868,differential drive robot control,edited  i have a differential drive robot that needs to drive down a hall and stay in the center  i have   ultra sonic sensors    on each side  currently  i thought of implementing pure pursuit and having a lookahead distance etc  but i am not sure if this is the correct approach  i have all the lower level pids for motor control working  i just need some help in choosing a path planning algorithm  will pure pursuit work to my needs  or do people have any suggestions  ,control pid differential-drive
2870,find the right actuator to control the flow of flour,i m building a circuit to control the flow of flour  the basic idea is to open that actuator  possibly valve   to let a specific amount go through and then close it  the tube should have a diameter of  cm max  i wonder what is the right actuator to use  maybe a valve is the right one  any other solution  also  it would be great if you pointed out some suitable actuators that i can buy online  ,actuator
2871,slam without data association ,i would like to build  d ekf slam in opengl  i ve implemented the entire virtual environment in which there is a robot that moves in  d and there are some landmarks feature based map   i have the motion and observation models  also  i ve implemented the sensors with gaussian noise  now  i would like to use mrpt to build slam  at this point  i don t want to use data association that is the robot moves and detects its pose and landmarks and discard the previous data which means i only concern with the current state vector  my question is is it possible to build slam without data association  please suggest me some articles so that i can enrich my background about only this issue   ,slam ekf
2873,how to calibrate differential drive ,i m building a robot with differential drive  i ve reached the point when i can drive it around on remote control and i m trying to get the localization working  now i would like to exactly measure parameters of the robot  model of the robot i m using has two wheels spaced  meters  each wheel has a distance per encoder tick  and  and variance standard deviation of the driven distance  and   when moving  distances are random variables from the following distributions   and   later this model might expand a little bit  what is a good way to measure the parameters  i found a way to measure    and   added that as an answer   but i have no idea how to measure the standard deviations  the model will be used as a prediction input in mcl  so i don t need covariance matrix for localization  ,localization calibration differential-drive
2875,connect sensors to beaglebone arduino in a complex robot,i m building the biggest robot i ve ever done  the hardware i have so far is as follows   hcr platform from dfrobot as a base x    v    rpm dc motor with two phase hall encoder x  sharp  y a   ir sensors x  urm   ultrasonic sensor x  ir ground sensor microsoft kinect  right now i m only using a romeo board  arduino     compatible  to drive the motors and process the pids for the wheels   steering and also access to all the sensors  except for the kinect   i have a beaglebone black running linux that is intended to be the main brain connected to the romeo using the rs    port and do the processing of the kinect   wifi access  i started thinking about connecting the sensors to the beagle board directly so i don t need to waste time sending commands to the arduino board to read the sensors and that yielded the first issue  beagle board works on    v instead of  v used on the sensors   after this i thought to create a board with voltage divisors to connect the sensors there and then using a ribbon cable to connect this new board to the beaglebone  i couldn t find any  x   idc male connector to create the  interface cable  between the two boards so the beaglebone option is out as i don t want to have tons of jumper cables all over the place  this morning i thought about all this again and i researched about gpio boards over usb and found three from numato  only one works on ttl  v and has   pins so i would need a few of them to use all the sensors so unless i design my own board this option is out too  at this point i m quite confused in terms of what s the best hardware i could use to drive this beast  right now i think i should use a intel nuc with linux for the kinect  wifi and usb link to a custom made sensor board  this custom made board will work on ttl  v  provide a power bus for the sensors and will interface all the  low level  sensors using usb as link  i also thought about an fpga for the custom board but i m not sure if this would help me or if it s worth the effort of learning how to use it  what are your thoughts on this  any idea on how this issues are solved on  complex  robots  ,arduino mobile-robot sensors computer-vision beagle-bone
2876,why linkage based haptic devices are much more common than cable  tension  based ones ,according not only to this link  but in my humble opinion to common sense as well  cable based haptic devices have got lower inertia and are less complicated mechanically  i also believe that controlling them is not that big deal   the inverse kinematics should be quite straightforward  moreover  the play should be easy to compensate   if there occurs any at all  since the cables are tensioned  cables should also be easy     just a guess from me   to be equipped with strain gauges or to become strain gauges themselves  allowing to enhance control capabilities of a device  where am i wrong  why is that the links based systems  e g  phantom or falcon  although that latter has got cable transmission   especially with impedance control  are the only i seem to be able to buy  is it because of cable elongation  creep   or too constrained workspace  esp  angles   ,sensors mechanism
2879,what to use as electrovalve ,i want do make following installation  blowing bottle tops as music instrument    and i want to use and rc servo as electro valve  throttle  to control air flow for each bottle  is there any other way to do that  ,rcservo mechanism valve
2882,how do i add an external library to the rock framework ,the rock framework already includes a lot of software libraries  however  i would like to add an existing external library so that i can use it for my component development  what is the preferred way of doing that  ,software rock
2885,can you identify the construction material system used in the pic ,what s the name of the  big meccano  used in the photo below to construct all the cabinets and racks  it appears to be an aluminium cut to length system of   way rails  i ve seen it used many times and assume it has a well known brand name to those that know   photo taken from theverge com and was a feature about how audi are building a new car  ,frame
2889,static equilibrium for   dof manipulator,i have a   dof manipulator  kuka lbr    and would like to calculate the joint torques needed to keep the arm in a static equilibrium  in most books the transposed jacobian is used to map the forces applying on the end effector to the joint torques   that however doesn t take the mass of the links into account  is there a way to calculate the needed torques for a given configuration so that  assuming an ideal case  by setting these torques the arm will be in a static equilibrium  cheers edit  for everybody interested  i found a solution to this problem in introduction to robotics   third edition by john j  craig on page          it is done with the aid of the iterative newton euler dynamics algorithm  the actual trick is  to set all velocities and accelerations to zero except for the base acceleration  the base acceleration will be   where g has the magnitude of the gravity vector but points in opposite direction  this is equivalent to saying that the base of the robot is accelerating upwards with   g and this upward acceleration causes exactly the same effect on the link as gravity would  ,torque manipulator
2890,filling   ml bottles with food grade liquid,a project has been given to me at work  with no schematics or idea of where it was going   i need to fill     ml bottles at a time with a food grade liquid  based on the parts i have  i think the design was going to use a air agitated pressure pot tank which is used for spraying paint  which would work if we weren t using food grade liquid  so right off the bat i cant use that  the main parts that i can use are an allen bradley micrologix plc    pneumatic cylinders  a couple solenoids  start and stop buttons   my question is  to fill a   ml bottle with this liquid  would a positive displacement pump with a vfd be the best way of slowing the pdp down enough to fill the     ml bottle at a time  i do have a little experience with this particular plc so the ladder logic is not the issue  its the figuring out the specs for the pump and the motor   any input would be very helpful also any links would be great  at this point im trying to determine if this is a huge waste of time and money or should i just go buy a filling machine for               ,electronics
2891,outputting a precise voltage in millivolts on arduino mega,so i need to output a varying voltage off an arduino mega in a range of    to    millivolts  which i ve attempted to do by sending a pwm signal off the board into a low pass filter which steps down the voltage  this works  but the problem is that arduino s analogwrite function accepts a value of         to represent the duty cycle of the pwm which isn t precise enough  a value of   yields around    millivolts and a value of   yields around    millivolts  is there some way to have a duty cycle that is more precise than the         range like           i think even this isn t really precise enough   or is there a better way to get precise voltage output  the mega is running on and outputting a max voltage of   volts  and the low pass filter contains an    kiloohm resistor and a   microfarad capacitor  ,arduino pwm
2894,what are some good cheap  silent  motors for mannequin robots and what kind of controller should i use ,what are some good cheap  silent  motors for mannequin robots and what kind of controller should i use  i m creating mannequin robots that require    motors    neck    shoulder    elbow    wrist    waist    hip    knee and   ankle motors  the mannequins will be bolted via a horizontal post from the lower back to a wall  this means they can run  dance  and pose  i may also do something with the horizontal beam so the robots can do side flips  and moves like the twist  jumps and crouches  they will not stand up  but be bolted as i ve described to a wall  they could even spin around completely to face the wall  i ve tried using  v hobby servos for the joins  these are too weak for lifting fibreglass mannequin body parts  they are too loud  they also make noise when poses are held  and they drop and smash when power is shut off  i have been using a handheld remote control for testing with only   channels  the robot must be programmable though  lets say the objective is to make a mannequin dance to  thriller  like michael jackson   i am open to using kinnect technology as the controller  so that a dancer can simply dance in front of my robot  who can copy and remember  but i m also open to controllers that allow me to force the mannequin into a pose at specific time codes in the song  if necessary  i am also willing to program the poses using some kind of lighting desk type controller  such as tech crews use in rock concerts to sync everything to go with the music   i have noticed that a power drill or winch is very loud whereas my fan is very quiet  i live in an apartment in which neighbours can hear footsteps from other apartments  i would not dare turn on a drill at  am because it would wake up everyone in the whole building  but i would have no guilt in turning on a fan  i need my robot to be as quiet as a fan  the voltage does not really matter for this project  i m happy to use up to    v from the wall socket  please let me know which motors and controllers are best for my mannequin robots  taking cost into account  thanks so much for any help     ,microcontroller robotic-arm motion humanoid
2897,how to read data from i c using i cget ,i m new to embedded devices and am trying to understand how to use i cget  or the entire i c protocol really   i m using an accelerometer mma      and the datasheet says the slave address is  x d  if my sao    which i believe is referring to the i c bus being on channel   on my raspberrypi v    from the command line  i enter  it returns  x    i think that means i m attached to the correct device  so now  i m trying to figure out how do i get actual data back from the accelerometer  the i c spec says i cget   y  i cbus chip address  data address  mode    so i have tried sudo i cget  y    x d  x    where  x   is the out x msb  i m not sure entirely what i m expecting to get back  but i figured if i saw some data other than  x    i might be able to figure that out  am i using ic get wrong  is there a better way to learn and get data from i c  the datasheet for my accelerometer chip is at  ,raspberry-pi i2c
2899,salvaging a bunch of laptop battery packs,i m working on my first robot project  i previously used a   v  ah sealed lead acid battery  but recently i aquired some    asus li ion battery packs  each of them     v and either      mah or      mah  the laptops have been discarded  and some of the battery packs seem to be dead  the battery packs have an   pin connector  inside  i assume there s a bunch of       cells and some electronics  my robot can handle      v directly  how can i use these batteries  how can i charge them without the laptops  i m a little put off by the idea of taking the       cells out of the packs and rebuilding my own battery pack and charging system  but if that s what s needed i have to do it  the packs are marked asus a   a  for the      mah ones  and asus a   a  for the      mah ones  ,battery
2902,solutions for finding position and heading in a multi level house,i was wondering if you could reccomend possible solutions for locating a robot within a multilevel house   what seems obvious to me is that need an altitude sensor to derive the story the robot  and a compass sensor to derive the heading   however i was wondering what i could use to locate the robots xy position in the house   if this requirement is unclear  imagine that i have to map a dot representing my robot position to an image of the current floor from the top  my original idea was to use gps  however as i need submeter accuracy that would be incredibly expensive   i also considered monti carlo localization  however that requires no obstruction between sonar sensors and walls   it is also a significant task programically   i had an idea to place   wireless beacons of some sort on the vertexes of an equilateral triangle surrounding the house  then triangulate my position using distance from each beacon   however  i have no idea how i would go about this hardware wise   do any of these ideas seem viable  and if so do you have suggestions on how to implement them  otherwise  can you reccomend an easier or cheaper alternative   my platform is essentially an arduino hooked up to sensors and motor drivers connected to java on a laptop over serial   thanks  ,arduino sensors localization gps
2904,using pic as webserver ,i want to show information about temperature over the internet using a sensor and pic  how can i do using pic   is there any way for the pic   f   a or   f to do it  does anyone hame some literature about it  schematics  ,microcontroller
2905,grasshopper effect on a quadcopter with kk     ,we have builded a quadcopter that use the flight manager kk      with the latest firmware  when we increase the throttle  it flight  when we keep the hand on the stick we are able to maintain it but when we don t touch to the throttle  it goes up and down  you can see an example on this video  we have tried different values for pid but we don t know what is the best for us  we have a large quadcopter with medium propellers  may be too small    does the weight of the quadpcoter or the width of the propellers can be a factor  what can be the problem  ,quadcopter multi-rotor
2908,simon k firmware when the imu outputs at   hz,i am building a quadcopter using the sparkfun razor imu which outputs the roll  pitch and yaw axes values at    hz  which limits the operations of the controller implemented on arduino imu   to    hz mx itslef  please tell me if flashing the escs emax   a  with the simon k firmware can do me any good   i ll be grateful     ,arduino quadcopter imu
2915,effect of adding a pole and zero to pid,i am confused about how adding a d  which adds a zero to the complete system  decreases the speed of the system  but when we normally add a zero to the system  it causes the system to overshoot  the same goes for the i part of the pid  normally when we add a pole to the system  it has less overshoot  but at the same time the integrator increases the overshoot  how can i make sense out of this inverse relation  ,control pid
2918,suggestions for stepper motor controllers,i am working on a project where a dslr camera will be rotated on a tripod on   axes  i m definitely using nema    motors as those are what i have  the motors will rotate    degrees every   seconds in normal usage so speed is not a requirement  the weight of the camera is     g and i m using  d printed parts for the remainder of the mount  i tried running nema    stepper motors off a adafruit motor shield v  but the whole thing overheats  battery  driver  and motor   by the way  the motor will be controlled by an arduino  i need to find another motor controller to use  i looked on ebay and things like this came up for    dollars which seems too good to be true   my question is what motor driver should i use for this project as i have little experience with them outside of arduino shields  ,arduino motor cameras stepper-driver
2919,how do i use the nicolas ziegel approach if my system never becomes unstable ,how do i use the nicolas ziegel approach when the root locus plot of my system never becomes marginally stable   for any gain  unless it is negative       how do i estimate my ultimate gain value     ,control pid
2920,understanding the pid controller,i am trying to understand the effects of p  i and d constants in a pid controller on a system  as far i ve understood  p and i make the system  faster   and d makes it  slower  which i read in books   but i don t actually understand what makes it go  fast  or  slow   how an integrator causes overshoot and all things like that  it makes sense that the p part causes overshoot  since it adds a gain  but what is the integrator doing  i want some kind of mathematical understanding on how all these parameters affect the system  i know how they work individually  but i m having a hard time understanding  how it affects the system as a whole  for example  how does a zero added to the system lead to decrease in overshoot  but when normally adding a zero to a system would create more overshoot  ,pid
2921,controlling digital servos,many websites say that analog servo motors work on   hz and digital servo motors work on    hz  my question is  does this difference apply only to the inner control loop of the servo or does the user of the digital servo actually provide    hz pwm signal  to rephrase  are all  most  servos including digital ones controlled with   hz pwm  or are digital ones specifically controlled with    hz pwm  thanks ,rcservo pwm servomotor
2925,why does a id controller not exist ,why doesn t a pid only consisting of id exist  ,control pid
2930,is it important to have good pi settings when we running in self level with kk  ,i have a kk      and i fly with the self level on  in the kk   there are two menus  one to set pi settings and another with selflevel settings  both enable to set p gain and i gain  is it important to have good pi settings when the self level is on  or is setting good values in selflevel settings sufficient  ,multi-rotor
2931,quad copter attitude control,i have built a quad copter completely from scratch  electronics  mechanics and software    i am now at the point where all my sensor data looks correct and when i tilt the quad copter the correct motors increase and decrease  i have been trying to tune the pids for a couple of days now  in rate mode it stays level and rotates at roughly the correct degrees per second when i give it a command  in stability mode a lot of the time it just spins around the axis and when i did get it stable it kept rotating from upright to upside down and then maintaining an upside down flat position  i have come to the conclusion that i am either doing something completely wrong or i have some     signs mixed around somewhere  would anyone who is knowledgeable about quad copter control code be able to take a look at what i have done and how it works as i m really struggling to work out what needs to change and what i should try next  my flight control code is posted below  the other relevant classes are hardware h and main cpp  the whole program can be seen on my mbed page at  if you need any more info or something explaining let me know  if anyone can point me in the right direction or has any idea of what i should try next it would be very much appreciated  thanks joe ,quadcopter pid imu
2933,does roborio support java   ,my frc team will recently upgrade from  compactrio  to roborio  compactrio only supports up to java      what version of java does roborio  ,microcontroller
2935,how pid affect the root locus of a close loop transfer function,i am trying to understand how a pid controller moves the poles and zeros of an transfer function   i ve been playing a bit with it  but aren t able to see some kind of connection   i mean that p and i rises the overshoot which would mean that the damping ratio gets smaller  thereby should  away from the real axis   and d should should do the opposite  but it doesn t seem to be true with the examples i ve used   am i doing something wrong   well i kind of just want a general knowlegde of how it affect second order systems   ,control
2936,best strategy for area scanning using little sensing bots,i m currently working on a school project about simulating robots scanning an area  but it has been a struggle to find what strategy the robots should use   here are the details  i am given a certain amount of robots  each with a sensing range of    they spawn one after another   their task to scan a rectangular area   they can only communicate with each other when they are within communication range   i am looking for the best strategy   i e  time efficient solution  for this   any reply or clue to the strategy will be appreciated   ,mobile-robot sensors coverage
2937,how does poles and zeroes affect the step response of an transfer function ,i have this close loop transfer function   it overshoots  but why  the poles are placed such that that the damping      so why the overshoot  ,control
2939,what does this  inverse  peak mean   step function ,i identified my system and now i am trying to tune pi regulator since i think i do not need d  i came across this graph while matlabing and i do not know what does it mean  i am using pidtune   to get my p and i values   i think computation is all correct  i made model in simulink to confirm   anyway see my picture and arrow is pointing at what i do not understand  why is my system going below zero first  it is supposed to be water flow regulator   transfer function    frac       s            s            s              continuous time pi controller in parallel form  k p   k i    frac    s  with    ,pid
2940,lqr design with low effort,i am trying to implement a controller for an inverted pendulum using lqr  with matlab command lqr a b q r    the problem is that the motors are relatively weak  so i tried to increase r  but simulations show that the effort is still very high  how can i reduce the effort  ,control design
2945,how does a robot efficiently store a map it makes ,from what i understand  you can create a map using sensors and storing values in an array   for example  the array can have   s for places not visited  and   s for places visited  or   s for open spaces and   s for occupied spaces  etc    the map i m thinking of making will have about      x      members   this means i need an array of   million members   that seems like a lot   if i have eight attributes about each member  like temperature  light level  sound level  etc    then i have    million pieces of information to capture    is this correct  or is there a better way to create a map for a robot using software  ,software mapping
2948,pid tuning method based on pole placement,is it possible to determine pid parameter using pole placement   i mean by solving the ch  eq  of close loop transfer functions  which consists of either p pi pd or pid controllers   because i ve tried it  an eventhough i am getting my poles at the locations i want the systems does not act as i assumed  an example  i want my system to be overdamped and to have settling time less than   sec  which means that i want my poles to lie on the real axis  and to be less than      g s    frac       s           s             s                   with p        i            d              i get a close loop system which is  g cl s      frac        s           s          s            s           s           s           s           s  but looking at it s step response i see it creates overshoot  which i cannot justify due to an step input    ,control pid tuning
2949,actuation of three reciprocating blades via conversion of rotary to linear,sorry if this is out of robotics  but this seemed the closest  a motor has to be used to rotate three cranks  they are in the same plane  but each should not run at the same time  only one that occupies a central position  corresponding to the motor  should rotate  the discs are mounted in rectangular frame that can be slid to bring the required disc to the central position  can anyone suggest a method to achieve this   basically coupling and uncoupling the motor shaft from whatever disc is in the centre   ,motor mechanism
2961,mckibben artificial muscles and the       ratio,i was recently reading that those artificial muscles had the highest power weight ratio while electric motors only have a ratio of less than        as electrical engineer i have never worked with pneumatics before and do not have a big idea about air pumps  my question is  how much will this ratio change if we consider an autonomous system   on one side  the mckibben actuators   air pumps and valves   energy source   and on the other side  electric motors   energy source  as an example  let suppose that somebody found a way to model and control the artificial muscles as good as the electric motors and make two autonomous walking leg models  which one would have a higher resulting power weight ratio   ,control power actuator torque battery
2963,how do i learn about arduino raspberry pi based robotics on my own ,i am interested in learning how to build a dynamic quadcopter  and hope to be fairly proficient with arduino raspberry pi  what resources and or practices might you recommend   ,arduino raspberry-pi beginner
2964,quadcopter pid output,i m trying to develop a control system to a quadcopter and one of my options is to use a pid controller  which i think is the most used method   from what i ve read  the commom strategy is to run a pid algorithm to each axis  my question is  how the pid output is converted to pwm signals  i m asking that because the three axes and the four rotors depend on each other  i mean  if i slow down a couple of rotors which are opposite to each other then the quadcopter will move down in a vertical axis  but if i speed one of them and slow down the other  the quadcopter will rotate in a different axis  so we cannot isolate each axis and associate them with a single rotor or a pair of those  and because of that  how can a pid output  which is associated to an axis  can be converted to pwm signals to the rotors  is that a mimo system  ,quadcopter pid
2966,what parts do i need for a strong robotic arm , i have found this robotic arm on the internet  and i was wondering if someone can tell me what parts i need to build it or similar  the video says it can lift a small cat  i need to be able to program it  so i ll need a controller  please recommend specific motor  controller links that you recommend  thanks    ,robotic-arm
2968,proper tuning method of an cascade controller ,would a control system consisting of   pid controller one plant  would be considered as an cascade controller   and how come would a proper tuning method be  as far i ve googled it seems to me that only best method is to manually do it  one by one   this is how my system looks like   ,control
2970,how can i dynamically control the amount of torque necessary to rotate something for a test rig ,i m looking to build a test rig for a robot that rotates a    diameter pipe       roll not yaw or pitch   i am currently testing a motor s performance when subjected to various kinds of pwm  high duty cycle  low duty cycle  etc   i would like to characterize how this performs under various loads  is there a simple mechanical mechanism i can attach to a fixture and insert into or around the pipe that lets me control how easy or difficult it is to rotate   i am thinking of something like a drill bit chuck that fits inside the pipe and expands or a circular clutch that clamps down around pipe to add resistance when one tightens a thumbscrew  i would like to go from no resistance to full stop for a  n m motor  i would like to be able to test how  sticky  the pipe is using a torque wrench  i imagine this would be very simple but i can t think of something that would do this  ,motor torque
2972,transfer function of dc motor being unstable due to a controller ,i am having a hard time grasping the concept of a dc motor  with load being unstable  and stable due to a controller  my confusions appears as i am trying to design a controller for one using z n method  and the transfer function i ve identified using matlab tells me that my dc motor always will be stable   which makes sense  since feeding it constant voltages  will lead to a constant veloicty   but to use the z n approach the system has be able to become unstable  and since this isn t possible i am getting confused if a motor are able to become motor for which i am to design a controller for   the question in simplicity   how come can a controller make a motor   if the motor itself cannot  due to pole zero plot   unstable    ,motor control
2976,selecting precise high torque motor and motor controller for use with arduino mega      r ,my current project calls for   motors     mechanical watts   and an assortment of sensors   i selected the arduino mega      r  to use as the basis for the project   i am having trouble determining the best motors and motor controllers for the project  the motors need to be very precise and very controllable  meaning i need to make very small changes to the speed of the motor several times a second   the motors will follow a position vs  time curve   i broke up the position vs time graph into     hundred sections   i found the acceleration degrees per second    of each section  and i want to put it in to the array and format it as such   float arr      position    acceleration between position   and    position    acceleration between position   and    position    etc     here is an idea of how i plan to program the motor   i am planning to run the motors in a pid loop so it will not be as cut and dry as the loop above    i saw the spark fun autodriver stepper motor controller  i thought the accompanying library would save me a lot of work  i very quickly noticed that it had some major limitations   first it did not allow me to very the acceleration while the motor was running  for example  if i call               kneemotordriver run fwd          i have to call softstop   or hardstop   otherwise the autodriver will keep telling me its busy  my interpretation  please correct me if i am wrong  is i cannot change any of the drive commands  i e   i cannot vary the acceleration   the autodriver does have other functions but they require a target step  i do not want to give a target step because i don t want to be limited by the steps      degrees on the stepper i have  i may want to stop at      degrees  but with the auto driver i cannot    the auto driver is also limited by its  a per phase current limit  just to summarize  i need a mega to control   motors with a minimum output of    mechanical watts  i need very precise control  i am planning on using a potentiometer or rotary encoder   the motors will run in a pid loop with several sensors   i need to be able to vary the speed several times a second  all   motors will be executing different motions and they need to be able to run very consistent over time   i e  when motor   is at   degrees motor   must be at    degrees  i am still open to the idea of a stepper motor i can live with having to stop on a step but i would really prefer not too  any and all help would be greatly appreciated  thanks  joel  ,motor
2980,definition of  or determine whether something is  a robust controller ,i am bit uncertain how i should interpret the definition of an robust controller   as far i ve understood  the closed loop system including the controller has to have a high gain for frequencies where disturbance appears  and decay at frequencies higher than the work area  or noise   both of these can be determined using a bode plot  thereby determining the robustness of my closed loop system   ,control
2981,acrylic plastic cutting services,i want to cut acrylic pieces that will be assembled into the body of a robot  what are some recommendations for acrylic plastic cutting services  does laser cutting produce the best results  ,manufacturing
2982,performance memory considerations for pathfinding lookup tables on robotc for a small set of paths,i m writing a c code generator geared toward robotc and complex tasks for an ftc team  and was wondering about some performance and storage concerns   how much memory is available for my program s data  it ll be mostly pre defined lookup tables  generally in the form of multidimensional arrays  how much nxt memory is available for my program itself  as in  roughly how much code can i expect to fit into a single robotc compiled program  how quickly do programs execute  generally  looking at disassembly most of my generated lines correspond to     opcodes   based on these  i m trying to make a decision of precomputation vs runtime pathfinding  i m using nxt tetrix  my major interest at this point with these questions is for pathfinding  i plan to have a   x   grid and be running djisktra s a  algorithm with a heuristic function that assigns a penalty to turns and is as close to consistent as possible  not sure if consistency monotonicity is doable with the turn penalty   roughly   paths would be cached if i decide to use the pre cached lookup tables  instead of a set  i ll probably use a boolean array for the set of nodes visited  the fact that i m working with a square layout will allow me to use a  d array for the map needed to reconstruct the path  i d love some feedback and answers to my question if anyone has any  thanks  ,nxt robotc
2983,securing a disc wheel to a shaft,i am in a situation where i need to secure a     wheel made of      thick mdf  of my own making  onto a        precision ground steel shaft  and this joint needs to be strong enough to convey a rather large amount of torque  about         in lbs  effectively a  hp motor driving the shaft at         rpm  i don t have a milling machine or any metalworking tools  so my preferred option of  milling flats onto the shaft  is out  my second option was to attempt to increase the surface area of the wheel s bore and then use an appropriate adhesive such as jb weld  is jb weld a suitable solution to this problem or is there a better method of fastening that doesn t involve modifying the steel shaft at all  ,wheel
2987,can i reuse the hall sensors in a brushless motor as an encoder ,i have upgraded the motors in my robotic arm to sensored  brushless rc car motors  the hope was to reuse the hall sensors to double as a rotary encoder  by tapping   hall sensors and treating the   bits as a quadrature signal  a crude quadrature since   of the   states will be longer than the other     this works when none of the motor phases are powered and i just rotate the motor manually  but once the stator coils are energized  the encoder no longer counts correctly  when running at low power  the counting is correct  but when running under high power  the count is monotonic  only increases or decreases  no matter if i run in reverse or forward  i m almost certain this is because of the stator coils overpowering the permanent magnets on the rotors  so is there still a way to use the hall sensors as an encoder  sorry if this is an obvious question  i d love to research this problem more if i had more time  update  i ve measured the wave forms with my dso quad and see the expected     degree separated signals  the measurement for phase c gets more inaccurate over time because i only had   probes  so i measured phases a   b first  then a   c  and then merged them  when esc speed is       when esc speed is       previously  i was using a hardware quadrature counter  eqep module on a beaglebone   at speed      this was counting backwards no matter if i do forward or reverse  i then implemented quadrature counting on an lpc    fn   ucontroller  the result was still bad at high speeds  count didn t change at all   the logic was   then i got the idea to change the code to not update prevstate until an expected state happens  to deal with glitches     int state   phasea    phaseb        if  prevstate                if  allowabletransitions prevstate        state                 rotations         prevstate   state            else if  allowabletransitions prevstate        state                rotations        prevstate   state            else                  assume transition was a glitch             else     prevstate   state   now the counting finally is correct in both directions  even at speeds higher than      but are there really glitches causing this  i don t see any in the waveforms  ,brushless-motor encoding hall-sensor
2988,voice control solution for linux robot ,i wanted to present a voice controlled robot in my lab s upcoming demo contest  my robot is essentially a x   ubuntu notebook resting on top of a two wheeled platform  so in principle any solution available on linux would do  i looked into julius  but it seems the only comprehensive acoustic model available for it is aimed at the japanese language   which coincidentally i can speak a little  but apparently not clearly enough to produce anything beyond garbled text  i also tried the google speech api  which has a decent selection of languages and worked very well  but requires internet access  finally there is cmu sphinx  which i haven t yet tested  but i m afraid might have a problem with my accent  i m a nativa brazilian portuguese speaker  and apparently there is no such acoustic model available for it   is that all there is to it  have i missed any additional options  as you may have guessed  my main requirement is support for my native language  brazilian portuguese   or failing that  good performance for english spoken with foreign accents  a c   api is highly desirable  but i can do with a shell interface  ,mobile-robot linux speech-processing digital-audio
2990,innovation step ekf localization ,let s say we have a bunch of observations  from sensor and we have a map in which we can get the predicted measurements  for landmarks  in ekf localization in correction step  should we compare each observation  with the entire predicted measurement    so in this case we have two loops  or we just compare each observation with each predicted measurement   so in this case we have one loop  i assume the sensor can give all observations for all landmarks every scan   the following picture depicts the scenario  now every time i execute the ekf localization i get  and i have   so i can get   to get the innovation step  this is what i did   z       z        hat z         z       z        hat z         z       z        hat z         z       z        hat z          where  is the innovation  for each iteration i get four innovations  is this correct  i m using ekf localization  in this book probabilistic robotics page         ,sensors localization ekf
2998,why does microstepping give less torque ,i am experimenting with using a stepper motor for a robotics project  i d like to use microstepping to give a better resolution and smoother movement  but i have noticed that the finer the microsteps  the lower the torque from the motor  why is this  for reference i m using the allegro micro a     motor driver  and a bipolar stepper motor  ,stepper-motor torque stepper-driver
3006,how can i achieve long distance  high quality  d scans on a mobile robot ,am going to be competing in robocup rescue in thailand next year   i was too busy to pull off a campaign for brazil this year    will be using cuda powered gpus  kinect xtions  and ros as the primary navigation system  but i need a sensor for long range scanning   at least    meters  it is probably overkill for the competition  but i want it to be used in other real world applications  it will need to be very robust  fairly light  high resolution  and proven  the cheaper the better  but high quality is a must  have read this question  but i need something that is available and proven now  what different sensing approaches are used in the current batch of indoor  d cameras  a similar question was asked before  but closed  lidar solutions  the suggestion was good   but i need something with a lot more range  at the moment am probably going to go with a the roboteye re   or re    d lidar  here is a paper that descibes how this sensor can be used on a mobile robot   does anyone have any alternative techniques  or suggestions of a sensor that can achieve similar results  ,mobile-robot ros slam kinect lidar
3007,industrial robotic arm,i had the opportunity to work for a factory company that is in the domain space of production and they want to use a robotic arm for part of the production line  they want basically a robotic arm with payload of about   kgs or more and an arm length of more than     mm i have researched a few companies like kuka com but i am not sure what i should be looking for when making suggestions and researching for it  are there any suggestions you can give me on few good points to be careful about with robotics arms  any innovating companies out there i should consider  how is an installation done and if i should find a supplier for it etc  please enlighten me   ,robotic-arm mechanism
3013,does it matter if my electronic speed controllers are close to my brushless motors ,i have built several quadcopters  hexacopters  and octacopters  this means that between the flight controller  i use  dr apm    or pixhawk  and the motors there are heavy duty power wires as well as a servo style cable carrying a pwm control signal for the esc  three short heavy duty wires then connect the motor to the esc  one for each phase  several times i ve heard or read people saying that the electronic speed controllers  escs  should be mounted far away from the flight controller  fmu seems to be the abbreviation en vogue  and close to the motors  i think the idea is that this cuts down on interference  i m not sure what sort  that could be emitted by the long esc    motor wires that would be required if you have the escs all at the center of the aircraft  another consideration is that escs can be cooled by propellers if they are right under the rotor wash  as mine usually are  so  i ve always mounted escs close to motors  but realized that design could be much simpler if escs are mounted centrally  so  my question is  what are the pros and cons of mounting escs close to the motor versus close to the fmu  ,brushless-motor multi-rotor esc
3016,tried normal distributions transform with my own files  in correct pcd format  and it throws errors  why , i ve used this program with the sample pcd s given and it came out correctly  this was confirmed by experienced users on here  now i m trying to use my own pcd s  i didn t want to bother changing the program so i just changed the names to room scan  and room scan   when i attempt to use them  i get this error   loaded        data points from room scan  pcd loaded        data   points from room scan  pcd filtered cloud contains      data points   from room scan  pcd normal distributions transform     build buildd pcl           kdtree include pcl kdtree impl kdtree flann hpp        int pcl  kdtreeflann  radiussearch const pointt   double    std  vector   std  vector   unsigned int  const  with pointt     pcl  pointxyz  dist   flann  l  simple   assertion    point representation   isvalid  point      invalid  nan  inf  point   coordinates given to radiussearch    failed  aborted  core dumped   this is the program i compiled   before you suggest it  i will let you know i already changed all of the pointxyzrgba designations to just pointxyz  it threw the same error before and after doing this  the thing that confuses me is that i looked at my produced pcd files and they seem to be exactly the same as the samples given for ndt  mine   sample from ndt page        e                e       d      f    e         c  f                          c         f    d       a              f e       e    a         c                   a a       a                   a                          a    f    e                   a                                a                     a              f    e                                       a    f    e                      does anyone have any ideas  ,kinect computer-vision openni
3017,programming language ,in general  what is a good programming language for robotics  i am a starting robo nerd and don t know anyone who would know things like this  ,mobile-robot wheeled-robot programming-languages
3021,directional hearing for linux robot ,i want to give my linux robot the ability to locate a sound source and drive towards it  i am reading a paper on sound localization that seems to cover the theory well enough  but i m at a loss as to how do i implement it  specifically i would like to know   how do i connect two microphones to a linux pc  how do i record from two microphones simultaneously  is there any library of sound processing algorithms  similar to how opencv is a library of computer vision algorithms  available for linux   ,mobile-robot digital-audio linux
3026,world files for simulating roads and tracks,hello i wanted to simulate a busy urban road similar to darpa urban challenge for an autonomous self driving car  i m in search of simulators for that  i ve seen gazebo since its integration with ros is easier but editing world files or indeed creating them itself is difficult  in torcs simulator i have seen many world files but not many sensors   i don t want much physics in my simulation  i want a light weight simulator for checking out path planning on an urban road  and in which creating roads are easier   i ve even searched for gazebo sdf files similar to urban city but in vain  ,simulator gazebo
3027,how frequently should a pid controller update ,i am developing a quadcopter platform on which will be extended over the next year  the project can be found on github  currently  we are using an arduino uno r  as the flight management module  at present  i am tuning the pid loops  the pid function is implemented as   i am having trouble interpreting the system response on varying the constants  i believe the problem is related to the questions below   how frequently should a pid controller update the motor values  currently  my update time is about         milliseconds   what should be the maximum change that a pid update should make on the motor thrusts  currently  my maximum limit is about       of the thrust range  at what thrust range or values  should the tuning be performed  minimum  lift off  or mid range or is it irrelevant   ,quadcopter pid
3029,alternative way to perform pole zero cancellation ,i ve read a lot places that making a controller which cancels the unwanted pole or zero is not good designing practice for designing a controller    it should make the system uncontrollable which off course isn t wanted   but what alternatives do i have      considering i have a system in which all poles and zeros lies on rhp   ,control design
3032,jacobian of abb irb    robot,can someone please help me with the jacobian matrix equations for abb irb    robot  or an easy way by which i can derive it given the dh parameters  i need it to implement some form of control that am working on  thanks ,control robotic-arm kinematics dh-parameters
3035,how to make one robot follow the other in parallel formation,this is quite a basic question  i m practising robot programming with vrep  i have   k  robots in the scene  one robot follows a predefined path  i want the second robot to move  in parallel  with the first one so they keep same orientation and same distance at all time  when there is a turn  i want the follower to slow accelerate a little to keep the parallel  in my implementation  i use wireless communication  the first robot will periodically  tell  the second about its speed  orientation  the second will use these parameters to calculate two speed to its two wheel  but when i run it  it doesn t work  the orientation of the follower is wrong  the distance is not maintained  i was totally confused  i think this is quite a rudimentary task  there must be some practise to follow  can somebody help to provide some ideas  references  that will be highly appreciated   ,kinematics
3040, smooth  inverse kinematics model for   wheeled differential drive robot,i have been reading about kinematic models for nonholonomic mobile robots such as differential wheeled robots  the texts i ve found so far all give reasonably decent solutions for the forward kinematics problem  but when it comes to inverse kinematics  they weasel out of the question by arguing that for every possible destination pose there are either infinite solutions  or in cases such as   since the robot can t move sideways  none at all  then they advocate a method for driving the robot based on a sequence of straight forward motions alternated with in place turns  i find this solution hardly satisfactory  it seems inefficient and inelegant to cause the robot to do a full stop at every turning point  when a smooth turning would be just as feasible  also the assertion that some points are  unreachable  seems misleading  maybe there are poses a nonholonomic mobile robot can t reach by maintaining a single set of parameters for a finite time  but clearly  if we vary the parameters over time according to some procedure  and in the absence of obstacles  it should be able to reach any possible pose  so my question is  what is the inverse kinematics model for a   wheeled differential drive robot with shaft half length   two wheels of equal radii  with adjustable velocities  and   i e  no in place turns   and given that we want to minimize the number of changes to the velocities  ,mobile-robot inverse-kinematics
3043,are there any problems with a variable frequency pid ,i am working on a quadrotor and am trying to solve the problems described here  in attempts to bring the refresh rate to     hz  i did an analysis of the functions  and most of the time     ms is being taken by the rc receiver input function  to tackle this  i have decided on two solutions   use interrupts   library  instead of pulsein reduce the frequency of pilot input  the second solution which is much simpler is to simply read the pilot input once in   pid updates  so  for  times  we have a update time of   and for the  time  we have an update time of t ms   will be around   this will create a system that will run on average in   now  how does a dual variable frequency affect the pid system  does the system behave as if working at the effective frequency  i have been searching for some time but i cannot find anything that discusses such a situation   ,pid
3049,how to define conditions for state machines in roby ,i am searching for a way that allows me to wait for some conditions on ports before applying a new state  my concrete problem  i want to make sure that my auv aligns to the right pipeline  therefore before starting the pipeline tracking  i want to check for the current system heading  my current state machine looks like this   find pipe back   state target move def  finish when reached    false      heading           pipe detector   state pipeline detector def pipe detector depends on find pipe back   role     detector  start pipe detector    forward pipe detector align auv event  success event  roughly i am looking for a way to condition the last forward  ,rock syskit
3052,gears in autodesk inventor are looking weird,i use autodesk inventor professional       i design my gears using the design accelerator  however  whenever i create gear trains  parts of certain gears become transparent  this seems completely random because sometimes if i zoom in or out or when i pan or orbit  the gears look normal again  i have experienced this problem using both the default and other material types  i also have ensured that each of these gears are enabled  here are some example pictures   any help or suggestions will be greatly appreciated  ,design errors
3058,why cannot we find ethercat shields ,i have a riddle about ethercat in mind and i d like to have your point of view about it    with the rise of open platforms and hardware  and easily accessible embedded machines  it is now rather straightforward to install a rt system such as xenomai on a raspberry pi  or a beagleboard black  or whatever cheap platform you prefer    now to connect these a rt bus would be really cool  e g  ethercat      hence my question  every hobbyist face the same problems with rt communication  so is there any good reason why there does not exist any open ethercat shield for raspberry pi or beagleboards  it would solve so many problems    any thoughts on why  any idea  ,communication
3062,how to connect a servo motor and a crank shaft,i have a standard  v   i am using the horn it came with it  i mean this piece    like the long arm in the middle  each of its holes are  mm diameter  then i have a  d printed crankshaft i did   its holes are also   mm  so while the servo horn is attached to the servo  i attach this crank to the horn in order to lift or lower a small scructure  what i am not sure is hot to connect these   pieces  horn and  d printed crankshaft   so far i have been using a paper clip  and at both end of it i placed   blobs of tin using a soldering iron  this has worked for nearly a year  but today i failed  and i was wondering if there s something more specific for my problem  which seems something common  i have seen some people use something called dubro ez connector  but it seems an overkill  plus it won t have space for my  d printed piece  some people seems to use a clevis pin  but i cannot find any with a diameter of less than    so my question is  how can i fix it  what can i put at both ends to stop if from slipping away  i have already tried simple things like simply bending it  ,arduino mechanism rcservo
3063,why should i still use ekf instead of ukf ,the unscented kalman filter is a variant of the extended kalman filter which uses a different linearization relying on transforming a set of  sigma points  instead of first order taylor series expansion  the ukf does not require computing jacobians  can be used with discontinuous transformation  and is  most importantly  more accurate than ekf for highly nonlinear transformations  the only disadvantage i found is that  the ekf is often slightly faster than the ukf   probablistic robotics   this seems negligible to me and their asymptotic complexity seems to be the same  so why does everybody still seem to prefer ekf over ukf  did i miss a big disadvantage of ukf   ,mobile-robot localization kalman-filter ekf
3066,what are some generally accepted lift capacity guidelines for multirotors ,e g  what general multicopter configurations would be generally accepted as recommendations to lift    kg   kg   kg   kg  etc  is there any general correlation between number of motors on a similar sized frame and lift capacity  ,quadcopter power
3069,quadcopter degrees of freedom,it might be kind of a stupid question but how many degrees of freedom are there in a typical quadcopter  i say some saying   and some saying    the difference stands in translation throughout the other   axis  horizontal ones   being strict to what you can directly tell the quadcopter to do  only   movements are possible since you cannot apply a pure lateral force  but you can tilt to start a lateral movement and align the body right after and let it hover in a horizontal axis  theoretically  so  formally  how many degrees of freedom should i consider to exist  ,quadcopter
3071,mahalanobis distance between   line features,i am implementing the atlas slam framework for a ground robot  using ekf slam for local maps and using line segment features  the line segment features can be abstracted to their respective lines  where d and   represent the distance and angle in the distance angle representation of lines   in the given framework  there is a local map matching step where lines of the local maps will be matched  and there is a need for a distance metric between   lines  the mahalanobis distance is suggested in the literature  however strictly a mahalanobis distance is between a single measurement and a distribution and not between   distributions  how do i find the mahalanobis distance between line    d      with covariance matrix s  and line    d      with covariance matrix s   in the ekf algorithm from the book probabilistic robotics by sebastian thrun  there is a computation during the feature update step  where it looks like the covariances  of a new measurement and an existing measurement  are multiplied to give a resultant covariance matrix  and then the inverse is used in the mahalanobis distance computation   that would be similar to  mahalanobis distance    d  d           inverse s  s      d  d           is that correct  ,ekf mapping
3073,data association with ekf ,given part of the following algorithm in page     probabilistic robotics  this algorithm for ekf localization with unknown correspondences     for all observed features          for all landmarks  in the map  do                                                             endfor                                          endfor my question is why the second loop ends in the line     shouldn t it end after the line     i ve checked the errata of this book but nothing about this issue   ,localization ekf data-association
3079,typical method for integrating a neural net into a plc,how would one typically integrate a neural network into an online automation system  as an example  we have developed a neural network that predicts a difficult to measure variable within a reactor using multiple sensors  we then use this predicted variable to tell the automation system to  for example  increase decrease the stirrer speed  how would someone implement this idea into a commercial system  would they develop a function block that can simulate the neural network  would they run a software on the server that reads and writes to the plc control tags  ,sensors control
3080,arduino quadcopter using bluetooth shield and android phone,i need help on how to go about building a quadcopter software from scratch with the available tools i have with me  i don t have a transmitter radio therefore the only way i can do remote control is using an android phone with the itead studio bluetooth shield that i was recently given  how can i use the existing open source software  i e aeroquad or arducopter  the following are parts that i have    arduino uno  bluetooth shield  four brushless motors  q    frame four esc turnigy  mpu      ,arduino quadcopter
3088,different particle filter min and max particle numbers give almost the same result,i m using amcl package in ros to localize a mobile robot  i ve changed  and max particles several times then calculated the output difference with odomotry to evaluate these parameters  the table below demonstrate results  as you see  there is no notable change in the output and if you ignore the first row of the table  output variance is small    and this is the particle filter output on the map   ,localization particle-filter
3090,how to request a specific mavlink packet from ardupilot ,i m developing a program for communicating with ardupilot using mavlink  i ve generated code based on the mavlink definition for ardupilot  and i have the basic communication working  what i can t figure out  is how to request ardupilot to send a specific mavlink message  i d like ardupilot to send me mavlink message attitude       every second  how can i do this  ,ardupilot
3091,how to overwrite default git source in autoproj ,i want to overwrite the git source of a package in autoproj  that package is by  default on gitorious and i forked it on spacegit to apply specific patches  according to the autoproj documentation     i set the new repo in the overrides yml by   but if i inspect the remotes of the newly checked out package  only the  fetch url is adapted to spacegit whereas the push url still points to  the default gitorious repo    git remote  v autobuild   git   spacegit dfki uni bremen de  project  orogen  package  git  fetch  autobuild   git gitorious org  rock control orogen  package  git  push   how can i overwrite both the fetch and the push source of a package in the  overrides yml  ,rock
3098,controlling a system with delayed measurements,assume i have a rather simple system i want to control  but all sensor measurements exhibit considerable time delay  i e     with my limited knowledge about control  i could imagine the following setup   one observer estimates the delayed state  using control input and  delayed  measurements  a second observer uses the delayed observer s estimate and predicts the current state  using the last control inputs between delayed measurement and current time  the second observer s estimate is used to control the system   can i do any better than that  what is the standard approch to this problem  and is there any literature or research about this topic  ,sensors control sensor-fusion sensor-error
3101,velocity model motion in matlab  probabilistic robotics ,i want to implement the velocity motion model in matlab  according to probabilistic robotics page      the model is as following   begin align    hat v          v   sample  alpha     v        alpha     w          hat w          w   sample  alpha     v        alpha     w          hat  gamma     sample  alpha     v        alpha     w         x     x    frac  hat v    hat w   sin  theta    frac  hat v    hat w   sin  theta    hat w   delta t      y     y    frac  hat v    hat w   cos  theta    frac  hat v    hat w   cos  theta    hat w   delta t       theta      theta    hat w   delta t     hat  gamma   delta t   end align   where   with this kind of variance   the kalman gain is approaching singularity  why    ,mobile-robot kinematics motion motion-planning noise
3102,  dof robotic arm,we are building a   dof robotic arm as a college project and we ve almost finished the designs  the problem is with the controls  we still havent thought on how to control the arm  as in   software gui interfaces   etc  any suggestions on this   also  is there any simulation software for simulating and testing robotic arms    ,control arm
3104,ekf localization known correspondences,i m facing problems with this book and it is the only book that discusses localization in depth  the results that i m getting makes no sense  i ve read a lot of papers  majority of them copy the localization algorithm from this book  my question here is why  and  are being changed every iteration   i m using them to get the predicted measurements in lines         so they should be fixed      for all observed features  do                                                                                         endfor            please suggest me other books that discuss ekf localization in depth   ,localization ekf
3105,will a   amp esc run a turnigy          ,i m a noobie just starting out and trying to come up what i need to build my first quadrocopter  i just wanted to run something by people with some experience before i commit to buying anything  would this esc be fine for running this motor  as i understand it the esc should be rated for slightly above what the max amps are for the motor  on top of that  should this battery be able to run all of the motors without any issue  ,quadcopter brushless-motor multi-rotor esc battery
3108,how to control a function with two different inputs,how might i be able to control one function  like brightness control of an led  with two different triggers  like a tactile switch and an ir remote   i am trying to be able to control the brightness with switches as well as ir remote when desired  ,control
3110,ros  best practices ,i m going to build a small robot system and it seems like that ros serves a nice framework to control and program the system  however i am wondering which is the best practice to manage the components of my robot  does it make sense to put all the sensors in one node  should i only put the sensors of the same type in one node or is it better so have one node for one sensor   is it a good practice to have some kind of handler node  which takes input from sensors and steers the corresponding actuators or should the actuator nodes and sensor nodes communicate directly   fused sensor nodes and actuator nodes with handler  single sensor and actuator nodes with handler  direct communication   for me i guess the best is to have some kind of handler  which handles the communication between sensors and actuators and have one node for each element of the robot  like in fig     because like that the system loosely coupled and can be extended easily  but i want to know what your opinion is  greetings ,control ros
3116,problems using syskit monitors    failed emission of the foo event of,i had just tested my first monitor  which results in the following error regarding the suggestion in how to define conditions for state machines in roby  unfortunately i ran into a runtime error  i don t know whether this is a bug or if i misuse the monitor     don t know whether this is a bug  or if i had miss used the monitor     here is the action state machine i m using          describe  find pipe with localization                optional arg  check pipe angle  false          action state machine  find pipe with localization  do             find pipe back   state target move def     some long stuff here                   pipe detector   state pipeline detector def             pipe detector depends on find pipe back   role     detector              start pipe detector                  pipe detector monitor                   angle checker    the name                 pipe detector find port  pipeline     the port for the reader                  check pipe angle    check pipe angle    arguments                 trigger on do  pipeline                      angle in range   true                     if check pipe angle                         angle in range   pipeline angle          pipeline angle                            end                     state valid   pipeline inspection state      align auv    pipeline inspection state     follow pipe                     state valid    angle in range  last condition                 end  emit pipe detector success event   for non monitor use  this works if the above is commented out              forward pipe detector align auv event  success event              forward pipe detector follow pipe event  success event                 forward pipe detector success event  success event             forward pipe detector find pipe back success event failed event  timeout here on moving         end  ,rock syskit
3117,device that can push out independent pin points ,i m looking for a device that can push out independent pinpoints from something similar to a pin point impression toy  i m looking to create a  d image from for example my computer  does anybody know the name of such a device or can point me in the right direction of making one   i ve been looking now for a while  but i m having some slight problems finding a good way to describe it as a search term  i m sorry if this is the wrong forum  ,3d-printing
3118,observation model jacobian for fixed transforms,let s say i have a hypothetical sensor that provides  for example  velocity estimates  and i affix that sensor at some non zero rotational offset from the robot s base  i also have an ekf that is estimating the robot s velocity  normally  the innovation calculation for an ekf looks like this   y k   z k   h x k   in this case   would just be the rotation matrix of the rotational offset  what are the ramifications if instead  i pre process the sensor measurement by rotating  by the inverse rotation  which will put its coordinates in the frame of the robot  can i then safely just make  the identity matrix   ,kalman-filter ekf
3121,where can i buy heavy duty omni wheels ,where can i buy multi directional omni wheels  i m specifically looking at something which can support in excess of    kg wheel  so around    kg in total  also  a possible mission profile would include a     meter excursion outdoors on asphalt path  so they should be a little durable  the only ones i can find online are small ones for experimenting   ,wheel
3124,pwm pid control for small   watts brushed dc motor,it is  good enough  for pid output directly controls  without further modelling  the pwm duty cycle  logic behind the question is   in case of pure resistance heater  pwm duty cycle percentage directly relates to power  on off time ratio   so  direct control is appropriate  however  motor has two additional effects  a  with considerable inductance  initial current is smaller and ramping up over time b  as rpm gradually ramping up  after time constant of mechanical inertia etc  increasing back emf will reduce current will it be wise to ignore the above two effects and still expect a reasonably good outcome   application is   volts    watt dc brushed motor  gear             rpm no load  pwm frequency    hz  driving diy  kg robot  ,motor pid pwm
3125,what is the actual application for manufactuing  with robot arm autonomous object classification system,i m a graduate student  and we re doing a project that is going to introduce a robot arm into manufacturing  our goal is to build up an autonomous object classification system  we already have the software and hardware required for the task  but we have no idea if there is any existing manufacturing scenario where we can apply the system and really improve the efficiency or save human resources  here is some info about the robot arm  for the hardware part  the robot arm is with   dof and  kg payload  the weight of the end effector is not counted   besides  the end effector is a    kg   fingered robot hand with  kg payload  the workspace is approximately a sphere with    m diameter  for the software part  we have programming by touch  by which human can drag the robot and record the desired pose  besides  we have pcl object recognition that can recognize the object and its pose in the scene  lastly  we have online trajectory generator and dynamic obstacle avoidance that can improve the safety when the robot corporates with human  since we know few about manufacturing  we hope that someone can give us a hint about the scenario and an actual application where we can apply this system   ,robotic-arm manufacturing
3132,ekf localization is approaching singularity  are my sensors too noisy ,i m getting this warning from matlab about kalman gain    the problem is coming from high variance of the measurement model  my question is here does ekf work with high noise in sensor  ,localization ekf
3133,installing openni on pcduino,following my previous question about pcduino kinect  decided to go ahead and buy the pcduino i wish to run my robot with  kinect pcduino shields   however i m having trouble getting started  i tried installing openni  nite and sensorkinect however openni installation fails  i haven t even gotten to installing nite and sensorkinect yet so no idea if that would work   i tried a bunch of pointers  here and here   for example the error i get if i follow link   is   ubuntu ubuntu   kinect openni platform linux createredist     after someone suggested it  i tried removing the  mfloat abi softfp option but that didn t help  there seems to be some compiling linking issue due to float types which i m not able to figure out  in link   the author mentions to remove the  calc jobs number    but that does not work and i get similar error  also similar problem exists for link   above if i follow link     make  won t work and will give the following error    usr bin ld  error        bin arm release libopenni so uses vfp register  arguments    arm release tinyxmlparser o does not    usr bin ld  failed to merge target specific data of file   arm release tinyxmlparser o  another approach would be to use simplecv instead of openni on pcduino as someone else claims it has worked before  however i ve never used simplecv with kinect before so unless it s not radically different i prefer using openni  any suggestions as to why i might be getting these errors are appreciated  any other pointers for solving the problem of installing openni on pcduino would be welcome  please let me know if you need more details about anything else  thanks in advance ,kinect arm openni
3134,libfreenect simplecv integration ,i installed simplecv and libfreenect on pcduino  running lbuntu   i separately verified that simplecv reads my usb webcam well and libfreenect  glview tutorial  gives me depth and rgb correctly  albeit and a pathetic framerate  what i want is to call cam   kinect   in simplecv but when i do that  i get the warning  you dont seem to have the freenect library installed  this will make it hard to use a kinect   although this is a warning i get an error if i then do cam getdepth    which says  nameerror  global name  freenect  is not defined   how do i let simplecv know that i ve installed libfreenect  ,kinect
3137,how to use quaternions to feed a pid quadcopter stabilization loop ,i m making a quadcopter  i have set up a pid loop to stabilize it to a given euler angle  pitch and roll   the problem arises when the roll approaches    degrees     degrees and up   the values don t make sense anymore  as it approaches the gimbal lock  i intend to make it do complex maneuvers like looping etc   which exceeds the    degree roll limit  how can i use quaternions to overcome this problem   i get quaternions from the mpu        i have read many articles on the matter of quaternions  but they all talk about rotations in  d software  and tweening between two rotation points  this makes little sense as i do not know imaginary numbers and matrices  ,quadcopter pid stability
3139,denavit hartenberg convention,there are two different conventions that can determine dh parameters    what is the difference between craig s     sec      convention and the spong     sec       convention  i know that both methods must have the same response       craig  john j  introduction to robotics  mechanics and control  addison wesley             spong  mark w   seth hutchinson  and mathukumalli vidyasagar  robot modeling and control  wiley        ,forward-kinematics dh-parameters
3144,inverse kinematics of parallel manipulator  delta robot ,let me start off by saying that i am currently going to university majoring in computer engineering   i love software hardware and i especially love robotics and i want to apply my knowledge of software hardware in robots   i have never taken a formal class on robotics  so i don t really know where to start or how to approach the mathematics that robots entail    currently  i am interested in calculating the inverse kinematics of a delta robot  to clarify a bit more  i am trying to determine the required joint angles that will position the end effector of the delta robot to a specific location given some x y z coordinate   the delta robot that i will be basing my design off of is shown in the image below   based off of some research that i have been doing for the past few days  i found that the sort of mathematics involved are usually like those of denavit hartenberg parameters  jacobian matrices  etc   i am going to be honest  i have never encountered denavit hartenberg parameters or jacobian matrices and i don t even know how to apply these to solve the kinematics equations and let alone find the kinematics equations   most of the articles that i have read  mainly deal with serial manipulator robots and the mathematics in finding the kinematics equations of those serial manipulators   i couldn t really find any good material or material that was easy to understand given my current situation on parallel manipulators    i wanted to ask my question here in the hopes that someone in the community could direct me to where i can start on learning more on obtaining the inverse kinematics equations of parallel manipulators and solving those equations  any help will be much appreciated  thank you  ,kinematics inverse-kinematics
3145,how to brake a brushed dc motor  belt driven linear actuator to within    mm of an end stop,i will have a belt driven linear actuator  consisting a gantry plate riding on two rails  i m thinking of using a brushed dc motor  the gantry will move from home position to the right  outbound  at  m s  the mass of the gantry will vary from  kg to  kg  on the return home  inbound  one must avoid spillage of contents which may require soft start stop or simply a slow return to home  in the outbound case  what i d like to know is how in a practical sense  do you brake the mass and bring the gantry to a stop  ensuring that the gantry plate always comes to rest to within    mm of an end plate  i m clearer how i can ensure the gantry stops to within    mm of the home position  because i can use a pwm ramp to slowly decelerate  i m wanting to avoid using an mcu  just want to use an ic with switches and potentiometers  you can also use math if you want to explain  of course  one seeks to begin to arrest the mass as close to the end stop in the outbound case as one can without problems  thanks  ,motor
3150,rock envire   vizkit d   change environment visualization  envire lib  from ruby script,i am using a ruby script to connent the multi layer surface map of the velodyne slam component to the vizkit d visualization  the visualizazion plugin is loaded like this  envireviz   vizkit default loader envirevisualization it is possible to get the mlsvisualisation object from the envirevisualization in order to set visualization properties  like colors etc   from the ruby script  rubys introspection abilities didn t help a lot here    ,rock
3152,autoproj snapshot with git detached head,i need to search in the git history of a couple of packages to  get back to a working state for a demo  i am searching by checking out  commits manually until i found the commits of all effected packages that  work together  by checking out commits manually  i will get into the detached head state   autoproj snapshot demo working now the demo working overrides yml will pin the commit where the head is  pointing to  e g   e e a     instead of the commit that i chose manually  for the package     e      is this the desired behaviour  in my opinion a snapshot should store the  current state of all my git repositories meaning that i can also select  commits manually  ,rock
3155,one of the best ways to numerically integrate the velocity ,i need to get position  from integrating velocity   one could use  st order euler integration as  however  doing so leads to errors proportional to sampling time   do you know any more accurate solution please  ,kinematics
3159,cannot launch irobot create  powers down upon minimal launch ,i just got an irobot icreate base and i ve followed the instructions given in  ros tutorials to setup the turtlebot pc and the workstation  i could successfully ssh into username turtlebot through workstation so i m assuming that is all good  i had an issue with create not able to detect the usb cable which i solved using the detailed answer given for question here  this solved the problem of  failed to open port  dev ttyusb   that i was facing before   now the next step would be to ssh into the turtlebot  which i ve done  and use  to do whatever the command does  i ve no idea what to expect upon launch   but apparently something s amiss since the create base chirps and then powers down after showing  kinect breaker enabler    process has finished cleanly as output and the log file location  see output below   but i dont see a prompt  i checked the battery and that s charged so that s not the problem  following is the terminal output  anshul anshulspc    roslaunch turtlebot bringup minimal launch     logging to  home anshul  ros log  d   a a fbdc   e  ba b      e f bb  roslaunch anshulspc      log checking log directory for disk usage  this may take awhile  press ctrl c to interrupt done checking log file disk usage  usage is   gb   started roslaunch server   summary           parameters     cmd vel mux yaml cfg file     diagnostic aggregator analyzers digital io path     diagnostic aggregator analyzers digital io startswith     diagnostic aggregator analyzers digital io timeout     diagnostic aggregator analyzers digital io type     diagnostic aggregator analyzers mode path     diagnostic aggregator analyzers mode startswith     diagnostic aggregator analyzers mode timeout     diagnostic aggregator analyzers mode type     diagnostic aggregator analyzers nodes contains     diagnostic aggregator analyzers nodes path     diagnostic aggregator analyzers nodes timeout     diagnostic aggregator analyzers nodes type     diagnostic aggregator analyzers power path     diagnostic aggregator analyzers power startswith     diagnostic aggregator analyzers power timeout     diagnostic aggregator analyzers power type     diagnostic aggregator analyzers sensors path     diagnostic aggregator analyzers sensors startswith     diagnostic aggregator analyzers sensors timeout     diagnostic aggregator analyzers sensors type     diagnostic aggregator base path     diagnostic aggregator pub rate     robot name     robot type     robot description     robot pose ekf freq     robot pose ekf imu used     robot pose ekf odom used     robot pose ekf output frame     robot pose ekf publish tf     robot pose ekf sensor timeout     robot pose ekf vo used     robot state publisher publish frequency     rosdistro     rosversion     turtlebot laptop battery acpi path     turtlebot node bonus     turtlebot node port     turtlebot node update rate     use sim time  nodes         cmd vel mux  nodelet nodelet      diagnostic aggregator  diagnostic aggregator aggregator node      kinect breaker enabler  create node kinect breaker enabler py      mobile base nodelet manager  nodelet nodelet      robot pose ekf  robot pose ekf robot pose ekf      robot state publisher  robot state publisher robot state publisher      turtlebot laptop battery  linux hardware laptop battery py      turtlebot node  create node turtlebot node py   auto starting new master process master   started with pid        ros master uri   setting  run id to  d   a a fbdc   e  ba b      e f bb  process rosout     started with pid        started core service   rosout  process robot state publisher     started with pid        process diagnostic aggregator     started with pid        process turtlebot node     started with pid        process kinect breaker enabler     started with pid        process robot pose ekf     started with pid        process mobile base nodelet manager     started with pid        process cmd vel mux     started with pid        process turtlebot laptop battery     started with pid         warn   walltime                     create   robot not connected yet  sci not available  warn   walltime                     create   robot not connected yet  sci not available  kinect breaker enabler    process has finished cleanly log file   home anshul  ros log  d   a a fbdc   e  ba b      e f bb  kinect breaker enabler    log  following is the log file   home anshul  ros log  d   a a fbdc   e  ba b      e f bb  kinect breaker enabler    log output   rospy client  info                           init node  name  kinect breaker enabler   pid        xmlrpc  info                           xml rpc server binding to            rospy init  info                           ros slave uri      xmlrpc  info                           started xml rpc server     rospy impl masterslave  info                            ready    xmlrpc  info                           xml rpc node  starting xml rpc server  rospy registration  info                           registering with master node   rospy init  info                           registered with master  rospy rosout  info                           initializing  rosout core topic  rospy rosout  info                           connected to core topic  rosout  rospy simtime  info                            use sim time is not set  will not subscribe to simulated time   clock  topic  rospy internal  info                           topic  rosout  adding connection to   rosout   count    rospy core  info                           signal shutdown  atexit   rospy internal  info                           topic  rosout  removing connection to  rosout  rospy impl masterslave  info                           atexit  from the logs  i could tell something told the create to power down  and since the log is named with  kinect   i tried minimal launch w  and w o kinect attached to the turtlebot pc  it doesn t make any difference   any clue what i might be missing  or is this the way bringup works  i guess not   ,ros irobot-create
3160,irobot create without ros ,is it possible to control the create without using any ros whatsoever  i know it has all these serial digital i o pins that connect to ros which controls it using drivers libraries  but how hard would it be to do so using  say  a pcduino  i m asking this because i m having trouble launching the create using ros  question  ,irobot-create
3162,bs  inconsistant pin state when connected to wire ,i have a bs  mounted on a parallax board of education rev d  i was trying to use a wire to determine whether a control was pressed   however  whenever there s a wire connected the state seems to fluctuate between   and   instead of staying one or the other  when connected to the desired button it still exhibits this behavior but has the added quality of switching to zero when the button is pressed  ideally it will stay zero while the buttons pressed and   when it s not  but instead it flickers between   and   when unpressed   what causes this behavior and why does it occur even when the wire is not connected to anything except the bus  the code used to get the state is   ,microcontroller
3164,autodesk inventor       rounding only at specific edge,i am using autodesk inventor      and i need to round a component of a device  i want to round the green marked edges  but not the red marked  but when i click  round   then the bottom edge will always be added to the rounding and i cannot de select it  any hints how to solve this problem   ,design
3166,maximum likelihood estimator  ml data association  ekf,this question is an extension to my previous problem  data association with ekf   my problem here is in the line    in the aforementioned link            when i compute this line  i m getting huge number   this is probability density function  why is the pdf getting bigger than   in a huge way  ,localization ekf
3170,path comparison,problem  the cartesian position of an end effector  no orientation  of a robot arm is recorded  say  every millisecond  the time steps can not be changed   during a motion  the robot arm is commanded the same path but with different velocities  so i get different trajectories  i want to calculate the deviation of the paths  which is the distances of equivalent points of two paths  the problem is to find equivalent points  since the two velocities are different the comparison at the same time steps of the trajectories makes no sense  i can assume that the paths underlying the trajectories to be compared are rather similar  the deviation for the ideal path being smaller than    of a typical length dimension of the path  i want to detect deviations of much lass than that   i have to map the timestamp of the recorded points to the path length  and make comparison of points at the same path length  but of course also the path lengths differ for different paths  so any deviation would distort the result for all later points  how can i compensate for this    is there a reliable algorithm   where can i find information   note  time warp algorithms  even memory optimized ones  are out of the game because of memory consumption   ,localization robotic-arm
3172,making a gripper changer for a robotic arm,how do you make a gripper changer for a robotic arm like this  i don t see how you could connect power control wires or what you use to hold the gripper to the arm  ,robotic-arm
3173,velocity control via vibration,i am working on a robot that has an accelerometer  this accelerometer measures the vibration of the robot  when the robot hits a certain vibration  i would like it to slow down in order to reduce the vibration  i thought about a pid controller  but i don t think it would work  does anybody have some input on different types of controllers i can use    mechaman  ,pid accelerometer navigation
3178,controlling a system with pid that resists backdrive,i m controlling the angular position of a pendulum using a dc motor with a worm gearbox  mechanically  worm gears are impossible to backdrive  using a pid controller on a pendulum system with a regular dc motor  no worm gear   the integrator would help the motor find the appropriate constant power setting to overcome gravity so the pendulum can hold any arbitrary position  with the worm gear  however  there is no need to apply constant power to the motor once the desired position is achieved  power to the motor can be cut off and the worm gear will resist gravity s force to backdrive the pendulum to the lowest gravity potential  it seems to me  then  that the integrator of the pid algorithm will cause large overshoots once the desired position is achieved  i want the integrator initially to help control the pendulum to the desired position  but once the position is achieved  i d need the integrator to turn off  the only solution i can come up with is to test for a special condition in the pid algorithm that checks if the position has been reached and the angular speed is small  then instantaneously reset the integrator to zero  is there a better way to handle the integrator in a system that resists backdrive     edit   when i originally worded my question  i was mostly just interested in the academic approach of backdrive resistance in a pid loop  but it ll help if i explain the actual mechanism i m building  the device is a robotic arm that rotates on a car window motor  it will also occasionally pick up and drop small weights at the end of the arm  manufacturing variability in motors and the difference in drive torque when picking up the small weights led to me consider a pid loop  ,pid
3181,how to calculate robot hand positions using roll  pitch angles,i want to calculate humanoid robot hand position with given shoulder roll  pitch angles and elbow roll angle  i m able to calculate elbow position using rotation matrix which includes shoulder angles  but i dont know how to calculate hand position using elbow position and elbow roll angle  can you propose a method to calculate hand position   ,robotic-arm forward-kinematics
3183,adding external magnets to a dc motor,is it possible to strengthen permanent magnet dc motors by simply attaching extra magnets on the outside of the motor casing   adding to the magnetic field  if this is not possible  the question becomes  what happens if i replace the magnets inside the motor with better magnets  i know that the coils will not handle more current than they currently do  so what will the net effect on the motor be  ,motor
3188,where to go to purchase parts for xy plotter,i am trying to build a  ft square an xy plotter  i have seen three designs so far    rack and pinion   threaded screw    belt driven  all these use a stepper motor to drive the system  each one has their obvious pros and cons but correct me if i am wrong  i believe the rack and pinion system is the most sturdy and easiest to put together  i googled for rack and pinion but all i get is industrial websites  is there any place that sells cheaper rack and pinion sets for hobbyists  the payload of the xy table is an eletro magnet that isn t extremely heavy  maybe a half kilogram at most   so obviously the motor must be strong enough to move anothe rack which will be significantly heavier than the payload  this is my first real robotics project so i am new to all this  ,stepper-motor motion actuator
3200,manipulator link applied torque,i want to implement a manipulator link using a physic library  i can only apply some torque to the centre of mass  but the torque should be applied at the beginning of the link  shifting a reference frame from the centre of mass and recalculating inertia tensor in the new frame is not a problem  neither is recalculating a new torque  based on the change of distance  but i think it is not the correct solution  in short  how can i scale a torque of a control signal applied at the beginning of the link to a torque of a physic simulation applied to the centre of mass  thanks  ,simulator torque
3206,current limiting stepper motors for reprap,i have been working on a robot project for a while  now i am tired of finding parts that just does the job  so it is time to do create parts  a  d printer will do the trick for many parts  but  d printers share a lot with a cnc mill in terms of control and parts  so my question is this  i am building a reprap style printer  but i will use more heavy duty parts and motors  hoping to make a aluminum capable   axis mill later  i found some bipolar nema    stepper motors at     nm and   amps per coil  according to the reprap org website  they recommend nema    and low voltage  seems to me that they use voltage to limit the current  can i build a reprap  and use current limiting stepper drivers with an arduino and some software i find online  and get away with these large stepper motors  or am i in for a lot of trouble  ,arduino stepper-motor stepper-driver cnc reprap
3207,best microphone for speech recognition tasks,i made several tests with different setups in order to achieve an acceptable speech recognition quality  it works well when i push a button to activate it but now i want it to be automatically activated when a user speaks  this is a big problem  especially when i only use the energy of the audio signal to guess when the user is speaking  that is why i thought about using a headset and not a distant microphone  in a headset the microphone is very close to the users mouth and it is easier to make correct guesses about when the user is speaking  now my question is if bluetooth sets used with mobile phones also have such a property  they are not long enough and their microphone is not positioned exactly in front of the mouth  is there a possibility that such devices can also capture some speech noise from a distant user  is there a significant difference in the signal energy coming from the user s speech and a   meter distant person s speech  ,digital-audio speech-processing
3208,electronic speed control concepts,i am a programmer who has never worked with electronics before  i am learning the concepts and hoping to build a quadcopter  with the control software entirely written by me  motor control seems to be the most important part  is it true that the typical brushless dc motor and esc  electronic speed control  can only approximately control the speed   that s because the esc seems to have only a very approximate idea how fast the motor is revolving  this still works for a pid  proportional integral derivative  controller because it gets indirect feedback from say a gyroscope whether the motor is going fast enough and so it can tell the esc to make it revolve  even faster  or  even slower   and that s good enough  is my understanding in the above paragraph correct  if so  i wonder whether a servo motor that can inform about its current rate of rotation could help do away with the esc entirely  i feel that if the microcontroller can receive an input about motor speeds and send an output requesting a certain speed  it would not need the esc  but i am not sure how servo motors work    what happens immediately after you request    rpm when say they were at   rpm  since they cannot adjust the immediately  should the microcontroller immediately adjust other motors to account for the fact that not all motors are at    rpm yet   does that imply that the microcontroller should only request very small deltas from the currently measured speed  so that the period of deviation from desired state is negligible  in the latter model  of requesting only very small deltas from currently measured speed  the algorithm seems like it would not really be pid since there is no way to control the acceleration  but may be requesting the servo to go from   rpm to    rpm causes it to reach   rpm much faster than requesting it to go from   rpm to   rpm  i feel i know so little i cannot put my finger on it more precisely  but i hope this gives an idea of the concepts i am struggling to absorb  to summarize  the questions are   can a servo  brushless dc  motor allow doing away with esc  does a servo motor accept control inputs such as  revolve at    rpm   does a servo motor offer an output saying  i am at   rpm now   does a servo motor at   rpm go to   rpm faster if it is requested to revolve at    rpm versus at   rpm  the less precise questions implicit in the text above    crossposted from electronics stackexchange  ,motor pid brushless-motor esc servomotor
3209,can active sensor data be fed into an autodesk inventor simulation ,i d like to drive the position of various components within a virtual assembly based on sensor data being collected in real time from an external device  does inventor support such a setup  the goal is to match the relative movements of the components on screen to the real world counterpart  for example  a absolute rotary encoder records the current angle of a physical joint and the virtual joint is rotated to match  is this feasible  my past searches for information on this have turned up empty  perhaps because i m using the wrong search terms  most results point to irrelevant mechanical stress simulations  ,sensors kinematics
3210,why production lines are so huge and power hungry ,i m thinking of starting my adventure in area of professional manufacturing  when i started to look onto machines i figured out that they are build somehow like in the   s  huge footprint  big  kw electric motors etc  is there any explanation why they are build in that way  the only one i can think of is  they were developed long time ago and if it worked  it stays as it is  btw  if you know other place where to ask this question please let me know  ,manufacturing
3216,is this gear design feasible ,i came up with an idea and am working with a mechanical engineer to design and prototype the idea but i keep sketching out my own ideas in the process and i just came up with this   i m quite sure this is not an idea he ll go with but i m just kinda curious whether or not this would actually be feasible   or for all i know it s already common place  or totally stupid     i dunno  what do you think   ,mechanism movement
3218,repairing non lubricated linear actuator,i have a chinese cnc mill  cnc    t  though several different devices go under this name   and its z axis was very imprecise  often being randomly off position by as much as    mm  i ve disassembled the linear actuator and discovered several problems with it  first problem is that they apparently forgot to lubricate the linear ball bearings  i make this conclusion because the rails have a set of grooves ground into them  and after wiping the rails with a tissue the only thing that is left is the finely powdered metal  with no traces of oil or other lubricant    second problem is the nut  i expected to see a ballnut  but in reality it is just a piece of threaded ptfe  the leadscrew rotates smoothly in it  but there is quite some lateral movement  i e  i can tilt it slightly without any opposing force   third problem is the overall mounting  in the picture below  the top left screw has been sheared in the factory and then they hid their mistake by tapping a larger thread and putting in a shorter screw that doesn t actually hold anything in the top plate   so the whole assembly was fixed in three  rather than four  points  however  the remaining screw was quite tight   so my closely related questions are   is the assembly even salvageable  how do i verify that linear ball bearings  the ptfe nut are relatively undamaged  can i just rotate the rails by     to get smooth surface again  what do i lubricate the linear bearings with  do i clean them before lubrication  i have an ultrasonic cleaner  any other advice on maintenance of the whole assembly  there may be something that i missed   ,actuator linear-bearing
3222,predicting the impact point of a moving object,suppose we have a moving object  a horizontal projectile motion as one of the most basic examples   is there any way to predict where it will hit finally  please note that i m looking for a machine learning method not a closed form solution  although we can track the motion  using kalman filter  that is only applicable when we want to predict the new future as far as i m considered   but i need to predict the ultimate goal of a moving object  to better express the problem let see the following example  suppose a goalkeeper robot that of course uses filtering methods to smooth the ball motion  it needs to predict if the ball is going to enter the goal or not  before it decide to catch the ball or neglect it to go out  input data is a time series of location and velocity  x y z v   ,machine-learning
3225,android vibrating based on arduino devices,i want to make a simple device that causes my cellphone to vibrate for    seconds when my phone is    feet away from it  how would i go about doing that  how small could i make the device  ,arduino
3227,finding a hydraulic actuator to be controlled through a mcu,i m researching potential actuators i can use on a project i m doing  i m designing a creeper  platform for rolling under vehicles  that can lift you up just like the operation of those hospital beds  the creeper will have a joystick that will control up and down motion as well as the option to drive it forward backwards left and right  i need an actuator that will support an average weight of    lbs that would be able to lift a body of that weight  i was thinking of a hydraulic actuator but i m not sure if these exist  i can very well have two actuators to share the load also  however  i need to control these actuators through a micro controller unit  i m planning on using a raspberry pi because i have an abundance of them mainly  but i ll be researching other potential units   therefore  my main question is where can i find an actuator that would be a good fit for this type of project that can be integrated with a micro controller unit  does anyone have experience with this type of project or any important details i need to take into consideration that i m not thinking of     ,microcontroller actuator
3231,up to what force is a servo motor a reasonable choice as an actuator ,i m working on an application where i need to apply a linear or angular force to operate a linkage mechanism  but i don t  yet  know what amount of force i will need  i anticipate that it will be less than     kg     n   the travel distance on the linkage input should be less than    cm  as i look through available servos  they seem to exist firmly in the scale model realm of remote control vehicles  and as such i am uncertain if any will be suitable for my application  for example  one of futaba s digital servos  the mega high torque s      is listed at    kg cm  from what i understand  this means that at   cm from the center of the servo shaft  i can expect approximately    kg force  if i wanted    cm of travel distance i would need roughly a      cm radius  which would diminish the applied force to                 kg  well below the     that might be required  question  is my understanding and calculation even remotely accurate  should i be looking at other types of actuators instead of servos  they seem to become prohibitively expensive above    kg cm torque   for the purposes of this project  the budget for the actuator is less than      us   for my application  i d like to have reasonable control over intermediate positions across the travel range  good holding power  and fairly fast operation  for this reason i have dismissed the idea of using a linear actuator driven by a gearmotor and worm drive  i am relatively new to robotics in the usage of motorized actuators  but i ve used pneumatic cylinders for many years  for this application  i can t use pneumatics  edit  per comments  some additional constraints that are important   linkage details  the linkage is a planar  one degree of freedom  part of a portable system  similar to a scissor lift mechanism   it is for a theatrical effect where the motion is amplified and force reduced  speed ratio and mechanical advantage are       power  it will be carried by a person  as such  the actuation needs to be battery operated  as no tubing or wiring can tether the person  tubing or wiring that is self contained is okay  because this is a portable system  battery power will be used  the control system will be designed specifically for an appropriate actuator  rechargeable batteries up to   v will most likely be employed  actuators could operate on as high as   v  ideally a motor would not exceed     amperes draw  but as it is not in continuous operation  this is not a hard limit  not pneumatic  i ve considered pneumatic actuation  using co  cartridges  for example  but the client would prefer not to use pneumatics  also  the ability to stop hold at intermediate points in the motion range is desirable  and somewhat more complicated to do with pneumatic actuators  speed  an ideal actuator will be able to move the input coupling    cm in     seconds  weight  weight constraints are not well defined  as it will be carried by a person  it should be moderately lightweight  the actuator itself should probably be less than  kg  but certainly this can vary   the rest of the mechanism will probably be     kg   size  the primary size constraint is that everything must fit within a space measuring no more than     x     x     mm  h x w x d   the linkage mechanism extends from and collapses outside the enclosure  parallel to the width  noise  the quieter the better  but noise is the least priority   servos seemed like the best choice for the job  but they don t seem to be available with the sort of torque i need  ,servomotor
3233,designing compatible spur gears for a robot gearbox,i m trying to increase the torque on the output shaft of my robot s gearbox   i have a motor with a pinion attached to it with   teeth   i want to create a gear with    teeth that will mesh with the pinion that i currently have   i ve got access to a  d printer to make the gear  but i don t know how to design the second gear so that it will mesh properly  what parameters do i need to know about the first gear    teeth  to ensure that the second gear     teeth  will mesh correctly   how do i translate these parameters into the design of the second gear  ,motor differential-drive
3234,robot interaction language,is there any well documented robot interaction language  i would imagine something like taking a user s speech in english  parsing it using some natural language processing like nltk or stanford nlp and then building a new sentence understandable by the robot  does something like this already exists  i recently found roila  but it seems like it is a whole different language and not just a reformulation of sentences using english words with less grammatical complexity  ,speech-processing
4238,i need a software that will help me track passage and identify fish in clear water,i am in charge of studying passage of different species of fish  six species  between lakes in patagonian andean range  we ve been thinking of deploying video cameras underwater  but we d need software that would control the cameras and record images only when the video adequately changes so as to avoid having to continuously check the video  if the software is also capable of recognizing the species that would even be better  ,software
4239,good method for retuning a pid after detecting oscillation,given a pid controller with an anti windup  what are some practical ways to retune the controller once oscillation has been caused and detected  i have access to the magnitude and period of the oscillation  i don t want to use the ziegler nichols method  rather i d like a method that allows me to specify a phase gain margin as i am returning the system   could someone recommend me towards a book article or theory  ,control pid
4247,tilt compensated motor output to keep altitude for quadcopter,the propellers of a multicopter produce thrust  unfortunately the thrust is the smaller  the more the copter is tilted  i was currently wondering whether there is an established method to calculate how much the overall thrust has to be modified to hold the current altitude  based on the current attitude  this is the way a calculate the motor output so far  rol pit yaw output already ran through the pids    ,quadcopter
4255,software to simulate mechanics of production line,is there any software where i can simulate production line elements  joints  motors  springs  actuators  movement   for example i want to simulate mechanism to unwind paper from big roll to weld it later with bubble foil and finally make bubble foil envelope  mechanism will look like this   i need it as simple as possible and preferably free  ,mechanism simulator
4256,imu based acceleration parameters for differential drive robot,i have a differential drive robot whose motors are virtually quiet while driving on a completely flat surface  but the motors make a lot of noise when on a incline  this is likely due to the correction required to maintain speed with the high inertial load where the robot cannot accelerate fast enough for the pid to keep up  but i noticed that some of the noise is related to acceleration  and the higher the acceleration  the smaller the amount of noise i hear  or the smaller the time the same level of noise lasts  up to a certain acceleration limit  otherwise the motors get really noisy again   i am trying to find out of how to use an imu that i have a available in order to change the acceleration based on how steep the path s incline is  any documentation  papers  tutorials  etc  about motion planning related to this topic that you can point me to  ,ros imu differential-drive noise
4261,stereo camera baseline not needed for calibration ,i am doing stereo camera calibration as described in this blog post  i wonder i do not need to input camera baseline for the calibration  the fact probably goes back to some very basic mathematics of triangulation  can someone explain  ,computer-vision calibration stereo-vision
4263,visibility graph toolbox for python,i m searching for a python toolbox library to do visibility graph based motion planning  i have searched on the internet  but couldn t find anything  i m probably missing out    is there any package  you can recommend me  ,motion-planning python
4265,determing limits of rotation in a robot workspace,how to determine the limit range of end effector orientation  roll pitch yaw  at one specific point xyz  i had derived forward inverse kinematic  i m making a program for  dof articulated robot arm so that the user can know the limit of tool rotation in global axis roll pitch yaw  at a certain point  ,robotic-arm
4266,are stereo camera calibration data standardized ,is there a standard format of how stereo calibration data  various matrices  usually saved in xml  are stored  can i load calibration data generated say from a opencv script in c to another opencv script say in c   or to completely different software where i create disparity image  ,computer-vision calibration stereo-vision
4270,solenoid to launch a ping pong ball,i ve been looking for ideas on how to launch a ping pong ball a small distance      metre  for a game  solenoids look like they might be useful but i m not      on what force type i need  i can mount it under a base and have the balls roll over it  with a pin pushing the ball up a ramp to it s target  as it s only a ping pong ball  it should be light  i was considering something like this   am i along the right lines  or should i go back to the drawing board  ,motor
4271,pd controller in c ,i am currently building a line following mobile robot  i ve done all my image processing work in c   and now i am in the control phase  i am looking for a pd controller program written in c  to start with  i ve searched a lot but without success  my robot is not an arduino based  it has a motherboard with a core i  cpu  and i am using a camera not an ldr sensor  ,control algorithm
4277,what is the difference between screw and wrench in rigid body motion ,a screw is defined by a six dimensional vector of forces and torques  it can represent any spatial movement of a rigid body  as written here   but i don t get the following distinction between screw and wrench    the force and torque vectors that arise in applying newton s laws to a rigid body can be assembled into a screw called a wrench    it seems to be some kind of contextualisation but in what way  ,dynamics theory
4281,what type of mechanism is this , held and rotated by the knurled ends  one in each hand  the silver spokes rise and fall in order for the assembly to rotate  what is it  some companies  salesmen show tool  found in an old building  unit has no markings  ,design joint
4285,sparse matrix in ekf slam,i ve successfully done with ekf localization algorithm with known and unknown correspondences that are stated in  probabilistic robotics   the results make perfect sense so i can estimate the position of a robot without using gps or odometry  now i ve moved to ekf slam with known correspondences in the same book  i don t understand this matrix   f  x j      begin bmatrix                    cdots                     cdots                        cdots                     cdots                        cdots                     cdots                        cdots                     cdots                        cdots                     cdots                     underbrace     cdots       j                    underbrace    cdots      n  j      end bmatrix   what is exactly the bottom of this matrix  the following  f  x j      begin bmatrix      cdots                     cdots          cdots                     cdots       underbrace     cdots       j                    underbrace    cdots      n  j      end bmatrix   is it as following  assuming n       f  x j      begin bmatrix                                                                                                                 end bmatrix   or   f  x j      begin bmatrix                                                                                                                 end bmatrix   where ones  represent a specific landmark   ,slam ekf
4287,kalman filter issue   gps odometry fusion,i am working on estimating a robots pose using odometry and gps  my first problem is that all kinematic model i have seen for a differential drive robot proposes using the displacement of the left and right wheels to evaluate the robots next pose  however  in my situation the robot i have only spits out current x and y pose relative to the starting point of the movement  can i use this as my state estimate p    x y t p    x  y      dx dy  where dx and dy are change in respective coordinates gotten from the robots odometry  if the above is posible how do i calculate the state covariance q of the filter  for gps  how do i evaluate the covariance r  i have tried to collect multiple reading of latitude and longitude from a fixed point but i dont know if this is righ and i just dont get evaluate the covariance from these data  feeling dumb   thank you in anticipation  ,mobile-robot kalman-filter gps odometry
4288,tilt compensated compass   at my wits  end,i m a bit at my wits  end here   i m trying to build a tilt compensated compass for my autonomous sailboat  ardusailor    i m using an invensense mpu      originally  i used the built in fusion support on the sensor to get a quaternion  pull the yaw pitch roll angles from that  and then use this formula to do the tilt compensation   where the various s angle is sin angle  and c angle is cos angle   that didn t work  i tried using a vector based approach stolen from here  that didn t work  then  i took away the tilt compensation  and just did an uncompensated atan  yh xh   and that produced very strange result as well   basically  as i rotate the sensor about the z axis  the value rotates between    and     degrees  completing a full circle  i e  as i make a     degree rotation  it starts at     gets to      and then back up to         is at about    magnetic     is at about        is at about        i see the same behavior from an hmc    l magnetometer chip as well  the thing is  looking at raw values  i get magnetic values that seem fine  and hard and soft iron offsets are in place   top row is corrected for offsets  using an ellipsoid fit method   bottom is raw  the numbers may look skewed  but they aren t   the scales aren t all the same  graphs are  in order  x y  y z  x z what could this be  ,compass magnetometer
4295,ekf localization when robot is in parallel with a landmark ,i m facing a real weird problem with ekf localization  the filer gives me wrong error every time the robot is in parallel with a landmark  i ve debugged the code many times but failed to solve the problem however i found out where is exactly the problem occurs  the following picture shows the scenario  the robot moves in a circular motion  there are four landmarks  i have indicted in the picture where the filer gives me wrong angle for the estimated state   as you see  when the robot is in parallel with all landmarks  i got a wrong angle for the estimated robot s pose    this is another picture shows how the estimated angle is wrong where the red circle is the estimated robot s pose and the blue one is the actual robot s pose    i did also track the problem numerically  what i found out is that the estimated measurement of landmark     is in the opposite direction of the actual measurement of landmark        and this is how i computed the angles   for the actual measurements  zobs              sqrt  map i      real robot          map i      real robot                             atan  map i      real robot     map i      real robot       real robot                                                                          i            add gaussian noise       zobs      zobs      sigma r randn         zobs      zobs      sigma phi randn         zobs      i   zobs      mod zobs       pi     if  zobs      pi    was positive     zobs      zobs        pi   elseif  zobs        pi    was negative     zobs      zobs        pi   end  for the predicted measurements q       map i      est robot          map i       est robot            zpre                                                                 sqrt q               atan  map i      est robot     map i      est robot       est robot                                                                                   i         if  zpre      pi    was positive         zpre      zpre        pi       elseif  zpre        pi    was negative         zpre      zpre        pi       end   ,localization ekf
4296,calculate object distance with camera,firstly i m unsure whether this question belongs here or on another se site  but i ll wing it for now   i ve recently been given the job of connecting up a  smart camera  to a setup where a robotic arm will pick and place objects from point a to point b  the real application for the camera is to check if the objects are out of alignment to their supposed positions  however i am curious to see if there is any way i can calculate the distance of an object given that i already know the objects actual size  naturally the camera will see the object as bigger when closer and smaller when farther away but how can i turn this information into depth distance from the camera  i have not yet started using the camera  for now it is just an idea  i will assume that i can calculate what percentage of the view frame is taken up by the object  for example if i have an object of uniform shape  i know that from dist  it takes up     of the view frame and from dist  it takes up     of the view frame   should this prove to be possible i imagine that it could have a number of different applications   anyway any feedback is appreciated  thanks      ,localization calibration cameras
4297,which micro controler processor to be used for autonomous stereo vision robot system ,i am very new two robotics  however i have a working stereo algorithm which i want to combine with a slam algorithm  i am developing this system for an other application but i decided integrating it on a robot first and testing it might be a good way to get used to the system and test its behaviour in a realistic environment   rather than testing it in some kind of software simulator only  however  i want the system to be autonomous and running on board of the rover   the system i am talking about will consist of  a stereo camera a rover with wheels with one motor each  possibly some kind of sensor that  measures  the movement  e g  how much the wheels turned maybe some distance sensor  appart from this it s only software the stereo software is already developed  the slam algorithm not  therefore it is currently impossible to say how much ram it needs  i am currently running the stereo vision only on an i  in approx   s  now my question  as mentioned i have no idea about robotics  and also my electronics knowledge is limited  so i have no idea what i need for this robot when it comes to the processor and the electronics   i read some stuff about the raspberry pi and arduino boards but i have no idea what to make from this  i am afraid that a arduino will not be able to handle the computational load of the stereo vision and the slam algorithm but i read that raspberry pis are not the first choice when interfacing with sensors is needed  in this case my stereo cameras   also i found the leika kit which is a robotics kit for the raspberry pi  maybe this would be a good option for me  maybe an entirely different system would be even more advisable   possibly someone else build an equally complex system before and can give me some advise form his her experience   ,arduino mobile-robot raspberry-pi slam stereo-vision
4299,arduino with two linear actuators  two acs    current sensors  and an l   n motor driver setup,i am using the l   n motor driver to drive two had  linear actuators    v each and a no load drive current of     ma each  linear actuator   motor driver  is a l   n dual h bridge motor driver controller board module for arduino robot i am also using a current sensor per motor to get feedback of what the motor is doing  only sensors i have available  but i can detect of the motors are moving or stopped   i am using two acs    current sensors  the supply voltage for each is    v to    v and supply current is   ma to   ma  current sensor  is an acs    current sensor  and here is the circuit diagram that i made for my actual setup  an arduino uno  two current sensors  to linear actuators  and one motor drive   circuit diagram    will this setup work  will i have enough current power coming out of the  v of the arduino to power both the l   n logic and the two acs    sensors  ,arduino control actuator current circuit
4303,autonomous obstacle detecting quadcopter,is it possible to build a quadcopter which can detect obstacles and thereby avoiding them in order to reach its destination  if so how could it avoid the obstacles and how can the destination be set ,quadcopter
4307,stepper does not turn,i always wanted to have a cnc to make pcb quickly at home   finally  i got a  x  kit from zentools recently and put it together  i attached a battery powered screw driver to  nd shaft of the stepper and moved the each axis all the way back and forward before wiring  all   axis moves smoothly  i can turn the steppers even by hand  every piece works smoothly  no mechanical jam  i decided to use grbl as controller software  tested the software without the shield or stepper  qv  testing grbl in arduino board without the steppers  i use universal gcode sender to communicate with grbl  i got an arduino cnc shield for arduino uno  put it together  attached to arduino uno  re tested grbl  it worked   i used reprep s stepper wiring article to connect stepper to the driver  wired   stepper to the stepper driver  x axis   powered the shield with   v     amp     w  dc regulated power supply   it was the power adaptor for an old     notebook  notebook died  i kept the adaptor  when the move   steps command  g  x   was sent  stepper makes a small move in the direction and then makes a grinding noise   can be seen on youtube   i tried switching  st pair s cables  using another stepper driver    drivers   turning the potentiometer to increase the current  but still no luck  i attached   photos of the cnc and the controller and controller unit  i tried everything i can think of  any suggestions    ,stepper-motor cnc
4308,what is the difference between the two different types of mecanum wheels ,while looking at mecanum wheels  i noticed that there are two different designs that are popular  one type holds the rollers in between the wheels frame  and the other holds the rollers from the center  is there a significant advantage to using one over the other  ,wheel
4312,low cost centimeter accurate satellite positioning  gnss gps ,i am looking for a cheapest possible gps setup with a centimeter precision without much hw hacking  i am not able to produce my pcb or do any soldering  though i would do that if there is no other way  so a kind of a easy to assemble setup would be welcome  i know about the      piksi thing but that is still too expensive for me  it seems like cm precision should be possible for much less   like employing a    usd raw gps sensor with an antenna and ordinary pc with rtklib software  i am not sure if it is better to use two gps sensor setup for rtk  one base station and one for rover  or whether i can get the corrective dgps data elsewhere  my region is czech republic   there seems to be national grid here allowing to stream correction data for reasonable cost   my application will be in a passenger car so i will not be limited with power source   no low power needed although that would be nice  i will be using the position readings within opencv   so i need to get the data into c c   code  the application is data collection so i can use raw gps post processing  ,gps
4313,pid integration over not constant dt   time ,is integration over not constant dt   time  a possible thing  let s say you have a pid loop with differentiating frequency  can the integral part of it still work   assuming you know the dt from the last iteration  could i just use a variable dt   time  in my calculation and the pid principle would still function correctly  ,quadcopter pid real-time
4316,compact design   building from off the shelf components,i want to build a small cylindrical arm  with a main      angular servo on the longitudinal axis  and a secondary angular servo with variable speed in a trasversal axis that rotates with the main angular one  the secondary needs to receive data and power from a slip ring across the main servo  since it must be able to rotate freely and must not be binded by wirings  the width of the cylindrical arm must be below     cm i ve reviewed the market for off the shelf servos and there are a few that could fit the bill for the main servo  i know where to obtain the slip ring required  but it beats me where to obtain the secondary servo  since the space limitations demand that it is really small        cm  and the smallest i ve been able to find on internet are     cm any suggestions are greatly welcome  ,servomotor
4318,cascading pid dc motor position   velocity controllers,i m trying to build a robot with a differential drive powered by two dc motors  first i implemented a pid controller to control the velocity of each motor independently  estimated the tf using the matlab s system identification toolbox  of the open loop system by the acquiring the velocity of each wheels encoder in function of the pwm signal applied by an arduino microcontroller  all went well and i successfully dimensioned the pid gains for this controller  what i m trying to accomplish now is to control the exact  angular  position of the dc motor  i thought in cascading a pid controller in the input of the other already implemented  so this way  i can give a position to the first controller  which will be capable of generate an output reference to the second  velocity  controller so it generates the appropriate pwm value signal to drive the dc motor accordingly  will it work  is that a good approach  or should i try to implement a different controller which outputs the pwm signal in response to a position reference signal  many thanks for your attention and i hope somebody can help me with these doubts  ,arduino control microcontroller pid wheeled-robot
4323,exoskeleton drive system help,i am currently working on an exoskeleton   the exoskeleton is going to help kids with cerebral palsy learn to walk   years sooner than traditional therapy   currently we are using   ame          with the roboclaw  x  a motor controller controlled by an arduino mega   the ame          motors are not powerful enough   in addition the ame          has a worm gear thus the motor cannot be moved when the motor is turned off   our position feedback system is a gear attached to the shaft of the motor which spins a gear on a potentiometer   the two gears have a     ratio    in order to better understand the project  please see the video    the ame          catalog page    we need a new drive system   more powerful than the ame          motor   we do not have an exact torque spec but we believe any drive system that is         more powerful than the ame               we like the rpm range of the ame           the drive system must be able to spin freely when the motor is not in use    we need a way to get position feedback  the potentiometer system we are using seems to work  however it adds to much extra hardware more stuff to break    ie  the gear on the potentiometer and the gear on the shaft have to mesh constantly and we have to zero the potentiometer every time we put the leg together so the potentiometer doesn t over spin     we would prefer to have an optical encoder inside the motor  we need to have the drive system be at a right angle   i need help designing a drive system that will meet the requirements    i think i might have found a motor that will work  the amp flow g        i like the g       because it can run at    v  thus it will take less amps than   v  will that motor get the job done  i need to gear this down to around   rpm   what type of gear box would work best  ,motor control microcontroller motion-planning encoding
4326,is there a rule of thumb for actuator torque overhead ,when installing a servo or other actuator  i measure the force needed to perform whatever action is needed and find an actuator that can generate more than the necessary force  however  i recently wondered if there s a rule of thumb or guideline for how much overhead is useful  before it becomes a waste  for a  perhaps oversimplified  example  say i have a lever to lift something  and the force needed is     newtons  an actuator that can manage     n maximum will have problems with this and stall  with any sort of friction or other imperfections  i would use an actuator that can produce     or     n   whatever is available and fits the design and budget  after testing  it may become apparent that     is overkill      is sluggish  but     is good  other than trial and error  is there a way to measure this  or a rule of approximation  i realize that variables in the mechanics and construction can significantly alter what force might is needed to be considered ideal  but is there a commonly accepted value for simple applications  something like  if you need x force  install an actuator with x       force   ,actuator force
4327,best technique to built an ejectable drawer ,i want to build a closet with ejectable drawers  on the top should be   buttons  each eject opening one of the four drawers of the closet   i am looking for ideas on how to accomplish this  what kind of springs  slider mechanisms perhaps  and other materials to use   any examples  ,motion
4329,how to machine aluminium on a low budget ,for my robotic projects i need some aluminium parts  currently i am looking for a way to build a chassis including simple gear box  so i need relatively high precision  which options do i have to machine aluminium without investing in expensive tools  this is what i could think of so far   design parts in cad and send them to a third party company for fabrication  the problem with this is that hobby projects almost never need large quantities and piece production can be still expensive  buy cheap tools to work aluminium by hand  i don t know which tools would fit this task best  moreover  the results might be inaccurate  which is a problem for designs with moving parts  find someone with a cnc who let s me machine my parts  this would most likely result in very slow prototyping cycles though   a method that i can do at home with not too expensive tools would be perfect  but i m looking forward to every solution  ,cnc chassis
4336,position control of an omni wheel drive robot,i want to create a robot that will navigate on a desired path  that path can be a straight line or a circular path with a given radius  i will use   or   omni wheel drive platform and for positioning  i am using this research paper which perform dead reckoning using mouse sensors  dead reckoning using mouse sensors i ve understood that i will get x  y and   positions  which are actual positions of robot  these can be used to calculate the error and then using pid to compensate the error  but  to find the error  i must have the desired position of the robot at that moment  for example  the robot is at       and it needs to move in a circular path of equation  x     y       y      now  i want to calculate the position at t     sec  how to do that  if someone has already done similar stuff  please post the link  i am not able to find any resource on web  ,mobile-robot pid kinematics wheeled-robot motion
4340,matlab for moving a robot towards the detected block,the matlab code is used to detect red colored object  but i want to control a bot to move towards the detected object  just need a simple algorithm or idea  controlling the servo i will be able to do it        ,mobile-robot microcontroller wheeled-robot robotc
4346,how to plot a line between two centroids in matlab, i am able to locate centroids of each blocks  but i am unable to join two blocks with a line segment by avoiding the obstacle as shown in the figure  please need help how do i achieve this using matlab  ,computer-vision motion-planning navigation matlab
4348,beaglebone uart spi i c latency,there seems to be consensus here that the beaglebone black has  ms  latency while toggling gpio pins due to the fact that gpio is handled outside of the cpu  are the uart i c spi lines equaly slow  or are they significantly faster  i ve seen references to people talking to the gpio more directly  could this decrease uart i c spi latencies as well  ,i2c beagle-bone
4357,device to roll a mat,i m looking for some direction on how to create a device that does the following  imagine you have a yoga mat  i want a device that can roll it up and unroll it without a human intervening in the rolling process  i reliable this is a robotics forums but there doesn t appear to be a section for mechanical engineering so i m posting my question here  ,motor mechanism
4359,diy laser cutter for small acrylic robot baseplate,need help to choose desk top  low cost  diy high school grade laser cutter for making base plate for diy robots  about maximum a  paper size  as this photo   idea  comment  advises  even if only partially cover some and not all questions  are welcome    what power is needed to cut acrylic   to  mm thick  many sellers at    to    watts range  what can these do  how cut thickness depends on cut speed  to what extend can i choose slow speed to cut thicker sheet  does cut thickness depends on color clear acrylic  it is co  laser   some units have options  like air blower and honeycomb bottom plate  what are their functions  what options are useful for this case  which cad  d drawing software is best supported by these range of products  apart from main function of cutting flat acrylic plate  some has additional z axis motor to rise lower work piece for engrave photo line letter marking on  d objects  what software is needed to support these  d operation   ,laser
4360,natural frequency computation  for pid gains computations ,i am currently trying to parametrize the low level gains of a robotic arm  this arm uses a classical pid for each joint  i am trying to use a method based on computation rather than a trial and error tweaking approach  the method i use considers each joint independently and assumes the system driven by the pid is linear  hence i infer a transfer function  a characteristic polynomial  poles and this gives me gains     and  for each joint  now  computed as i did  these gains depend on the natural angular frequency  for example   k p     a w    where  is the inertia and  is the natural angular frequency  hence my question  how shall i compute   the natural angular frequency for my system  is this an enormous computation involving the geometry and other complex characteristics of the robot  and that only a computer can do or are there simple assumptions to be made which can already give a rough result for   i guess this is a complex computation and this is one of the reasons why pid gains are most often found by trial and error rather than from computation  though i am looking for some more details on the subject to help me understand what is possible and what is not  kind regards  antoine ,control pid robotic-arm
4362,mechanical or electrical engineering for robotic and automation ,i have decided to pursue a career in automation and robotic  at the moment  i am being torn between mechanical and electrical engineering  i know that both of them relate to my choices of career  and at the moment  i think that i like them equally  i hope you guys can help me solve my dilemma by using your insights experiences to assist me with the following questions        from your experiences and opinions  which of the two engineering fields is generally more crucial and challenging  especially in an automation robotics project     which will see an increase in demand and importance in the near future  which of them might become outdated obsolete or at least develop at a slower rate compare to the other  i have a feeling that ee has a slight edge over this matter  however  i am not so sure     which of the fields is more versatile  which is more physical demanding  i am actually quite frail     which is generally easier to self study  robotics is obviously an incredibly broad and complex field and i have prepared to step outside of my comfort zone and do lots of studying by myself to achieve my goals and passion    i could probably come up with a few more questions  however  i am sure that you guys got the gist of my puzzle  thank you very much and i apologize if there is any grammatical error  ,beginner automatic
4364,denavit hartenberg parameters for scara manipulator,i m going through the textbook robot modeling and control  learning about the dh convention and working through some examples   i have an issue with the following example  given below is an image of the problem  and the link parameter table which i tried filling out myself  i got the same answers  except i believe there should be a parameter d  representing the link offset between frames   and    this would be analogous to the d  parameter    if anyone could explain why i might be wrong  or confirm that i have it right  that would be great  i hate it when it s me against the textbook lol   cheers  ,forward-kinematics dh-parameters
4366,pid in a system with pole at origin,i ve seen in a lot of places some methods of tuning a pid controller  most of them will say that one should apply a step input to the system and based on that response you can tune the pid parameters following some rule of thumb  but what about a system which one of its pole is at origin  in other words  a step response on a system like that will have an infinitely increasing ramp in the output  theoretically   an example  let s say we have a spinning wheel  fixed at center  and all we can control is the amount of torque applied to make it spin  if we can read its position  angle  and we want to design a pid controller to set its position  more or less like a step motor   how can that be done  note that a step input in this case will be a constant torque and this will make the wheel spin faster and faster  how should one proceed  ,pid
4369,artificial potential field navigation,i ve been working on my two wheeled mobile robot i ve been trying to perfect my obstacle avoidance algorithm which is artificial potential field method   also i use arduino uno kit   the basic concept of the potential field approach is to compute a artificial potential field in which the robot is attracted to the target and repulsed from the obstacles  the artificial potential field is used due to its computational simplicity  the mobile robot applies a force generated by the artificial potential field as the control input to its driving system   the artificial potential field method in its computations depends on the distance between robot and goal or target and the distance between robot and obstacles that effected the robot  which could easily get for ultrasonic senors  i applied the artificial potential field method in matlab environment   simulation and it is done successfully   really what i need in the simulation is to get the current position of mobile robot and position of goal as x  y coordinates  to compute the distance between robot and goal  and the obstacles positions  the output of the artificial potential field is the desired angle to avoid obstacle and reach to the goal   the method give the robot the angle the pointed to the goal then the robot goes toward that angle and if the robot face an obstacle in his way  got from sensor reading  the artificial potential field will update the angle to avoid the obstacle and then re give the robot the angle that pointed to the goal and so on  the question is how could i apply the artificial potential field method in real would  what should i get  is it easy to do that or it is impossible   i had rover   with two normal dc motors and two encoders  incremental rotary encoder  per each wheel  any help or suggestion on the topic will be highly appreciated please   edit  based on the response from shahbaz  the case is very simple  but first  there is something to know that i constrained with some limitations that i couldn t overstep them  one of them is that the real world should be exactly as simulation for example in the simulation i consisted that robot started with       on coordinates  x  y axis and i should put the goal point for example          and feed this point in the artificial potential field method and then compute distance between  robot and goal  so i don t need any technique to determine the position of goal  and i don t know if i could applied that  the second constraint is that i should use the encoders of wheels to determine the current position of mobile robot and its orientation depending on a calculation formula  something like this here  even if that will be inaccurate  i had a rover   with two normal dc motors and two encoders  incremental rotary encoder  per each wheel  each encoder has four wires i don t know how to deal with them yet  and how could i translate the pulses of encoders or how to work out the x y position of your robot based on the shaft encoder data  i am still searching for    ,mobile-robot
4370,rock syskit  how to add multiple instances of same component into a network,i ve been going through syskit tutorials at rock robotics org  in the tutorials e g  first composition  there are two different components declared with   i was wondering how could i add an additional rocktutorialcontrol into the composition  so that the instantiation would then create two separate instances of the same component  i ve tried something like add rocktutorial  rocktutorialcontrol   as     foo   but this apparently isn t the way to go  syskit instanciate command shows only one instance of rocktutorialcontrol  but gives two roles to it  rock and foo   what is the meaning of  role  in this context  i ve noticed that the tutorial explains how to make multiple instances of the same component when we re declaring our components as devices  but how to do this with components that should not be concerned as devices  br  mathias edit  this was my first question to stackexchange  and i don t know what s the policy for adding additional information to the original question  but here we go  it seems that both the deployment and configuration need to be different when there are two instances of the same component  i did a small scale testing with two components  using task library  foobar user  using task library  foobar proxy   module foomodule   class foocontrol   syskit  composition    add foobaruser  task   as     producer     add foobarproxy  task   as     proxy    add foobaruser  task   as     consumer      producer child connect to proxy child   proxy child connect to consumer child   end end  where foobaruser  task has an input   output port of  std string  foobarproxy  task has corresponding i o ports  foobaruser  task has also two configurations called  default  and  other   it also has two deployments  foo depl  and  bar depl   in order to create a  pipeline  where data flows producer     proxy     consumer  i made define line  define  conf and depl   foomodule  foocontrol use  producer     foobaruser  task use conf  other   prefer deployed tasks  foo depl     consumer     foobaruser  task use conf  default   prefer deployed tasks  bar depl     and then instanciated the network with  syskit instanciate scripts    nwtest rb conf and depl def   the component instanciation failed if either use conf or prefer deployed tasks clause was left out  in both cases the produced error was  cannot deploy the following tasks       multiple possible deployments  choose one with  prefer deployed tasks    ,rock syskit
4371,dynamic tracking precision of ur    ,i am willing to use a universal robot arm  ur    in a path following mode  i e  i have a desired trajectory for the robot s effector and i would like the effector to follow it as close as possible  the specs here give a repeatability of      mm  this is not written but i guess this is the static precision  after the robot had enough time to converge to the position   now what about the dynamic precision  i e  max position error while performing the desired trajectory   does anyone know more than me on this matter  kind regards  antoine  ,dynamics errors
4379,torque control and monitoring of servo,i am trying to control the servo motor operation by torque control by interfacing the sensor to an avr   which will continuously monitor the torque value from the sensor and control the torque according to the given set point  is it possible to make such a setup  if yes how  thanks  ,torque servomotor avr
4380,mechanism to oscillate a needle like object in vertical motion,i need to pop out a needle like object toothpick matchstick etc  from a hole in a surface and push it back in automatically i need to make a array of such needles in which each needle s position can be controlled individually the objects aren t supposed to be oscillated continuously  instead they are to be locked in one of the two positions either above the surface or inside it  i am trying to search a mechanism to achieve this this can be easily done with a simple dc servo motor  but the problem is i have to do this in very limited space about   such objects in base area of   cm x   cm moreover the power source would be dc    v so far i have thought of creating small electromagnets with springs but still not sure about it any inputs will be appreciated   ,mechanism
4384,translation the shaft encoder data,i am designing a robot in real world and i want to plot everything in x y  cartesian  coordinates  i just want to use the encoders of wheels to determine the current position of mobile robot and its orientation depending on a specific calculation formula  like this    even if that will lead to inaccurate calculations   actually   i found out this formula below to compute x  y coordinates from encoder data but i still confused in some sides of this formula    i had a rover   chassis form dagu with two normal dc motors and two encoders  incremental rotary encoder  per each wheel  how could i translate the pulses of encoders or how to work out the x y position of the robot based on the shaft encoder data  i deduced some of values from rover   chassis   cm   conversion factor that translates encoder pulses into linear wheel displacement dn   nominal wheel diameter  in mm    about    cm ce   encoder resolution  in pulses per revolution    encoder resolution       state changes per   wheel rotations n   gear ratio of the reduction gear between the motor  where the encoder is attached  and the drive wheel    gearbox ratio         in rover   chassis there are   small wires with female headers  red is   v for the encoder   black is  v  ground    white is signal a   yellow is signal b   the important wires in each encoder are signal a and signal b  so  how to get values of nl   nr  in the formula above from signal a   signal b   is the value of nl is the direct value from  wire signal a or signal b   the same question for nr    thanks a lot ,wheeled-robot quadrature-encoder
4385,it s worth to make a line follower using a raspberry pi and a web cam ,i wonder if this would be a competitive robot compared with one made with a traditional approach using a microcontroller and infrared sensors  i suppose that raspberry can perform an edge detection to tell the dynamic of the line far away  much more that the infrared sensor  but how fast can the raspberry do this process  should be a relative simple process in terms of computational requirements   an edge detection in a high contrast arena  probably the bigger issue would be get the relative position of the robot respect to the line  may be a combination of the camera with some infrared sensors would work better  and what about the size  the robot will be significantly bigger when is used a camera and a raspberry for the control  ,raspberry-pi line-following
4392,ekf slam and mahalanobis distance ,so far i have done ekf localization  known and unknown correspondences  and ekf slam for only known correspondences that are stated in probabilistic robotics  now i moved to ekf slam with unknown correspondences  in the algorithm in page                                                               i don t understand the line     in the book page      the authors state   line    sets the threshold for the creation of a new landmark  a new landmark is created if the mahalanobis distance to all existing landmarks in the map exceeds the value   the ml correspondence is then selected in line       what is  in line    and how is it computed  also  what is the mahalanobis distance  i did research about mahalanobis distance but still i can t understand its role in ekf slam    edit   i found another book in my university s library robotic navigation and mapping with radar the authors state   the mahalanobis distance measure in slam is define as     which provides a measure on   the spatial difference between measurement  and predicted   feature measurement   given by   d      m  z  j   k    hat z   i   k      z  j   k     hat z   i   k    t  s       k  z  j   k    hat z   i   k    this   value has to be calculated for all possible  combinations  for which   d  m  z  j   k   hat z   i   k    leq  alpha  often referred to as a validation gate   leave me to the same question what is   ,slam ekf mapping
4393,is a genetic alogorithm suitable for mobile robot path planning ,regarding my project work  i have to write an algorithm for mobile robot planning  for that  i have chosen genetic algorithm  is it good for mobile robot path planning  if it is  then where can i start from and get some guidelines  ,mobile-robot navigation algorithm
4394,single shaft vs double shaft motors,i am trying to make a line follower robot and i need help regarding the type of dc motor to use  so we have a single shaft bo motor and a double shaft bo motor  can anyone help me understand what is the difference between the two  here s the link for  single shaft bo motor   double shaft bo motor   ,motor line-following
4395,counts of quadrature encoder,simply  i had rover   with   dc motors and   quadrature encoders  i just want to use encoders to measure the distance of travelling for each wheel  to start with  i just want to determine the total counts per revolution  i read the article about quadratic encoder from this broken link  in rover    each encoder has four wires  red   v or    v   black ground   yellow  signal    and white  signal     i connected each wire in its right place on arduino uno board  using the circuit   rotary encoder channela attached to pin    rotary encoder channelb attached to pin   rotary encoder  v attached to  v rotary encoder ground attached to ground   for one encoder  i test the code below to determine the total counts or ticks per revolution  the first program by using loop and second by using an interrupt  unfortunately while i run each program separately  rotating the wheel     degree by hand  the outputs of these two programs was just  gibberish  and i don t know where is the problem   could anyone help  arduino programs posted below  first program   the second program  with interrupt  static long s  counter    static long s  counter     void setup       serial begin             attachinterrupt    write s   change      attach interrupt to pin       attachinterrupt    write s   change      attach interrupt to pin       serial println  begin test       void loop        void write s        s  counter      serial print  s  change       serial println s  counter      void write s        s  counter      serial print  s  change       serial println s  counter      ,mobile-robot quadrature-encoder
4396,ros navstack with skid steering robots,i am migrating from a differential drive design to a skid steering design for my robot  and i want to know how easy would it be to use the navstack with skid steering  would there be any problems in terms of localization and things like that  if i let two wheels on the same side of my robot  two on left side and two on the right side  maintain same velocity and acceleration  would the unicycle model of a differential drive robot still apply for skid steering  ,ros navigation differential-drive driver
4398,machine vision vs computer vision ,i m trying to understand the core differences between the two topics   is one simply a newer term   connotations of automobile vs automation   something with a screen vs without  i ve only ever heard the term   tagged   ,computer-vision
4399,what laser power for cutting and engraving wood and acrylic robot baseplates ,need to buy a diy high school grade laser cutter engraver   how much laser power is needed for wood  acrylic    to  mm thick   cutting and decorative engraving   what parameters i need to take care in selecting suitable machines    ,laser
4405,expression used with rotary encoders,while i am reading and collecting information about rotary encoders   i faced some troubles about the meaning of some expressions concerned with encoder  which make me to be confused and stray   these expressions or words are    count per revolution  rotation    pulse per revolution  tick per revolution  transitions per revolutions   number of transitions  number of state changes i thought the transition is same as state changes which means change from high to low or low to high   but what about the others what is the diffenece among them  count   tick  pulse  transition      etc   and what the relationship between transitions and pulse   could anyone clarify that   please ,mobile-robot
4409,quadcopter  stabilization along the z axis  for holding altitude ,i recently spent some work on my quadcopter firmware  the model is stabilizing its attitude relatively well now  however i noticed  that it is changing its altitude sometimes  maybe pressure changes  wind or turbulence   now i want to get rid of these altitude drops and found not much literature  my approach is using the accelerometer   calculates the current g force of the z axis if the g force is        g and longer than    ms  then i feed the accelerometer term  cm per s   into the pid the output is sent to the motors  the model now reacts when it is falling down with an up regulation of the motors  however  i am not sure  whether it is smart to feed the current acceleration into the regulator and i currently wonder  whether there is a smarter method to deal with sudden and smaller changes in altitude  current code    ,quadcopter multi-rotor
4410,programming the odometry of rover  ,i have started in the programming stage of my project   and my first step is to made and test the odometry of my rover   robot on arduino uno by using encoders to determine position and orientation   i wrote this code and i don t know if that code right or there are some mistakes   because i am novice to arduino and robotic field so i need for some suggestions and corrections if  there were    thanks a lot arduino codes posted below   ,mobile-robot
4413,arduino power supply,i want to power my arduino uno and i know i can do that either by connecting it with usb to pc or with dc power supply but i want to connect it with a battery source kindly see the image below  and i know its a silly question but how do i do it  the battery connector is not the regular dc jack but the one that s found in rc toys  so how do i power my arduino with that battery   and also how do i connect it with a dc power supply adapter to charge it once its discharged  please also mention the specifications of the dc power supply adapter that is to be used while charging this battery   ,arduino battery
4414,motor control using arduino raspberry pi,i m new to robotics  i would like to know if    output lines can be taken from an arduino or raspberry pi  ,arduino raspberry-pi
4415,virtual testing environment for drones,does anyone know of a robotics developer environment ideal for testing ai programs for drones  e g  quadrocopters  planes  helicopters  etc    i would like something like microsoft robotics developer studio that includes a virtual environment  such as an outdoor environment with gravity  wind  etc   to test out flight dynamics  i would like the options to add sensors to the virtual drone  such as gps  altimeter  gyros  etc  that the ai program can then use to steer the drone  ,quadcopter artificial-intelligence machine-learning
4420,why models are not perfect to represent robotic environments ,sebastian thrun says in his paper on particle filters that   no model however detailed fails to represent the complexity of even the simplest of robotic environment  what does he means by this  can someone please elaborate  ,localization theory
4424,comprehensive comparison of slam algorithms,i m looking for a research paper or series of papers that compare the performance of various simultaneous localization and mapping algorithms for rovers in a variety of real world environments   in particular  i m looking for computational speed  accuracy  compared to the real world environment  and memory   power efficiency metrics   is there a journal that regularly publishes experimental performance comparisons  ,slam reference-request
4426,how to filter vibration programatically ,i m working on a quadcopter  i m reading the accelerometer and gyro data out from the mpu     and using complementary filter to calculate the roll and pitch values  when the quad is on the floor  and the motors are turned on the roll values are    it is very messy  after minus five there is plus seven  i would like to filter out this too high low values programmatically but i have no idea how to do it  edit  at this moment i think the solution is the low pass filter  i ll let you know if it is successful or not  ,quadcopter accelerometer gyroscope
4427,free of charge robot magazine  journal  newsletter or similar,what free of charge robot magazine  journal  newsletter or similar publication are available    either geared toward technical professionals or the general public  ,untagged
4430,what would be a good heuristic to solving this ,the aim is to guide a bot from source  to goal g while passing through all the checkpoints    in any order                    g                 s                     one way to solve it would be to select one checkpoint as goal from current state and then guide the bot to it  then select the next checkpoint as goal and current checkpoint as source and guide the bot to its new goal  eventually guide it to the state g from the last checkpoint but this technique relies heavily on the order of checkpoints traversed  i would like to know if a good heuristic can be found to decide which checkpoint to go to next  ,artificial-intelligence
4435,computer vision using the freak local features descriptor   why overlapping fields ,i am currently studying the freak descriptor and i read the article published by its designers  it states that the aim was to mimic the retinal topology  and one of the advantages that could be gained is the fact that retinal receptive fields overlap  which increases the performance   i thought about it a lot  and the only explanation i was able to come up with is the fact that  looking at this problem from an implementation point of view  a receptive field is the ensemble of an image patch centred around a pixel  plus the standard deviation of the gaussian filter applied to this patch  the size of the receptive field represents the value of the standard variation  the bigger the size is  the more pixels will be taken into consideration when gaussian filtering  and so we  mix  more information in a single value   but  this guess of mine is very amateurish  i would appreciate it if someone could give an explanation from what goes on in the field of image processing computer vision neuroscience  ,computer-vision
4439,raspberry pi finer servo control,i m usig rpi and servoblaster to control servos  i ve set the   but i d like to decrease it to  us  i ve tried to set the step size to  us  but the servoblaster displays  invalid step size specified   i ve also tried to set the pulse width in micoseconds like echo       us    dev servolaster  it works  but it s unpredictabe  step size is set to  us   echo       us    dev servoblaster   motor starts spinnig echo       us    dev servoblaster   motor   smoothly   speeds up echo       us    dev servoblaster   motor s speed has not changed echo       us    dev servoblaster   motor smoothly speeds up  ok  assume that it can be changed by        but  echo       us    dev servoblaster   motor s speed has not changed   why   echo       us    dev servoblaster   motor speeds up  but   fastly   echo       us    dev servoblaster   motor   smoothly   speeds up  motor  turnigy aerodrive          esc  turnigy multistar   a any idea  ,raspberry-pi servos
4440,finding changes in environment using  d laser,i have known map of the environment   d occupancy grid map   i am trying to find if anything changed in environment using  d laser while navigating by using maximum likelihood of laser with known map   my question is how to know which measurements are corresponding to changes  my environment is not static and has some changes which is differs from known map  now i am trying to find which objects newly came into the environment or moved out of the environment using laser  ,slam mapping laser occupancygrid
4442,what is the technical name when robot wheels are aligned to perform spot turn ,i have a robotic simulator that enables a   wheel rover to perform spot turn  to prepare the rover to spot turn  i have to arrange align the wheels in such a fashion   what is the technical name of it  circular wheel arrangement  circular alignment   ,mobile-robot wheeled-robot wheel
4447,is there any advantage to velocity motion models over odometry motion models for slam ,i ve seen several examples of slam algorithms  ekf slam  graph slam  seif slam  written in terms of the velocity motion model   i have yet to see an example of any slam algorithm utilizing the odometry motion model   i wonder if there is an inherent advantage to using the velocity motion model over the odometry model for this problem   does it have something to do with the fact that odometry sensor information comes after the motion has already taken place  whereas velocity control commands are executed before motion  ,slam motion
4449,assumptions about the nature of landmarks in slam algorithms,i m trying to understand the role of landmarks in slam algorithms   i ve glanced over a few books concerning landmark based slam algorithms and i ve come up with a rudimentary understanding which i believe is flawed  how i think slam works  as i understand it  landmarks are a set of points in a map whose locations are known a priori    furthermore  the number of landmarks in a map is fixed   the number of landmarks detected at any one time may change  but the number of landmarks that exist in the map remains static at all times    my understanding is that slam algorithms exploit the fact that these points are both uniquely identifiable and known a priori    that is  when a robot senses a landmark  it knows exactly which landmark it detected and thus knows the exact location of that landmark   thus  a slam algorithm uses the  noisy  distance to the detected landmarks  with known location  to estimate its position and map    why i think i m wrong  in my naive understanding  the usefulness of slam would be limited to controlled environments  i e  with known landmarkds  and completely useless in unknown environments with no a priori known landmarks   i would presume that some sort of feature detection algorithm would have to dynamically add landmarks as they were detected   however  this fundamentally changes the assumption that the number of given landmarks must be static at all times    i know i m wrong in my understanding of feature based slam  but i m not sure which of my assumptions is wrong    do feature based slam algorithms assume a static number of landmarks    do the landmarks need to be known a priori   can they be detected dynamically   and if so  does this fundamentally change the algorithm itself  are there special kinds of slam algorithms to deal with unknown environments with an unknown total number of landmarks in it  ,slam
4456,pulse position modulation as used in rc controls,how are several channels multiplexed down to a single physical wire  if two channels are transmitting the same value in the same frame  wont there be an overlap of the pulses  ,rcservo pwm
4463,choosing motor for a tricopter,i m a newbie in rc field  i am planning to construct my first tricopter ever   can anyone help me to find the power rating to select the motor for a tricopter  i am at the beginning stage of construction   arm length of frame    cm each   i need a thrust of about  kg    nearly     gms for each motor  ,motor
4465,what s the difference between yaw and attitude in quad rotor,i have a big miss conception between yaw and attitude    isn t both represent  how far is the quad from earth     also if you could post how to calculate them from imu  gyro  accele   magent    ,imu
4467,need to clear some concepts  ahrs   attitude   yaw pitch and roll   marg sensors  ins,it s been while since i started reading about ins  orientation and so for quadrotors    i faced the following terms   ahrs   attitude   yaw pitch and roll   marg sensors i know for example how to calculate yaw pitch and roll   but does it related to attitude    what s attitude  any way and how it get calculated   ahrs  attitude and heading reference system  does it formed from yaw pitch and roll    marg magnetic  angular rate  and gravity    how it s related to other terms    what about ins   inertial navigation systems      my questions here are about these concepts  and there meaning   how they cooperate with each other   how they got calculated and which sensors suits for what   ,navigation
4469,image size vs image resolution,i read somewhere that in the case of photoshop for example  the size refers to the number of pixels an image contains  but resolution involves the pixel s size  i don t know whether this definition goes for all the other fields  in computer vision  what s the difference between image size and image resolution  ,computer-vision
4472,how to make mac detect avr board using usbasp and burn program to it ,i am new to embedded  starting with avr programming using c  i am working on mac os         so far i am using avrdude and xcode as ide  it works very well  for now i am testing my code using proteus  but now i want to burn my  hex to avr atmega   board  i have usbasp  which i am able to connect and it lights up the board  now after searching on the internet  i think mac is not detecting my board  i have checked  dev directory  but no usb device found   so i am not sure what to next  how to make mac detect my board and burn my  hex on it  i ve found this   but no idea how to use this or its required or not  so question stand is  how to make mac detect avr board using usbasp and burn program to it  fyi  i ve installed crosspack on mac   ,usb embedded-systems avr
4474,servo controlled valve,i am trying to build a servo controlled water valve   max pressure     psi   valve size       can anyone recommend a suitable     turn valve  either ceramic  ball valve  or anything else that is easy to turn  even under pressure  it must require very little torque to turn  so a standard servo can rotate it with a small lever attached  ,servos valve
4476,quadcopter one beep and blink problem,i have just built my first quadcopter  and have run into a bit of a snag  when i plug in the power  i only get one beep and a red blink from the flight control board  and nothing else happens  when i turn on the controller  however  a red light turns on on the reciever  otherwise  nothing else happens  from what i can tell  i have plugged in everything correctly  and am not sure how to proceed   flight control board flight control board manual  pdf  esc s  i do not have a connection from the power distribution board to the flight control board  because i am assuming that it gets its power from the esc s  here is the video i used to figure out how to build a quad    side  note about the video  i have not cut the esc s cords as done in the guide  seemed like a silly step  also i have seen other applications where they were not cut  i have not updated the firmware on the board  i have put it in out of the box here is the board s user manual  pdf  ,control quadcopter
4477,how to calculate altitude from imu ,how to calculate attitude from imu    for example  mathematical equations  ,imu
4486,ackerman steering model,i am trying to create a simulation of a robot with ackerman steering  the same as a car   for now i m assuming that it s actually a   wheeled robot  with two wheels at the back  and one steering wheel at the front   knowing the wheel velocity  and the steering angle a  i need to be able to update the robot s current position and velocity with the new values at time t    the obvious way to do this would be to calculate the position of the centre of rotation  where the axles of the wheels would meet  however  this leads to an undefined centre of rotation when a      this means that the model doesn t work for the normal case of the robot just driving in a straight line  is there some other model of ackerman steering which works over a reasonable range of a  ,mobile-robot simulation
4487,relative navigation systems,im trying to develop a system that autonomously navigates a large outside space  where accuracy is vital  gps is too inaccurate   there are a number of options but have largely been used inside  has anyone tried these or used anything else  wifi triangulation  dead reckoning  rfid landmarks ,navigation
4488,what s the most adapted programming language for robotic and principally ai ,i m currency a web programmer and i m very passionate by robotics and specialty for artificial intelligence   i have already make some c   program for microship and arduino for little robots and other lisp codes  example for labyrinth path search  but i think it s not really applicable for projects further   i have read a lots for artificial neural network to create artificial mind  but it s very theoretical and i have no idea to reproduce that on code  someone have a idea to help me  a specific language  or just a c   library    if you have some links  articles  or other tutorials i take it  thank a lots   ,artificial-intelligence programming-languages
4489,how to calibrate an imu unit ,simply   how can i calibrate imu unit    i read some papers about this topic and was wondering if there are any standard methods  ,imu
4492,dc motor control   speed torque curve,i am having some trouble understanding how to practically use the speed torque curve of a dc motor  i understand that the gradient of the speed torque curve is defined by the design of the motor  the exact position of the curve depending on the voltage applied  so if the voltage is changed the speed torque curve is also changed but remains parallel to the initial curve before the voltage was changed  see figure below   so my intuitive guess is that when using the motor at a given desired operation point  desired speed and desired torque   the corresponding speed torque curve cd has a gradient specified in the data sheet of the motor and passes through the operation point  this curve cd is obtained at a corresponding voltage vd  see diagram below   so my next guess is that in order to have the motor operate at this desired operation point  you have to set the voltage applied to the motor to vd  and apply a current id  computed using the torque and the torque constant   now from what i read this is not what is done in dc motor controllers  these seem to only drive the motor using current and some sort of pwm magic as is shown in the following diagram by maxon   anyone knows why voltage is not used in dc motor control and only current is  i do not understand how you can set the speed if you do not modify the voltage  and what is pwm useful for  i have looked for hours over the internet and could not find anything relevant  thanks  antoine  ,motor control
4496,how to get pure end effector translation through jacobian ,i have a   dof arm that i am controlling with joint velocities computed from the jacobian in the standard way   for example     large j     begin bmatrix  j p   j o  end bmatrix    j   dagger    j t jj t          dot q   trans    j   dagger  p v  e  trans      dot q   rot    j   dagger  o v  e  rot      dot q     dot q   trans     dot q   rot   however  when specifying only translational velocities  the end end effector also rotates   i realized that i might be able to compute how much the end effector would rotate from the instantaneous   then put this through the jacobian and subtract out its joint velocities    so i would do this instead of using the passed in    v  e  rot      r q    r q  dot q   trans    where  computes the end effector rotation for those joint angles    is this ok to do  or am i way off base   is there a simpler way    i am aware that i could also just compute the ik for a point a small distance from the end effector with no rotation  then pull the joint velocities from the delta joint angles   and that this will be more exact   however  i wanted to go the jacobian route for now because i think it will fail more gracefully  a side question  how do i compute  to get global end effector angular velocity   my attempts at converting a delta rotation matrix to euler angles yield wrong results   i did some quick tests and implemented the above procedure to achieve pure end effector rotation while maintaining global position    this is easier because  is vector subtraction    and it did kind of work  ,kinematics robotic-arm jacobian
4498,robot loud alarm,we are working on a project where we want to sound an alarm if somebody is messing around with our robot  e g   the robot is being shaken abruptly or the cameras lidars are blocked   i am using  loud speakers       x   inch    watts   ohm speakers   but they are not loud enough  are there any small speakers or alarm systems small enough  but loud enough  closed to a car alarm  that you would recommend   ideally something that i can just plug into the robots computer  or interface with through a microcontroller  either one would be fine  ,microcontroller ros navigation
4504,quadcopter cannot balance ,i am bulding a quadcopter using these compenents   microcontroller  tiva c lanchpad  arm cortex m       mhz   but running at   mhz in my code mpu        sensorhub ti esc   hobbywing skywalker   a  i use the sample project comp dcm from tivaware and use that angles for my pid which running at    hz i test pid control on   motors  but the motors oscillate as in the video i found on youtube from one guy  quadcopter  unbalance ,quadcopter
4510,which type of camera should be used for detecting road lanes for good processing in matlab,what are the parameters which should be selected to choose camera for lane detection system what parameters should be kept in mind  like picture quality frame rate cost e t c   which camera will suit best to my application  ,cameras
4511,euler angles from  dof imu,using the adafruit  dof module i need to convert the accel   magneto   gyro into euler angles for a motion capture application  any hints on where to start  managed to get x y z when the imu is facing upward but when that orientation changes the axes dont behave normally that is because i am not using euler angles  so any hints to any reference where to start  the euler compass app is an example of what i am trying to get to  get pitch yaw  roll for the imu module irrespective to how its kept  ,imu
4513,whats the logic to implement a particle filter for a robot with range sensor ,i am trying to implement a particle filter for a robot in java  this robot is having a range sensor  the world has   obstacles     in the top and   in bottom  i am calculating the distance of the robot from each obstacle s center and then performing the same activity for each particle  then  i calculate the difference between the robot and particles  the particles for which the difference with robot measured distance are small  i give them higher probability in resampling  but  the problem with this approach as told by my friend is that i am assuming that i already know the locations of the obstacles  which make this all process useless  how should i approach it rather in a sense that i don t know the obstacles  how can the particle filter be implemented then  how will the particle filter work in case i don t know the obstacles location  an example of process would be great help  thanks  ,localization particle-filter
4514,pledge algorithm for maze solving robots,i saw this maze  and tried to apply pledge algorithm on it  but i am not able to solve this maze using this algorithm  what am i missing  i want to ask  what i am doing wrong  pledge algorithm  in both cases we don t get to exit   you can read about these algorithms at    ,mobile-robot
4516,how can one create a robot which respondes to input following a flowchart ,what are the most basic skills and components needed for creating a robot which gets two  yes  or  no  inputs with two push buttons  and goes down the defined flowchart and plays the relevant audio file each time it gets an input  a flowchart like this   ,microcontroller
4520,correcting gps track with visual odometry  sensor fusion ,i am trying to build low cost and precise outdoor positioning  i explored ns raw with rtklib   this would be doable but probably will need either a base station to get the correction data for rover or external correction data which may be a hassle  the action radius with own base station is quite limited too  this solution is not really straightforward while you have to deal with either in house or streamed correction data  i am wondering whether one would be able to substantially improve the accuracy of an ordinary  uncorrected  gps glonass device  maybe one found in a common smartphone  with stereo visual odometry  today s consumer gnss chips seem to have reasonably stable accuracy in the  m range  the viso   library has a translation error of about    on    m distance  the idea is to use the visual odometry for  smoothing  the rough gps track   the question is how this can be technically done in terms of sw  the input would be two tracks   one from gps device and the other viso   library  i think i need a kind of filter that will fuse the sensor data to get greater precision  ,computer-vision gps sensor-fusion odometry
4523,ensemble kalman filter slam,i know that there is an extended kalman filter approach to simultaneous localization and mapping   i m curious if there is a slam algorithm that exploits the ensemble kalman filter   a citation would be great  if at all possible  ,kalman-filter slam reference-request
4526,pid tuning quadcopter problem,i am tuning pid for quadcopter  the problem i have is that with different base throttle  i seems that i have to adjust different pid gains in order for the quadcopter to balance   ,pid
4531,purpose of programming an esc,i am planning to buy an esc for my tricopter setup  what is the purpose of programming an esc  i am cost effective and is it really necessary that i should necessarily buy a programming card to program my esc for my model  ,esc
4533,  v arduino dual bridge to supply at least  a,i am looking for a   v dual motor controller that can supply at least  a per channel for two   v motors  and that can be used with an arduino  do you know of any product with those specs  thanks ,arduino motor ros h-bridge
4536,yaw angle calculation for drone pid from two distance sensors,i m building a control system with a parrot ar     drone where i have access to thrust controls for up down  z   left right  y   forward backwards  x   turn left and turn right  yaw  through a ruby library on my computer  the goal of the system is to keep the drone a particular distance from and parallel to a wall while moving in the up down and left right directions  we have added two sonar distance sensors to the left and right forward props   the main problem i am having is figuring out how the two distance sensors equal a yaw reading     so i can feed that into the pid and then take action on thrust to the turn left or right for correction  maybe just getting some help with the conversion from two distances to the yaw angle would be a big help  but any thoughts on the pid are greatly appreciated too since it is my first time working with it  ,sensors quadcopter pid
4540,can we use this line sensor as a proximity sensor ,i have an rsl line sensor which is designed to distinguish black and white lines  it detects white surface and gives me digital   as output  with   in case of black  but the surface needs to be close to it  as it uses infra red sensors  i wanted to use this sensor as a proximity sensor  to tell me if there is a white surface near it  is it possible to do this  i think the only problem here is that we need to increase it s range of giving    currently  it gives   only when white surface is too close to the sensors  i want   even if the white surface is there at a bit more distance  also there is an adjustable screw there to adjust something  under which pot is written  i am working with an arduino  ,arduino mobile-robot sensors
4542,velocity derivatives using quaternions,how to compute the angular and linear velocities quaternions  i am new to this area and although i have studied the algebra i am unable to understand how to compute the velocities  ,kinematics
4545,how to control an arduino board with wireless ps  controler ,i m currently building a hexapod bot  composed with an arduino mega board and an usb ssc     from lynxmotion   but now i want add a ps  wireless controller to move my hexapod  i have made some search but nothing realy interesting  maybe the servoshock module but it seems works only with the servoshockshield  a kind of arduino card with servo output    can i use the servoshock module alone    can i connect it with rx tx port of the arduino mega board   do you have other solution for me   board with documentation and sources codes    thank you all ,arduino wireless
4546,what are the calculations for a badminton robot and mechanisms ,i am designing a badminton robot but i am very confused about mechanisms needed for a badminton robot and various calculations needed for millisecond response i am also confused about calculations needed about the forces needed and efficient angles needed for hitting the shuttlecock please suggest me some ideas or suggestions needed for construction of badminton robot  ,sensors design mechanism actuator servomotor
4554,using kinect for medical application but without computer  is it possible ,i have to use kinect for an application  however   the final work must be mobile  it means no computer  consequently  i thought using a microcontroller to handle data from kinect  but is it possible  my job is mesuring some points of a body  axis x  y  z  and get back these coordinates  i don t know if i m enough accurate   ,microcontroller kinect
4555,reverse lift mechanism,i have made a rc robot from a wheelchair and i m planning to attach a snow plow  i m wondering if there is any mechanism that would be able to lift the plow when reversing   i have only   channel transmitter so i can t control the plow s movement through it so i was thinking of some mechanical lift that triggers when reversing  do you guys know about something i could use for it  thanks  ,wheeled-robot mechanism
4558,pd algorithm for a quadrotor  simulation ,i have a big problem trying to stabilize a quadrotor with a pd controller  the model and the program has been written in c   and the model dynamic has been taken from this source in internet   well  in my code i wrote the model like in the eq  system   see eq       on page       where body ang current  angle  and body pos current   position  are structures defined in a class to store position  velocities and accelerations of the model given the   motor velocities about all   axis    large  cases     ddot x      sin  psi   sin  phi     cos  psi   sin  theta   cos  phi    frac u    m    cr   ddot y      cos  psi   sin  phi     sin  psi   sin  theta   cos  phi    frac u    m   cr   ddot z     g     cos  theta   cos  phi    frac u    m   cr   dot p     frac i  yy    i  zz   i  xx  qr    frac j  tp   i  xx   q  omega    frac u    i  xx    cr   dot q     frac i  zz    i  xx   i  yy  pr    frac j  tp   i  yy   p  omega    frac u    i  yy    cr   dot r     frac i  xx    i  yy   i  zz  pq    frac u    i  zz      once i get the accelerations above i m going to integrate them to get velocities and positions as well     get position and velocities from accelerations    body pos current  x dot   body pos current  x dot     real duration   body pos previous  x dot  body pos current  y dot   body pos current  y dot     real duration   body pos previous  y dot  body pos current  z dot   body pos current  z dot     real duration   body pos previous  z dot   body ang current  phi dot     body ang current  phi dot       real duration   body ang previous  phi dot  body ang current  theta dot   body ang current  theta dot     real duration   body ang previous  theta dot  body ang current  psi dot     body ang current  psi dot       real duration   body ang previous  psi dot   body pos current  x         body pos current  x dot     pow  real duration          body pos previous  x dot   real duration     body pos previous  x  body pos current  y         body pos current  y dot     pow  real duration          body pos previous  y dot   real duration     body pos previous  y  body pos current  z         body pos current  z dot     pow  real duration          body pos previous  z dot   real duration     body pos previous  z   body ang current  phi           body ang current  phi dot       pow  real duration          body ang previous  phi dot     real duration     body ang previous  phi  body ang current  theta         body ang current  theta dot     pow  real duration          body ang previous  theta dot   real duration     body ang previous  theta  body ang current  psi           body ang current  psi dot       pow  real duration          body ang previous  psi dot     real duration     body ang previous  psi      copy the new value into the previous one  for the next loop     body pos previous  x   body pos current  x  body pos previous  y   body pos current  y  body pos previous  z   body pos current  z   body pos previous  x dot   body pos current  x dot  body pos previous  y dot   body pos current  y dot  body pos previous  z dot   body pos current  z dot   body ang previous  phi     body ang current  phi  body ang previous  theta   body ang current  theta  body ang previous  psi     body ang current  psi   body ang previous  phi dot     body ang current  phi dot  body ang previous  theta dot   body ang current  theta dot  body ang previous  psi dot     body ang current  psi dot   the model seems to work well but  as like reported in many papers  is very unstable and needs some controls  the first approach for me was to create a controller  pd  to keep the height constant without moving the quadcopter  but just putting a value  for example   meter  and see how it reacts  here the small code i tried     pd controller    double e           body pos current  z            is just a try value    thrust  esum   thrust  esum   e  thrust  total         e         real duration   thrust  esum   the problem  as you can see here in this video  is that the copter starts falling down into the ground and not reaching the desired altitude      meters   then it comes back again again like a spring  which is not damped  i tried already many different value for the pd controller but it seems that it doesn t affect the dynamic of the model  another strange thing is that it goes always to a negative point under the ground  even if i change the desired height  negative or positive   what s wrong in my code   could you me please point to some documents or code which is understandable and well documented to start  thanks edit  many thanks to your suggestion  hi was really surprise to know  that my code had lots of potential problems and was not very efficient  so i elaborate the code as your explanation and i implementers a rk  for the integration  after i ve read those articles  here and here i got an idea about rk and its vantage to use it in simulations and graphics pc  as an example i rewrote again the whole code     calculate the acceleration about all   axis    pos  dvel x        thrust  total   masse         sin  body position  angle theta     cos  body position  angle phi     cos  body position  angle psi     sin  body position  angle phi     sin  body position  angle psi        pos  dvel y        thrust  total   masse        sin  body position  angle phi     cos  body position  angle psi     cos  body position  angle phi     sin  body position  angle theta     sin  body position  angle psi        pos  dvel z        thrust  total   masse         cos  body position  angle phi     cos  body position  angle theta                pos  domega phi       torque  phi     jxx     pos  domega theta     torque  theta   jyy     pos  domega psi       torque  psi     jzz         get position and velocities from accelerations    body position    rkintegrate  body position   real duration     which is much more clear and easy to debug  here some useful functions i implemented  quadrotorcontroller  state quadrotorcontroller  evaluate  const state  initial  const derivative  d  double dt      state output  output position x   initial position x   d dpos x   dt  output position y   initial position y   d dpos y   dt  output position z   initial position z   d dpos z   dt   output velocity x   initial velocity x   d dvel x   dt  output velocity y   initial velocity y   d dvel y   dt  output velocity z   initial velocity z   d dvel z   dt   output angle phi     initial angle phi     d dangle phi     dt  output angle theta   initial angle theta   d dangle theta   dt  output angle psi     initial angle psi     d dangle psi     dt   output omega phi     initial omega phi     d domega phi     dt  output omega theta   initial omega theta   d domega theta   dt  output omega psi     initial omega psi     d domega psi     dt   return output       quadrotorcontroller  derivative quadrotorcontroller  samplederivative  double dt  const state  samplestate      derivative output   output dpos   samplestate velocity  output dvel x   pos  dvel x  output dvel y   pos  dvel y  output dvel z   pos  dvel z   output dangle   samplestate omega  output domega phi     pos  domega phi  output domega theta   pos  domega theta  output domega psi     pos  domega psi   return output       quadrotorcontroller  state quadrotorcontroller  rkintegrate  const state  state  double dt      const double c       f  const double c       f  a        f  const double c       f  a        f  a        f  const double c       f  a        f  a        f  a        f   const double b       f    f  b       f    f  b       f    f  b       f    f   derivative k    samplederivative     f  state    derivative k    samplederivative  c    dt  evaluate  state  k    a    dt      derivative k    samplederivative  c    dt  evaluate  state  k    a     k    a    dt      derivative k    samplederivative  c    dt  evaluate  state  k    a     k    a     k    a    dt       const derivative derivativesum   k    b    k    b    k    b    k    b    return evaluate  state  derivativesum  dt       now i m really lost because   because the simulated qudrotor has the same behavior as before  nevertheless i ve implemented the same pd algorithm as discussed in the paper  it stabilize on z  height  but it get really crazy due to unstable behavior   so    i dunno what is wrong in my code and my implementation  and above all i cannot find any source in internet with a good self explaned dynamic model for a quadrotor  regards ,control quadcopter
4562,non linear complementary filter on so   corrected equations ,while reading the paper  multirotor aerial vehicles  modeling  estimation  and control of quadrotor  by mahony  kumar and corke  i stumbled across the following equations for a non linear attitude observer  which i would like to implement  but i believe there is something wrong   where  and  are etimates of orientation and gyroscope bias   are measurements and  are scalar gains  which may be set to   for measurements that are not evailable  now  and  need to be matrices  due to their definitions   and thus  need to be vectors   but then what is the correct version of the second equation   ,control quadcopter
4568,what is a pid as is related to quadcopters,i m trying to make a quadcopter from scratch  i have a fair amount of experience with adruinos  and i m trying to understand how to necessary systems work  and i can t seem to figure out what pid means  is it a method of regulating pitch and roll  like a stabilizer  i think from what i ve read that its a system that detects orientation of the craft and tries to correct it ,arduino quadcopter microcontroller pid beginner
4569,are consumer grade cnc machines capable of cutting tile ,i d like to slice and dice floor tile into pieces so i can arrange it in geometric patterns  i have cad designs for the parts  would any consumer grade cnc machine be capable of doing the job  ,cnc
4573,laser beam based model probability in case of single particle,i am trying to calculate likelihood of laser scan   at give pose   with known map    using beam based model      my scan has     rays i e   when i calculate  it becomes zero as multiplication all propabilities   in ros amcl they are using ad hoc which works better like  later they normalise it with number of particle to get weight of each particle  my query is how to get probability normalised and not zero with single calculation  i e image in case of single particle  thanks  ,mobile-robot slam laser probability
4575,use linear quadratic regulator to minimize output error,i would like to create an infinite horizon  continuous time lqr with a cost functional defined as j    int      infty  left  e t q e   u t r u  right  dt where e is the states  error   but i have trouble concluding to the appropriate ricatti equation since  is a function of time therefore leading to a term of    is this problem solvable  any ideas  ,control
4577,can t read current on pololu dual mc      motor driver shield for arduino,i purchased a pololu dual mc      motor driver shield for arduino  and for some reason i cannot read current from the motor controller  on the serial println   it just prints weird data  garbage   and when i use ros  robot operating system  i only see       minus zero  value for both motors  all i ve done is plug the shield on my arduino uno r  model  and run the demo that comes with the sample library       how can i fix this issue  ,arduino ros actuator stepper-driver current
4578,kinect   development kit to aid obstacle avoiding robot ,some friends and i are interested in working on a robot  i know little to nothing about robotics  but do have a lot of experience with programming  before we start  i am hoping that i can find some development kits or libraries that will help aid the goals of the robot  which are   robot needs to move from point a to point b  while moving  it needs to detect rocks  approx    foot diameter  on ground  it needs to detect rocks that are big enough to stop it  turn away from them  and proceed    in theory  we will want to detect the kinect s angle via the accelerometers  and use that data to obtain cartesian coordinates of the ground from the kinect s sensors  later  we will want a way to assemble a  map  in the robot s memory so that it can find better paths from a to b  right now we aren t concerned with the motors on the robot   only the vision element  ie  i am not really interested in software that interfaces with the motors of the robot  only only something that interfaces with the kinect   ,computer-vision kinect
4579,quadrature encoder counts,actually   i have been since two weeks looking for convinced and final solution for my problem   actually i am completely lost   i am working on mobile robot  rover    with   motors     encoders   the controller that designed to the robot needs to know the odometery of mobile robot  x  y  heading angle     actually i am trying to function the encoders for this purpose   getting x  y  heading angle by measuring the traveled distance by each wheel   so to get the x  y  heading angle values   i should compute a accurate readings without missing any counts or ticks as could as possible   the problem now is   in the code in the attachment   while i am testing the encoders counts   i noticed that there is a difference between counts of encoders even when they spin in the same constant speed  pmw    the difference increases as the two motors continue   so i thought that is the main cause of inaccurate odometery results   in the output of the code  in the attachment also  the first two columns are right and left motors speed   the third   forth columns are right and left encoder counts   the fifth column is the difference between two encoders count   as you could see  that even when the speed of two motors are approximately the same  each motor feed up with     pwm  there is a difference in the encoder counts and as you could see that the difference become big and big as the motors continuing spin   one thing i thought that sending the same pwm value to two different motors will almost never produce the exact same speed   so i think that i should detect the absolute motion of the motors and adjust the power to get the speed distance   but when i test the speed of motors after feed them with     pwm at same time   the two speeds were almost identical   but i noticed that there is a difference between counts of two encoders even when the motors spin in the same constant speed   actually   i don t know where is the problem   is it in the code   is it in the hardware   or what   i am completely lost   i need for patient someone to help   the result                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ,mobile-robot wheeled-robot quadrature-encoder
4580,linear slider motor mount location   pros cons,i m currently designing a linear camera slider  that will be used to hold camera equipment weighing just about    kgs including all of the lenses and monitors and everything else   for those who don t know what a camera slider is  it s a linear slider on top of which a camera is mounted and then the camera is slided slowly to create some nice footage like this  the problem now  looking at the commercially available camera sliders out there  there seems to be two ways in which the motor maybe mounted on these sliders   motor mounted on the side   motor mounted directly on the carriage    i would like to know which option would be optimal   performance wise  this slider maybe used vertically too  to create bottom to top slide shots   efficiency wise and  which one of these two will be resistant to motor vibration  these motors vibrate a lot  the effects of which may sometimes leak into the produced footage   additional questions  motor mounted on the carriage directly maybe  just maybe more efficient  but it also has to carry it s own weight in addition to the   kg camera load  pulling force is greater than pushing force  i have no idea why  would be great if someone explained why  atleast in this case    so a motor mounted in the end should be able to lift vertically with ease  does a belt setup as shown in the first figure above really dampen the motor vibrations  will won t the motor vibrating on the end get amplified  because  the whole setup will be attached to a single tripod in the exact center of the slider  which design will be less stressful for the motor  taking inertia into consideration for both cases  which one of these designs will be best suitable for vertical pulling of load against gravity   manufacturers use both designs interchangeably  so it s hard to predict which design is better than which  any help would be much appreciated  please note  this question has been migrated from the stackexchange physics  and electrical  forum by me because the mods thought it would be appropriate here  ,control design stepper-motor motion
4583,what are some low cost alternatives for lidar ,it need not be as effective as lidar or it may have some disadvantages when compared with lidar    what are the probable alternatives  edit  i m intending to use it outdoors for navigation of autonomous vehicle  is there any low cost lidar or is there any alternative sensor for obstacle detection  ,sensors navigation cameras sonar lidar
4587,two state linear actuator,i need two state linear actuator  you can have a look at the picture to understand what i mean   don t care about the hand    i need to electrically move the things like this squares up and down  bidirectional linear actuators are needed  what is the cheapest and tiniest actuator  or sth else  that i can use to move this squares up and down  there are just two states   up   down    don t care how much higher a square rises  when it is up  ,actuator
4589,particles not behaving correctly in the implementation of particle filter,i am implementing a particle filter in java  the problem with my particle filter implementation is that the particles suddenly go away from the robot i e the resampling process is choosing particles which are away from robot more than those which are near it is like particles chase the robot  but always remain behind it  i am trying to find the root cause  but to no luck  can anyone please help me where i am going wrong  i am adding all the imp  code snippets and also some screenshots in consecutive order to make it more clear        details  i am using a range sensor which only works in one direction i e  its fixed and tells the distance from the obstacle in front  if there is no obstacle in its line of vision  then it tells the distance to boundary wall   code  calculating range  calculating weights       this method calculates the importance weights for the particles based on the robot range which is     the reading of the range sensor for the robot      private double measurementprobability int index        double probability        double particle x position particlelistx get index       double particle y position particlelisty get index       double particle vx particle x position      double particle vy particle y position      int range counter        int loop counter         int distance   calculaterange particle x position  particle x position  particle vx  particle vy  range counter  loop counter        probability    calculategaussiandistance distance  sensenoise  robot range         system out println probability                 return probability     private double calculategaussiandistance double mu  double sigma  double x         double gdistance math exp     math pow  mu   x       math pow sigma               math sqrt       math pi    math pow sigma              return gdistance     resampling       this method provides a resampled particle back to the list  it chooses a particle randomly     from the list based on the weights with replacement      private int giveresampledparticle         int index   randominteger    n         double sample           double maxweight   maximumweight         sample    randomdouble    maxweight       while sample   particlelistprobability get index                 sample    particlelistprobability get index           index    index       n            return index     ,localization particle-filter
4591,robotc color sensor error,i am trying to write a simple program where the robot lego nxt   will follow a blue line   i am using an nxt color sensor and the problem is that only   motor is moving  i know that none of the motors are broken either because i tested them out  can somebody help me diagnose my problem  ,sensors robotc
4592,for robot wheel control   brushless dc motor or servo motor ,simply  when to use brushless dc motor and when to use servo motor    what are the differences   specially when adding an encoder to the dc motor you can have the position and it will be similar to servo motor    ,motor brushless-motor servomotor
4595,do simple  non sonic  omni directional rangefinding beacons exist ,i am on a robotics team that plans to compete in a competition where one of the rules is that no sort of sonic sensor is allowed to be used  i guess that limits it to some sort of em frequency right  ideally  my team is looking for a simple beacon system  where beacon a  would be attached to the robot  while beacon b would be attached to a known point on the competition space  then  beacon a can give information about how far away b is  after some searching  i could only turn up laser rangefinders that required pointing at the target  i am a cs student  so i m not familiar with the terminology to aid searches  another nice property would be if the beacons also gave the angle of beacon a in beacon b s field of view  although this is not necessary  since multiple beacons could be used to obtain this information  we have an xbox     kinect working  and able to track things and give distances  but it looses accuracy over distance quickly  the arena is about   meters long   and this beacon should be as simple as possible  we only need it for a relative position of our robot  alternate solution  another way to solve this would be for an omni directional beacon to only give angle information  two of these could be used to triangulate  and do the job just as well  ,localization electronics laser rangefinder
4599,the uncertainty of initializing new landmark in ekf slam,in ekf slam  based feature map  once the robot senses a new landmark  it is augmented to state vector  as a result  the size of the state vector and the covariance matrix are expanded  my question is about the uncertainty of the new landmark and its correlation with other pairs of the covariance matrix  how should i assign them  when i assign them to be zero  the error of the estimation this landmark won t change as time goes  if i assign them with very large value  the estimation is getting better every time the robot reobserves this landmark however  the error approaches to fixed value not to zero  i assume the problem id with assigning the uncertainty  any suggestions  ,slam ekf errors mapping
4607,quadcopter roll  pitch fluctuation,for my quadcopter  i turn on the quadcopter while letting it stable on the ground  but i see that the roll  pitch fluctuate with the max difference being    degree  when i protect the sensor with soft material  then i observe the max difference is around   degree  is this fluctuation for the quadcopter  by the way  i use complementary filter and dcm with scaling factor being     gyro and     accel thanks in advance  ,quadcopter
4608,deducing single wing plane transfer function aka transfer function estimation through set of points,i m trying to control a plane via roll  using pid controller    i had a problem finding the transfer function thus i used the following method      fix the plane in an air tunnel  change the motor that controls the roll in fixed steps and check the   roll  thus i will have a table of roll motor degree  next is to deduce the nonlinear function using wolfram alpha or   approximation neural network     is this a correct method or should i try another method    ,pid
4609,is increasing gyro   accelerometer sensor range is good or bad   how does it affect the accuracy,i ve been using mpu     imu unit   gyro   accelerometer     i found that i can set acc range to      g or  g till    g  and same for gyro         deg sec       deg sec and so  i know that they are low cost and full noise   so which settings to the range are best to ensure higher accuracy    ,sensors imu accelerometer gyroscope
4610,forward kinematics d h parameters for perpendicular joint axes,i am trying to compute forward kinematics of the kuka youbot using dh convention    the arm joint   and arm joint   are revolute and rotate about the world z axis  pointing to the sky  but the other   joints are all revolute and rotate about x axis  let s say  points horizontally  dh convention says the  joint distance  is along the  common normal   but unless i am mistaken  the only common normal is the y axis  and that is also horizontal  meaning there is no joint distance  i was thinking i would use link offset for joint    joint   but then i ran into a problem with joint    joint   link offset is supposed to be along the previous z axis  and in that case it would point horizontally out to nowhere  but link distance still doesn t work either  because that is the common normal distance  and as established the common normal is x axis  also horizontal  so now i feel very screwed  i am sure there is a simple solution but i can t see it   so i guess the question is  how do i use the dh convention for the links between     and      when the joint rotational axes are perpendicular  ,kinematics forward-kinematics dh-parameters
4612,controlling multiple arduinos wirelessly,i am designing a experiment of controlling   small wind turbines wirelessly  for each wind turbine  i need to measure power time series  or voltage or current time series  from the generator  and control blade pitch angle  yaw angle  and generator load  using variable resistance   the control input will be all pwm signal  i am planning to put an arduino uno with a zigbee wireless module to each wind turbine  making it measure the power time series and transmit to the central node  as well as receive the control input from the central node and command the control input to servo motors  the central node will be additional arduino uno  here are my questions  is it possible for each arduino to send time series signal to central node wirelessly without interference with other arduino     wind turbines transmitting time series to a central server   if it is possible  how can i implement such network   recommending a source for learning would be also greatly helpful  interface between the central node and the computer software  the algorithm in the computer need to process the received power time series and determine the optimum control input for   wind turbines  then these control input should be transmitted to wirelessly to   wind turbines  in such case  what is the good option to interface the algorithm and the arduino connected to the computer  currently the algorithm is written in matlab  i heard there is the sketch interfacing arduino and matlab  is it efficient enough for such project  ,arduino
4625,seeking dirt cheap  wheeled  programmable robot,i was playing the old  confuse the cat with a flash light  game  when i thought that i might like to program a confuse a cat robot  something  probably with tracks  which can right itself if he flips it over  and which i can program to move randomly around a room  turning at walls  making an occasional sound or flashing a light  since i am on a very tight budget  i wondered if there is some cheap kit which i can program     arduino  raspberry pi  any platform  so long as it is programmable  thanks in advance for your help ,mobile-robot
4627,control a     ghz ar drone from the computer,i had a doyusha nano spider r c mini copter  it s controlled by a  ch joystick     ghz  i look for a low cost method to control it from the computer  the software is not a problem  but how can i transform the wifi or the bluetooth signal of the computer to an r c signal compatible with the mini copter receptor  or is there another solution that is low cost  ,control quadcopter wireless
4632,what mechanical parts can be attached to dyj   stepper motor ,sorry i am asking a mechanical question here  but  after all  where else people have experience with using motors  if there is a better forum for this  please do guide me  everywhere i ve seen online  the stepper motor dyj   is used in tutorials  to rotate on its own  or  at most  to spin a clothes pin attached to it  i am trying to get arduino to work for my    year old kid  he s got the motor rotating  now what  how does he attach anything to it  don t laugh  i made him a wheel out of a raw potato  he is happy with it now  where can i find any guidance as to what to do next  ,arduino motor
4635,  v compressor and air pressure control,i am trying to make a simple robot with few functionality for someone  one of these functionality is inflating a balloon inside the robot  i know how to control a compressor using arduino but the problem is that the requested task is bit different here  there must be an air exit and it must be controllable through arduino  so he can inflate the balloon to a certain pressure  and depress the air from another exit if needed  i don t know if it is possible to have a depression through the same pressure in valvle  i think that it can be done somehow using a solenoid     valve or something but i am bit unfocused these days and i need some hints  any thoughts  ,arduino wheeled-robot mechanism industrial-robot valve
4639,where do roboticists look for used sensors hardware ,i recently built a self driving vehicle type robot for a competition  and am looking to sell sensors  gps  ins  etc   used in order to have money for the next project  is ebay where people tend to go looking for used sensors and hardware  ,sensors servos
4642,finding a light load high precision servo motor,i have a project that requires me to be able to accurately and repeatedly rotate an object     degrees  the object is small and lightweight  let s say several grams   the axis does not necessarily have to always spin the same direction  it simply needs to be able to stop reliably at             and        degrees from the origin  i have very limited experience with motors and robotics  but my understanding is that a servo motor will be my best bet for accuracy  if that incorrect  please let me know   since i know next to nothing about these motors  the spec sheets list a lot of specs which don t mean all that much to me  i m hoping to learn  but in the mean time  what specifications do i need to be focusing on for these requirements  it doesn t need to be high speed  when i say accurate  it doesn t have to be absolutely perfect to the micrometer  but i would like it to be able to run through a loop of stopping at         and     hundreds of times without visually noticeable variance   the more precise the better though  to be more specific about the accuracy  let s say the object being rotated will have a flat surface on the top at each of those   stopping points   upon inspection the surface needs to appear level each and every time through hundreds of cycles  could these requirements be met by a servo that might be used in building a quadricopter  or am i going to be looking for something higher grade than that  ,servomotor
4648,controlling dynamixel servo wirelessly using arduino mega,i am planning to control multiple dynamixel servos  mx  t or mx   t  wirelessly using arduino mega  since this servo uses serial communication  i need an additional serial port to interface with xbee module  although it seems to be very common application controlling these servos wirelessly based on arduino  i could t find any of them in web  i found the two very well constructed libraries    this library is for mx  t servo  which is the same servo i am trying to use  but it uses uno therefore  i cannot interface with xbee    this library use uart   serial   to interface with servo  ax     motors  therefore  i can connect xbee module to uart   but  the problem is that this library is outdated and not compatible with mx   t servo anymore  so my question is here  is there any one who has experience in controlling dynamixel mx  t  mx  t servo series using xbee module simultaneously  if you have experience  please share with me  is it possible for arduino mega can interface with xbee module using serial   i e   rx   tx     if it can  i might be able to use the library  without any modification  ,serial
4650,slam without landmarks using sonar,i m currently programming an app for a robot and i d like to make him map a zone and then make him move autonomously from one point to another  i have to solve a slam problem  but the biggest matter is that i can t use landmarks to find myself in the environment  the robot just has the abilities to move  and to make distance measurements over           degrees using a sonar  i can t find any simply explained algorithm that permits me to solve this slam problem with the no landmark limitation  have you any idea   ,slam sonar
4656,over voltage on a brushed electronic speed controller,this is for a battle robot in the hobby weight class       kg max  i want to drive the robot using    cordless drill motors rated at      volts  i have  s lipos which means i have   x     volts or      volts  so far so good   the problem is that i bought   escs and only afterwards noticed that they are rated for    s  or max of      volts   so my question is am i likely to damage the esc if i use my  s lipos instead of  s lipos  or should i just buy  s lipos and live with the reduced performance  ,motor esc
4657,adding reverse function to a brushed motor electronic speed controller,this is for a hobby weight       kg  battle robot  i bought two escs for my drive motors but the escs do not have a reverse function  or brake for that matter   is there any simple way i can achieve this through maybe either    the r c settings  setting middle position of joystick as stopped  top wards as forward and bottom wards as reverse    or could i maybe achieve this using arduino  i have a card with relay switches that i can use with the arduino so am not worried about high voltage or current but i am worrying it could get messy    i could just buy two new escs with the above features but they cost quite a bit more than the ones i already have so i would prefer to try a few tricks first   if there are any  ,motor esc
4658,can a  s lipo battery be changed to a  s and a  s ,newbie to robotics here   i bought a  s lipo but now realise that it is overkill  and these things are expensive  so  given that  as far as i know  the pack is apparently made up of individual cells of     volts each  is there any way in which i could somehow  safely  separate out the cells to get a  s and a  s or even single  s cells  ,battery
4663,how to periodically estimate states of a lti if the output is measured irregularly ,how can i periodically estimate the states of a discrete linear time invariant system in the form  dot  vec x    textbf a  vec x   textbf b  vec u    vec y   textbf c  vec x   textbf d  vec u  if the measurements of its output  are performed in irregular intervals   suppose the input can always be measured    my initial approach was to design a luenberger observer using estimates      and  of the abovementioned matrices  and then update it periodically every  seconds according the following rule   if there has been a measurement of  since the last update   dot  hat x    hat  textbf a   hat x   hat  textbf b   hat u   textbf l  y  measured   hat  textbf c   hat x     if not     dot x   hat  textbf a   hat x   hat  textbf b   hat u    i have omitted the superscript arrows for clarity  i believe that there may be a better way to do this  since i m updating the observer using an outdated measurement of   which is outdated by  seconds in the worst case   ,control sensor-fusion
4672,shortest path using wave planner ,how could i compute the shortest path between point a and b using wave planner  i don t see how using the wave planner would give me the shortest  it would just give me a path  as far as i can tell  i would only be able to give a random path to the destination  but nothing else than that  ,theory mapping
4674,what should i be looking for in a dc motor that will be used in a urov thruster ,i know that some dc motors produce a lot of torque but only actually move at a very slow rate  while others do the exact opposite  i know that i need some sort of balance between torque and the rpm s of the motor for use in a underwater thruster  but i am not sure what i should favor more  torque or rpm s  also  it would be great if someone could suggest a motor at or below the      range for a urov  ,motor torque
4675,position controller for a quadrotor,i have a question regarding the implementation of a quadrotor s position controller   in my matlab model the quadrotor takes   inputs  a desired altitude    and desired attitude angles       which reflects the motion described by the differential equations of the model  see last picture     here an insight into the implemented matlab dynamic model  as you can see it has a structure like an inner loop controler   anyway   it  hovers  perfectly on the starting point   perfect graphs      now i just need to go over and implement a sort of position controller to let the quadrotor to get from a start to a goal point  defined as usual through   coordinates    that s tricky because i don t have the same space state variables as input and output of the system  so the controller must take a vector of three coordinates and be able to output   different angles to get there  the only exception is the height because it will be simply bypassed by the controller and doesn t need another calculation loop  a different story is for the three angles     my first idea was to simply create a feedback between the position given at the output of the simulated system and the desired position as in the figure above  but that rises another question  my quadrotor model solves the following equation system    large  cases     ddot x      sin  psi   sin  phi     cos  psi   sin  theta   cos  phi    frac u    m    cr   ddot y      cos  psi   sin  phi     sin  psi   sin  theta   cos  phi    frac u    m   cr   ddot z     g     cos  theta   cos  phi    frac u    m   cr   dot p     frac i  yy    i  zz   i  xx  qr    frac j  tp   i  xx   q  omega    frac u    i  xx    cr   dot q     frac i  zz    i  xx   i  yy  pr    frac j  tp   i  yy   p  omega    frac u    i  yy    cr   dot r     frac i  xx    i  yy   i  zz  pq    frac u    i  zz      that means that they expect  as in the matlab model above  the desired angles and height   but now i need right the inverse  given a desired position calculate the right angles     for the direction is the solution really simple  since i can write something like   where y and x lies on the horizontal plane  this is not so simple for the other two angles  so what can i do at this point  just  invert  the given equations to get the desired angles  another idea could be to implement a simple pd or pid controller  this is much more easier given the fact that i can experiment very quickly using simulink and get very good results  but the problem is here again  how get i the desired angles from a desired position  ,pid quadcopter
4677,how to estimate yaw angle from tri axis accelerometer and gyroscope,i would like to estimate the yaw angle from accelerometer and gyroscope data  for roll and pitch estimate i ve used the following trigonometric equations   and a simpified version of the kalman filter to consider also angular rates  the roll and pitch estimates are accurate  accelerometer values need to be filtered in presence of chassis vibrations    in order to get the yaw angle i m using the following equation  yaw   atan  ax ay     rad to deg   but the it doesn t work  do you have any advice  ,sensors quadcopter kalman-filter imu accelerometer
4679,mpu       yaw angle drift,i use mpu      also use dcm and complimentary filter to compute roll  pitch and yaw  however  my yaw is not so smooth  how can i solve that problem  i looked at the datasheet of mpu      but i didn t see anything related to sampling frequency of magnetometer like gyro and accel  ,quadcopter
4682,is there an advantage to multiple magnetometers for heading computation,i m building an autonomous sail boat  ripped out the guts of an rc sail boat and replaced with my own mainboard etc   the controller board i have can accommodate both an mpu     and an hmc      is there any advantage is using both magnetometers for a tilt compensated heading  i m thinking that i could compute the unit vector with soft hard iron offsets removed for both  and then average  the two vectors to get one slightly better one  not sure if it would yield a better result though  ,sensors sensor-fusion
4687,tricopter simulation to test control algorithms,i am looking to write and test my own control algorithms for tricopter flight  i am looking for a simulator that can simulate a tricopter but at the level of receiving simulated pwm and returning simulated gyro  compass and other sensor readings  ideally it would also have graphics for visualization  need not be fancy   ultimately  i want to port this to a real tricopter but at the moment i would just like to simulate it  any suggestions for free simulators that are low level as i described   ,control quadcopter simulator
4688,acceleration formula for a differential steering robot,i have the formulas to derive the rpm s of each wheel from the robot s linear velocity  now  i am trying to do the same thing for the acceleration  mainly angular acceleration   for linear acceleration i am always assuming that the linear velocity of the wheels is the same as the robots when the robot is moving on a straight line   according to physics  am i right  but angular acceleration seems more complicated  specially when the robot is following a curved path  not necessarily turning in place   any readings or ros packages that deal with this acceleration issue  thanks ,ros wheeled-robot differential-drive
4689,short distance ball transport,i m looking for a way to transport balls  diameter   mm      mm up with over a slope with a length of     mm  currently i m considering the usage of a belt system but i cannot seem to find a good belt system  because of space constraints within my robot  normally i would probably take a nylon belt and jam nails trough it to make little slots and then use that  however this would result in considerable reduction in available space as it means that i have to also take into account the extra space required for the nails on the way back  this means that ideally there would be a way to reduce the space used by the nails on the way back  does anybody have a good solution for this  ,kinematics manipulator
4693,is it possible to track movement on a tennis court ,i d like to track my run in an indoor tennis court  gps won t be available so i was thinking researching for other solutions  accelerometer  i concluded it s a no go because while playing tennis the player makes a lot of movements that include spinning his body that can alter the data  then i thought that a     point ir system might help but again from what i ve understood it s hard for the ir system to track the movement since they won t be able to focus on the player  so my final thought went to radio systems but i couldn t find any info and it s also hard for me to see a theoretical solution at least on how i can mesure the movement speed of the player  so here is my question  is there any existing system that is able to track random movement of an object  athlete  and give info like speed and distance  is there anywhere resources about how such a system might be achieved or at least the exact technology used for it  any suggestions and ideas are greatly appreaciated  ,arduino kinematics movement
4698,interface multiple i c slaves to microcontroller,i want to communicate the tiva c arm cortex m  to sensorhub from ti which has multiple sensors with different i c addresses such as mpu      bmp     temperature sensors    with a single i c slave  i can communicate to it successfully  but if my project involves interface microcontroller with both mpu     and bmp     then i get stuck  anybody suggest me the process of commnunication in this case  ,i2c
4699,robot docking for self recharging,i want to build a simple obstacle avoider robot  but this time i want it to be self recharging so i am building a dock for this purpose  so i want it to be able to locate the dock and go for it when battery voltage is lower than a fixed value  i am having trouble to chose the right components for locating the dock  i think i am going to use an ir emitter on the dock so the robot can head toward it when battery is low  let s forget about the orientation problem for the moment  but if you have any thoughts about it that will be helpful  but i am not sure if the robot is able to detect the ir led  or whatever  from a long distance  over    meter  is it possible to use this solution for this distance  if not  what do you suggest   if there is a simple ready solution to buy that s ok  let s say i have no budget limit  ,sensors localization wheeled-robot battery wireless
4701,a general question about pid controller,i have a basic question because i m trying to understand right now a concept that i thought it was obvious  looking at this video he is going to feedback the variable state x with the input of the system  which is a force f   now  if i m correct it is only possibile to feedback variables which share the same units  so i expect to drive a meter through an input variable which is a meter and the difference will be then feed into the pid  is the example in the video just to show up how to use simulink  or i m wrong   ,pid
4702,advice on mounting a servo for a nerf sentry gun,i am trying to make a nerf sentry gun to shoot my co workers  i am building it more or less from scratch and have come to the part where i need to come up with plans to assemble it  i am looking for advice on how to mount the mg    servos to allow them to tilt and pan  i originally thought about having a base with a metal rod through the middle and use a gear to control the pan functionality  the idea is it would mimic a skateboard truck with a gear that would turn the rod through the middle and pivot the shooting mechanism  another idea was to have the metal plate sit on top of the servo and use one of the attachments to attach it to the top plate  the problems i see behind this is the attachment is just a small piece of plastic and over a short period of time i could see this wearing out especially if the shooting mechanism is not centered perfectly  i also need to come up with a solution to make it tilt but i think i have an idea for this to simply use a rod with a gear to turn the pvc pipe barrel   here are the servo s i am using sorry if this is the wrong forum for the question but i was unsure where else to look for some expert advice   edit   for anyone intersted i found an example of someone doing almost exactly the same thing with blueprints  i am going a slightly simpler   cheaper route and mounting the servo to the bottom of the spinning plate between the lazy susan plate i ordered  this way i don t have to buy the gears which are rather expensive and without the gears it may reduce some of the torque   ,mechanism servos servomotor
4704,self powered quadcoptor,i have this idea or a very curious question in my mind  i am no where near professional though  but i would like it to be answered   we all know how wind turbines can be used to generate electricity  so is it possible to create a quadcoptor that will start with some minimal power by small battery but in time will sustain and keep its system on by self generating electricity and keep on rotating its rotors on its own without other external supply   ,quadcopter
4705,amperage on brushed motors,i am currently building a hobby weight      kg  robot and will be using   x      cordless driller motors for my wheels   the thing is i keep reading about high amperages when working with r c models such as quadcopters but when i connect my cordless driller motor to my bench power supply and monitor current draw it never rises above     amps even when i try to stop the motor by hand   of course in the arena in the event of a stand off i have plastic wheels which will slip so i am not too concerned about stall currents   i am now left wondering whether i have mis calculated or whether people make a lot of fuss about high currents for nothing  or do these currents only perhaps really apply to brush less motors  ,motor
4706,diode or capacitor across terminals of brushed motor,i am currently building a hobby weight robot      kg  and will be using   x     v cordless drill brushed motors to drive my wheels   i have read somewhere that due to  induced currents  when i turn the motor off  or reverse it presumably   i should protect it by using a diode or a capacitor across the terminals   which should i use  capacitor or diode  and what are the parameters i need to consider for these components  voltage or current    some answers to a similar question discussed capacitors but not diodes  are diodes relevant  would i seriously damage the cordless drill  presumably quite tough  motor if i did nothing  and don t motor controllers have any form of inbuilt protection for the motors anyway  ,motor
4707,spinning disk weapon,i am building a hobby weight robot and my weapon of choice is a spinning disk at the front  as regards the disk i was thinking of buying commercial  grinder type  disks and change type of disk depending on the  enemy s  chassis construction material  so for instance i would have an aluminum cutting disk if the enemy s chassis is made of aluminum and so on  first question is therefore  do such disks do the job in practise  or break  fail to cut   secondly  should i use a brushed or brush less motor for the disk  i actually have escs for both but sort of feel a brushed motor will give me more torque while a brush less motor might give me more speed  so which is more important speed or torque   i do know   from my uncle who uses metal lathes   that machines that cut metal usually spin at a slower speed  drills  cutting wheels etc   indeed he likes to say that metal working machines are safer than wood working ones partially for this reason   but i am a newbie and really would like to have an effective weapon if possible and breaking or not cutting disks do not make such a weapon  also is it normal practise to use one battery for everything  drive and weapon  or have two separate batteries  ,motor battle-bot
4713,rotate  and stop  a large disk in very tiny increments,in a lab build i m doing  i m stuck at this problem  so i am fishing for suggestions  i m creating a turn table type setup where i need to make readings  with a nanotube tip probe i ve already designed  similar to an afm probe  on the very edge circumference of a    cm radius disk  substrate   the current hurdle is  i need to get the substrate disk to move circularly in steps of     mm displacement    meaning  i occasionally need to stop at certain    mm increment positions  what would be a way i can achieve this  assuming an accurate feedback system  with accuracy of say      mm  e g   with quadrature optical encoders  is available if needed for closed loop control  specs of commonly sold steppers don t seem to allow this kind of control  i m at the moment trying to study how  e g  hard disks achieve extreme accuracies  granted they don t have such large disks   certainly  direct drive like i m currently building  see below image  probably doesn t help   ,motor stepper-motor
4715,control a robot with pymorse on morse simulator question,i am new to morse and robotics  this code control the robot by giving the linear and angular velocity  this is the scene description  and this is the control script import pymorse with pymorse morse   as simu      simu robot motion publish   v       w         the robot moves well  but when i remove the semantic cameras from the scene description the robot do not move  i am confused  they are just sensor  why the robot don t move   ,mobile-robot sensors control
4716,motor for weapon for hobbyweight,i am currently building a hobby weight      kg  robot  the weapon will be a vertical spinning disk at the front  it will probably be a commercial one from the hardware store or i could maybe get one made  i have   cordless drill motors to drive my wheels so i should be ok there  but i am still lost where it comes to what motor i should get for my weapon  i am now inclined to think it should be brush less although i am still open to other opinions  can anyone please recommend a good motor  in line brush less  or brushed motor that will give me the speed and strength i need for the weapon  ,motor battle-bot
4717,detect road surface in a traffic scene point cloud,i want to analyze a traffic scene  my source data is a point cloud like this one  see images at the bottom of that post   i want to be able to detect objects that are on the road  cars  cyclists etc    so first of all i need know where the road surface is so that i can remove or ignore these points or simply just run a detection above the surface level  what are the ways to detect such road surface  the easiest scenario is a straight and flat road   i guess i could try to registrate a simple plane to the approximate position of the surface  i quite surely know it begins just in front of the car  and because the road surface is not a perfect plane i have to allow some tolerance around the plane  more difficult scenario would be a curvy and wavy  undulated   road surface that would form some kind of a  d curve    i will appreciate any inputs  ,mobile-robot wheeled-robot computer-vision algorithm stereo-vision
4721,how to convert pid outputs to appropriate motor speeds for a quad copter,i am building an autonomous robot using pid control algorithm  so  far i have implemented pid using online resources references  i am testing for stabilizing an axis of the quad copter  however  i am not successful to stabilize even one axis  description  my input for the pid is an angle value i e the orientation of the quad copter measured by ahrs  a gyroscope that measures angles  and the motors take integer values as speeds  what i am doing is   where ajusted value is a buffer that accumulates or subtracts the pid output value based on either pid output is  ve or  ve  i also tried  motor right speed   base speed   pid output  motor left speed   base speed   pid output   both don t seem to be working  i have tested using a wide range of p gain values  from very small to very large   but the quad copter only oscillates  it does not self correct  your help with suggestions would be greatly appreciated  thanks  ,quadcopter
4722,brush less motor specs vs efficiency for multi copters,i am looking for some figures surrounding the specs of brushless motors and their relative efficiency  in power usage terms  for multi copter use   there are   basic specs for motors themselves     motor width  eg   mm     motor height  eg   mm      kv    rpm per volt supplied  eg    kv     wattage  eg    w  this would then be a          kv    w motor   what i am looking for is a chart containing     motor spec    pack voltage  eg     v     amps drawn   various   throttle      to      say     static thrust from various propellers    x     x  etc etc  does such information exist  i know its a bit subjective as prop and motor designs vary slightly  but a baseline would be a start  ,brushless-motor
4723,hokuyo urg   lx ug   and mac compatibility issues,i ve got my hands on this laser range scanner but seem to have some problem receiving any output from it  i can t find any guide on  how to set it up on the internet  so i was wondering if it is even possible to set it up for mac or shall i do it using linux and ros   ,communication laser rangefinder
4724,biped walking using genetic algorithm,i am working on a project but i lack advanced programming knowledge  especially about genetic algorithms  i am developing a prototype using webots       for the simulation  the project is to use genetic algorithms to evolve the gait of a biped robot  i have developed a physical model  but i am still uncertain about the motor choice  for the algorithm part  i find it hard to understand how to set the algorithm parameters and how to determine the fitness function  could you please suggest a fitness function  thank you for your help and efforts  ,algorithm machine-learning legged
4725,recursive tree representation for multi agent robots ,i have been going through a code base for multi agent motion planning  and i came across a recursive tree building algorithm for the agents  i haven t been able to figure out the algorithm  does anyone know what it is called  or any other similar kinds of algorithms so i could read more about it  here is what i got from the code   the node of the tree is as follows     each node has a max and min value for x and y  and also a begin  end  left and right value   then the tree is split either horizontally or vertically based on which limits are longer  x or y   and an optimal value is found and agents are split   then these split agents are recursively build again  thank you very much   ,multi-agent
4726,ros node does not seem to do anything,i have the following code for the ros turtlesim    the idea behind this code is to introduce a random error to then practice error recovery in my code but this node does not appear to do anything at all  i do know that my other nodes are running but this one just doesn t appear to do anything  it doesn t exit it just hangs  anybody know how to fix this  ,ros
4734,can i make an automatically parking robot car with ir sensor ,it would be easy to understand if you imagine a robotic vacuum cleaner   for some models  it goes back to a specific place automatically to recharge  like this  i want to make a robot which automatically goes to the place where a specific signal like infrared ray  is emitting   following is the scenario that i ve imagined    set the ir emitter in a specific place of a room  it always emits infrared ray    i connect   ir receiver to my  wd robot car   front  left  right  and back side    they receive ir from the emitter  i earn the distance from the emitter to each receiver with the intensity of ir    with these values  arduino find out which receiver is closest from the emitter and choose the direction to go  but i could t know this will be possible  because ir is a kind of light ray  so i can t get the distance with the difference of arrival time like ultrasonic   i searched several kinds of ir sensors  but they were only for sensing the possibility of collision   so my question is these    can i get the distance and the direction from ir emitter to my arduino device with an ir receiver   if i can  then how many ir receivers do i need  and if i can t  what can i use to substitute ir emitters and receivers  i guess ir can be interrupted because of sunlight or other light  so i guess i need some daylight filter  do you think it s essential     ,arduino sensors wheeled-robot
4738,wheeled robot motion primitives  is throttling forward and crab motion considered as one ,i am simulating a wheeled robot of six wheels and can be independently steered  like mer opportunity  the wheeled robot can perform throttling forward    crab motion              wheel orientation when heading is                     and turning on the spot             wheel orientation                  my question is  is it correct to say that i have   motion primitives  throttling forward is basically crab motion with heading zero  ,wheeled-robot motion
4741,numerical example for paden kahan subproblems ,i am writing a kinematics library in go as part of my final year project  i am working with product of exponentials method and have successfully implemented the forward kinematics part of this  i need help with the inverse kinematics   i understand the theoretical aspect of it  i would like a numerical example where actual numbers are used for the paden kahan subproblems as the ones dealt in  a mathematical introduction to robotic manipulation   murray li and sastry   freely available online pdf    i specifically need help with knowing what should p q be when trying to solve the inverse kinematics  the book just says given  a point p q around the axis of rotation of the joint  but how do you know these points in practice  like when the robot is actually moving  how do you keep track of these points  for these reasons i need a numerical example to understand it   ,inverse-kinematics product-of-exponentials
4745,how do i get this transformation matrix ,i ve just started taking a robotics course and i am having a little problem  i need to rotate the  coordinate system into a position  where  will be parallel with    the transformation matrix is given  but i have no idea how i can figure out this transformation matrix from the picture that can be found below  actually  i know why the last vector is           and the previous vector is            but i can t figure out why the first vector is         and the second           ,robotic-arm industrial-robot
4749,survey for local navigation,i was wondering if there was a good book or paper that surveys current techniques in local navigation  the earliest one i could find was from      and i was hoping to find something more recent   i have worked with certain approaches such as the dynamic window approach and the velocity obstacles approach  i m hoping for some book or paper to give me a broader perspective to the problem of local navigation which i believe has been fairly robustly solved by a number of autonomous driving companies   thank you   ,navigation motion-planning
4750,pid control tuning,im currently designing a robot for my undergraduate project  one of the task of this robot is to follow the wall  for the purpose i m using a pid control system  where the reference is given from a ultrasonic sensor  so my problem here is im having a hard time tuning the pid  i know i can find the p coefficient pretty easily by plotting the desired set point range vs desired motor output speed  even then the robot is not so stable  so i though of adding di part of pid  but how do find out roughly the values of these coefficients without just trying out random values  manual tuning   thank you so much  much appreciated  ,motor control pid
4754,build a ros robot with slam without laser,i ve build a simple wheeled robot based on two continuous servos  controlled by raspberry pi running ros groovy  with a smart phone mounted on top to provide additional sensors   i d like to situate the bot in a room and have it move to various points on command   i don t have laser ranger finder but do have a good ultrasonic ranger finder and kinect sensors  what are the typical ros setup for this  the idea i m thinking is to personally  e g  manually  map my room using kinect and use this map using only the ultrasonic range finder sensors and imu in the lightweight robot   would this be possible  ,localization ros slam raspberry-pi ultrasonic-sensors
4755,parameter  of denavit hartenberg,by watching this video which explains how to calculate the classic denavit hartenberg parameters of a kinematic chain  i was left with the impression that the parameter   or   will always be positive   is this true  if not  could you give examples where it could be negative   ,forward-kinematics dh-parameters
4759,how to find the height of a rock with a rover ,so  i am designing a rover that will navigate to a rock  and then calculate the height of the rock  currently  my team s design involves using an ultrasonic rangefinder and lots of math  i was interested in what sensors you would use to solve this problem  or how you would go about it  assume that the rover has already located the rock   additional info  we are using an arduino uno to control our rover  it is completely autonomous  ,arduino wheeled-robot algorithm
4761,sending a smartphone s gps wireless,i m building camera device which is able to take pictures of paragliders in mid air  to let the camera know where the glider is i thought about using gps data from the pilot s smartphone  my question is  what are possible ways to transmit the gps data to the groundstation and which can be considered a good solution  i thought about sending the data to a server via some mobile network  but a direct communication solution would be preferable  the pilot has mid air pretty good mobile reception and the maximum distance between pilot and ground station is around  km  ,gps communication wireless
4762,learning materials for beginners in robotics and quadrocopters,i am a web developer  i am fascinated by quadrocopters and i am trying to learn how to build one and basically i am trying to jump into robotics fields  i don t have much electric circuit and electronics knowledge so i did some research on how to build and what type of knowledge you would require to develop such flying machine  so i started learning basics of electronics from lessons in electric circuits by tony r  kuphaldt the books are very interesting but i could not find a technique so that i can implement what i learn from the books  basically i am just going through the stuffs  and understanding them little by little  what i want to know is that what is the right way and effective way to learn electronics and electric circuit from your experience and i should i do now so that i can increase my learning speed so that i can achieve my goal  while i was researching i came across topics such as mathematical modelling and modelling the quadrocopters first and them implementing them on real  how can i gain such knowledge to model something mathematically and implement such in real life  how much math and what areas of mathematics do i need to learn and how can i learn such   now you have idea what i want to learn and achieve  can you please suggest me a road map or steps i need to take to gain such knowledge and skill to develop myself  so that in near future i would be able to build such flying machines on my own   ,quadcopter
4764,which is more useful  instantaneous rate of change of displacement or average rate of change of displacement ,instantaneous rate of change of displacement is given by   while average rate of change of displacement is given by   v t     s t n     s t n       t n    t n      the first one gives the slope or derivative of a displacement function at a particular instant of time and thus varies with time  i was wondering how is it going to help me calculate the velocity of my robot s end effector  which is the foot of the leg of the robot bipedal   if i make a reading of the position of the robot every  ms to keep the approximation as accurate as possible  my instantaneous velocity would be zero wouldn t it  since my robot wouldn t have moved anywhere in  ms time  agreed   t  would increment as t dt  dt         s  then v t  would be v          s          s        which is zero  because there is no displacement in that small time frame  right  am i doing something wrong here  or on the other hand  do i just use average rate of change  i have this question  since  if there is a manipulator  in my case the foot of my robot  and it s trajectory is given by a  x  homogenous matrix    c t   s t         s t   c t                          where c s are cos theta  and sin theta respectively   if on paper  this is differentiated  this would give me a spatial body velocity matrix as        d theta  dt        d theta  dt                                  so how do i compute this differentiation in code  i just need something of the sort of a pseudocode  ,mobile-robot
4766,how to power extra usb devices for beaglebone black,i m building a robot that uses a beaglebone black  however i have several different usb devices that i want to connect to it  microphone  usb sound device and some other things   now i have heard that the usb output of the beaglebone doesn t power more then    a  so the combined draw of these usb devices is likely to exceed this by a fair margin  so i started looking for powered usb hubs to use instead  however these tend to be powered by    v and my robot currently only has a   v power supply and a converter to  v for the beaglebone  which given the size expense and inefficiency of converting power to     from   v and then back again doesn t seem very good  is there a good method for fixing this   ,power usb beagle-bone
4771,tracking robot in a room,i m trying to track a simple robot  e g  arduino  raspberry pi  even toys  in a room using fixed location kinect sensor s  and cameras at different parts of the room   how might one usually use to do this  edit     more specifically  i want to know the position  and if possible  orientation  of an moving object in the room using one or more cameras or depth sensors   i m new to the area  but one idea might be to use blob or haar to detect the moving object and get its location from kinect depth map  and i m trying to find what package i can use for that end   but for navigation to work i d have to pre map the room manually or with kinect   i can put some sensors on this tracked moving object  e g  imu  sonar  but not a kinect   i am allowed full pcs running ros opencv kinect sdk in the environment  and i can wirelessly communicate with the tracked object  which is presently a raspberry pi running ros groovy on wheels  ,arduino computer-vision kinect
4775,image processing in bright lights,we are working on a project which requires us to detect and hit a ball  we are trying to accomplish the task by detecting the position of ball by processing the input from a camera  the problem is that we are required to do this in very bright lights  the bright lights are making it difficult to detect the white colored ball   is there a way we can write the code such that it automatically reduces the intensity of lights in the image  is there an efficient way to extract only the v component from the hsv image   we have very limited experience with image processing so any alternative approach to detecting the object will also be helpful ,computer-vision
4782,power switch and common ground on a battle robot,i am constructing a     kg hobby weight battle robot and one of the safety rules is that the robot must have a power switch that turns off power to the motors  and weapon   the robot has three sub systems  the drive motors  one battery   the weapon  another battery  and some lighting  a small   volt battery   i have read that since all these will be connected to the same receiver it is important to have all the electronics sharing a common ground for everything to work properly  now i know that usually it is the  live  wire that is connected to the switch  but i was thinking of hitting two birds with one stone and connecting all the ground wires  rather than the live wires  to the switch  in this way i still turn off power and also have a common ground  in terms of safety  shorts  etc i am not too concerned because i am using xt    connectors and have been careful to use only female plugs for the power leads  so no prongs are visible   it seems to me that it should work and still be safe enough especially since i am not dealing with mains voltage levels here  but on the other hand i don t want to look stupid  does this way of connecting to the switch make sense or am i violating some unwritten law  is this normal practice  would it effect the circuitry in any way to have the grounds connected together  i was also thinking of using a switch from a pc power supply  as far as i know this is rated for reasonably high currents  in my case i will have   cordless motors  each of which might be drawing up to   amps when under load  so say    amps in all  has anyone out there ever used such switches or did you buy high current ones  in that case what should i ask for  thanks  ,control power battle-bot
4784,gazebo import robot gives error,i m trying to import the tutorial robot given at this link however this gives the following error    this sugest something is wrong with parsing but does not actually point towards any line of my code  the example is only     lines long         link name  chassis          pose               pose         collision name  collision            geometry             box               size           size              box            geometry          collision          visual name  visual            geometry             box               size           size              box            geometry          visual          collision name  caster collision            pose                      pose           geometry             sphere             radius      radius            sphere          geometry          surface           friction             ode               mu    mu               mu     mu                slip       slip                slip       slip               ode            friction          surface        collision        visual name  caster visual          pose                      pose         geometry           sphere             radius      radius            sphere          geometry        visual      link     link name  left wheel        pose                               pose       collision name  collision          geometry           cylinder             radius     radius             length      length            cylinder          geometry        collision       visual name  visual          geometry           cylinder             radius     radius             length      length            cylinder          geometry        visual      link      link name  right wheel        pose                                pose       collision name  collision          geometry           cylinder             radius     radius             length      length            cylinder          geometry        collision       visual name  visual          geometry           cylinder             radius     radius             length      length            cylinder          geometry        visual      link     joint type  revolute  name  left wheel hinge        pose                  pose       child left wheel  child       parent chassis  parent       axis         xyz        xyz        axis      joint      joint type  revolute  name  right wheel hinge        pose                 pose       child right wheel  child       parent chassis  parent       axis         xyz        xyz        axis      joint      model    sdf   this is on ubuntu        is there any hint at what i m doing wrong or what information can i provide to better come to a solution  ,simulator gazebo simulation
4787,scan matching finds right rotation but false translation,i m currently developing a slam software on a robot  and i tried the scan matching algorithm to solve the odometry problem  i read this article   metric based iterative closest point scan matching for sensor displacement estimation i found it really well explained  and i strictly followed the formulas given in the article to implement the algorithm  you can see my implementation in python there   scanmatching py the problem i have is that  during my tests  the right rotation was found  but the translation was totally false  the values of translation are extremely high  do you have guys any idea of what can be the problem in my code   otherwise  should i post my question on stackoverflow or on the mathematics stack exchange   the icp part should be correct  as i tested it many times  but the least square minimization doesn t seem to give good results  the parts that might be problematic are the function getaxx   to getbx    starting at line      as you noticed  i used many decimal decimal values  cause sometimes the max float was not big enough to contain some values  ,slam
4789,probabilistic velocity obstacles,i have been working with the velocity obstacles concept  recently  i came across a probabilistic extension of this and couldn t understand the inner workings   source  recursive probabilistic velocity obstacles for reflective navigation   what does the equation at the bottom and the top mean  vij is the relative velocity of agent i to agent j  ri   ci and rj   cj are their respective radius and centers  update  what does inf ri   rj  and sup ri   rj  mean  does it mean that i should define a function that goes from   to   from inf to sup  and if not  then how do i calculate the value of pcc at any given point  ,probability
4793,proportional controller error doesn t approach zero,i m reading this pdf  the dynamic equation of one arm is provided which is   l  ddot  theta    d  dot  theta    mgl sin  theta     tau  where     joint variable      joint torque    mass    distance between centre mass and joint      viscous friction coefficient    inertia seen at the rotation axis    i would like to use p  proportional  controller for now     tau    k  p    theta    theta  d    my matlab code is   for solving the differential equation  function dx   odesolver t  x   dx   zeros        parameters   m       d           l       i           g           t   x       pi       dx      x      q dot     i t     i d x        i m g l sin x       dx      q dot   the error is   my question is why the error is not approaching zero as time goes  the problem is a regulation track  so the error must approach zero   ,control dynamics manipulator
4794,motor controller calibration,i bought   brushed motor controllers from china to use with my hobby weight battle robot       these are intended for use with my   cordless drill motors which will be driving the left and right wheel respectively  the robot will therefore be steered in  tank mode  by varying the speed and direction of rotation of the   motors using the two joysticks on my turnigy  x transmitter  my question is  i have seen videos on youtube where people calibrate brushless motor controllers  escs  using some system of pushing the joystick on a standard transmitter forward and listening to tones and then doing the same for reverse and so on   however when i asked the suppliers about a similar procedure for these brushed controllers  all they could say is that they did not need calibration  the exact words were  it seems that you re talking about transmitter for copters but this esc is for rc car or boat  you pull the trigger  it goes forward  you push the trigger  it reverse  and you don t need to calibrate it  just plug it  then it can work     my transmitter is not one of those gun shaped ones used for cars  so am i in trouble with these controllers or should they work correctly out of the box as the supplier seems to be implying    you may fairly ask why have i not just tried this out and the simple answer is that my lipo charger has not yet arrived and i therefore cannot power anything up as yet   ,motor
4796,changing tank drive  differential  mode to single joystick drive mode,i bought   brushed motor controllers from china to use within my hobby weight battle robot      these are intended for use with my   cordless drill motors which will be driving  the left and right wheel respectively  the robot will therefore be steered in   tank mode  by varying the speed and direction of rotation of the   motors using  the two joysticks on my turnigy  x transmitter  i am seeking to refine the model and make it easier to operate so does anyone know of a way in which i can somehow synchronize the motors to get a single joystick steering system   my transmitter has   available channels so if this is part of a solution then i am fine with it  i also have an arduino available if needs be   ,motor differential-drive
4797,risk of overloading motor controller,i bought   brushed motor controllers from china for my hobby weight battle robot      these are intended for use with my   cordless drill     v motors which will be driving the left and right wheel respectively  i will be using  s lipos which  when fully charged  have a voltage of     v  can someone put my mind at rest that the    volt excess is unlikely to damage the controller  which is rated for    v     v   also is the fact that the motor controllers are rated for    amp likely to damage my motors   i am to be honest not very clear on current and how this is drawn from a lipo battery  for instance would connecting a lipo directly to my motor result in a massive discharge or does the motor just  take what it needs  in terms of current  can someone maybe kindly point me to an article which casts some light on the subject or even more kindly explain it to me here  ,motor battery
4798,rnn instead of a pid controller,i am building a drone using the raspberry pi and i am using   pid controllers to control the speed and the value for each angle  can i use a recurrent neural network  rnn  or other neural network to stabilize the angles  if so what can the training data be  what type of neural network  nn  is best suited for this kind of application  ,pid raspberry-pi artificial-intelligence
4804,ahrs algorithm question,as far as i understand  ahrs use orientation reference vectors to detect orientation error  and we can use magnetometer to correct yaw drift  but i see from my ak    magnetometer that the data is not so stable  it kind of fluctuates continuously  how can we use this data for ahrs algorithm  ,quadcopter
4808,is the input of esc really limited at    hz and will the pid controllers work properly ,based on the wiki page of esc  the esc generally accepts a nominal    hz pwm servo input signal whose pulse width varies from   ms to   ms  for our project  we integrate a flight controller for our uav  naza m lite and we want to implement position control  we already have localization and we can control the quadrotor by applying servo width to roll  pitch  yaw and thrust throttle  since the esc only accepts    hz  will the pid controller work at only    hz  ,pid
4815,using i c s scl and gpio pins as sda,the beaglebone black which i work on has only   i c busses  say for some crazy reason  i need to use   i c busses  i dont want to chain any of the devices  the idea is to have every device s sda line separated and use a shared scl line so i can use the same clock and have as many sda lines as i want  since the scl clock is hardware controlled there wont be any major issues here  the gpio can do around    mhz of switching so i am happy with that   if that works out  i can spawn   threads to talk on   i c lines making my solution faster  do you think its doable  i would like to hear from you guys as this idea of using  scl and gpio as sda just popped in my head and i thought of sharing it with you guys   cheers  ,i2c
4820,choosing motor characteristics,i have just sized the dc motors i want to use  corresponding to my robot and its intended applications   my figures include a     uncertainty factor to account for friction in reducers and other losses   now i need to actually choose the exact motors i want to buy from the manufacturer  i am targeting maxon motors as i am not an expert and want no problem   i have a few down to earth questions about linking the mechanical needs to the electrical characteristics   maxon states a  nominal voltage  in the characteristic sheets  is that the voltage you should apply to the motor  this may be a dumb question but i have followed the full maxon e learning course and read about other tutorials on the web and i could not find this information anywhere  can anyone who knows about motors confirm  as far as i understand  the nominal torque corresponds to the maximum torque the motor can sustain continuously  so i guess  as a rule of thumb  i should find a motor with a nominal torque   my max torque  after reduction   or around  right  also i chose a motor reference         found here  which has a stated power of   w  as the nominal voltage is   v  i was expecting to have a nominal current of  a  but it states  a  where am i wrong  the motor i chose has nominal speed       rpm   nominal torque       mnm  my needs are max speed        rpm   max torque         mnm  this means a reduction factor of     for speed and     for torque  should i choose a gear closer to     or      what is the  rated torque  mentioned when choosing a gear  i know my input torque  torque on the motor side  and my output torque  torque on the system side   does that correspond to any of these two   i have followed some theoretical and practical courses on the web but i find it hard to find answers to my down to earth question    thanks  antoine  ,motor
4824,implementing a position control for uav through a flight controller  plant model is unknown,we are using naza m lite for our flight controller without gps  the localization is obtained through our rgb d camera sensor  we are able to teleoperate and even implement pid controllers for roll  pitch  yaw and throttle channels for our quadrotor  however  we do not know the plant model because what we are inputting from arduino to the naza m lite are servo pwm ranging from      to         for throttle         altitude hold       maximum throttle         minimum throttle for pitch  roll  yaw       maintain   angle       and      moves the   quadrotor towards its respective axes   however  even at      on every channel  the quadrotor drifts  maybe due to flying indoors and the wind pushes the quadrotor  once it gains momentum  it drifts  we are having trouble tuning this because we do not know the relationship of the output is to the position  if the output were velocity  it would have been easier  but as in our case  it is not  is there a way to find the plant model of the naza m lite and how can we tune this  ,localization pid quadcopter uav
4827,nao motor model identification,i am trying to create a model for the nao  robot  s motors  the figure below shows the step response for the knee motor  afaik the nao internally uses a pid controller to control the motor  i have no control over the pid or it s parameters  thus i would like to treat the motor including pid as a black box  theoretically it should be possible to model pid motor as a  system  i e  a second order lti system  a  system is defined by the following differential equation  t   ddot y  t     dt dot y  t  y t    ku t   i tried fitting a  model but was unable to find good parameters  any idea what model to use for this kind of step response  edit  i tried modifying the equation to add a maximum joint velocity like this  t   ddot y  t      frac  dt dot y  t    m     dt dot y  t    m       y t    ku t   where  is the maximum velocity  the fraction should be equivalent to   however i am not sure if this is the correct way to introduce a maximum joint velocity  the optimizer is unable to find good parameters for the limited velocity formula  i am guessing that is because the min   introduces an area where parameter changes do not cause any optimization error changes   ,motor
4828,is the nominal voltage of a motor the voltage to apply to the motor ,i have just sized the dc motors i want to use  corresponding to my robot and its intended applications   my figures include a     uncertainty factor to account for friction in reducers and other losses   now i need to actually choose the exact motors i want to buy from the manufacturer  i am targeting maxon motors as i am not an expert and want no problem   i have a few down to earth questions about linking the mechanical needs to the electrical characteristics  among them  question     maxon  or the other manufacturers  states a  nominal voltage  in the characteristic sheets  is that the voltage you should apply to the motor  this may be a dumb question but i have followed the full maxon e learning course and read about other tutorials on the web and i could not find this information anywhere  can anyone who knows about motors confirm  i have followed some theoretical and practical courses on the web but i find it hard to find answers to my down to earth question    ,motor brushless-motor
4829,choosing dc motor  max needed torque vs nominal torque,i have just sized the dc motors i want to use  corresponding to my robot and its intended applications   my figures include a     uncertainty factor to account for friction in reducers and other losses   now i need to actually choose the exact motors i want to buy from the manufacturer  i am targeting maxon motors as i am not an expert and want no problem   i have a few down to earth questions about linking the mechanical needs to the electrical characteristics  among them  question     as far as i understand  the nominal torque corresponds to the maximum torque the motor can sustain continuously  so i guess  as a rule of thumb  i should find a motor with a nominal torque   my max needed torque  after reduction   or around  right  ,motor brushless-motor servos servomotor
4830,stated power for a motor does not equal nominal voltage x current ,i have just sized the dc motors i want to use  corresponding to my robot and its intended applications   my figures include a     uncertainty factor to account for friction in reducers and other losses   now i need to actually choose the exact motors i want to buy from the manufacturer  i am targeting maxon motors as i am not an expert and want no problem   i have a few down to earth questions about linking the mechanical needs to the electrical characteristics  among them  question     i chose a motor reference         maxon reference found here  which has a stated power of   w  as the nominal voltage is   v  i was expecting to have a nominal current of  a  but it states  a  where am i wrong   ,motor servos servomotor
4831,selecting a gear reduction  torque vs speed,i have just sized the dc motors i want to use  corresponding to my robot and its intended applications   my figures include a     uncertainty factor to account for friction in reducers and other losses   now i need to actually choose the exact motors i want to buy from the manufacturer  i am targeting maxon motors as i am not an expert and want no problem   i have a few down to earth questions about linking the mechanical needs to the electrical characteristics  among them  question     the motor i chose  maxon brushed dc         found here  has nominal speed       rpm   nominal torque       mnm  my needs are max speed        rpm   max torque         mnm  this means a reduction factor of     for speed and     for torque  should i choose a gear closer to     or      ,motor brushless-motor servos servomotor
4832,how does the  rated torque  for a gear relate to the maximum torque ,i have just sized the dc motors i want to use  corresponding to my robot and its intended applications   my figures include a     uncertainty factor to account for friction in reducers and other losses   now i need to actually choose the exact motors i want to buy from the manufacturer  i am targeting maxon motors as i am not an expert and want no problem   i have a few down to earth questions about linking the mechanical needs to the electrical characteristics  among them   question     what is the  rated torque  mentioned when choosing a gear  i guess it is related to the maximum torque the gear can support    but now  i know my input torque  torque on the motor side  and my output torque  torque on the system side   does that correspond to any of these two  ,motor brushless-motor servos servomotor
4836,how to control pid yaw,my yaw angle varies from      degree to     degree    if my current heading is about     degree  then the wind makes it rotate to the left at about      degree  then how can pid control it to make it rotate back to the right at     degree  since  for pid   error   setpoint   input in my case  setpoint        and input         the the error                       so instead of moving to the right and apply pwm       it rotate to the left and apply pwm       and come back to the desired position  which is     degree  ,pid
4840,a robotics computer with graphics card  lots of computation power  battery  no screen  no keyboard ,i m working on a robotics platform and we need an on board ubuntu machine to run ros image recognition  does anyone know of a good set of computer hardware that has  no screen no keyboard built in battery  for charging separate from the robot  quite a bit of compute power  i       gb ram   i thought about using a laptop  but the keyboard and screen are a lot of extra weight volume i don t want to carry around  something like an intel nuc is appealing  but has no battery  ,driver
4843,how to change the orientation of an object w r t a scene ,i am trying to localize an object in a point cloud using ros  pcl  for that i capture the scene and model using asus xtion pro sensor  i use rgbdslamv  for capturing the model   then i use icp  nonlinear version  to find the transform from the model to each cluster of the cloud  the cluster with the lowest score is chosen as the best matching cluster   pseudocode   however  i am not able to find the correct transformation  here are the screenshots of the results i got      the red colored object is the transformed model overlayed onto the scene  the yellow object represents the original model in the coordinate system of the scene  now  my concern is why there is no proper transformation  am i missing something   second  i see that the object model and scene are in different coordinate system  so the model appears inverted when presented in the scene s coordinate system  is there a way in which i can transform the model upright before running icp  thanks    ,computer-vision kinect
4847,understanding a sliding mode controller for quadrotors,i m really willing to understand and implement such a controller  sliding mode  for a quadrotor  i ve found this interesting document explaining that topic  if you scroll down until page      don t be scared  the document is just     pages  you can find the following height control law  equation        u      frac m   cos  phi  cos  theta   c    dot z r    dot z     ddot z r    epsilon    sgn s      k   s     g   the explanation of most of the term should be quite easy  but let s focus on the variable z  the height  or altitude if absolute  of the quadrotor  anyway the control law  pretends  not only the goal height z  through   but even the vertical speed  and vertical acceleration   r means here reference   now   to me is not clear whether those variables the setpoints are  that must be reached once the quadrotor reaches its predefined height or they just symbolize an abstract mathematical formalism but are going to be most of the time zero  because i want to reach the target height with  but         i hope my question is clear  even if this i put in the title  sliding control  i think it may be helpful for other type of controllers  regards ,quadcopter
4853,controlling a    w motor with   v   a batteries with an arduino board,i want to build a robotic vacuum  i have a    w   v vacuum motor that i want to switch on automatically at a set time every night  the batteries i will be using will be  x  v   ah deep cycle gel batteries connected in series  i want the arduino to switch the motor on and off  so my first real question i guess is will the  v supplied from the arduino be able to switch on a motor that big  the second question is a mosfet the answer  my apologies i m pretty new to all this but love it   can i control a    w motor with   v   a batteries with an arduino board and a mosfet  what type of mosfet would i use  ,arduino
4855,is a simple range sensor described below sufficient to implement particle filter localization ,i am trying to implement a monte carlo localization particle filter localization with a simple range sensor  the range sensor only sees in the direction the robot is heading and returns back any obstacle in its line of sight  if there is no obstacle  then the sensor returns back the distance to the boundary wall i e  there is no maximum range for sensor  but  the problem is that i am not able to locate the robot s position  now  i am feeling is it cause the sensor is not powerful enough  is it feasible to do localization with such a sensor or should i change the sensor type  please tell me what you guys think  ,localization particle-filter
4857,continous rotation with cables,a motor needs to spin n     degrees  on top of the motor there are distance sensor which scan the room  i e  lidar  what options do i have for implementing a continous rotation while having cables which are in the way  ,motor chassis
4863,real time operating system for robotics vision,i have robot vision system which consists of conveyor with encoder  two cameras  gigabit eth and usb  and simple illuminator  i need to trigger cameras and illuminator when encoder reaches position interval  i m considering using real time operating system for this task  encoder  illuminator and cameras connected to pc and vision system application runing on it  which real time solution you can reccomend for this problem   i m considering using beckhoff twincat software which turns normal operating system into rt   ,computer-vision real-time
4866,what happens when a brush less motor stalls ,ok apologies for those who think my questions are not direct enough as i got warned about this  i am really new to this and i will try to keep this one direct enough for the forum   for obvious reasons i cannot test this out without damaging something so would prefer to learn from the experience of others  i have a  turnigy trackstar          t     kv brushless  motor which i will be using for my weapon  spinning disk    relevant specs of the motor are  kv       max voltage    v max current   amps watts      resistance        ohms max rpm        i will use this with an esc with the following specs  constant current    a burst current    a battery     s lipoly       s nixx bec   v    a motor type  sensorless brushless size     x      mm weight    g programming functions  battery type  lipo  nixx brake  on   off voltage protection  low   mid   high protection mode  reduce power   cut off power timing  auto   high   low startup  fast   normal   soft pwm frequency   k     k helicopter mode  off    sec     sec  start up delay  if the motor stalls  i know the current draw will increase drastically  so my questions are   in the case that the motor stalls  my disk gets stuck in the opponent etc   then what gets damaged  the motor  the esc  both  and how long before this happens   would i have time to turn the r c switch off before irrevocable damage occurs  once i am obviously observing the action    notes  i will be using an on off switch on the r c to just turn the motor on and off  so no proportional speed increase etc   plus i will be using an      volt battery even though the motor is rated for a    volt maximum   thanks  ,brushless-motor esc
4872,roll  pitch calculation problem ,my problem is that when i hold my sensors  mpu      so that  y axis is downward  and y axis is on the horizontal plane  i expect that pitch      degree   and roll     degree  but actually pitch      degree  and roll       degree  however  when roll      degree and pitch     degree  that is what i expect   do you know what cause my problem  thanks ,quadcopter
4873,choosing suitable simulator for a swarm of auvs,which of the following simulators is the best choice for simulating a swarm of auvs working together to perform a mission  please clarify your reason and if you know any better choice  i would greatly appreciate it if you kindly help me  please consider the need for doing hardware in the loop hil  simulation    webots v rep auv workbench gazebo uwsim swarmsimx   in addition  notice that capability to connect to the middle wares like ros is really important   the other option is using a game engine like blender but i think it needs a lot of developing effort and is time consuming  would you recommend this approach be used  if not  why not  and what would you recommend instead  ,mobile-robot ros simulator auv
4874,what middle ware do you recommend for a swarm of auvs ,working with a swarm of robots  collaboration between the nodes is really important either for the goal of simulation or real word operation   middle wares are the frameworks for this special purpose  i know some of the relevant middle wares like ros general purpose but popular  or umvs that is basically design for auvs   now  i have two questions   do you know any other choice for the above mentioned purpose   what criteria should i consider for choosing a middle ware suitable for my purpose   thank you  ,mobile-robot ros
4875,arduino lightsensor blocking code,i have a gy    light sensor and i am trying to make a skittle sorting machine  there is a little wheel skittles can drop into then they are turn to    degrees read by the light sensor then dropped out the bottom  the problem is the code seems to get stuck after reading the light sensor  it still flows through but won t execute the moving of the servo   as soon as i take out the readsensor line the servo works like normal  do i have to dispose of the color sensor some how   ,arduino sensors rcservo
4880,programming a g code interpreter,i want programme my very own g code generator for my final year electrical engineering project  i know that there are many open source g code generators out there  but i need a g code generator which generates a g codes for custom circuit designs drawn by the user and pass the g code serially to my   axis cnc machine  so currently i m working on a qt based gui where i draw  dxf format circuit diagrams and electrical components  like resistors  capacitors  and when i press a  generate g code  push button i should generate a text file with nice set of g codes for my designed diagram  so the problem here is  how do i generate the g code  is there any specific algorithm to follow or adapt  i tried googling for g code generator algorithm but i couldn t find any helpful stuff  ,cnc circuit
4885,developing a quadrotor using ros,i  suppose who know ros and how it works  at least most of you  i have some question regarding the implementation of a quadrotor in that  framework    d movements  a quadrotor has  dof and moves in a  d  environment  looking at the various ros packages i could not find any  package that allows to drive a  robot  in the  d space  the package   move base for instance allows only  d  make sense to use this  package for such a project  i thought to use  d navigation projecting  the  shadow  of a quadrotor on the ground    moveit  it seems a real interesting and promising package  but i read that it is for robotic arms and not expressly indicate for  quadrotor  maybe one can use the possibility to create a virtual  floating joints in moveit to let the quadrotor any movement in a  d  environment   that s ok  but i cannot understand whether is  too much   and not useful for a flying robot  trajectories  the possibility to create a  d trajectory in the  space seems to be not a standard package of ros  i found octomap  which allows the creation of  d maps from sensor datas  very interesting and for sure very useful  but   i don t think it could be useful for  creating  d trajectories   should i in that case create an extra package to compute  d trajectories to be feed into the quadrotor  or there  already something like that   there is already an existing project hector quadrotor which seems to  acclaim a good success ans it is very considered in the field  most  people refer to that project when speaking or answering question  regarding quadrotors in ros  i saw many times that project   since  weeks  and due to the total lack of documentation i didn t try anymore  to understand how it works  really too difficult   another interesting project  ardrone  has comments in the source  code   in russian        could you me give any good suggestions  or point me in the right direction  please  it would help me to understand how to focus my searches and which  package i can cannot use  update  my goal is to let the quadrotor flying and using gmapping to localize itself  i ve heard and read al lot of stuff about that but i found all this tutorials very hard to understand  i cannot get a global vision of the software and sometime i run in problems like   is there a package for this task  or should i invent it from scratch   thanks  ,ros quadcopter
4888,how to make a robot following a virtual eight figure pattern without using microcontrollers ,the robot should go around   boxes and stop at the starting point after tracing a   figure pattern  with micro controllers  i guess it can be easily done using sensors or navigation algorithms  please suggest how can be one made without them  ,mobile-robot
4890,will ais ever be as advanced as the human brain ,i m reading a book about a hypothetical economy in which robots work for us because they eventually became able to do everything we do   our work here is done  visions of a robot economy  by nesta   i was wondering though  is it theoretically possible for a human brain  an extremely complex  artificial intelligence the way i and many others see it  to comprehend itself in its deepest details and produce an artifical intelligence which is exactly identical  it sounds unlikely  if not then  how close can we get  this is not a philosophic question  the ideal answer would be a rigorous demonstration based on metrics simplifying the problem to be able to answer it  however objective answers with valid arguments are always interesting  too  ,artificial-intelligence
4891,quadcopter hovering problem,my quadcopter can lift off the ground  but it kinds of circles around  here is my video  anyone helps me  ,quadcopter
4897,are there surface texture sensors for integration in circuits ,i have a project in mind for a robot which is able to recognize surfaces  and thought about including the following sensors   a temperature sensor a colour sensor  or a complex of electronic components to determine a colour and a texture sensor  or  as above  a complex of components to fulfill the purpose  now  i did some research on finding a preferably small  texture sensor for soldering into an electronic circuit  similar to those little temperature sensors one can buy  i already thought that  small  would probably turn out to be not small at all before i searched  but my research has been fruitless  not just fruitless like in  i can t find exactly what i want   but fruitless like in  i cannot find anything similar to what i want      most things that turned up either were scientific papers about whole devices  or whole devices for purchase  some company even choose  structure sensor  as the name of their ipad compatible  d scanner  which made the search utterly depressing as every second article i found is about buying some pre built ipad device  all i need is the electronic component  nothing else  so hope that any of you people can spare me some research time and recommend me a company site whatever which sells such texture sensors   btw   i do know that surface sensors are probably a bit way more complex than temperature sensors  and my hope for getting what i want is low  but just because i cannot find something  ot does not mean that it doesn t exist   ,sensors
4900,inverse kinematics constant end effector angle,i have a simple rrr manipulator where one motor controls the base rotation  and the other two allow movement in a plane extending forward from the base and upwards downwards  are there any standard ways to ensure the angle of the end effector remains constant  my current solution uses explicit trigonometric expressions based on distance between joints  but if there is a better way to solve it to include restraints i d be open to suggestions  edit the manipulator is essentially like the image below  but with an additional base rotation  this allowed for the inverse kinematics to be simplified  as a reference here is the site   ,inverse-kinematics
4901,how to tune the pid parameters using fuzzy logic ,i previously used the ziegler method to tune the parameters of my pid controller to control my robot s position  i then implemented fuzzy logic for self tuning the parameters   i have two inputs to the fuzzy logic controller  one is the position error and the error rate  i know that my problem might be due to not understanding the effect of each parameter very well  the problem is that i am confused in setting up the fuzzy rules  when do i need to use high and low values for kp  kd and ki to achieve the best tuning  is it that kp must be very low when the error is almost zero  hence  the robot is at the desired position   the same question applies for all of the three parameters  ,control pid tuning
4902,lm     and lm     regulator make microcontroller hang,i am making a self balancing scooter which runs off   x   v sla batteries connected in series to make   v  everything works as expected except for the power supply which makes me pull most of the hair in my head for   weeks now  hope someone could help  the     v motors run off the batteries directly  now for my scooter  i need a    v line for the half bridge drivers  and a   v line for the signal part  for    v i am using a lm        hooked to the batteries       and for the   v signal i am using a lm     adj  also hooked directly to the batteries  or is it supposed to be hooked to the output of lm        for better performance     the problem is that  when the motors are under load this power supply system makes the microcontroller hang  or reset i am not too sure  since everytime i have to try to turn off the power switch immediately  because the motor keeps running with whatever value they are fed with right before this happens   usually within   minute of riding  which is very dangerous when someone is onboard  i have read and re read the datasheet of lm     and lm     many times  and have tried many settings  from recommended to different values of capacitor and inductor  for the diode  i am using the ss    i guess its not because of electromagnetic interference  since while i do have the pcb located near the motors  the pcb is actually put inside a homemade faraday cage which is grounded  battery     and the motor cases are also grounded  plus that the microcontroller only hangs when motors are under load  i e  me on board   especially when i go from forward to backward  the motor controller is self made  using   x auirf    s mosfets  i also put   x     uf caps between the motors and the    v  would anyone be so kind to throw some light  what would a power supply for this kind of application is supposed to be  ,motor
4903,self locking actuator  friction versus worm gear,i am planning to control my bicycle derailleur with an electronic circuit  the advantages being multiple but not topic of this question  the actuation would be performed by placing the assembly very close to the derailleur  but not on it  and by winding the usual steel cable around a spool placed on axis of a gear  and by using a motor to turn the gear   this question concerns the alternatives for the spool self locking mechanism  and eventually the kind of motor to use   in the literature i found  and other similar ones that directly modify the derailleur with a stepper motor  and then are forced to keep the stepper motor powered up all the time to keep some torque on the shaft  i consider this inefficient  therefore i require a self locking system to be able to remove power  i come up with two ideas   worm gear operated by a dc motor  where the steel cable is wound around the gear  this system is self locking or almost self locking  according to the gear ratio  the gear cannot  easily  drive the worm  a motor driving normal gears with an appropriate reduction factor  but with an additional friction element  whose friction force is greater than the strength of the spring mounted on the derailleur  sorry if i mixed the technical terms   this is what normal bicycles already have  the friction along the cable and in the element placed n the handle is high and keeps the derailleur in place   both system would be assisted by a position sensitive element  a trimmer   to detect the actual position of the gear and or of the derailleur  all configured in a closed feedback loop  i don t consider additional options for the gear such as this one   that consists of parallel axis gears  whose teeth are however shaped in a manner to achieve self locking without the need of a low efficiency worm system  from my point of view  i cannot see any clear advantage of worm gear vs friction except for   the worm gear may allow me to build a more compact assembly  thanks to the two axes being perpendicular speed vs torque  worm gears reduce the torque requirements  but the motor has to spin a lot and i cannot wait   seconds for each gear change   concerning the choice of the motor type  this is not the main question though   i think that   a worm gear allows me to easily use a dc motor  since torque requirements are low and i don t need to detect the position of the shaft  moreover  dc motors increase torque with decreasing speed  while stepper motors have the maximum torque defined by the stepping frequency  dc are more compact and cheaper  important if i decide to offer this assembly as a kit and not unique  personal prototype  i am working with  v supply and i fear most easy to get dc motors  old printers  scrap electronics  work on   v  with a significant reduction of the available torque when operated at  v   i was looking for a  mechanics  section in stack exchange but i couldn t find it  so i opted for robotics instead of electronics  ,brushless-motor stepper-motor
4904,is there build your own garage robotic assembly lines out there ,i am new to robotics  and would like to build a smaller robotic arm than in manufacturing facilities  i want a small robotic material handlers that can pick up or handle small objects around    x   x    objects  essentially a small robotic assembly line in my garage  are there any kits i can purchase that deals with robotic assembly lines  i was wondering has anyone dealt with this before any suggestions on this  ,robotic-arm
4911,robot to manipulate poultry,i am a software engineer and also a poultry farmer  i periodically have to manipulate my poultry in such a way as to grab their head and hold them for a brief period  approximately         seconds   this is an extremely labor intensive process and it occurred to me that i might be able to use robotics to do the same task   i am a software engineer so i know very little about robotics and am hoping that someone can point me in the right direction   can someone please refer me to companies and or robotic systems that might be able to help me with this task  i currently load the poultry into cages specifically designed for this process   i am thinking that these cages could still be used as they keep the birds from running and make it much easier to capture their heads  i recently read about a raspberry pi that had a port of deep belief image recognition sdk and thought this might be a promising start  ,robotic-arm
4913,gyro rate gets increase problem,i am using pid controller to stabilize quadcopter  its working well on the jig  but when i removed jig it went up and hit ceiling  i analyzed my data and from which i come to the conclusion that at static poisition my gyro sensor is outputing    deg sec but when i start motors  without being control in  gyro rate jupms to     deg sec  this increase in rate due to vibrational noise is causing quadcopter to liftup without beign my intension  any suggestions to get rid from this vibrational noise   ,sensors
4914,robotics simulation from png map,i am a complete beginner at this  i have an arbitrary map as a png file  black and white  only   and i m supposed to draw a robot at a position x y  and then i m supposed to simulate the robot taking a laser scan measurement for an opening angle of     degrees  separation of each scan line is   degrees  so  obviously  each laser scanline is supposed to be obstructed by black pixels in the png map  while the other lines just keep on going for an n distance  i ve attempted drawing scanlines around the object  but i m running into issues when it comes to getting each line to be obstructed by the black lines  to my mind  it requires a completely different approach  any helpful advice on how to get started would be greatly appreciated  ,python mapping simulation
4928,simplest and cheapest way to create a spring back latch,my and a friend are hacking together a nespresso coffee pod dispenser  we have our heart set on a particular design after thinking up countless ways of dispensing a single pod   the design has a single flavour of pods in a vertical tube so they tend to fall down  one or more latches around the base of the tube stop any pods from falling out  releasing the latch for   ms will allow the pod through    mm fall  well past the lip of the pod  while catching the next one  the latch is the problem component  i haven t yet found a suitable product off the shelf  ideally  the solution would be compact and cheap      and moderately bulky  rotating latch with string attached to rack and pinion powered by electric motor   don t think it s a simple enough solution  rotating cam   how a gumball machine works  i suspect    this was also suggested in an answer  but would involve both a mechanical and electronic motor component  not as simple as option       i have a  d printer  so i am open to mechanical solutions   a custom latch with crude electromagnet for example   note the desired size of the latch  yellow   holding pods  orange  in a tube  black   yes  motors can work  but they would be quite bulky  i m not after the obvious solution  but a clever one  or one which finds the suitable product   i understand that with only one latch on one side  the pods will not sit perfectly vertical  and the latch would need to be higher up   ,mechanism
4930,chassis materials for hobby weight      kg  battle robot,i have sorted out all the internals for my robot  drive systems and weaponry  and now i need to put it all together in a chassis which will be about    cm wide by    cm long by   cm high  i have examined different options  including perspex  acrylic and polycarbonate as well as aluminum  in a number of thicknesses  however i have excluded perspex and acrylic because  unlike polycarbonate  they tend to shatter if bent  so now it is down to polycarbonate and or aluminum  so here is the problem  up for discussion or a solution   but first i must point out  a  that the overall weight limitation in turn imposes chassis weight limitations  b  that this is my first ever robot wars entry  and  c  i am likely to be up against cutting and tearing devices   i already have the weights of the different materials in hand  so all of the following options are possible in terms of weight  option    do it all in   mm polycarbonate  option    combine a thin    mm aluminum  outer shell with an underlying   mm polycarbonate one to get a good mix of the properties of both  rigid and hard  thin and heavy   flexible and strong  thick and light   option    as option   but the other way round    mm polycarbonate on the outside and   mm aluminum on the inside  should i go with option         or something else altogether that maybe i am not seeing   note  having it all in   mm aluminum is not possible as it will be too heavy   i checked  should i have the aluminum on the outside as a heavy duty shell or on the inside as a  last resort  layer   note  in my mind these layers would be held together with nuts and bolts with washers to spread any impact loads  but even here should the nuts and bolts be tightened for rigidity or left slightly loose for impact absorption   any advice  especially from people seasoned in the art of robot warfare please  ,wheeled-robot chassis
4933,power switch standards and suitability for purpose,i scavenged a   terminal power switch  legion eps     from some electronic device  don t remember what it was  and it has the following markings on it  legion eps     a    vac tv    a    a    v  t     i would like to use this as the main power switch for my robot which will have nothing higher than    volts and a  normal  total amperage  i e  with all the motors in it running  of around    amps  but of course if a motor stalls then the current will rise much higher   first of all i cannot understand how the same switch can be rated for different amperages  i cannot find any datasheets for this switch that might help nor any reference to the standards  tv   and  t     so i would like to know if this can handle     amps at    volts  if it helps at all  the wires currently connected to the terminals are quite thick and have     awg     volts  written on them  secondly i would like to ask whether i need to cater for normal running amperage levels or for stall current levels  which are obviously much higher  although people talk about stall currents running over     amps in some cases   which quite frankly cause me some concern   i cannot seem to be able to find any such switches on any robot component websites  so i am starting to think that it is the  normal  level of current i should plan for and not the  stall  one  am i right in this  ,current
4934,perfect implementation of asimov s   laws,after seeing the movie  i  robot  i got this question  if asimov s   laws  actually implementing law   automatically implements the other    are perfectly implemented on a quantum computer that controls an army of humanoid robots  and it  decides that taking complete control over the politics and economics via revolution is the best way to ensure human happiness  shouldn t it be allowed to proceed peacefully to ensure minimal loss of life  isn t the hero s decision to destroy the computer fundamentally wrong   ,theory
4937,can i use qt to communicate with a lego nxt robot ,qt has native bluetooth support  but can it be used to communicate with the lego nxt robot  ,nxt robotc
4939,why can t i use different escs together on a multirotor ,i m working on a diy quadcopter build from scratch and have bought a  pack esc from castel creations while i currently have my quad up and running sort of   from what i ve read on the various sources and forums on the internet  i am not able to  not recommended to use different escs together on the same quad  as i bought my escs together as a   pack  and am not able to buy any replacements unless i were to switch out all   of them  this has me worried in the eventual case of a spoilt esc in the future  from what i can gleam from various posts on the internet  it seems to have something to do with the rate at which escs communicate with the flight controller if so  can i not simply buy a esc programmer and program all of them to communicate at the same rate  i ve asked the dude at my local hobby shop  and he said that i cannot should not be using different escs from different brands or even the same brand but different models  i e   v     v   escs together  i would really appreciate it if someone were to clarify what exactly is the issue with using different escs together on the same quadcopter  p s if it helps  i m currently using the apm     as my flight controller on a wfly transmitter and a f    frame  ,quadcopter microcontroller electronics esc multi-rotor
4943,what servos does this robot use ,well  i wanted to use some very small servos for a project and the smallest i could find there these    but danny choo  a japanese blogger  started a business with robotic dolls some time ago and i remember him mentioning somewhere on his site that he uses servos in his dolls    also this pic  containing doll nudity    this is about   cm in height and therefore the servo in my first link is obviously too big  to e g  fit inside the arm  i was wondering what kind of servo or motor in general if it s not a servo in the end  he is using that is so tiny it can fit in there  does anyone here have any idea  ,motor servomotor
4944,does anyone have a working example of using qt to communicate with nxt ,i m stumped  i ve been looking through all of the qt classes and i m so completely and utterly lost  there are only three examples of bluetooth use in qt  but none of them work for me  i just need a program that can talk with nxt and analyze an image from a webcam  has anybody gotten this to work before  ,nxt troubleshooting
4946,joint angle correction using lm,i have a camera mounted on a rotational joint  i need to calibrate the extrinsics of this camera  i can fix the camera at an estimated angle  facing the ceiling   then i want to get the real angle  for that i track key points in the ceiling while moving my robot forward  supposing that odometry is perfect  i will see a difference between real key points shift and estimated shift from the odometry  i thought about using levenberg marquardt to find the optimal solution which is the angle and of my camera in the robot frame but what would my equation look like  ,cameras odometry joint
4948,submarine screw and the isolation from the water,how does the submarine prevent water flow through the screw mechanism  the mechanism rotates the screw so there should be a little gap  how come the water doesn t come through this gap in to the submarine  ,motor design
4949,has hierarchical learning been embodied in a robot before ,i ve been reading about hierarchical reinforcement learning  hrl  and it s applications  a well written literature review on the subject can be found here  however  i was wondering if research has ever been done where an hrl system has been implemented on an individual robot  this paper seems to imply that it has been  by saying that the delivery task that it models  is commonly used in hrl  both in computational and experimental settings   however  my google scholar searches haven t turned up any fruit as to what this real world experimental setting might be  help would be appreciated for finding either model based or model free implementation of hierarchical reinforcement learning in a robot  ,machine-learning reinforcement-learning reference-request
4953,measuring the performance and response rate of escs,how would i go about measuring and quantifying the performance of an esc  i am looking to measure the response rate in hz  of an esc  as well as it s performance i e how fast it starts and stops  as well as how much it increases decreases the motor s speed per tick   i m assuming that i can manually program an esc and it s response rate with a programming card module that is compatible with said esc  but i would still not be able to measure the exact performance of the esc  i would appreciate any and all inputs and suggestions  p s this question is linked asked in conjunction with a previous question of mine here on the robotics stackexchange here   why can t i use different escs together on a multirotor  ,sensors quadcopter electronics esc multi-rotor
4954,raspberry pi vs beaglebone black rev c on vending machine,i wish to start my vending business  but none of the existing vending machines fit my needs  so  i need to choose the  brains  to my vending machine under current development  the user experience of my vending machine will be   user change their products on touchscreen display  firegox open rails application running in the  brains    insert moneys  after that products will be returned to the user and notification  json query  will be send to it saas   there are requirements   popular  i want to use a widely used computer for better support  debian like or centos like system  easy to develop rails apps on them  big count of gpios working with touch screen and large display  at least      working with mdb protocol  for currency detector needs   so  i need your hints  it seems that beaglebone is more powerful then raspberry pi  but there is one problem  it doesn t support many of the video outputs  is there any solution to make good video output on beaglebone  do other such computers exist  ,raspberry-pi beagle-bone
4955,comparison of the efficiency of dc motor current limiting   control methods ,i am using the wheels and motors of an rc toy car as a simple robotics platform  the car has   motors  one drives the back wheels  the other steers the front wheels  the steering motor is stalled by design when steering  it is blocked at a fixed angle by the plastic chassis  it draws      a when stalled  i e  anytime when steering     due to this marvel of toy engineering i have to use an oversized motor driver ic  l   b    a continuous  and this motor draws about  w of power      a x    v   i m using this ic to control the other   normally rotating   motor as well  which appears to be the same type      a stall current  around    ma no load  and        ma at normal loads   testing with various series resistors i have found out that    a are sufficient to turn the steering wheels and keep them in position  using a resistor might allow me to use a driver ic with a lower amp rating  l   d       a   however the same energy is still wasted  only as heat  while this is not a serious issue with this toy setup  i am planning to build bigger robots with significantly more power  so energy conservation and current control will be important in the long run  and motors may also stall accidentally  looking into dc motor current limiting  i ve found the following approaches   series resistor   simple  cheap  bidirectional  wastes energy  dissipates heat current source with     transistors and sensing resistor   relatively simple  however i ve only found unidirectional circuits  which would get shorted when switching motor direction  is there a way to use this method bidirectionally   and or with a   channel h bridge ic     i cannot place it before the ics common supply  because the   motors draw different currents    chopper circuits pwm   will this reliably protect the ic from overload  is it energy efficient   are there other other methods i am unaware of  something on the principles of switching supplies  would it be simpler in my application to use   separate drivers h bridges and place a voltage divider between them  so that a lower voltage is provided for the inefficient stalling motor and more to the one that moves the robot   so how do the above  methods compare in terms of efficiency and simplicity of design  what is the preferred method in robotics other dc motor applications   also  is it standard practice to limit dc motor current  or a motor is most efficient if allowed to draw as much current as it needs  is it acceptable to use a dc motor that is mechanically stalled by design  or is this only used in cheap crap toy cars  ,motor power driver current h-bridge
4956,what kind of lidar is necessary for slam ,i ve read about various robots using a  d lidar system for slam   such as at igcv     but i m wondering how good exactly does the sensor have to be  specifically   what accuracy is necessary   what field of view is necessary  is it enough just to have lidar scanning forward in a    degree sweep  what angular resolution is needed  i realize that probably with super clever software you could probably do slam with a couple ultrasonic sensors  but using standard packages for software navigation what s a reasonable minimum value for these parameters   and any other important ones i ve forgotten   ,slam navigation lidar
4958,how to program an inovatic usb interface ,in my possession i have an inovatic usb interface   in detail  ui  x  v          i would like to program it to do some simple stuff and things  i am familiar with c  programming but from what i have heard its not possible to program this interface with c   what it looks like      where can i find the drivers for this interface   i have checked the inovatic website but they only have the v    version of the drivers and i m pretty sure that i need v      how can i program it  what language do i use   ,microcontroller
4959,connecting multiple servos to a robotic arm,i am computer programmer and it s really been long since i have done electronics  i need help on connecting my servos to an arduino to power my robotic arm  this is the robotic arm that i am trying to build  i have come up with the connections as shown in the below diagram with my basic knowledge and browsing the internet  i have omitted the signal wires for clarity   what i would like to know is   will this work  is this a good decent design  i think it isn t as i have   battery packs  i would like to have a single power source that would save me the trouble of maintaining so many batteries  to do this i have thought of using a voltage regulator but i am concerned about how this would perform if one servo starts drawing too much load  it might suck up all most the power leaving very little for the other servos   any suggestions would be greatly helpful  ,arduino robotic-arm servos
4960,stereo vision on a moving vehicle,when i put stereo camera on a moving platform and sync the cameras  what kind of delay between the cameras is tolerable  this would probably depend on the motion  but are there some guidelines  are there any practitioner guides on how to build a moving stereo system  ,stereo-vision
4965,how to use gear motor   with arduino,i am new to robotics  i want to make a robot using arduino uno r   i need to use gear motor   for that here is the link   the problem is that motor needs   ma current  but arduino only outputs only   ma current   i want to supply the motors with another power source and use a switch to connect both the circuits  can you please tell me what type of switch i can use  thanks in advance   p s  sorry if i used any wrong technical terms ,arduino motor
4966,keeping two wheeled wall following robot straight,i have a two wheeled  two dc motors  robot that needs to follow the wall beside the robot  the issue is that the dc motors spin at different rates  because they are not identical  of course   so the robot does not go straight when the same voltage is provided to each motor  how can i use ir distance sensors  and op amps  to keep the distance from the wall constant   the robot must travel parallel to the wall  ,two-wheeled
4967,keeping two wheeled wall following robot straight,i have a two wheeled  two dc motors  robot that needs to follow the wall beside the robot  the issue is that the dc motors spin at different rates  because they are not identical  of course   so the robot does not go straight when the same voltage is provided to each motor  how can i use ir distance sensors  and op amps  to keep the distance from the wall constant   the robot must travel parallel to the wall  ,motor
4972,can triangulation by measuring angles to   beacons to find location work over a large outdoor area,to determine an outdoor location i think that i need to measure the angles between at least   beacons and take into account the order i sweep the beacons   is this a workable solution to get positional accuracy of about   cm in a house block sized area  rewrite of question  note no distance measurement is suggested only angle measurements  i am proposing that it might be possible to have a minimum of   local rf beacons and a robot device that sweeps an antenna through a circle identifying the angles between these beacons and to use this information and the order that the beacons are seen to find an absolute location   i tried to prove this geometrically and it seems that with the   beacons there is   unique solutions without knowing the order and   solution if the order is known   there would  i believe  be no need to try to find the distance to the beacons   my question is  could this be implemented for a reasonable cost with some nrf  l   based transcievers and some sort of rotating antenna  ,localization
4980,could a robot be programmed to be human ,this is all hypothetical  if it was possible  it would have been done by now  i realise that this area has been touched upon in many sci fi movies but i wondered that if it was even feasible  how could it be achieved  i know that it would raise a lot of ethical questions  i don t doubt that but i m interested in the science  what would a robot s brain have to be like to function like a human brain  for example  for it to have emotion  e g  love  empathy   learn new things and remember them  make all those connections that a human brain does  thanks to all who reply  ,mobile-robot humanoid
4983,dualcopter degree of freedom,i am a newbie in this drone field  i am curious to know what type of rotation and translation a dualcopter can achieve   by rotation and translation i mean can it be able to roll  pitch and yaw like quadcopters  if not  in any copter what makes them to roll pitch and yaw  furthermore are there any dualcopter design that have movable wings that will rotate the rotors itself or do up and down motion while flying  ,quadcopter multi-rotor
4986,backstepping integrator  changing the virtual control,given the following differential equation   ode in the following form   found in many papers  example  and describing the dynamic model of a quadrotor  in this case i m interested as an example only for the vertical axis     i get the movement about  after integrating the variable  two times  as control input i can control   which represents the sum of all forces of the rotors  a backstepping integrator  as in many of papers already implemented  defines a tracking error for the height  and for the velocity  to build virtual controls  through the virtual controls one can find the needed valueof  to drive the quadrotor to the desired height  see the solution later on  but wait   as said above i need to track both  position error and velocity error  now i asked myself  how can i transform such equation and the corresponding virtual controls to track only the velocity   in my code i need to develop an interface to another package which accepts only velocity inputs and not position information  i should be able to drive my quadrotor to the desired position using only velocity informations  tracking the error for the z displacement it not allowed  the solution for the more general case looks like   for   i could simply put brutal the  for not tracking the position on z but i think that is not the correct way  maybe could you please point me in the right direction  regards ,control quadcopter
4987,how do i determine the heading of a six wheeled robot ,i have a robot simulation that simulates mars exploration rover with six steerable wheels  in case of the following steering configuration  i d say the heading of the rover with respect of the rover s body is about    to the right  my question is what is the right approach of calculating heading with respect of the rover body   do i simply sum the steering angles of steering actuators and divide it by the total number of the steering actuators   additional note  assuming no slippage on a perfectly flat plane  ,wheeled-robot
4990,open source implementations of ekf for  d pose esimation,i am looking for open source implementations of an ekf for  d pose estimation  inertial navigation system  using at minimum an imu  accelerometer  gyroscope    absolute position  or pose  sensor  this seems to be such a recurring and important problem in robotics that i am surprised i cannot find a few reference implementations  does everyone just quickly hack together his own ekf and move on to more interesting things  is that not rather error prone  i would ideally like a well tested implementation that can serve as a reference for fair evaluation of possible improvements   ,kalman-filter ekf pose
4991,seamless motor movement,with the lego nxt mindstorm kit i would like to have a rotating carousel that has  perfect  movement  this carousel has baskets and therefore it has quite a bit of inertia  i would like to find a method to calculate the perfect time to slow it down  taking into account motor friction  and momentum etc  here is some data i ve collected   the motor power is the power to the motor  the break time was the time it took to stop from the time that the motor power was set to    the over turn dist was amount of rotation in degrees that the motor continued to rotate after the power was set to    is there a specific method or approach to optimize the motors movement so movement can be precisely rotated to x degrees  ,motor motion motion-planning
4994,best ugv platform ,my lab is interested in a good all terrain ugv that can also be used indoors  we are particularly interested in the clearpath husky  clearpath jackal  and the robotnik summit xl  or xl hl   though we would welcome any other suggestions  does anyone happen to have experience with more than one of these  and can speak to their pros and cons  ,ugv platform
4996,nano quadcopters microcontroller and battery,i am looking into building a nano quadcopter  but as i watch more resources and videos i get more confused  regarding some of the things that i hope would be answered here  i am in very basic level of expertise here  i haven t built any robots or quadcopters to be exact  what i want to know is  when i program a quadcopter say using intel edison chip  how do i power the quadcpter  i could not find that small size battery to move the propellers and start the chip  further more what is the procedure i should follow while developing a nano or small quadcopter  i saw a link on instructable that uses python on raspberry pi and then that raspberry pi control the arduino to control the robot  can it be done only by using raspberry pi itself   i am getting confused and i would like to know if i have to make small or nano quadcopter what should i be doing to get started  most of the latest chip support linux and high level programming language like python  so i hope i can go about programming the entire quadcopter using python or similar high level language and i don t suppose i have to stick with c langauge now  if i am wrong please help me understand the matter  there is high chance that i could be wrong  ,arduino quadcopter raspberry-pi python
4998,good  d simulator for outdoor autonomous navigation,what s an appropriate tool for simulating a car driving in a simple closed loop racetrack  i m trying to implement the control logic for an autonomous vehicle  and i d like to be able to first simulate the behaviour before testing on a physical platform  the target environment is mostly  d  but there are some  d obstacle like small ramps and arches  so i can t use a strictly  d simulator  i ve looked at some robotics simulators  as listed here  but they seem like overkill and none of them seemed designed to model outdoor environments  i ve done a little work with gazebo  and i can t find any guide of texturing the ground sky background  all i really need is some way apply a texture map to the ground and sky  create a handful of obstacles  and then to calculate a camera feed as a simple two wheeled chassis moves along a mostly  d course  however  i need the video input to be as realistic as possible because i don t have access to the real world racetrack  i need to be able to test and train the control logic in the simulator  and then load that logic onto the real mobile platform and have it navigate the course  ,navigation simulator cameras
5001,how does power get to the flywheel in a motorized gyroscope ,when i look at my toy gyroscope  i have never seen the inside of a motorized gyroscope   the central flywheel is suspended within the various gymbals and needs a lot of freedom of movement   it s hard to see how an electric motor in the flywheel hub could be supplied with power  how do  real  gyroscopes maintain angular velocity in their flywheel  ,gyroscope
5006,turning position level fk to motion level fk,i have a position level forward and inverse kinematics blocks that i built on simulink by using s function  i need to obtain the motion level fk and ik as well   fk input is two motor angles and output is planar x y coordinates and ik is the other way around  now i wonder if i simply put a derivative block at the output of each block  would it work   i tried and this and cascaded the blocks to see if the input overlaps with output but it didn t  so apparently my idea is wrong   can someone explain why it is   ,inverse-kinematics forward-kinematics
5011,linear state space model for mobile robot,how can i write a linear state space model for a   wheel mobile robot with ackerman steering in terms of error  i want the robot to follow a line  the robot is rear wheel drive  ,mobile-robot line-following
5014,control circuit of a humanoid robot  something like icub or asimo ,my friend and i are building the upper body of a humanoid robot for our m sc thesis project  there are    dc motors in this robot  the thing i want to know is what is the best way to command these motors simultaneously  the design i had in mind is for each motor to have its own micro for position and velocity control and then one master micro to command and control the slave micros  if this is the best way to go how does the master micro command slave ones simultaneously  another question i have is what is the best micro for the robot to go with between arm and pic  i want the master micro to receive its command from a pc  any help would be appreciated  ,control microcontroller communication
5016,remote control laser meter,i am looking to buy a laser distance meter and to connect it to a motor and a  g cellular to control both the motor and to mesure the distance  i will appriciate your advice on how to do so  thanks ,laser
5020,i am new in robotics    i want to know about slam algorithm    how should i proceed ,please give me guidance how should i proceed to know about slam algorithm  i am following some youtube videos but those are not so much helpful for me       ,computer-vision
5023,is the accuracy of estimated position in localization better than estimated position in slam ,we estimate position of robot in localization and slam  my intuition says we get better position estimation in localisation than in slam because we have better sensor model likelihoods in localization because of given complete environment than in slam  i would like to know the difference in accuracy of estimated position in localization and slam  ,localization slam particle-filter
5028,trying to design a mechanical system with vertical and horizontal movement,i m trying to devise a system to lift a   kg weight a distance of    m vertically  and allow it to move in out a distance of   cm  i d like the motions to be able to occur simultaneously if possible   i m thinking for the vertical motion i can use a suspended climber system  however i am unsure as to how i devise a system for the horizontal motion  in the horizontal plane i need nothing to protrude   only when the device is told to extend  so a horizontal suspended climber system isn t a possible solution  i m thinking i will need to use   electric motors  also   i d like to mount it to the side of a car   so lightweight and low power draw is a must  does anyone know if there is anything available that will do this  or suggest how i could combine a couple of systems to make this work  any information is appreciated  ,mechanism
5031,connect to video stream with java app instead of console and mplayer,i m building a quadcopter using raspberry pi  there is the pi camera connected to the raspberry pi which is streaming the captured video  i can connect to this stream via wi fi on my notebook  linux  by using the console command  nc  and then show it by  mplayer   what i want to do though is avoid the console commands and connect to this stream directly through my java application  the reason is i want to do some image processing operations with this video so i need to have it in my application  is there anyone able to help me  ,quadcopter raspberry-pi cameras linux
5034,control circuit of humanoid robot  is it worth to learn and use ros ,i am building the upper body of a humanoid robot for my m sc thesis project with    dc motors and multiple sensors  something like i cub or nao   i have basic knowledge of communication protocols and i have worked with micros before but i have no knowledge and experience on working with ros  the question i have is whether or not it is worthy and practical for me to learn ros and use this for my robot or should i stick with what i already know  ,microcontroller ros humanoid
5036,calculating the force of this system,my native language is not english  so i don t know all the specific terms you may expect me to use  i apologize for that   anyway  i have a motor and three connecting rods  in french  bielles   so point c will have a circular trajectory and a  thanks to the sliding pivot  pivot glissant  i really hope i am using the right translations   should have a perfectly vertical trajectory  my question is  how could i calculate the force f  i need this to emboss a piece of paper  thanks a lot for your attention  ,force
5037,kalman filter model values or state space original value  which values to use ,i am using l gd   and i am trying to implement a kalman filter for it on the stm  f  discovery board  i have though a few questions about that   after the filter gave me the values  do i have to make an average between them and those of the original model or should i use them as they are  according to this document  we don t use the original state space vectors in the filter  so how could we have  correct  space state estimated values   ,kalman-filter gyroscope
5039,best localization method ,i am making a robot that is supposed to roam inside my house and pick up trash using opencv  i plan to send information from my arduino mega to my arduino nano connected to window pc using radio transceivers  i also plan to send video feed from raspberry pi camera over wifi to the windows pc  the windows pc then uses opencv and processes other information from the sensors and sends command back to arduino mega  i have right now   arduino mega raspberry pi   usb camera   wifi dongle xbox     kinect  wheel encoders sonar distance sensor arduino nano windows pc  i want to know how to keep track of the robot like the room it is  i think what i am trying to do is slam  but i just need to make the map once because the rooms don t change much  i am open to ideas   cost is a factor  ,arduino mobile-robot localization
5041,bluetooth integration with msp   ,i am trying to integrate bluetooth in a project with msp    so to be able to communicate between it and my pc  doing a search on ebay i found the following item  hc       transceiver bluetooth module backboard interface base board serial  there are also a lot of other bluetooth modules that appear to be a lot more expensive and their boards are populated with ic s that this one doesn t have  so i am wondering if this is what i need or it has another use  ,arduino
5044,wiring  v sensors to beaglebone black,is there a  cape  to make wiring sensors into a beaglebone black easier  whenever i read some guide for wiring a sensor into the beaglebone  like this one  it always recommends attaching wires directly to gnd   v and signal pins  which is horribly messy and unmaintainable  even for small projects  you end up having several wires connected to the same gnd  v  pins  so if you need to replace or repair something  you end up disrupting the wiring for every other component in your project  most arduino guides assume this bad practice too  but at least i ve found various  gvs  shields to help organize groups of gnd  v signal pins so i can attach individual sensor cables  is there anything similar for the beaglebone  i can t find anything appropriate googling  breakout  or  io  cape  i could only find one gvs cape  but it s less than ideal  since it only exposes    v gpio pins  and everything else it exposes as    v or    v which are incompatible with most peripherals  ,beagle-bone
5045,how to choose the state space model for   axis gyroscope to implemnt a good kalman filter,i am using this gyroscope in order to measure the rotation of my robot around the z axis  i want to implement a kalman filter in order to improve the values  what i came with since now is this space model      k      k  dt    k  w k      y k    k  z k   where  is the angle   is the angular rate given by the gyro and  is the noise   i hold up my gyro and measured    values while it was steady and find out that the variance is equal to          what i want to ask   is what i did is correct  how can i find out    according to the data sheet noise density is equal to      dps sqrt hz  how can i use this information to find out  and correct  if it is wrong   ,kalman-filter gyroscope noise
5047,find centre of circle  when robot can  see  a partial arc,i originally asked this here but i am struggling to take the concepts  particularly  circumcenter   discussed there and apply it in my context  so here it is in my context    i have a small robot that can  see   via a camera  a partial arc  from a birds eye view  therefore i know the height and the width of the square and therefore the width and height of the arc  i am sure there must be a way of approximating the circles centre  what would be the quickest  not necessarily the most accurate  way of helping my robot find the centre  in my head these are the steps of the problem   break up the arc into evenly spaced vectors   work out the angle between the vectors use this information to complete the circle   work out radius of circle  find the center of the circle  basically i would love some input on this problem because i think i know    dot product   add up the lengths of all the vectors to get circumference and then divide by pi  then divide by    or divide by tau        i think this is where circumcentre comes in  basically i feel i have some pieces of the puzzle but i am not sure how they fit together   i am currently using python with opencv and you may have guessed  i am not great at understanding math unless its expressed in algebraic formula or code   here are some illustrive pictures to reference   ,computer-vision navigation
5053,why does the pixhawk have   imus,i was looking at the pixhawk specs and noticed that it has   different imus  invensense and stm  is it for redundancy or does it have any other higher purpose  ,uav
5058, d robot arm inverse kinematics with minimum joint loads,suppose i have a robot arm with  linkages of fixed length and equal density whose motion constrained within a  d plane   i want the end effector to reach a particular pose     i know that in general  there can be multiple solutions that can reach this pose   for my particular application  i m interested in a solution that minimizes the maximum torque exerted over any joint under the influence of the weights of all the linkages  combined    is there a way i can reformulate the inverse kinematics problem as a minimization problem over the joint loads   can i formulate my objective function to be differentiable  i e  so that i can use traditional optimization techniques    would this yield an unique solution  in a least squares sense  for the  d planar motion problem  ,inverse-kinematics
5059,implementing a torque controlled method on a position controlled robot,i am working with a position controlled manipulator  however  i want to implement a torque controlled method on this robot  is there any way to convert a torque command to a position command  i try to find research papers on this but i have no idea where i should start or which keywords i should use in searching  do you have any suggestion  ,robotic-arm industrial-robot manipulator
5062,what motors should i use that do not require gearboxes  this is a car like robot,i am new to robotics  and ime looking for a    v motor that can be used to power a car like robot i will have two of these  so i can turn on spot  furthermore i want them not to require a gearbox  so i can just attach them to the wheels  i don t really know where to start looking for one   i have heard servos have built in gearboxes  but don t they only have     degree rotation  so does any body know a motor like i described in paragraph    or at least point me in the right direction   ,motor
5068,simulator for an adaptive  under actuated robotic gripper,i am looking to build an adaptable robotic arm with under actuated three  or four  fingered hands  before i start shelling out money  i want to test my prototypes in a simulator which would ideally  allow me to try out various actuators  and also possibly a tactile sensor  like a pressure sensitive resistor or a pressure sensitive conductive sheet    simulate different environments and tasks like gripping various shapes  sizes  weights etc  be able to talk to an external learning inference programs for the adaptive part  which  i think  goes under the name  dexterous manipulation planning  tasks   with sensory feedback from tactile sensors within the simulator and also camera input from a separate module    what are my options for such a simulator  including those that only   partially address my requirements above   a bit about my background  i dont have any recent experience in building electronics hardware projects  although i have experienced it as part of my labs during electronics engineering under graduation  a field that i have left a long time back  i am just a wannabe hobbyist now  ,robotic-arm motion-planning simulator planning
5071,plastic that s transparent to ir range sensors,sharp ir range finders are pretty popular sensors  but i usually see them externally mounted and directly exposed to the environment which makes them prone to being damaged or getting crufty  i have a few that i d like to use on an outdoor rover  and i d like to cover them with some sort of transparent case to protect them dirt and impacts in the environment  what type of plastics would be completely transparent to these sensors  and where would i buy simple sheets of it  ,sensors rangefinder
5074,ubuntu arm lacking  sys devices cape bone iio,i m trying to pull analog input from a beaglebone black using this tutorial  however when i go to  there is no cape bone iio  i have spoken with several other programmers and one of them suggested that the cape bone does not work with the newer versions of linux  however downgrading could have negative impact on the rest of the project  is there any other solution  ,beagle-bone linux
5079,communicating with syringe pump using pyserial,let s first start of by explaining that i do not have a decent background in electronics and interfacing with them  so maybe this is a stupid question  i am currently trying to connect an old harvard    syringe pump  website  pdf manual  to a computer  with the goal of controlling things like pump rates and direction  for this purpose  i connected the instrument to my computer using a d sub usb conversion dongle  i then connected to the dongle with pyserial without issues  however  whenever i try to send commands or request the instrument s output  for example   the instrument does not do anything at all  requesting data  read       returns only a couple of  x    i suspect i am communicating with the dongle itself rather than the pump  when the pump is turned off or unplugged  i get exactly the same results  could anyone explain to me why my method does not work  my python code for reference  import serial   pyserial module    open the connection ser   serial serial   dev ttyusb    baudrate       bytesize    stopbits    timeout    print ser   returns  serial id  x cc      open true  port   dev ttyusb    baudrate       bytesize    parity  n   stopbits    timeout    xonxoff false  rtscts false  dsrdtr false      see if the connection is truly open print ser isopen     prints true    run the pump motor ser write  run r    additional observations  when the instrument is plugged in but the above code is not running  the pump does all sorts of things at random  move one way  stop  move the other way  etc    this behaviour is much less pronounce but still present when the code runs  and  locks  the channel or something    this seems to suggest that the reference voltages  logical high and low  are not properly set at    v and      v respectively ,control usb rs232
5082,unable to hover my quadcopter,i m currently flying a f    quadcopter using a apm     flight controller while i am able to get the quad off the ground and relatively steady horizontally via the use of trims  however  i am unable to get the quad to hover no matter what i do i ve tried using trims on throttle but i am still unable to get it hover on my transmitter  wfly wft  ii   where the throttle has  ticks   i am currently stuck between too little lift and too much lift  where i push the throttle up by    tick  and the quad goes from slowly decending to ascending  and vice versa  is there any way i can get my quad to hover   with my hands off the throttle if possible   as currently  evern with me trying to fly it  i can never get it to hover vertically as it alternates between ascending and descending whenever i fiddle with the throttle  ,quadcopter multi-rotor radio-control
5095,following a trajectory with lqr controller,we want our wheeled robot to follow a  rather short  trajectory  we wrote an lqr controller  which works well in simulation  however  our robot offers two problems      the reported state information does not seem to be very accurate      its motion seems to underly some random deviations  we did not succeed in establishing a good model to predict the robots motion with a given control input  is it possible to manage these problems with the lqr controller  if yes  how  ,control wheeled-robot kinematics
5097,optimal number of robots for cooperative surveillance,suppose we need to detect the occurrence of a special event in a large area e g  a city   if we need that each point being visited every h hours  how could we find the optimal number of robots for cooperative surveillance   notice that there is no control center  ,multi-agent swarm
5099,robot safety standards for software,i am looking for possible iso standards for robot safety specifically for software  i have come across this presentation that mentions many iso standards and it s not very clear which exactly applies to software  the most probable ones are   iso         iso           iec       iec       iso ts        the safety related to software seems to be categorized as level   and level   in the presentation above  i would appreciate if anyone with knowledge in this area could point me to the right standard  they are quite expensive so i could simply go through them all to see which one applies  as a side note  some standards like c have their standard  draft  freely available  could there be free copies of drafts for those standards too  ,software
5103,arduino  lcd screen has weird noise with multiple pictures,i m connecting an arduino to a lcd screen using the following library  for the display code i have written a simple piece of code that should display   picture os eyes    angry one friendly  and switching at regular intervals  however the display keeps showing me weird pixels around the borders that shouldn t be there  by making it show the same eyes twice this can be fixed however as long as i have both eyes being used it runs into trouble  here is my code    each time i re upload the image it changes the way the noise patterns look suggesting this is some kind of overflow problem  however changing the last byte of the bitmaps creates lines at the bottom of the screen  right where the noise is on one of the images  note that with different images this noise can very much  cut  into the images even creating not active pixels    s  rather then just set ones  suggesting that the images themselves to at least fit the display   ,arduino
5104,robotic cell simulation software plc,i need to simulate robotic cell where cartesian robot trims a pcb arriving on conveyor  picks it up with vacuum cup and and places in another device  after receiving signal from device the robot would pick it up and place on another belt  i want to make the cartesian robot myself using servomotors and control cell using a plc  would there be software that can simulate all this  i would also need to integrate sensors and possibly machine vision  ,simulation
5106,how do i set up a rubber hand experiment with precise latency ,the rubber hand illusion  wikipedia  involves touching both a fake arm and a subject s real arm simultaneously  this causes the subject to feel that the fake arm belongs to him  normally a human delivers both touches  so the timing is approximate  i want to vary the latency between the fake touch and real touch precisely     ms at minimum  to probe how close they need to be to create the illusion  what can i use to touch a human and fake hand lightly at variable but precise times  ,research
5108,looking for a cheap ish  micromouse that i can program with c c  ,i m looking to buy a micromouse  i e  a small single board unit with wheels and ir sensors that can move around freely   i ve done a lot of searching but have only found resources relating to building one from components bought separately  however  i m more of a programmer than an electrician so i fear i would struggle with this  anybody know where to buy one of these in the uk   picaxe does some suitable stuff but they re basic only unfortunately   my budget is about      ,arduino mobile-robot wheeled-robot micromouse
5109,regarding long distance wireless communication,i have a requirement to transmit some sensor data through wireless to a distance of   kilometers  i am a newbie to these technologies and concepts  can anyone help me by providing some pointers to start with this   ,wireless
5110, d magnetometer calibration algorithm,i want to calibrate my compass  which is installed on a board which inherits a gps module  because the gps antenna is up side down the compass is      inverted  the easiest way to correct the problem would be to invert the rotation matrix        however i got interested how a general approach to calibrate a compass would look like  i found some approaches like this  they seem to collect magnetometer readings an project them on a sphere  but what is actually the point in this   does someone know how a general calibration algorithm of a  d magnetometer looks like  ,calibration compass magnetometer
5111,redundant arm path planning and trajectory following,i have a  dof robotic arm and a set of end effector trajectories in cartesian space i need it to follow   how do i deal with the redundancy in the arm when planning to follow these trajectories both with and without obstacle avoidance  ,robotic-arm motion-planning c++ planning
5116,how to find a solution for quadcopter pid control,i ve built a quadcopter and a rig to safely test it on  i m working on the pid for controlling the roll pitch and yaw  i understand how a pid works on a more simple plant like say a robot with wheels and i m just really in the dark   i believe   with controlling and stabilizing a quad  my question  how do i make these sensor readings effectively alter the motors  throttle   firstly  my approach is based on this model     my imu calculates the roll and pitch as a value between       where being perfect balance will read as       now a degree of       means approximately    degrees from the original axis  a normal input to the pitch to go forward would be something like       meaning tilt    degrees forward  now my motors take some value between   and      originally i thought this would mean i would have to modify my motor values like so   c   throttle   roll   pitch   yaw d   throttle   roll   pitch   yaw b   throttle   roll   pitch   yaw a   throttle   roll   pitch   yaw  finally  i m taking those floating point numbers  from the imu and computing them like with this method  which appears to be the normal way as far as i ve found  rollpid compute  steering roll   gyro roll         pid t is either  define pid t float    or double  i know its a reserved type but  a pre processor definition will change that before it would matter   pid t compute pid t input            uint   t now   millis            if    now   last time      sample time                 pid t error        set point   input              error sum           error              pid t d error      error   error last                output   kp   error   ki   error sum   kd   d error               error last   error              last time    now                   i don t know where to go from here  also i have angular rate calculated from my imu i just haven t encountered a solution that called for it   edit  below is a graph of roughly     readings    ms apart  so roughly six seconds where i hold it in one hand and roll it roughly   degrees right  with kp   ki   kd     ,quadcopter pid design
5118,finding the position of a servo,i am building a collision avoidance system for my robot  as a part of this system i am using a pan and tilt kit     my aim is to pan the sensor attached to this kit  and thus plan the route the robot should take  in order to pan this sensor  i need to know the angle the kit has panned  and need to be able to call upon that angle at point in time   basically the sensor keeps panning  and at a point in time when certain conditions are met  it stops panning  when those conditions are met  i need to be able to extract the angle the sensor is panned at  the servo being used on is   if someone could help me find a way to extract this information that would be helpful  i did read somewhere that the servo could be hacked and changed into a closed loop system where the effective angle would be shown  but that option is not viable  thanks ,mobile-robot sensors servos
5126,apm planner on linux ubuntu  open from file  not working,i can t open parameter list with apm planner  moreover i can t find anyone with same problem  i run it on ubuntu trusty       it does not see files with any extensions including  and txt downloaded from internet or created with my version of apm planner  any ideas how can i fix it   ps ls  la from terminal user laptop   apmplanner  parameters  ls  la total    drwxrwxr x   user user      dec            drwxrwxr x   user user      dec              rw rw r     user user      dec          paramter param  i have param  txt files in downloads folder also  ps  ,ardupilot
5130,pid for quadcopters,as already mentioned the pid output values that correspond to the error from the desirable error and current error has no units  let s say we are using only the proportional part of the pid  is it better to map the output of the pid values to the corresponding thrust values on each motor  or is it better to increase the proportional coefficient  until the output values correspond to the proper thrust value to the motors   for example if my desired angle is   and the angle that the sensor is reading is    degrees the difference is multiplied by kp and the output is added or subtracted from the current thrust depending on the motor  if i increase kp too much  then the quadcopter is oscillating and not listening to the controller command that i am sending for the desired degrees from the joystick  if i map the values then it is listening to the joystick commands and not oscillating so much  why is this happening  isn t mapping the pid output values to bigger values the same as increasing kp  ,arduino pid
5132,what is the maximum payload weight for create   can i use old create accessories with the create   ,i m attempting to build a heavy platform on the create   but am worried about weight on the platform   what is the maximum weight for the platform and is there an optimum  i have an old create and want to know if any of my existing cables and accessories can be used with the new create     ,mobile-robot irobot-create
5133,what is recommended prerequisite knowledge to get kid started with create   ,what aged children is the create   appropriate for   what is prerequisite knowledge   is this an appropriate first robot kit for a child  ,irobot-create
5138,connecting an arduino uno with a beaglebone black over usb,i have an arduino uno and a beaglebone black and would like them to talk with eachother  both the beaglebone and the arduino have their own  v power supplies so no need for power to be transferred over usb  the used communication line we would like to use is the direct serial line  preferably in such a way that the arduino can just call serial read   in order to get the bytes it needs  there won t be many   how do i get this to work on the beagleboneblack  i suspect we can call the serial write somewhere inside the bbb we mainly program in c     but how do we achieve this   ,arduino serial usb c++ beagle-bone
5140,simple yet effective angular position sensor to be used in robotic hand,what is the best yet simple to use angular position sensor  i am building a robotic hand and i want to implement this sensor at the joints of the fingers  i don t need a module  just an analogue output  thank you  ,sensors hall-sensor
5148,step motor and bevel gear calibration,i am new to robotics  i want to understand how gears state is preserved as the gears turned to same positions repetitively   i have a bevel gear and a step motor connected to one gear  this gear will turn    n   degrees  that is to say there are   states gears will stay in  the problem here is there will be force on the gear  which is not connected to motor  in any direction  that force must not change worm position even in micrometers  i think there should be a locking mechanism  is there any applications of that you can give example of  ,stepper-motor stability
5149,defining a trajectory for a quadrotor,i  m looking for a trajectory generator  the algorithm doesn t matter  since i m going to write it using c     that generates a trajectory  a parametric curve in space  defined point by point which is going lately to be feed into my quadrotor drivers  i m honest  i don t know where to start   reading the following interesting answer  but the problem here is  the trajectory has a pd controller with it  my quadrotor should take just a parametric curve as input  ompl  this library seems very powerful and interesting  it let the user to define a planner which many different algorithms  the problem is that it is not well documented  good examples and explanations are missing and till now i could nt find anything related to quadrotors  which does use that library  there is an example for a quadrotor  which doesn t find my expectations and i cannot figure out  how to implement it in my package  i don t want just copy and paste code that i don t understand  b spline and bezier curve   and the whole family of parametric curves  i found very interesting libraries in internet that implement those algorithm directly c    the problem here is  i can define some points in space  generate a spline that contains them and interpolate points for the pid controller in the quadrotor  the basic idea is like a dog chasing a rabbit  a point is generated from the start point of the spline and regularly sent to the quadrotor  the latter flies behind the point  trying to reach it until a goal point has been reached  what is the problem here    in this case i can only generate a curve based on geometric properties and not considering the dynamic and the kinematic of the quadrotor  which i would consider for a future project   the rabbit runs and has a tighter curve radius than the dog  which could result in a strange behavior of the quadrotor   i d like same good tips to point to the right direction  which kind of trajectory planner are usually developed fr such an application  thanks  regards ,mobile-robot ros quadcopter movement
5150,what is the easiest method to plot a temperature in my pc ,after a lot of learning  i m launching a reballing business and i feel the need to have a realtime plot of the temperatures involved  ideally   or    and i have an arduino uno and a few k type thermocouples  i was researching the subject and saw a lot of different approachs  most of them use arduinos to send serial data to a pc port  then from there they process it with phyton  other guys matlab  some use ms excel plus a free add on in vb for apps  etcetera  and now after some reading i feel overwhelmed by all the different methods  so i wonder  perhaps i m already losing perspective here  may be there is a simple method i can use and kiss way of get it done  thank you  ,arduino sensors microcontroller electronics
5152,to control an omni wheel robot wirelessly using bluetooth and arduino,i am trying to control an omni wheel robot which has   motors using   joysticks  plus there are some actuation switches which i want to control too  i am using arduino mega and a pair of bluetooth wireless module hc      this bluetooth modules works on serial communication  how should i program arduino to send both the analog values provided by the joystick and the input from the switch continuously  ,arduino serial communication
5156,sun tracking with        degree accuracy ,for a school project i am looking to track the sun with         degree accuracy for use with a parabolic dish reflector  say we need a final output torque of about   nm  what kind of gearing motors and feedback would you guys use to accomplish this  the sun position will be found with a solar positioning algorithm  i am pretty new to this all but from my research stepper motors seem the easiest but brushless dc motors  from what i have read  can yield better results with smoother tracking  i am confused how you even use regular brushless dc motors to achieve precision positioning  i am aware of encoders but i don t really understand why the bldc are preferred for this particular application  and how one would implement them   any ideas that can help kick start my researching  ,motor brushless-motor stepper-motor servomotor
5164,how to send a new mavlink message from ardupilot ,i m trying to add a new message to the mavlink interface  following this page  there are the steps i took   added the message to ardupilotmega xml  right at the end of the file   regenerated the mavlink messages headers using   libraries gcs mavlink generate sh  it worked okay and the new headers appeared  then i added a function to the gcs class to make sure i m sending on the right channel  void gcs mavlink  send testing testing testing         mavlink msg testing testing testing send chan         now it s time to send the message  i added my own function to the scheduler  on last priority   i made sure the function is called by sending text first and seeing it on the mission planner console  here is the function i added  static void a testing loop void        for  uint  t i    i num gcs  i                   if  gcs i  initialised                           gcs i  send text p severity high pstr  testing string                 gcs i  send testing testing testing                        my message  however  isn t received on the mission planner end  it might have been received and ignored by the mission planner  but anyway it doesn t appear on the console window  even with  mavlink message debug  on  is there configuration to be made to the mission planner for it to receive new messages  or am i sending the message wrong  also  is there a way to filter out messages from the console when using  mavlink debug mode   i m using sitl for testing  i don t have enough reputation   but this should be under the tag  mavlink   ,ardupilot mavlink
5169,error as a state space,i am reading the following research paper regarding trajectory tracking of mobile robots   there are two things at the start of the paper that i do not understand     the author derives equation     as the state space model of the system in which he considers the error as the state  can anyone please elaborate on why he is using the error as the state space model of the system and not the vx  vy  and w omega  angular speed  of the robot     why does the author linearize the system around the reference trajectory  ,mobile-robot wheeled-robot differential-drive
5171,how would i go about learning to code a flight controller ,i m interested in quadcopters multi rotors and want to eventually code my own flight controller ala an apm and or pixhawk  i ve got a little experience in programming  i e i know about if else else if conditionals   and have done a little programming with php  though it was procedural code  i currently have a quadcopter that i built assembled myself that is running on a f    frame  using a apm     flight controller so i have a reasonable grasp of how a quad works  and i would like to take it a step further and make my own adjustments to the code base  with the eventual aim of coding my own flight controller  i ve had a look at the code base  but am still unable to get a grasp of what the code is actually doing    yet  how would i go about learning how to code a flight controller  i m thinking that i would have to learn c     oop first  but how familiar proficient would i have to be with c   before i can reasonably attempt to edit the code base also  what else would i need to learn apart from c     oop i am looking at setting a   month timeframe deadline for me to do this  would it be possible  ,arduino quadcopter microcontroller multi-rotor
5178,i want to control a sewing machine motor  need help with choices,i ve got an industrial sewing machine  think  can sew with thread that looks like string  and has no trouble pounding through    layers of sunbrella fabric    it s got a   hp motor to power it   i ve got a smaller machine as well  w  a     or     hp motor  which i might work on first   the motor is a  clutch motor  which is always on  and a foot pedal engages a clutch  so unless you  slip the clutch   you re basically always sewing fast or stopped  i d like better control  in particular  i d like to   be able to stop with the needle  up  be able to stop with the needle  buried   i e   most of the way down  be able to press a button to move forward exactly one stitch be able to adjust    probably with a knob    the top speed of the motor have the motor off when i m not actually sewing  the   hp motor is probably overkill for what i m doing  i don t suppose i ve ever used more than about     hp even on the toughest jobs   i d appreciate any comments on my thinking so far   from what i ve read  it looks as if a dc motor is the way to go  max torque at zero speed  which is nice for that initial  punch through the material  thing  and the ability to  brake  by shorting the   and   terminals   brushless would be nice   but expensive  and i have a nice dc treadmill motor  and if i drive it at about      v  it ll give me more or less the right speed  adjusting pulleys will do the rest  such dc motors are powered  in electric lawnmowers  for instance  by running ac through a diode bridge rectifier to produce pulsating dc  and i ve got such a bridge rectifier handy  i also have an old autotransformer that i can use to get   vac pretty easily  thus i can get   v pulsating dc to drive the thing     but that may or may not be a good idea   i ve also got an arduino and the skills to program it  and several years of electronics tinkering  and some rc experience   but no experience handling larger dc motors like this one  i ve been told the magic words  h bridge   and found this motor driver which certainly seems as if it ll allow me to turn on off the motor  and regulate the voltage going to the motor  i don t know whether  when presented with pulsating dc at the input  it ll still work  any thoughts on this   i also can t tell    there doesn t seem to be a handy datasheet or instruction page    whether this thing can do braking   for position sensing  there are lots of places i can get information    either from the needle baror the handwheel of the sewing machine  so i m not too concerned about that part  to give a sense of the problem  a typical stitching speed is something like      stiches per minute  so if i m just sensing whether the needle is in the top     of its travels or the bottom quarter  we re talking about something on the order of      hz  which doesn t sound like a challenging control scenario   i guess my questions are these   will pulsating dc work with a controller like the one i ve cited   would i be better off with an rc motor controller  i can t seem to find one designed for the   v range that can handle    amps  unless it s for a brushless motor  which i don t have  and i think that i want one that has braking ability as well  and i worry that with an rc controller  the software in the controller may prevent me from making the motor stop at a particular position    any comments suggestions appreciated   btw  i m happy with mathematics and with reading data sheets  and i ve read  a few years ago  about half of  the art of electronics   just so you have an idea of the level of answer that s appropriate    to answer  jwpat s questions   i got my voltage value by saying that the motor is rated for  i think     v  and is    hp  yikes   but turns at something like      rpm   here s one that looks just like mine    dividing by   or    i got  about    v  to give me about      rpm   i m at the office  the motor s at home  so i can t tell you the exact part number  alas   i honestly don t think that the no load vs load condition is a big deal  because i can wangle a factor of   with pulleys   the sewing machine is a juki      current motor clutch are similar to this  sorry for the lack of detail here   ,motor control power
5180,making a robot that knows your location,i ve just made a radio frequency remote control using pic microcontroller and i want to do something useful with it  i am thinking of a robot that gets things for you while you are at bed but here comes the question  how am i going to have the pic determine the location of the remote control calling for it  it can t really be done using a gps module because it will all be in the house  what options do i have  ,microcontroller localization
5182,interfacing arduino uno with   dof razor imu,i have followed the tutorial for razor imu and it worked perfectly when the imu is directly connected to the pc  currently  i am trying to interface the   dof razor imu with the arduino uno by simply connect the rx to tx and tx to rx  sadly  it doesn t work  so  i am just wondering  has anyone done this before  or can anybody give me some hints  much appreciated   ,arduino imu
5188,compound vision system or megapixel camera reduction,are any commercially available compound vision sensors available  not a simple   sensor system using photo diodes but a genuine sensor that can provide a    x   compound matrix  would some form of reduction in the granularity of a megapixel camera be a better option  the real purpose is to reduce processing time to a minimum  while extracting the maximum basic information   ,computer-vision
5189,arduino depth sensor,i m looking for an arduino compatible depth sensor not for water  what i need is a sensor very similar to an xbox kinect  but much smaller  that will tell me what is in front of the sensor and also the shape of the object  for example  if i place a cylindrical water bottle in front of the sensor i would like to be able to figure out how far away the bottle is and also the shape of the object  in  d  i don t need to know whether it is actually a cylinder only the general shape   the sensor only needs to be accurate at most   meter away  does this exist and if so where can i purchase one  if it does not exist wholly what pieces do i need to buy to put it together  thanks  ,arduino sensors kinect
5192,alternatives to cameras for a dirt sensor for an autonomous vacuum robot ,when i use a standard manual vacuum  i often notice that i have to pass over a spot several times because a single pass does not necessarily catch all the dirt   my eyes brain can easily perceive this information visually  but i don t know how an autonomous robot vacuum can detect whether a pass over a patch of dirt was successful or not   what kind of sensor action can i use to determine if the robot vacuum successfully picked up the dirt from a particular patch    i would prefer to avoid a visual camera if at all possible because it would necessarily have to be mounted above the robot and thereby limit the range of reachable locations   is there some other low cost sensor that can accomplish the same task that can be placed low to the ground  ,sensors
5193,can mapping be done in real life applications without also solving the localization problem at the same time  i e  slam  ,i know that occupancy grid mapping requires the assumption that the robots  pose is always known when generating a map   however  i also know that in reality  position and orientation usually treated as uncertain in practical applications   assuming that my target mapping environment is inside a home  is there a way i can overcome inherent robot pose uncertainty in a real world application of occupancy grid mapping without resorting to implementing a slam   that is  what is a low cost way to increase the certainty about my pose    or is occupancy grid mapping only useful in theory and not in practice    update  it is clear to me  from the responses given  that occupancy grid mapping is just one possible way to represent a map  not a method in and of itself   the heart of what i really want to know is   can mapping be done without also solving the localization problem at the same time  i e  slam  in real life applications   ,slam mapping occupancygrid
5196,is there a brushless motor controller accepting over     updates s ,i want to use brushless for my line follower  the problem is most escs don t accept more than         updates s due to the characteristic of steering signal  is there a way to overcome this with a custom flash or am i out of luck  ,brushless-motor esc line-following
5199,slam goal babbling,i am struggling to find good links to the use of goal babbling in slam applications  has this technique been used as a method for optimizing movement in a slam environment  ,localization slam motion-planning mapping
5201,how can i power a wheel but let it spin freely when not under power ,how can i power a wheel but let it spin freely when not under power  i saw the question how can i modify a low cost hobby servo to run  freely   but i m more interested in knowing if there is some sort of gearbox that disengages   moves to  neutral    when no torque is being applied to it  two ideas that come to mind are   a drive gear on a spring loaded arm with a nominal amount of resistance before engaging  perhaps when under power it would first use power to move in one direction  then it would engage with another gear  but without power the spring would return it to a non engaged position a centrifugal clutch   although i d like something that works at low rpms as well  the idea is to create a small bot that can move up and down a track  but if someone interacts with it when not under power it will just roll and won t damage the gearbox  ,motor power rcservo radio-control
5203,simple vector problem  weight vector components   sine and cosine of rotation ,i have the quadcopter in the photo below  it has rotate  degrees about the  y axis  i want to get the x and z components in the local frame for the weight w which always points along the vertical downward   we simply have  wx   w sin theta   wz   w cos theta    suppose that w    n and theta      deg  then  wx        sin         n    wz        cos              n  the negative sign in the angle was put because the rotation is about the  y axis  counterclockwise   wz seems correct as it is pointing towards the negative local z axis but wx is   which seems wrong because according to the diagram it is supposed to be    indicating that it point towards the negative local x axis  what s wrong with my simple calculation  edit   using rotation matrices  we have the following rotation matrix when pitching  rotating about y axis    this matrix is used to transform vectors from inertial frame xn yn zn to local frame xb yb zb  to find the components of the weight w  we can multiply this matrix by w  doing so  we get the same result  wx   w sin theta   wz   w cos theta    ,quadcopter frame
5208,the algorithm for the following analog controller    digital controller ,i have found a continous control in the following form   u s     left  k  p     frac k  i   s    k  d   frac n       frac n  s    right e s   but since i need it to  convert  in a digital control i need something like   y  k    y  k      q    e  k      q    e  k     or everything that i can use in a digital way  is there any algorithm to achieve such transformation  actually the problem is the term  in the equation  at first i thought that it was a simply pid controller but the n term is far from my understanding thank you very much and happy christmas   ,control pid
5209,how high of a gear ratio can a motor have ,i want to make a robot arm where a joint is powerful enough to lift   kg up at a distance of   meter   this requires torque    about    nm  so now i am trying to find the requisite parts to put this together  i e  motor   gears and then controller   it seems that i will require a very high gear ratio to make this happen  for example this motor   has stats  stall torque         oz in         nm no load roation speed         rpm to get my required torque  i need a gear ratio of            about        and the max speed drops to about     rpm   my questions     do my calculations so far seem correct  it seems a bit suspect to me that an    motor with some gears can cause a     lbs dumbbell to rotate about a circle of radius  m twice a second  i m barely that strong   this type of torque would be awesome for my application  but perhaps i m missing something in the calculations and being too optimistic  e g  efficiency      is it safe to operate a motor at such a high gear ratio  gears are small  and i m worried they ll easily crack break wear down quickly over time  does anyone know of example gears that i should consider for this  thank you very much for any help  cheers  ,motor robotic-arm gearing
5214,how does fliike smiirl counter mechanism work,first of all please see this video    i think there is ony one stepper motor  or servo  working in the mechanisim  but as you can see each flip counter works alone and separately  it is not like classical counter mechanism like this    how does it works  ,mechanism stepper-motor
5218,i want to be a guy of robotics,i will be beginner need a help i want to gain knowledge about robotics so it need a basic theoretical knowledge what is the best way to start  ,beginner
5220,clicking nxt brick,help  i have recently installed lejos nxj on to my nxt brick  and soon after my batteries died  i inserted new ones  and now i cant start my brick up  when i press the startup button orange  it makes a clicking sound and when i let go it stops  i have tried reflashing the brick with both lejos nxj and the nxt software and both programs say something along the lines of  unable to locate brick   any suggetions  ,mindstorms
5223,non markovian problems approaches in robotics,as far as i can tell  the markov assumption is quite ubiquitous in probabilistic methods for robotics and i can see why   the notion that you can summarize all of your robot s previous poses with its current pose makes many methods computationally tractable  i m just wondering if there are any classic examples of problems in robotics where the markov assumption cannot be used at all   under what circumstances is the future state of the robot necessarily dependent on the current and at least some past states    in such non markovian cases  what can be done to alleviate the computational expense   is there a way to minimize the dependence on previous states to the previous  states  where  can be chosen as small as desired  ,probability
5224,nano sized electric motors,what is a good website for buying    v continuous motors  i m looking to build a clockwork robot but i cannot find a motor small enough to fit inside my power box and i don t want to mount it outside of the box  i have a    by      space that the motor needs to fit into  i have found a few websites but they look sketchy and none of them have good reviews  ,motor brushless-motor motion
5226,i need more robots,i know that this isn t a programming question  but it is robotics so i thought you could all be flexible since it s my first question  anyway  i love making robots using robot kits that come with instructions  it s always fun to use afterwards because of the controllers i build with it  the problem is that i can t find anymore robots  they are all either too expensive  not what i m looking for  or both  can anybody give me links to some good robot kits  my price limit is            here are the three robot kits i have built  i need kits that are like these  robot arm   remote control robot beetle  i can t post more than two links  go to maplins and type in the name of the robot and you ll find it  it s a rover version of the robot arm    in   all terrain robot kit   i don t want to program this robot  i want it to be like it is in the examples above  buy the kit  read the instructions  then build it   thank you all in advance  ps  any further information will be given if asked for  ,control
5227,theory on rigid body motion in robotics book,i am reading some theories related to rigid body motion from the book  a mathematical introduction to robotic manipulation  by prof  richard murray   i am focusing on chapter    sec   to derive some formulation  according to his introduction of chapter  we present a modern approach treatment of the theory of screws based on linear algebra and matrix groups   i myself feel rather understandable and comprehensive explanation from this approach   however  his scope in this chapter is limited in inertia coordinate frame where he refers to as spatial frame and moving frame as body frame  is there any other references that treat the topic in the reversed order  spatial as moving non inertia frame and the other one is inertia frame  thank you  ,control
5229,how can i replace acceleration in the dynamic model of the robot ,in the dynamic model of the robot  it is obvious that we found the torques as functions of the angular acceleration of the joint as well as the linear acceleration of the link center of mass along the three axies  my question is regarding the values of these accelerations  in general  step motors specifications do not give the acceleration  thank you ,torque
5238,joint compatibility branch and bound  jcbb  data association implementation,i would like to implement the joint compatibility branch and bound technique in this link as a method to carry out data association  i ve read the paper but still confused about this function   i don t know exactly what they are trying to do  they compared their approach with the individual compatibility nearest neighbor  icnn   in the aforementioned method we have this function   this function simply the inverse measurement function or what they call it in their paper the implicit measurement function  in laser sensor  given the observations in the polar coordinates  we seek via the inverse measurement function to acquire their cartesian coordinates  in icnn  every thing is clear because we have  this function   so it is easily to acquire the jacobian  which is   h  ij  i      frac  partial f  ij  i     partial  textbf x     for example in  d case and  d laser sensor    and the inverse measurement function is   m  x    x   rcos  phi    theta     m  y    y   rsin   phi    theta    where  and  are the location of a landmark and   r    sqrt   m  x  x         m  y  y           phi   atan  left   frac  m  y  y    m  x  x    right     theta  using  in matlab  we can get   any suggetions  ,slam ekf mapping data-association
5240,irobot create   discrepancy betweenopen interface specifications and create   serial to    v logic,i am cautiously moving forward with my new irobot create    planning on using a raspberry pi with rosberry installed to control the create    discovered a problem with the pin out specs between the irobot roomba open interface  oi  specification and the create   serial to    v logic document  here is the discrepancy  marked by discrepancy   pin   oi   serial to    v  vpwr roomba battery voltage vpwr roomba battery voltage rxd  roomba tx discrepancy txd  roomba rx discrepancy brc  ground discrepancy gnd  ground gnd  roomba brc discrepancy  the discrepancy is with pins            don t want to fry my raspberry pi  any clarification and or help appreciated  ,raspberry-pi irobot-create
5248,how to attach a motor to a blade ,the hole is a slightly too big for the motor s shaft  i thought about hot gluing them together  link to picture here ,motor quadcopter multi-rotor
5250,need a relay alternative,i have an application that needs a xbee and another module to be turned on and off digitally via a microcontroller  the setup is   xbee s and an application board is connected to the microcontroller  on poweron i need   xbee and the microcontroller to come on and do its routines  after the uc gets the signal from the xbee  wirelessly from a basestation  the board has to turn on the other xbee and application board  and when the operation is over  the xbee and board is to be powered back down  i dont want to put them in sleep or low power state  just power both those devices off   i was thinking of using a relay  but i cannot find a    v  a smd equivalent system  i am looking for a smd type of footprint to go on a very compact board   what options do i have  the xbee needs around  a power and the application board    ma  ,power
5251,feedback controller  is there any influence between outer and inner loop when running at different frequencies ,i ve develop a quadrotor  only simulation on my pc using ros  and the feedback controller resumes more or less the following structure   where you can think that process is the dynamic movement of the quadrotor  motion equations   the inner loop is the attitude controller  it just sets the orientation about all   axis  and the outer loop is the position controller that takes care where the quadrotor actually is  why are they separated  because in many papers i found out that the attitude controller  pitch  roll  yaw  need to run at higher frequency then any other controller in the system  the position controller instead needs to run at lower frequency  the following picture is a better explanation of my description  don t be scared   it is more simpler than one could think   now i did it as in the paper  but i discovered that my quadrotor was really unstable and i spent days and days trying to correct the gains of the controller without getting a stable system  my intuition said to me that maybe they are running at wrong frequency  so i put a different frequency values for the position controller being sure it is not a multiply of the main frequency  something like     hz and     hz for example   lately i removed the timer in my program  c    and let the position controller run at the same frequency as the attitude controller just because i run out of ideas and suddenly worked everything nice  so here is my question  what should i consider when my system has an outer inner controllers  how to be aware of that  regards and happy new year    ,control quadcopter
5255,where is the function  mav return  defined ,i m trying to understand the source code of arduplane  the mavlink message is decoded using a set of  functions  e g   mav return float when i grep recursively for  mav return float  i could not find where it is defined  i wonder if i m missing anything     update here is the source code of ardupilot  including arduplane   ,ardupilot
5259,is my quadcopter loop fast enough ,i ve been working on a quad copter for awhile now  recently i ve finished the interface for pid tuning and its leading me to question several design decisions   the quad uses a raspberrypi as its pilot  the entire loop takes less than   ms  imu data is gathered  the throttle speeds are calculated  and then finally sent to an arduino micro  over an spi interface  where they are   to each esc  can a quadcopter fly with a loop that slow    ms     hz   ,arduino quadcopter raspberry-pi
5260,the aerial refueling problem  sketch of a feedback controller,at first happy new         i m looking for my next simulator development  a tanker is flying at constant speed      knots   no acceleration  no change of altitude or direction   the tanker is approached from behind by a uav which needs to refuel or transfer data through a wire  the uav knows the direction  the speed and relative position from the tanker in order to approach it smoothly  it knows that at about   m from the tanker is the contact successful  here a picture i found on internet but it is clear more than thousand words   to achieve the task i thought to implement a  simple  pid which controls the position and the velocity  but for this i have in my mind two different designs approaches   solution one  the motion equation of my system provide the position  and velocity  of the uav  to simplify things i will consider just  but of course  must be eventually considered too   those are feedback with the desired position   m  and velocity      knots  of the tanker  the feedback line is separated for each state and pids are working quite indipendently as in the following picture    please note that to simplify things i never considered the acceleration   solution two  this is the most tricky one and i was yesterday thinking about it all the time  in this case only one state vector is going to be feedback to the desired setpoints  in this case i would feedback only the velocity then integrate it and feed the result into the second pid  maybe the following picture is clearer    but here i m not really sure if the second idea is conceptually wrong or could be affordable  i m pretty sure that the first one is working and leads to good result  but i was wondering if the second one is affordable or is not recommended for a control design  regards ,control pid uav
5261,how to program parallel pid control loops  so i can give my robot multiple set points to follow,so i m in the process of building my robot and it has encoders on every wheel measuring speed and position and a compass sensor measuring heading  i have   seperate pid loops at the moment  i can either control the robots speed or i can control the robots position or i can make it follow a heading using a line following type algorithm  now i am completely stuck on how to merge these control loops  how do i control the robots heading and its speed  so i can say to it   go at    degrees at  m s  or  go at   degrees for   metres then stop  really i would like to be able to control all    heading speed and position so i could say  go at    degrees for    metres at a speed of  m s  however i have no idea how to merge the loops  at the end of the day there are   inputs  heading  speed and position  and   output  pwm to motors  so do i need to use some kind of miso control scheme  if so which one   i ve looked at cascaded control but that only accepts   set point where i want to set   different set points  maybe some kind of state machine  i m so stuck   ,motor sensors control pid
5267,questions on gears for a robot actuator,i have some questions regarding building a gearbox for a motor to create a robot actuator  given my desired motor and loads  i ve determined that a gear ratio in the         range is adequate for my application   here is my motor choice for reference   here are my questions     mounting gears to a motor  if i have a motor with a shaft diameter of     in     mm   what size gear bore should i use  and how do i attach a gear to the shaft in practice  i m not that mechanically inclined  yet       say i build a gearbox of ratio        as such   i have no idea of how  durable  such a set up would be  for my application  i am looking at moving an  kg mass from     meters away  coming out to a total torque of    newton meters  how can i tell if the gears will break or not   for reference  these are the gears i m looking at  and i m pretty sure they re the same ones in the video        assuming those gears above were to fail  what type of gear material would be recommended for my load application of max   nm      what efficiencies can one expect from gears of different types  i ve been assuming     conservatively as another answer mentioned   thank you for any help  and please let me know if anything was unclear  ,motor robotic-arm torque gearing
5276,why make bipedal robots ,a friend and colleague of mine who studies robotics says that bipedal robots present much greater challenges for stability and locomotion than those with more legs  so why is there so much effort to develop bipedal robots   are there any practical advantages  of course  i see the advantage of having arm like free appendages  but it seems like   legs and   arms would generally be a better design  ,mobile-robot design legged
5279,which encoder should i use with a   v dc motor and  mm shaft ,i would like to control the position and velocity of a dc motor like this one  zy my          v     a      w   the motor comes with a    tooth sprocket and the diameter of the shaft is  mm  it s not possible to apply an encoder to the back of the motor  see picture  the angular velocity in the description is      rpm  which encoder do you recommend    ,motor quadrature-encoder
5282,uploading edited code for arducopter,i m attempting to customise some code for my diy pentacopter frame  to that end  i ve modified the some existing code  and saved it under ap motorpenta cpp and ap motorspenta h   i m currently trying to upload the code onto my flight controller  but am currently unable to do so due to the following problems  problems unable to upload to my apm              unable to select my pentacopter frame          problem      i ve saved my customised files in the ap motors library  and have compiled the arducopter     code in ardupilot arduino       gcc       windows   after which i upload it using mission planner  however  when i am uploading the hex file  i get the following error    uploaded succeeded  but verify failed   exp e  got    at          however  when i try uploading it directly from the modified arduino ide  i get a series of warnings   followed by the messages  avrdude verification error  first mismatch at byte  x c     x         xe  avrdude  verification error  content mismatch  followed by the message     avrdude done thank you     does this mean that the uploading of the firmware to my flight controller is successfull  also  is there any difference between uploading via mission planner and the modified arduino ide  problem    in the mission planner  originally there is the option to choose one of several frames   i e quad hexaocto  etc  after uploading my firmware  how would i go about selecting my penta frame for use also is there any further thing that i would have to do  apologies in advance if the questions are rather inane  as i have little programming experience to speak of  i would really appreciate any help i can get  thanks in advance   ,arduino quadcopter microcontroller ardupilot
5283,public dataset for monocular visual odometry,i am planning to develop a monocular visual odometry system  is there any indoor dataset available to the public  along with the ground truth  on which i can test my approach  note  i am already aware of the kitti vision benchmark suite which provides stereo data for outdoor vehicles  if anyone has access to the datasets used in the following paper  svo     it would be even more great   ,computer-vision odometry
5292,lifting robot to lift small crates,i am trying to design a robot to lift tote crates and transport them around in a localized area  i want to be able to carry   tote creates at a time   this robot needs to be able to pickup the creates  i only want the robot to carry three at a time so keep is small and mobile  i was thinking of a design with a central lift that could carry the crates  what would you suggest as a simple ingenious way to create this robot   ,design wheeled-robot mechanism
5293,how do self driving cars really work ,i m absolutely fascinated by the notion of a driverless car   i know there is a lot involved with it and there are many different approaches to the problem  to narrow the scope of this question to something reasonable for the se network  i m curious to know if there is a common sequence of subproblems that every driverless car needs to solve at each timestep to make an autonomous car possible for real life  point to point transportation possible   i imagine that once the starting point and target destination on a given map are set  a self driving follows an algorithm that loops through certain operations to solve certain problems along the way   i m more interested in knowing what those problems are specifically at a high level  rather than detailed algorithms to solve them   do all self driving cars solve the same subproblems along the way  ,automatic
5300,linear or switching power supply for a embedded project,power block designing noob here  i have a beaglebone  x xbeepro s  and another    mah device connected to the board i am building a pcb around  i need some advice on weather to use linear voltage regulation vs switching mode regulation   secondly if i am using linear voltage regulation setup do i need multiple regulators for the different devices   my plan is to use a  s     mah battery    fuse     x    a lm     s in parallel output feed to the beaglebone and a lm     for both the xbees  or its better to have each xbee on its on lm     drawing power from a seperate lm      linear regulators tend to get hot on full load  hows the performance of switching mode regulators   ,power battery
5302,code control your arduino with keyboard,i ve seen lots of examples on how to communicate from arduino to the computer  but the few that talked about computer to arduino communications were very hard to understand  my question is  what code can i use to control my arduino uno with my keyboard if it helps  i m trying to set up a wasd steering behavior  ,arduino programming-languages
5307, d camera for beginner,i want to buy a  d camera with depth sensor  can anyone can give me advice on which one will be the best  i have a experience with kinect  but configuring kinect for linux is painful and also kinect generate sometimes a big latency  i am looking for low latency  a good depth sensor and a good api for linux  i am thinking about a currera r  update  i found a quite cheap and good camera from ximea  thay have a very nice support for libraries like opencv matlab etc  so for newbie like it is perfect  ,sensors beginner
5310,interfacing high resolution image sensors with arm board,i m working on a project requiring hd  stereo  video processing  most of high resolution   mp   sensors use mipi csi interface   i managed to get a board with an exynos  soc  the soc itself has   mipi csi  interfaces  the problem is that the pins to those interfaces are not exposed and it s  almost  impossible to reach them  so i decided to use the usb    buses  the problem is when i get to significant bandwidth        gibibits s per sensor   i don t think usb    will work out   but this could be solved with a compressed stream  via a coprocessor  i was thinking that cypress  cyusb   x chip was a good candidate for the job  but one of the problems is that i can t do bga soldering by hand nor have been able to find a bga soldering service in switzerland  any ideas on other interfaces i could implement or other coprocessors with mipi csi  interface  just a final remark  space and weight are important as this is supposed to be mounted on a drone  ,cameras usb stereo-vision
6310,what type of antennas to use for xbeepro    ghz,i am planning to use    ghz xbeepro   mw devices for a project that requires a coverage area of around      km   when i go to select an antenna there are various options like circular virtical  horizontal polarized etc  which antenna would give a coverage for a field  i cant have it directional  one point to another point   by devices will be moving around on a field   what type of polarization is recommended for this kind of a setup  my base xbee will be on a elevation of around   m from the ground so i have a clear line of sight for all the moving modules   there are going to be around      moving modules streaming data at around    readings per second   a    dbi antenna should suffice the application  and what about polarization   ,battery wireless
6313,how do you calculate the moment of inertia of a quadcopter ,i m building a quadcopter for my final year project  i have a set of equations describing attitude and altitude but they involve    and   none of the papers i have read describe how these are calculated  they simply choose it before their simulation  can anyone help  ,quadcopter kinematics
6314,communicating between a beaglebone black and an arduino using ttyo ,i m trying to get an arduino to talk with a beaglebone black   i have followed this tutorial for getting ttyo  open on the bbb and used the following command on to set the serial line correctly   wiring is set up according to this tutorial       stty  f  dev ttyo  cs       ignbrk  brkint  imaxbel  opost  onlcr  isig  icanon  iexten  echo  echoe  echok  echoctl  echoke noflsh  ixon  crtscts next data is sent using the following method    the arduino uses the followingvoid loop     code to check for serial communication   include  spi h   void setup                  setup                          serial begin          void loop          if serial available                 digitalwrite     high            delay                         wait for a second          digitalwrite     low        turn the led on  high is the voltage level           delay                         wait for a second          digitalwrite     high            byte b  b  b  b             b  serial read                        however it seems no message is received  it does not give any error either   as an alternative i have also tried a variant of the code suggested in the wiring tutorial resulting in the following code  import sys from bbio import     serial  begin       for arg in sys argv      print arg     serial  write arg      delay     called with pyton test s    this printed s    but the arduino remained silent   edit i have now also tried to exactly follow the wiring tutorial so that gave me the following sketch   char indata         allocate some space for the string char inchar        where to store the character read byte index         index into array  where to store the character  void setup       serial begin          pinmode     output        digital sensor is on digital pin     digitalwrite     high     delay          digitalwrite     low     delay           void loop       serial write  a      digitalwrite     high     delay         digitalwrite     low     delay         if  comp  a               digitalwrite     high         delay              digitalwrite     low         delay              char comp char  this        while  serial available           don t read unless                                       there you know there is data               if index          one less than the size of the array                       inchar   serial read       read a character             indata index    inchar     store it             index       increment where to write next             indata index             null terminate the string                      if  strcmp indata this                   for  int i   i    i                  indata i                       index            return               else           return              and on the bbb we turn on the echo script with  pybbio examples  sudo python serial echo py  the effect remains that there is no error but also no data delivery   ,arduino control serial communication beagle-bone
6315,pose estimation  how to populate set of known edges and points ,i am building an estimator that solves for the camera pose relative to a reference frame which contains a known set of features and edges  currently  the system works with an unscented kalman filter with four known points  red leds  in the reference frame  i am now hoping to improve robustness by adding edges to the model as well as robust features  i would like to add additional points that are uncovered by some opencv feature finding function  fast cornerharris       so far i found the paper  fusing points and lines for high performance tracking  and  robust extended kalman filtering for camera pose tracking using  d to  d lines correspondences  which seem to detail how to fuse edge and feature matching for pose estimation  is there a strategy to populate the known set of edges and features when it is impractical to measure them with a ruler tape measure  my first thought is to start with a small known set of features  my red leds  then run some slam algorithm and keep all features edges that have some minimum certainty  thanks a bunch  i have misunderstood the ransac algorithm  this is not appropriate for my application   for those interested  i am hoping to use a similar approach to the one presented in the following paper  youngrock yoon  akio kosaka  jae byung park and avinash c  kak   a new approach to the use of edge extremities for model based object tracking   international conference on robotics and automation        ,kalman-filter computer-vision pose
6322,getting started with jetson tegra k ,after working for a long time on my arduino due  i needed a better and more powerful prototyping platform for my future projects  for which  i have placed an order for nvidia jetson tegra k  board which runs on linux and supports cuda based development  being a newbie to linux  i have no idea where to start from and what to do for getting started with code execution on the jetson board  please suggest the initial steps required and from where can i get familiar to linux environment    thank you ,linux
6323,powering a multirotor with dedicated batteries for each motor,i m currently thinking of extending the battery life of my quad by powering each motor and esc individually  i  will be using   dedicated battery for each motor  and   dedicated battery for the flight controller itself  bringing the total to   batteries for the entire quad  my thinking is that by powering each motor with a dedicated battery  given a power draw consumption  the flight time of my quad will be increased by  x as each motor will have  x the capacity to draw from  putting the problem of weight aside  would this be a feasible idea  also  i am currently using just   battery to power all motors  and as such  i only have to plug in the single battery and i can calibrate my escs  how would i calibrate my escs if i am using dedicated batteries for my apm     and each motors would i be able to get away with powering my apm using the bec on my escs  ,quadcopter power battery
6325,ambiguous definition of error state  indirect  kalman filter,i am confused by what precisely the term  indirect kalman filter  or  error state kalman filter  means  the most plausible definition i found is in maybeck s book       as the name indicates  in the total state space  direct  formulation  total states   such as vehicle position and velocity are among the state variables in the filter    and the measurements are ins accelerometer outputs and external source   signals  in the error state space  indirect  formulation  the errors in the ins    indicated position and velocity are among the estimated variables  and each   measurement presented to the filter is the difference between ins and external   source data      years later roumeliotis et al  in     write   the cumbersome modeling of the specific vehicle and its interaction with a dynamic environment is avoided by selecting gyro modeling instead  the gyro signal appears in the system  instead of the measurement  equations and thus the formulation of the problem requires an indirect  error state  kalman filter approach   i cannot understand the bold part  since lefferts et al  in     write much earlier   for autonomous spacecraft the use of inertial reference units as a model   replacement permits the circumvention of these problems   and then proceed to show different variants of ekfs using gyro modeling that are clearly direct kalman filters according to maybeck s definition  the state only consists of the attitude quaternion and gyro bias  not error states  in fact  there is no seperate ins whose error to estimate with an error state kalman filter   so my questions are   is there a different  maybe newer definition of indirect  error state  kalman filters i am not aware of  how are gyro modeling as opposed to using a proper dynamic model on the one hand and the decision whether to use a direct or indirect kalman filter on the other hand related  i was under the impression that both are independent decisions       maybeck  peter s  stochastic models  estimation  and control  vol     academic press            roumeliotis  stergios i   gaurav s  sukhatme  and george a  bekey   circumventing dynamic modeling  evaluation of the error state kalman filter applied to mobile robot localization   robotics and automation        proceedings       ieee international conference on  vol     ieee            lefferts  ern j   f  landis markley  and malcolm d  shuster   kalman filtering for spacecraft attitude estimation   journal of guidance  control  and dynamics                      ,localization kalman-filter navigation errors
6327,beaglebone black power supply for hexapod,i am trying to build a hexapod with camera interfacing using a beaglebone black for college project  i m not sure what power supply to give so it can power up to bot  having in mind that it should be portable  mobile  and it should power about    servo motors along with the camera  wifi and the processor  your help is needed very badly as i m nearing the deadline for the project  ,power servos beagle-bone hexapod
6328,language to code beaglebone,i m trying to build a hexapod with beaglebone in the linux environment  im thinking of using ubuntu   what is the best language to use for coding purpose to make robot controls  camera and wifi integration etc  ,control programming-languages beagle-bone linux
6331,passing power through a motor,how would one go about passing power through a motor  let s say we have some basic robot which has a motor that slowly spins a limb  on each end of that limb  there is a motor which again spins a limb  because the first motor is always going to be spinning  any wires would twist and eventually break  so a wired approach wouldn t work  the same goes for the subsequent motors  i know that dc motors use brushes to get past this  but how is this generally solved in engineering robotics  this must be a problem that has come up before  and there must be a solution to it  any ideas     ,motor stepper-motor power
6334,what is inverse depth  in odometry  and why would i use it ,reading some papers about visual odometry  many use inverse depth  is it only the mathematical inverse of the depth  meaning   d  or does it represent something else  and what are the advantages of using it  ,slam computer-vision odometry
6339,understanding the bode plot,i m not sure if this is the correct forum for this question about automatic control  but i ll try to post it anyway  so  i ve just started to learn about control systems and i have some troubles understanding bode plots  my textbook is really unstructured and the information i find on the internet always seem a little bit too advanced for a beginner like me to grasp  so i hope you can help me to understand this   i would like to know what the information we find in the bode plot can tell us about how the corresponding step responses behave  i know that a low phase margin will give an oscillatory step response and that the crossover frequency decide the rise time  but how can we see if the step response has a statical error in the bode plot and what does the phase graph of the bode plot actually mean  ,control automatic
6341,lt     logic level question,i plan to use the lt     in my application pcb to act as a switch control from a micro controller side to control the on off state of   module boards which will be connected in the pcb     st load is  v  a   nd load is    v    ma   the lt     will get a  v input at the vs terminal   does anyone know how much voltage is required to be used at the in  and in  pins  the datasheet doesn t say how much voltage can be used here  i am guessing it will be  v  but can it do logic level with    v  my microcontroller board gives an output of    v and not  v so i ll have to make a logic level converter before feeding the pins in  and in  if it s not    v tolerant   please confirm  if anyone has used this ic before   ,circuit
6345,battery system for a robot with a raspberrypi or microcontroller,i m building a robot which is actually a rotating ball  all my circuitry will be inside this ball  i m using a raspberry pi as the brains  apart from raspberry pi  i ve an h bridge ic  l   n   a   axis accelerometer   gyroscope  mpu       and probably some more additional digital components  these will work with a  v or    v supply  another set of components are electromechanical devices like a  kg torque servo and       rpm dc motors  here are my questions   everything will work on battery  i can get a    v and  v supply from a  v battery using l        v and      regulators respectively  i know that it s not at all reliable to share the power source of the control circuitry with high load devices like motors and servos  should i have a dedicated separate supplies for electromechanical components and the control circuitry  servo will run on  v supply and motor will run on a   v supply  how should i go about this one  again  separate batteries for servo and motors  can of this work on a single high capacity battery  somewhat like      mah   here are some of my calculations  servo current   v   at no load      ma  at around  kg load      ma motor current    v   at no load      ma  at around  kg load      ma raspberrypi and other digital circuitry   v      v       ma  that includes an xbee  thus  the overall current at a  kg load  with two motors  comes around     a it would be really awesome if this thing gets done with a maximum of   batteries  else  it may get messy while placing the batteries inside the ball  space is limited  ,motor power servos battery
6348,what does the sensitivity function mean ,i m studying for a test in automatic control and i have some troubles understanding sensitivity functions and complementary sensitivity functions   there s one assignment from an old exam that sais  someone suggests that you should reduce perturbations and measurement noise simultaneously  explain why this is not possible   the correct answer sais   since the sensitivity and complementary sensitivity transfer functions add up to    i e    one cannot improve both the output disturbance and measurement error suppression at the same time   i don t really understand this answer and my textbook is not to much help either  so i would appreciate alot if someone could explain how they got to this answer  also  is the sensitivity function always representing the perturbations in the system and the complementary sensitivity function the measurement noise  my textbook seem to imply this  but i m really not sure if this is always true  ,control noise automatic
6351,accounting for error in multiple electric motors,our goal is to drive an autonomous robot with a differential locomotion system using two identical electric motors and an arduino uno    for each wheel   from our understanding  over time the motors can lose accuracy and may result in one motor rotating more than the other  is there a way to account for possible error in the speeds of the motors so that the robot can end up in a very precise location  our thoughts were to have an indicator which would allow us to count the number of rotations of each motor and compensate if a noticeable difference began to appear  ,arduino mobile-robot two-wheeled
6355,dealing with position inaccuracy and latency in pid loop,background  i am new to pid  for my first pid project i am using a simple p loop and     degree linear potentiometers for position feedback  i am using the roboclaw  x  a motor controller   the motor controller has    speeds between   sometimes the potentiometers can vary as much as     degrees when not in motion   i am using an arduino mega with a   bit adc to control the motors    my question  how can i filter or reduce the variance in the potentiometers   in addition  it takes a certain amount of time for the motors to react to the command  and it seems to throw off the p loop   how do i account for the latency  in my program  example  for this example the p loop was run every       milliseconds  i will tell the motor to go to     deg sec  and it will go to     deg sec  the p loop then reacts by lowering the value sent to the motor however the speed then increase to     deg sec and then the p loop lowers the value again  then the speed will drop to    deg sec  thanks so much for any help  joel ,arduino motor pid software avr
6356,how do i achieve this  grid of dowels powered by piston like movement,i am completely new to this site and robotics  but i have experience in programming  and programming microcontrollers    i would like to create a grid of  pixels   where each  pixel  is a metal or wooden dowel that is programmed to push in and out  like a piston    i m imagining a lot of pixels  maybe   x    where each could be quite small in diameter          the arduino would have control over the linear movement   up and down   of each pixel  could anyone point me in the right direction for accomplishing this  ,arduino mechanism servos servomotor
6366,how can i improve the range of an xbee s b ,has anyone used the xbee wifi modules  done a range check on them  with my laptop i get a range of around    m on industrial level accesspoints on a football field  well how good are these devices   if i get a sma connector version and use a higher gain antenna am i looking at ranges from        m    talking      dbi gains here   ,wifi
6367,how to combine an accelerometer and a gyroscope to find robot location and orientation in  d  d space,i have data from an accelerometer that measures x y z acceleration and data from a gyroscope that measure pitch  roll and yaw  how would i combine this data to find robot location and orientation in  d or  d space   ,localization accelerometer algorithm gyroscope
6371,basic programming in arducopter,i am starting with a project using arducopter  i am a person familiar with arduino  but seeing the arducopter for the first time  commands codes and everything is completly different compared to normal arduino programming  i am not getting any help or commandlist for specific purposes in arducopter  any body can help me in leading to any links which can help me out   ,arduino ardupilot
6374,ros send message on startup doesn t seem to work,i have the following code     code that isn t interesting has been removed  running this causes the following output to appear    rostopic echo  questions   then it does not show me an initial message being sent  changing         if  first                        askmath   first      into              askmath   first     does appear to work but it then sends a message every cycle rather then just the one at the start   does anybody know what is wrong here   ,ros c++
6382,can a jacobian be used to determine required joint angles for end effector velocity position ,i m in the early stages of working with a simple robot arm  and learning about the jacobian and inverse kinematics  from my understanding  the jacobian can be used to determine the linear and angular velocity of the end effector  given the angular velocity of all joints in the arm  can it also be used to determine the cartesian position of the end effector  given the angles and or positions of the joints  furthermore  suppose that i want to determine the required angular velocities of the joints  in order to bring about a desired linear velocity of the end effector  can this be done by simply inverting the jacobian and plugging in the desired parameters  ,kinematics inverse-kinematics forward-kinematics manipulator jacobian
6383,pcb making at home,i ve made many pcbs at home but still there are some mistakes  i tried ironing  drawing methods but it doesn t work very well  i use eagle cad for design pcbs  please help me   ,design
6386,robotics advice needed,for a high school project i will be building a robot that will draw an image on a whiteboard for you based on what instructions you give  to accomplish this a motor will move the pen on each axis similar to how a  rd printer moves but without the z axis  as far as code goes i m fine but i was wondering if anyone could give me an insight on how to go about building the robot  i e  what motors  best system for moving on axises etc  all help is appreciated thanks ,motor mechanism
6395,mobile camera calibration and rectification frame rate,i ve been searching the internet for an answer to this question  but i haven t come across anything that will help me  basically  we have a meka humanoid robot in our lab  which has a shell head in which a pointgrey usb     camera is embedded  i use the pointgrey camera driver  for obtaining the images from the camera  the head has   degrees of freedom  up down  left right   i am intending to use this camera with the ar pose package to detect and track ar tags on objects  i understand that camera s must be calibrated for effective use  forgive me  i don t know much about camera  which i do with the camera calibration package  my question is  since this camera is  mobile  meaning since the head can move so does the camera  how would i go about calibrating it  currently  i have the head fixed at a position and i ve calibrated the camera in that position and got the parameters in the yaml file which i can load for rectification  in particular  if the head moves does the calibration file that i obtained in the previous position become invalid  if so  as asked before  how would i calibrate this camera for all of its possible field s of view  which can be obtained by moving   this camera has different video modes and in the mode i m using i can get a frame rate of   hz  i e  after driver is launched i get   hz for rostopic hz  camera image raw   however  when i rectify the image using image proc  i get a frame rate of only about  hz on rostopic hz  camera image rect color  is this normal  is there a way for me to increase this frame rate  please let me know if any more information is required  thanks for your help  ,ros cameras calibration
6398,eliminating electrical noise from my motor driver,background  i am using an arduino mega connected to a roboclaw  x  a motor driver   i asked this question about the system  but i have since narrowed the scope of the problem   i tried adding a bunch of different size capacitor between the  v and gnd  when the roboclaw is switched off then a     micro farad capacitor seems to eliminate all noise but when i turn on the roboclaw no capacitance valued i tried                                            microfarads seems to eliminate any noise   i even tried hooking up a   v battery with a  v regulator to the logic battery on the roboclaw and connecting it to the ground on the arduino   then i tried using a separate battery for the pots and connecting the aref to the   v on the battery  no matter what i try when the roboclaw is on the potentiometer value will vary as much as     degrees   i found the degrees using  map analogread a                  in addition i took a bunch of data and graphed it and found that if i took    instantaneous data points and averaged them together it would help significantly reduce the variance   i chose    because it take     ms      worked really well but it took    ms   to help explain the averageing of analog read  here is my code  unsigned int num      for  int i      i     i        potreading   num     my question  what is my next step in eliminating this noise   is there a formula i can use to find a better capacitance value  should i try putting capacitors on each potentiometer between  v and gnd   any other ic i should try to help with this   on my previous question someone mentioned optocouplers  what size would work best and where in the circuit do they go   is there code i can write to help eliminate the size of the variance beyond what i have written  thanks so much for any help  joel ,arduino motor electronics noise driver
6405,difference between kinematic  dynamic and differential constraints,i would like to know the simple difference between kinematic  dynamic and differential constraints in robotic motion planning  ,motion-planning
6406,state space and control space,i would like to know the difference between state space and control space in relation to motion planning  i would like a simpler explanation  ,motion-planning
6408,can replicatorg or mattercontrol drive a reprap rambo motherboard ,i m fairly new to  d printing  i m considering motherboards i might use to control my printer  i m hoping to find a board that i can easily control using either   replicatorg mattercontrol  i like these programs because they seem reasonably current  mature and straight forward for beginners  my question is can i control a rambo v    board from either of these programs  these programs don t include explicit support for the rambo as far as i can see  but maybe i m missing how printing software works at this point   what is a rambo  the rambo v    board is a creative commons open source design  it integrates an arduino  stepper motor drivers  heater   fan controls  power management and more  an example implementation looks like this   for more background info on what a rambo board is  you may read about it on the reprap community wiki  ,3d-printing reprap
6409,the ide using for programming the atlas robots,atlas gets an upgrade   the new video of the atlas robot is out so i m curious about the ide with which they are coding this thing  ,dynamics
6412,how do i control a servo using a beaglebone black running ubuntu,i  have a beagleboneblack and would like to use it to control a servo for my robot  i m mostly programming in ros and as such am looking preferably for a c   solution  is there an easy way of controlling a servo on a bbb running ubuntu       on the kernal      most tutorials i have tried referred to files i did not have so i m unsure  ,ros servos servomotor beagle-bone c++
6417,comparing lqr and pid controllers for inverted pendulum problem,as far as i can tell  both lqr and pid controllers can both be applied to the cart pole  inverted pendulum  problem   what are the pros cons to using one controller over the other for this particular problem   are there any reasons situations where i should prefer one over the other for this problem  ,control pid
6418,tracking landspeed underwater,i am hoping someone might be able to nudge me in the right direction  apologies for the long post but wanted to get all the information i have gained so far down  basically i am after a solution to record the path my vessel took under water for later analysis like a bread crumb trail  requirements  ideally have a range of at least   meters however if there were no other options i would accept down to   meters  working fresh and salt water  the vessel is    cm x  cm  so size and power consumption are a factors  it would be traveling roughly parallel to the sea bed at variable distances from the sea bed  range of      meters  does not need to be super accurate  anything less than   meters would be fine  measurement speed range of       mph  measure direction the object was moving in  i e  forwards  sideways  backwards  i am planning to use a compass to ascertain n  s  e  w heading  options i have discounted   accelerometers   this was my initial thinking but in doing some reading it seems they are not suited to my needs  unless you spend loads of money  and then the solution would end up being too heavy anyway    optical flow   looks too new  from a consumer perspective    complicated  i don t know what its range would be like  also requires additional sonar sensor  current favorites   sonar    simplest use is distance from object  however can use doppler effect to analyse speed of a moving object    m range  nice  presumptions  if i fired this at an angle to the seabed i could deduce the speed the floor was  moving  below which would give me the speed of my vessel  i am also presuming that i could interpret direction of movement from the data  i presume that the sensor would need to be aimed at an angle of around    degrees down to the seabed   laser rangefinder   although it works differently to the sonar the premise of use looks the same  and thus i have the same queries with this as i do with the sonar above  presume if i mounted the sensor behind high quality glass  to waterproof it  then performance would not be impacted that much  this is a lot more costly so if it does not give me any advantage over sonar i guess there is no point   water flow meter    super low cost and simple compared with the other options  i would potentially use a funnel to increase water pressure if it needs more sensitivity at low speed  would then just need to calibrate the pulses from the sensor to a speed reading  significant limitations of this is it would be registering a speed of   if the vessel was simply drifting with the current  its speed over the seabed that i am interested in  current favorite option is sonar  with the option of using water flow meter as second data source  however are my sonar presumptions correct  have i missed anything  any better ideas  ,sonar laser underwater rangefinder acoustic-rangefinder
6423,particle filter weight function,i am trying to implement a particle filter in matlab to filter a robot s movement in  d but i m stuck at the weight function  my robot is detected by a camera via two points  so a single measure is a quadruple    yp   xp   yp   and states are the usual  x y alpha  to detect its pose in  d  as far as my understanding goes i should assign a weight to each particle based on its likelihood to be in that particle position with regards to the current measurement  i also have the measure function to calculate an expected measurement for a particle  so basically i have  for each instant  the actual measurement and the measurement that a single particle would have generated if it were at the actual state   assuming all noises are gaussian  how can i implement the weight function  i kind of noticed the mvnpdf function in matlab  but i can t actually find a way to apply it to my problem  ,mobile-robot wheeled-robot particle-filter
6428,sensor that will produce a sinusoid phase locked to a high rpm shaft,is there a sensor that will produce a sinusoidal signal phase locked to a high rpm       rpm  shaft  i am attempting to build a coaxial helicopter based on the architecture described in this paper which requires increasing and decreasing drive torque once per revolution  and i would like to do this modulation in hardware  ,sensors
6429,grid mapping probability calculation algorithmic complexity,i have stumbled upon an equation     where the probability of an occupancy grid map cell is calculated  my teacher insists that it s possible to approximate the algorithmic complexity of this long equation  but i m not so sure  the description of the factors used in this equation are described here on page     item      with keeping in mind that this calculates occupancy probabilities of a   dimensional array from sensor measurements  is it really possible to approximate the algorithmic complexity of actually calculating occupancy with this equation in bigo by just taking a look at it and not delving much deeper into the details   ,algorithm probability occupancygrid
6430,how does a two gear pull back car toy work ,this is not a robotics question  but this stack exchange is the closest i could find to mechanical engineering  please refer me to a better place to ask this  if one exists  hopefully someone might just know this   i got a pull back car for my boy at mcdonalds  and it has two gears  it starts slow  then speeds up after about two seconds  it s impressive to me  especially given the inherent cheapness of toys sold by mcdonalds  it feels solidly built as well  i couldn t find anything related to this concept  the wiki on pullback motors does not include any information on multiple gears  any ideas on how this works   ,mechanism
6434,differential robot yaw estimation using kalman filter,hello i am building a differential drive robot which is equipped with quadrature encoders on both of the motors  my aim is to be able to predict the heading  yaw angle  of the robot using a kalman filter  i am using an mpu      imu  as of now m just interested in yaw angle and not the roll pitch  as i understand  i will be needing the z axis of gyro to be fused with the magnetometer data in order to properly estimate the heading angle  my problem is how do i implement the bias and covariance required for the kalman filter to work  gyroscope would be my process and magnetometer data would be my update step yeah   from the datasheet i have found the angular random walk of my gyroscope to be     degrees second for    hz motion bandwidth and a constant bias of    degrees second at room temperature  if i am not mistaken i should include the bias in my state prediction equation   also how do i get the covariance matrix q   ,kalman-filter imu
6436,choosing a wifi antenna for outdoor robot,a time has come for my robot to get some more permanent computer than my laptop balanced on top of it  i have selected a mini itx board that can be powered directly from battery and some components that go with it including a wifi card and now i m thinking about the antenna i will need  constraints i have identified so far   the robot s body is a closed aluminium box  so i think this rules out keeping the antenna inside  the robot is intended to work outdoors  so it needs to be waterproof  vibrations might be an issue   and the questions   what parameters should i watch when selecting an antenna  is it ok to use indoor stick antenna and seal the mounting point with hot glue  does it change anything if the antenna will be sticking out of largish sheet of alluminium  the robot will also have gps  is it possible that the two will interact badly under some circumstances   ,mobile-robot wifi
6437,how to provide power to a robot raspberry pi ,i m building a robot and powering it with a raspberry pi  i am looking at this battery pack  but i am flexible with which one to use  my problem is that i need to be able to charge the robot while it is still on  and apparently that is not good for a single battery pack to be charging while being used  they seemed to say so in the video   am i wrong  otherwise  how could i go about charging the robot while keeping the raspberry pi running  edit  this is my first robot  other than my lego nxt kit   so i don t have any prior experience with robot batteries  ,mobile-robot battery
6442,quadcopter multiple esc angles glitch,i m developing my fligth controller board on tiva launchpad for quadcoper and while calibrating pid i discovered an unexpected behaviour  sometimes quadcopter seems to experience random angle errors  while trying to investigate it  i ve figured out that my code if fairly trying to compensate tham  as soon as they appear   but do not cause them  even more   i ve discovered that such behaviour appears only when two  or more  motors are adjusted  while one motor system shows pretty good stabilisation  here is code for pmw output for different motors   and here is recorded angles for system with one motor and two motors   to be sure that it s not the algorithm problem  while recording this angles only integral part of pid was non zero  so angles were not even stabilised  my question is   could esc noise each other  in my quad they are quite close to each other   just few sentimeters away  to cause such behaviour  thanks a lot  ,quadcopter pid esc
6445,ways of reversing motor direction easily,my set up consists of a brushed motor  ex cordless drill type  connected to a motor controller which is in turn connected to a lipo battery and an r c receiver  all my cables are fitted with xt    connectors except for the cable that goes to the receiver which is a   wire pin  usual white  red and black   the above set up is one of a pair which i am using in my battle robot  the motors are connected to drive wheels  left and right respectively  the problem is the motors are turning in opposing directions  for some reason i neglected to switch the polarity of the wires of one  motor at the time i attached the xt    connectors and i really am not looking forward to re soldering    so my question is whether there is any fast way of reversing the direction of rotation without soldering   for instance can the r c transmitter  a turnigy  x without any modding be programmed to switch up for down  hence forward for reverse    or can i maybe switch the pin connector going into the receiver  i don t think so because the ground is probably common  but worth asking just in case i guess    any ideas or should i just get soldering  ,motor
6446,how do you design quadcopter pid algorithm ,just to give a bit a context  here are the equations i m using for the angular accelerations          jx    and         jy    so my plant gains would be             jx  along x axis and            jy  along y axis the basic pid structure is  gain kp desired measured  ki integral desired measured   kd differential desired measured  lets just say my plant gain for angular accl around x axis is  g and my pid gain is pg  to obtain a controller  do i do   g  pg  open loop gain l and for closed loop l    l    my question is  am i right about what i m doing and do i upload the algorithm in time domain form or frequency domain form  silly question as frequency domain is for analysis but my only control experience is purely theory and entirely focused on analysis using root locus and nyquist  ,arduino control pid
6447,role of chi  in slam back end optimization,all most all slam back end implementation compute chi  estimates  chi  computation is usually used to compute the best fitness score of model to the data  how it is related to optimization framework for slam  rgds nitin ,slam theory
6452,fuses for mechanical systems,   if there s a better stack exchange site for this  let me know  the mechanical engineering one is closed so i m not sure where else is appropriate    do mechanical systems have fuses   in an electrical system  like a charging circuit for example  we prevent large loads from damaging the system with fuses and circuit breakers  these will disconnect the inputs from the outputs if the load get too high   do mechanical systems have a similar mechanism  something that would prevent gears or linkages from breaking when the load gets too high by disconnecting the input from the output  ,mechanism
6459,relative frame calculation,what s the quickest way to calculate a relative coordinate of a frame  as shown in the code below  the kuka robot language this     is referred to as the geometric operator   i would like to perform this calculation in matlab  scilab  smathstudio or java  could you please advise on which library to use and or how to proceed   ,programming-languages
6462,beaglebone black doesn t autoboot when powered over jack or vdd pins,i have a bbb and it works quite well however when i power it over the barrel connector or over the vdd pins rather then use the usb connection it doesn t automatically boot  when i put the barrel connector and usb in at the same time and then remove the usb it continues running  this is running on ubuntu arm  i have tested that the power supply is between      and      v and is capable of sustaining this to just over   ampere edit it appear the bbb does boot when supplied with     v lab power supply at     a power consumption  so that suggest something is wrong with the power supply  but how do i test it seeing i was able to verify that it can supply  a at  v  this power supply works by feeding a   v battery into a step down to convert it down to  v if that matters  power supply power linux beaglebone black beagleboard ,beagle-bone linux
6463,single touch based sensor and odometry slam in noisy rectilinear environment,a co worker said he remembered a      ish  icra  ish   paper which used just a touch bump sensor and odometry to do slam  i can t find it   i ve paged thru the icra and iros agendas and paper abstracts for            no joy  i found a couple of  interesting papers but my coworker says these aren t the ones he remembered  foxe       tribelhorn a   dodds         background   i m trying to make a lego mindstorms bot navigate and map our house  i also have a ir sensor  but my experience with these is that they are really noisy  and at best can be considered an extended touch sensor  regards    winton ,slam
6467,help for cracking robotics interview,i am studying electronics engineering  i am fond of robots since my childhood  i have small doubt i e  if i want to get placed in robotics and automation based company  what should i must study reference books softwares etc  perticularly for cracking an interview   in simple words as electronics engineer what other specific skills  like embedded c programming etc  should i go through  ,control microcontroller electronics
6469,is there a name for the steering style wheel actuation used on curiosity ,i read up on the wheels of curiosity  and also about the suspension  but is there a name for the steering  it looks similar in nature to the front landing gear on an airplane  but searching those terms didn t turn up and answer  i ve attached a picture with the area of interest highlighted    image  gene blevins reuters   ,wheeled-robot
6471,how to connect hc sr   ultrasonic sensor to apm     ,i am working on my final project by autonomous quadcopter  my tasks are to make a quadcopter  which should do object avoidance and it should auto land using ultrasonic sensors  any possible ans to it  how should i connect hc sr   ultrasonic sensor to my apm     board  even apm     has a port i c  ,quadcopter
6475,what is the price of pioneer p dx,i wanna know how much does  pioneer p dx cost  nothing mentioned in the website and i don t want to fill out the form regarding this matter   ,mobile-robot
6476,how to run custom hardware from a laptop,i am looking to build some custom hardware  nothing too fancy  just some motors  cameras and the like   and i need it to be controlled by my laptop  its going to have to do a non trivial amount of image processing   is there a way to attach  motors to a laptop where  via usb e sata  it seems like something that should be very easy to solve  but i can t seem to find it anywhere  i am not looking to get an arduino raspberry pi  really just connect the motors  and be able to control them individually  i am comfortable adding more power from a second source to supplement the usb power  ideas  ,motor usb
6478,rocker bogie suspension system   pitch angle,what does this sentence mean    the chassis maintains the average pitch angle of both rockers   put in other words    the pitching angle of the chassis is the average of the pitch angles of the two rocker arms   what is a pitching angle in this context   please explain both pitching angles  ,mobile-robot wheeled-robot
6488,creating an xbox remote that replaces spectrum dx c or dx e without wifi,hello i m a new rc enthusiast   is anyone interested in rc s controlled through xbox remotes  the project is to use an xbox one or xbox     remote to either hijack a dx e or dx c remote or create a transmitter compatible with the spectrum receiver out of the xbox remotes  i ve seen applications that use wifi but i m not sure thats the route i m looking for  from what i ve read there is limited range and signal loss through the wifi network plus it may create a lag larger than what would be desirable in racing  the rc is a losi scte short course race truck  i m not to savvy with electronic jargon but will study and learn what i can  thanks for your thoughts    ,brushless-motor
6493,  wheeled    motor robot control,i decided to work on a   wheeled robot position mapping problem  for that i have   dc motors with encoders from pololu  i have the following two questions   do i need to know the model of each motor in order to tune a controller  what are the steps approach used to get a good mapping  let s say   mm maximum error    ,pid wheeled-robot odometry
6495,how can i send a jpeg image to a microcontroller via usart ,how can i send a jpeg image to a microcontroller via usart  ,electronics embedded-systems
6500,dh matrix to homogeneous transformation matrix for each joint,given a dh matrix for a set of joints  how would you convert the data into homogeneous transformation matrices for each joint  i ve looked online  but can t find a good tutorial  ,kinematics joint dh-parameters
6508,low power computer for stereo vision,i would like to build a motorized robot with stereo vision that sends visual input to a pc over wifi for processing  a raspberry pi would have been perfect for the task if it would be possible to connect   cameras  the pi   would be powerful enough for two usb webcams  with minimum  fps  i guess  but the shared usb seems to be a bottleneck    cameras   wifi dongle   what other options are there to send input from   cameras and control a motor  or an arduino   ,computer-vision cameras
6510,multiple pids in quadcopter,i am wondering what the use is of two pid loops to control a quadcopter  one pid for stability control and another pid for rate control  why can t you just use one pid per axis to control a quadcopter where you take the current and desired angle as input and motor power as the output  ,quadcopter pid
6511,what type of servos are used in industrial robot arms like universal robot ur  ,i ve noticed that the industrial robot arms have very smooth  fast  and strong movement   does anyone know what type of servos they use   i m trying to build my own and don t want to have the jerky movement that is seen in a lot of diy robot arms   thanks   ,robotic-arm servos
6515,computer vision with single camera vs  distance sensors for obstacle detection,i am going to start a new project consisting in implementing an autonomous driving rc car  the car as it is now  has a camera installed on each side of the car  i e    cameras in total  they are connected to a board which is able to read and process the video input  i have been researching about obstacle detection using a single camera  without stereo cameras  e g  single camera vision and mapping system   and although it seems possible it also seems quite complex  modifying the cameras set up is not an option  i already have some video processing algorithms  like dense optical flow  which might help me  but i am not sure whether i might me able to implement the system in the time i have    months   i also don t know how reliable would be the final solution  if the first approach is not feasible  as an alternative option i also could install distance sensors in the car to detect obstacles  it seems that usually the most preferred choice is to use ultrasonic sensors  i would need to install them and i would not take advantage of the cameras  but it seems that the final complexity would be lower  is the first approach feasible  what are the pros and cons of each approach  if i implemented the second option  how many sensor would i need  ,sensors computer-vision ultrasonic-sensors
6516,stallable motor        duty cycle higher torque motor that can be stalled without burning up,i have a project where i need a motor that can turn some number of rotations which will spool up a cable attached to a spring closed device to open it up  when power is disconnected  the spring closure will cause the spool to unwind and the device to close  in the closed position  no power is available   i e  the closure mechanism needs to be      passive   in order to keep this open for some time  i will need a motor that is capable of being stalled for long periods without having the windings burn up  i know some motors can do this  such as the motors they use on spring closed hvac dampers  but i don t know how to find them or if there s a particular name i should be using to find them  i know i could probably do this with a stepper motor  but that seems overkill for the application  the only requirements are higher torque to open this mechanism  no gearing that prevents the motor from spinning when power is disconnected  and the ability to be stalled  ,motor
6522,pid controller for trajectory with mutliple setpoints,we implemented a pid controller for our quadcopter which allows us to fly from point a to b  the precise position of the quadcopter is measured using an external tracking system  now that we can fly from a to b  we would like to implement a controller to fly more complex trajectories with multiple set points  e g  from a to b to c or flying in a circle using sample points  we tried to use our regular pid controller for this but this of course doesn t work well since the pid controller forces the quadcopter to stabalize at any set point  we would like to have a controller that allows the quadcopter to fly a trajectory fairly smoothly  i think this has to be a controller that takes into account multiple set points in the trajectory at the same time so that it can already slow down speed up based on the trajectory that is ahead  can someone point me to some controllers   algorithms that i can look at to realize this  do i need a completely different controller to do this or will it be an adapted version of the pid controller that i have now  ,quadcopter pid
6523,building an open loop controller for a simple dc motor position problem,in order to identify the dynamics of my dc motor  i am trying to command it with xcos using the arduino tool box  the problem that i am facing is how to give the motor an input command such that i get some given angle position as output  i can only control the input voltage to the motor via pwm  i have been thinking about converting the angle to voltage but i can t figure it out  can somebody help me  ,arduino motor control
6526,  axis magnetometer question,apologies if this is a stupid question  but if i have a   axis magnetometer  and i calculate the vector magnitude as     then should i not always get the same value  regardless of the sensor s orientation  mine is all over the place  and i feel as though i m missing something obvious  ,imu magnetometer
6531,using hobby servo as axle,i am designing a pan tilt camera mount using standard hobby servos     many existing designs use the servo shaft as a revolute joint  as opposed to simply a torque producing element   as a revolute joint the servo mechanism is subject to different torques and forces   is using a servo shaft as a revolute joint recommended practice or should a bearing be used  ,rcservo
6532,what is the scope of electronics engineering in robotics automation ,i am beginner in robotics  i have taken admission for electronics engineering one year back as we don t have specifically robotics engineering branch in my country now i am suffering from questions like what is the scope of electronics  not electrical  engineering in robotics  automation i am unable to distinguish between the role of electronics engineer and computer engineer in robotics as in both cases programming is required also if i don t like to do programming coding  are there any other options to stick to robotics   automation field as per my branch electronics engineering   is concerned    ,control electronics embedded-systems
6536,motor for a hydraulic pump in a hydraulic system,i m not entirely sure if this is the right area to post this question  but looking at the other subjects on stackexchange  this seems to be the best fit  i am a complete beginner to hydraulic systems  and i ve wanted to learn more about this area  i m designing a hydraulic system that involves using hydraulics to push pull objects using pistons  i have looked at what the basic requirements are for a hydraulic system  but there is one thing that escapes me  i come from an electronic background  and i noticed that the hydraulic pumps  for example  this one  seem to lack a motor to drive the fluid  am i wrong  if not  i ve been looking everywhere for a motor that can should be attached to said pump  but i cannot seem to find anywhere that sells them  is it just a simple dc motor  with correct specs   or should there be a specific motor designed for hydraulic pumps  looking around  i came across this  but looking through the specs  i don t see a power requirement  and being used to seeing power consumption in datasheets  i m not even sure it is a motor  ,motor
6541,beaglebone   pru questions,i will be using at least one programmable real time unit  pru  to send pulses to a stepper motor driver but before i begin  i am trying to lay out the structure of my programs  i am using this library pru linux api  for loading assembly code into the pru instruction memory but there doesn t seem to be much documentation other then whats at that wiki and the source  github pru packageh my c program will be calculating the position of the sun using an algorithm and executing the assembly writing a pulse count to the pru s  data memory so they can just switch on off a gpio at my desired frequency and for the number of pulses required to turn a stepper the appropriate number of steps  i am not even sure if this is an acceptable method but i am pretty new at this and it seems like a simple way to accomplish my task my questions regarding the library functions are   is there a significant performance difference between using  or prussdrv pru write memory to give the pru s  access to the pulse count  would it be better halt the pru assembly program after has completed the tasks for each pulse count then re execute it with new values  or keep the pru program running and poll for a new pulse count to be written in   i plan to send a pulse count every    seconds or so  any suggestions on revisiting the whole structure and logic are welcome as well  ,c beagle-bone
6544,what s the smallest rotation a brush less motor can perform ,for example  i have a brush less outrunner with    poles and    stator windings  it has three connectors  can this motor be controlled in a way that it performs a single step of    degrees           ,motor brushless-motor
6553,create artificial integelent robot ability to communicate with computer   which language i should use,i know some languages like php  c c   and java but i m not expert in these languages  i want to create an artificial intelligent robot that can do these task   able to communicate with computer  usb  bluetooth or other  able to perform some specific task present a  visual interface  finding path  speed and others  access its micro controller device and attached devices and so on     editor note  solve world hunger     can any one please suggest which programming language will be good for programing this type of robot  i have heard about c c   and assembler and robotc and labview but i am unable to decided which language to use for my project  sorry for my bad english  ,microcontroller artificial-intelligence robotc
6560,don t understand how sensor works  metal wired directly to i o pin of arduino,i m trying to understand how an electronic musical instrument  called an e chanter  works  imagine a recorder or other wind instrument  but with the holes replaced with metal contacts  and the sound played electronically  so no air is needed   basically  there are several metal contacts  as shown in this link   they each appear to be wired only directly to one pin of the arduino   i can t figure out for the life of me how this works   can anyone explain it  are the fingers being used as some kind of ground or what on earth is going on   i have a physics background so can understand some technical info  but just can t fathom how on earth this magic works  thank you very much ,arduino sensors
6564,jacobian matrix of  dof body  with imu ,i am trying to derive the analytical jacobian for a system that is essentially the equations of motion of a body    degrees of freedom  with gyro and accelerometer measurements  this is part of an extended kalman filter  the system state is given by   where  is the quaternion orientation of the body expressed in the global frame   and  are the biases in the gyro and accelerometer respectively  expressed in the body frame  and  and  are the velocity and position of the body expressed in the global frame  all vectors are   x   except  which is   x   in  format  and   below  which is   x    the equations of motion   t is time  are    dot  mathbf q      frac       mathbf q   otimes   left   begin array  c       hat  omega     end array   right      dot  mathbf b  omega           dot  mathbf v     r  top   hat  mathbf a       hat  mathbf  omega   times r  mathbf v    g     dot  mathbf b a           dot  mathbf p      mathbf v   second order terms are ignored   and  are the corrected accelerometer and gyro biases   and  are known  and are expressed in the body frame   is the rotation matrix  dcm  formed from  and  is the gravity vector   these equations have been validated against an aerospace engineering software library  i need the jacobian  but i cannot find this jacobian in any texts  i do find the error state jacobian eg this paper   i am struggling with doing this myself because i don t know how to handle the quaternion norm constraints  i also am concerned about the validity of a solution given through numerical differentiation  any help or explanation would be greatly appreciated  this is going towards an open source robot localisation project  ,control kalman-filter jacobian
6565,communicating between a beaglebone black and a servo controller,i am a complete newbie and recently joined a robot team at my school in order to gain some experience  i have been assigned a task of driving a servo using a pololu mini maestro usb servo controller  i am using the beaglebone black  bbb  with the python adafruit library  how do i make the bbb communicate with the servo controller  if you guys could point me in the right direction  i d really appreciate that  right now  i don t even know where to start  not sure if it matters  but this is the servo i am using   ,motor microcontroller
6566,robot navigation feedback using image processing,in my project  i ve successfully analyzed the arena and have detected the obstacles using an overhead webcam  i also have computed the shortest path  the path data is transmitted to the robot via zigbee  based on which it moves to its destination  the problem is  my robot is not taking accurate turns which would cause error in the rest of path it follows  could anyone please suggest any methods techniques for feedback from the robot so as the path is corrected and the robot follows the original path computed without any deviation   basically a tracking mechanism to avoid deviation from the original computed path  ,computer-vision navigation motion-planning
6570,fusion of gnss position data and prefused   dof ahrs data,bosch  freescale  invensense  st and maybe others are releasing   dof ahrs platforms containing their own fusion software and outputting filtered sane fused data  attitude as quaternion and linear acceleration   i would like to use these for the quality of their respective company fusion algorithm  and would like to merge gnss position and velocity data to it  i have found multiple examples of heavy        states kalman filters merging raw   dof imu data and gnss position velocity  but i have a hard time finding a computationally lighter version of gps ahrs fusion as these new   dof ahrs already fuse imu raw data themselves and this process should nt be done twice  would you maybe have pointers on the algorithm s  or type of filter to use   thank you  ,quadcopter kalman-filter imu gps sensor-fusion
6571,kalman filter with incremental encoder   optical mice,currently i am building a robots with   incremental encoders with a optical mice sensor  the reason to install a optical mice sensor is to provide better feedback when slippage happen on the encoders  i wonder if i could apply a kalman filter to get a better distance feedback with these   kinds of sensors  especially when the control input is unknown  for example i push the car with my hand  but not applying a voltage to the motors  i have read some examples to use kalman filter  gyro accel   encoder gps   either one of the variable used is in absolute measurement  while in my case  two feedbacks are dead reckoning   any help is appreciated          ,kalman-filter quadrature-encoder
6572,what kind of linear actuator can be used for very small forces over relatively long distances,what kind of linear actuator can be used for very small forces  pushing      kg over a flat  smooth surface  in steps of    mm over a total length of about    mm  i only seem to find actuators that are very large and are overpowered  extra details  speed requirements    mm s duty cycle     times in half an hour  once per day it must be compact and not much longer than    mm when concealed price must be under      ,actuator
6575,how to distribute tension load on a three footed claw ,good day    i am helping my little ones   and   to develop a robot that can pick up and stack cubes three high as well as gather blocks   they came up with the design that enables them to pick up three cubes at a time when lined up and then pull up the claw  turn  drive to another cube  place the cubes on the stand still cube and release     well they got the claw made with two rods connected to gears to motor and the rods reinforced  then they made insect like legs     pairs of two on the rods  with gripper feet pads on the ends of the legs  all of this works as it opens and closes  the problem is that when they try to close the claw on the cubes and pick up all three cubes  the first   closest to motor feet have a nice tight grip  the second   middle feet   have a lighter grip and just barely can lift the block  and third   farthest from motor doesn t even have a grip on the blocks     i think it s because the second and third set of feet are farther from the motor  but how can they evenly disperse the tension load so the claw can pick up all three blocks  i tried putting elastics on the feet for better grip and unless we put ten on each foot for the third set and maybe five on the second set it wont work   even though it s a quick fix i would like to help them figure it out the proper way of spreading the load so to speak   we also tried putting a small band on the third set of legs   the robot could still open and close and that worked for the third set but not the second   we tried putting a band on the second and third but the legs wouldn t open anymore   i could use a lighter band but is there another way  we only have one little motor to run it so we can t give all the leg sets it s own motor and even if we did there would be weight issues    thank you in advance  ,design mechanism vex
6576,robotics jargon question  how to conjugate  teach  ,as a non native speaker i have a  maybe trivial  but to me not clear  question concerning the verb  to teach   of course  from school  and online dictionaries  i know the past tense of  teach  is  taught  not  teached   but in robotics  to teach  has a special meaning  like   to make special ponts orientations known to the  arm  robot   e g  by guiding the robot to those points orientations    does it make sense to have a different past tense for  teach   i e   teached   in this case   maybe a reference were it is used explained    i would say  no  the past of teach is taught  and that s it    but some of my colleagues   also not native speakers   have a different opinion   ,reference-request
6581,stereo camera vs kinect,any one can advice me on the ideal perception sensors for pick and place application using a robotic manipulator with ros support  i have generally looked at things like kinect and stereo cameras  bumblebee   which provide depth that can be used with pcl for object recognition and gripper positioning  are there any other sensors would be preferred for such application and if not what are the drawbacks of stereo cameras in comparison to kinect or other sensing capability   thanks  alan ,sensors robotic-arm kinect stereo-vision
6583,is our laptop wifi single channel or multiple channel  this is for controlling a bot,we are building a hobby drone quad coptor  with a camera for footage  so to control the quad  i have been suggested web here  to use minimum of four channels for power and for turning etc   so which means i need one channel for every separate task to be done  for eg   if i want to rotate the camera  then i suppose i need the  th channel and so on   now my question would be   i have seen a lot of drones ardrone  walkera  which are controlled by an android or an iphone app  so the wifi used to connect the drones is  single channel or multi channel  if single channel then how can i control different tasks like to control turning of the quad or camera in different axis  also if i want the gps location from the quad  do i require to have another transmitter  i am using planned to  a raspberry pi    openpilot cc d for flight control  p s this is my first drone  kindly show some mercy if i ask don t understand your comments  ,quadcopter navigation radio-control wifi
6586,denavit hartenberg convention or the product of exponentials formulation  when dealing with the manipulator kinematics ,though  denavit hartenberg notation is commonly used to describe the kinematics of robot manipulator  some researcher prefer the product of exponential instead  and even the claim that it s better  which one should i use  and which one is generally better  is final solution same for both kinematics and dynamics  any suggestions  a mathematical introduction to robotic manipulation ,robotic-arm industrial-robot dh-parameters product-of-exponentials
6587,frc roborio eclipse can t find edu wpi first wpilibj,the first time after importing a project into the eclipse workspace we find that eclipse cannot find the wpilibj  on any import line  eclipse says  unresolved import edu  ,microcontroller wheeled-robot
6590,how do quadcopters turn left and right ,in this picture  a sketch of a quadcopter is displayed with rotor s direction of motion   the magnitude of the rotational velocity is depicted by the thickness of the lines  thicker lines are higher velocity  thinner lines are lower velocity    i m told this is the correct way to produce turning motion  but my intuition  which is usually wrong  tells me that the two pictures should be reversed   my argument is  as follows   for the picture on the left  the two rotors of higher velocity are spinning clockwise   if the motion of the rotors of greater velocity are clockwise  shouldn t the quadcopter also rotate clockwise   what am i missing here  ,quadcopter dynamics
6592,can i use a pwm hho controller to control a brushless dc motor ,i m an electronics newbie  the part i m talking about is this   my question is  can this type of part be used to control brushless dc motors  ,arduino brushless-motor
6593,guidance   info about quadcopter project,i m new in forum and since i made some research the past days i d like to get some guidance about constructing   programming a quadcopter from scratch since i m completely new on a project like that  quadcopter frame  thinking about to construct an aluminum   cm diameter frame which will weight around    g  what kind of motors should i get in order the frame with the board motors etc  will be able to lift  board  i m thinking to use arduino uno or raspberry pi       with a little bit of research i made i conclude that raspberry could make my life a little bit easier since you can add wifi on it  the quadcopter will be controlled via a pc laptop through wifi   what can you suggest and why  esc  as far as i ve seen in most of similar projects people using escs in order to control the motors throttle  can you avoid that  with programming pids that make the same job in order not to use more hardware  about pids and code in general  thinking about to simulate the whole project in simulik  matlab and somehow  if it s possible  to convert the matlab code into c   and download it on the chip  what do you think about that  about the whole project  i m trying to minmize the hardware as much as it s possible  use only  x motors  the board with the chip on it  cables and probably some sensors  in order to minimize the total weight of construction and ofc the price  that s all for a start  i m gladly waiting for your answers and ideas  ,quadcopter
6596,suggestions for beginer in robotics,i am beginner in robotics i want to make serious start from scratch with interest but confused from where to start so can anyone give some suggestions for   as a beginner in robotics  are there some simple and basic robots or circuit designs which i can make by myself in the home so that i can gain practical knowledge of robots     or should i first read books  can anyone suggest some good reference  book names articles  links free on line  video lecture series   ,beginner
6597,need of kalman filters in unimodal measurement model,i have recently been studying kalman filters  i was wondering that if sensor model of a robot gives a unimodal gaussian   as is assumed for lkf  and the environment is pre mapped  then the sensor reading can be completely trusted  ie  max value of kalman gain   removing the need for odometry for localization or target tracking purposes and hence the need for the kalman filter  please clarify  ,kalman-filter
6599,how to get the     matrix from the twist using product of exponentials  in robot kinematics ,in robot kinematics  we have   where  is     vector   how do i get the   by   transformation matrix by using product of exponentials  ,robotic-arm kinematics forward-kinematics product-of-exponentials
6601,help with code that is supposed to drive a servo controller,i posted a similar question before as i was just getting started with the project but i wasn t specific enough so got a weak response from the se community  but now i am at a point where i have python code which is supposed to rotate a servo through pololu s maestro serial servo controller     based on the  serial interface  section of the user s guide     i sent a sequence of numbers starting with decimal     and     which are the  first command byte  and the  device number data byte   respectively  the user guide says that    is the default device number  so i tried changing it to    because that s how many servos my servo controller can drive  but that doesn t make much difference because the servo doesn t rotate at all  the numbers after that are the same as the example from the user s guide  i am not sure what the        and    are doing  but the   targets the servo port     on the servo controller  the port to which my servo is connected   the servo doesn t move  regardless of what sequence of numbers i put in  i have very little experience  so if you guys could point me in the right direction or at least point to some useful resources on the web  i d be very grateful   ,python
6604,choose zigbee modules for full wireless mesh,what is the most common zigbee ip modules to create full wireless mesh mode   i know that it should be    coordinator and    router to create full mesh but i am interesting about what kind of modules it would be better to buy by comparing price  quality and tutorial material  it would be graet if you know some zigbee modules based on arm cortex  or atmel mcus and if you have some additional tutorial materials to control those modules and  understand it  i am looking for zigbee modules only  but not xbee    because they have difference in organization of network   ex    first of all  zigbee mesh can create own zones to control devices   but in xbee mesh which from digi comany can create only full mesh and only one big or huge zone to control devices   secondly  zigbee modules   aes encryption  can lock down network and prevent other nodes from joining  xbee   aes encryption    and it is coming soon    ,mobile-robot microcontroller radio-control communication wireless
6606,cheap wheeled robot without tether  does not need to be programable ,i am looking for cheap wheeled robot that can be controlled remotely  i do not really care about how  rf  bluetooth  wifi  ir  other    as long as i can control around    robots without interference in a small arena  they are always in the line of sight   i would like to emphasize that i do not need them to be programmable and it is important that they are cheap  ,control wheeled-robot
6607,best practice to write a ros service for a serial communication class with many options,i have been asked to write code to implement serial communications with a camera in order to control its pedestal  movable base  as well as set a few dozen other camera options  the catch is that i have to make it usable by ros   what would be the best practice to implement this functionality in ros  i understand  the concept of services  but i think that there should be a better way than creating a different service file for each option  thanks  daniel  ,ros cameras serial
6613,multiple limbs on small robots,note  i m a firmware developer experienced with sensors and networks  but not much with motors  i am trying to build a small hobby robot  like a cat sized spider  i am thinking of using servo motors with position control  so i don t have to use encoders to know where the motor is  assuming six legs  i know  spiders have eight   with each leg being able to move up down and left right  that already translates to    motors  if you want to bend a knee  that gets the number to        motors on such a small robot is overkill  isn t it  i have thought of a couple of ideas  but not having a strong mechanical background  i cannot tell whether they are doable sane  one of my ideas is to use a magnet on the end of the limb  the end inside the chassis  and a small permanent magnet above it  the magnets attract each other and this keeps the limb firm under the weight of the robot  a stronger controllable magnet  a coil  would attract the limb even more and let it lift in the air  the following drawing may help   this would allow the up down movement of the leg  and a servo would control its left right movement  however  i fear that such a system would not be strong enough to hold under the weight of the robot  or whether a reasonable coil would be compact enough  in short  my question is  how can i control six legs each with two or three degrees of freedom with a reasonable number of motors  is having one motor per degree of freedom the only possibility  ,mobile-robot servomotor
6617,jacobian based trajectory following,i would like to control my   dof robot arm to move along a cartesian trajectory in the world frame   i can do this just fine for translation  but i am struggling on how to implement something similar for rotation   so far  all my attempts seem to go unstable    the trajectory is described as a translational and rotational velocity  plus a distance and or timeout stopping criteria   basically  i want the end effector to move a short distance relative to its current location   because of numerical errors  controller errors  compliance  etc  the arm won t be exactly where you wanted it from the previous iteration   so i don t simply do    instead  i store the pose of the end effector at the start  then at every iteration i compute where the end effector should be at the current time  take the difference between that and the current location  then feed that into the jacobian  i ll first describe my translation implementation   here is some pseudo openrave python   the rotation is a little trickier   to determine the desired rotation at the current time  i use spherical linear interpolation  slerp    openrave provides a quatslerp   function which i use    it requires conversion into quaternions  but it seems to work    then i calculate the relative rotation between the current pose and the target rotation   finally  i convert to euler angles which is what i must pass into my angularvelocityjacobian   here is the pseudo code for it   these lines are inside the while loop  rot t    np dot pose start         velocity transform           desired rotation of end effector   second from start quat start   quatfromrotationmatrix pose start    start pose as quaternion quat t    quatfromrotationmatrix rot t     rot t  as quaternion    use slerp to compute proper rotation at this time quat target   quatslerp quat start  quat t   t elapsed    world to target rot target   rotationmatrixfromquat quat target    world to target v rot   np dot np linalg inv pose current          rot target    current to target v euler   eulerfromrotationmatrix v rot    get rotation about world axes  then v euler is fed into the jacobian along with v trans   i am pretty sure my jacobian code is fine   because i have given it  constant  rotational velocities ok    note  i am not asking you to debug my code   i only posted code because i figured it would be more clear than converting this all to math   i am more interested in why this might go unstable   specifically  is the math wrong   and if this is completely off base  please let me know   i m sure people must go about this somehow   so far  i have been giving it a slow linear velocity       m s   and zero target rotational velocity   the arm is in a good spot in the workspace and can easily achieve the desired motion   the code runs at    hz  which should be sufficiently fast enough    i can hard code the angular velocity fed into the jacobian instead of using the computed v euler and there is no instability   so there is something wrong in my math   this works for both zero and non zero target angular velocities   interestingly  when i feed it an angular velocity of      rad sec  the end effector rotates at a rate of    deg sec  update  if i put the end effector at a different place in the workspace so that its axes are aligned with the world axes  then everything seems works fine   if the end effector is    degrees off from the world axes  then some motions seem to work  while others don t move exactly as they should  although i don t think i ve seen it go unstable   at    degrees or more off from world  then it goes unstable   ,kinematics jacobian
6620,what is the best software package to draw the robot manipulator and indicate dh parameters and different axes ,i m wondering about good software package to draw the robot manipulator and indicate dh parameters and different axes  any suggestions  ,robotic-arm industrial-robot robotc simulation
6622,is khepera ii still adequate for learning,a professor in my university is asking me to study robotics with him  by robotics i understand programming a robot to move around  avoid obstacles  figure out a maze  etc   he sent me some manuals for khepera ii   when i first read the specs  i was surprised by the low specs   motorola       cpu      mhz     kb ram     kb flash  but then i looked at some of the new arduino boards and they had similar specs  so maybe that s ok  i guess the cpu speed and ram aren t that important if i m going to control the robot from a normal computer that can handle real time computation  what about the software  i glanced at the manuals and saw only c and assembly code  khepera i is from      and khepera ii is from       i think robots have advanced much since       is using khepera ii adequate for university level learning  considering i can probably give          for a newer one  i ask in terms of hardware of the board  motors and sensors  as well as in the programmability  this question might seem vague  i m ready to improve it by giving more detail upon request  ,mobile-robot
6624,ball and plate possible sensors use,i am looking  for sensors to give me the position of a ball  on a plate in order to make a ball and plate problem    what came to my mind is to use image processing but since i never did some serious image processing i don t know if it is a good idea  eventually can you please help me to find some  cheap  sensors in order to get the position of the ball on the plate  thank you for your attention  ,control sensors
6632,ros  iai kinect  issues,here is what i did on ubuntu       lts running on a toshiba satellite  intel i   nvidia with usb     and     ports          refer to scripts found here  setup ros by running this install ros sh script setup opencv by running this install opencv sh script setup pcl by running this install pcl sh script installed  libfreenect  via the instructions at the master branch made the changes and installed cloned the repository into an empty catkin workspace sourced the respective setup zsh files from my  opt ros     and from the devel  folders   at this point  i have encountered no issues i tried running    and i get the following message   error                           registerpublisher  failed to contact master at  localhost          retrying    so i assume i need to run roscore or something like that  so if i run   roscore  in one terminal and  rosrun kinect  bridge kinect  bridge  in another terminal  i get the following segmentation fault   error                           registerpublisher  failed to contact master at  localhost          retrying      info                          connected to master at  localhost        parameter          base name  kinect             sensor           fps limit            calib path   home parthmehrotra catkin ws src iai kinect  kinect  bridge data            use png  false      jpeg quality             png level         depth method  opengl      depth device            reg method  default        reg devive             max depth             min depth             queue size     bilateral filter  true edge aware filter  true        publish tf  false      base name tf  kinect     worker threads                 segmentation fault  core dumped   rosrun kinect  bridge kinect  bridge  i must be overlooking something really trivial  thanks for taking the time to help me   ,ros kinect
6639,how to plot  of a landmark in ekf slam,i have implemented  d slam using ekf  the map is based feature in which there is only one landmark for the sake of simplicity  i ve read some papers regarding this matter  they plot the  plus the error  i would like to make sure that i m doing the right thing  in my project  i have the estimate of the landmark s position and its true values  the true values here are the ones that the sensor measure not the ideal case  for example  the ideal case of the landmark position  is         but this value is not accessible by any means  therefore i will consider the true values the ones that are coming from the sensor   now the error in the landmark s position in x axis is formulated as follows    text error   x     hat x    x  the below picture shows the error in blue color  the red color represents the error bounds which is  my question is now is this the way people plot the errors in the academics papers because i ve seen some papers the bounds doesn t not look like mine  even though mine decreases monotonically however in some papers it is more curved and it seems more reasonable to me  any suggestions   ,slam ekf simulation mapping
6642, time varying  and  nonautonomous  dynamical systems and their lyapunov analysis,it is possible to distinguish the properties  time varying  and  nonautonomous  in dynamical systems regarding lyapunov stability analysis  does it make a difference if the system depends explicitly on  or indirectly on  due to a time varying parameter  i want to explain the problem in detail  let a dynamical system denoted by   with state   we say that a dynamical system is nonautonomous if the dynamics  depend on time   i e   dot x   f t x   for instance the systems   dot x     t x    and   dot x    a t x  are nonautonomous  let  be a bounded time varying parameter  i e   and strictly positive  i e     particularly  the second example is more likely denoted as a time varying linear system  but of course it is nonautonomous   in lyapunov stability analysis autonomous and nonautonomous systems must be strongly distinguished to make assertions about stability of the system  and the lyapunov analysis for nonautonomuos systems is much more difficult  and here for me some questions arise  when i want to analize stability of the second example must i really use the lyapunov theory for nonautonomous systems   it follows for the candidate   dot v    a t x    which is negative definite  is the origin really asymptotically stable  as i suppose  or must i take the nonautomous characteristic into account in this case  i would suppose it makes a difference if a system depends explicitly on  as in the first example or just indirect due to a time varying parameter  since  approaches infinity  but a parameter does not  ,control dynamics
6643,can a quadcopter hover while tilted ,is there a way to make a quadcopter maintain steady hovering  no lateral movement  constant altitude  while tilted left or right   if so  how can i accomplish this   ,quadcopter
6648,automatic agricultural robot using     ,i want to build a automatic agricultural robot for my final year diploma project  the basic idea is to program      to drive the robot in a fixed path in farm for ploughing the farm which i am planning to do by setting a particular distance till which it will go straight and then take a u turn and plough in next lane  width of the farm will also be set so when it completes full farm it ll stop and go back to starting point  the only catch is to reprogram it as per size of the farm of the person who uses it  so i want to add a number pad with which he can set the length and width of the farm as well as width of each lane as per his needs without professional help  can this be done using      or should i go for avr or pic microcontrollers  i have just started studying programming and interfacing of      so i am not that good in programming  if its possible how do i do it  can someone please help me with circuit diagram for this project  after everything i said i need in my project if i still get an empty port in microcontroller i would love to add a fertilizer sprayer or water irrigation system and a gsm module so that a farmer can simply ask the robot to start working using his mobile phone  as i am making just a prototype i want it to be as small as possible  suggestions are welcomed  ,microcontroller wheeled-robot electronics artificial-intelligence
6649,pid control of tank like robot and imu,consider a tank like robot with a motor driver channel for each side of the robot  two motors on the left and two motors on the right  and an imu  i m interested in driving the robot in a straight line using the yaw data from the gyro and magnetometer of the imu  removing the noise caused by slightly different behaving motors  and the possibility to change the desired direction angle  for example some event comes and i want the car to switch the desired direction to      degrees and turn while driving  i m using arduino uno  minimu   v  and two drv     single brushed dc motor driver from pololu  can you please give me some hints and a short pseudo code example  thanks  ,arduino pid imu
6650,microcontroller for running linux rtai,i m a beginner in robotics   i d like to ask what are the minimum recommended specs for a microcontroller to run a real time system such as linux rtai  what is the popular microcontroller for running linux rtai   thank you  ,microcontroller embedded-systems real-time
6651,are robotic pollenators being designed ,with the bee hive collapses  growers are desperate for pollenation options  is anyone working on swarms of tiny flying robots to augment the bees  they could look for a certain color  poke around inside the flower for a moment  and move on to the next  when they need recharging  they fly back to their hive  the same reason bees fly back    of course  replacing germinators that run the seeds through their digestive systems would be a different problem  ,mobile-robot
6652,how to get a python node in ros subscribe to multiple topics ,how a ros node written in python could subscribe to multiple topics and publish to multiple topics  all examples i found were for a single topic  is this an event driven model so subscription to multiple  events  is allowed or it is more like a loop  so it can listen only to one  source  at a time  ,ros
6657,what dynamic system could these equations represent ,i have equations of a dynamic system  i need to figure out what this physical system is   the equations are   begin align   dot x     bx   kx   x      dot x     x      dot x      alpha  u x     beta x    end align  all i can figure out is that it is maybe a mass spring damper system  plus a feedback control  but i am not quite sure about the terms  and   what do these two terms mean  ,control dynamics
6659,graphslam  why are constraints imposed twice in the information matrix ,i was watching sebastian thrun s video course on ai for robotics  freely available on udacity com    in his final chapter on graphslam  he illustrates how to setup the system of equations for the mean path locations  and landmark locations   to setup the matrix system  he imposes each robot motion and landmark measurement constraint twice   for example  if a robot motion command is to move from x  by   units to the right  reaching x    i understand this constraint as  x   x       however  he also imposes the negative of this equation  x   x     as a constraint and superimposes it onto a different equation and i m not sure why   in his video course  he briefly mentions that the matrix we re assembling is known as the  information matrix   but i have no why the information matrix is assembled in this specific way  so  i tried to read his book probabilistic robotics  and all i can gather is that these equations come from obtaining the minimizer of the negative log posterior probability incorporating the motion commands  measurements  and map correspondences  which results in a quadratic function of the unknown variables  and    since it is quadratic  and the motion   measurement models are also linear   the minimum is obviously obtained by solving a linear system of equations  but why are each of the constraints imposed twice  with once as a positive quantity and again as the negative of the same equation   its not immediately obvious to me from the form of the negative log posterior probability  i e  the quadratic function  that the constraints must be imposed twice   why is the  information matrix assembled this way   does it also hold true when the motion and measurement models are nonlinear  any help would be greatly appreciated  ,slam
6661,freeimu external magnetometer,i have been using the freeimu library successfully but now i want to add an external magnetometer that i can mount away from my motors  i ve figured out how to modify the freeimu library to use an external magnetometer and i am getting data  what i can t figure out is what i need to change now that my magnetometer orientation has changed  on the free imu it is mounted like this   the external compass is mounted like this   upside down   rotated      around x  i am changing the value inside the   function as all the other code calls this to get the magnetometer data  so far i have tried   changing the sign for the y and z values after i have got them from the magnetometer  changing the sign for the y value only changing the sign for the z value only added     to both the y and z values subtracting     from both the y and z values subtracting     from y and adding     to z adding     to y and subtracting     from z changing nothing  the calibration gui gives always gives me strange results  and doing the changes above just rotated mirrored the magnetometer red and green graphs  i am unable to get rid of the key hole shape   the red is xy  the green yz  the blue is zx  does the fact that zx works mean that my issue is with the y value  this is how it looks using the on board magnetometer   what should i try next  thanks joe edit i tried rotating the external magnetometer so it is in the same orientation as the freeimu magnetometer and i still get the same result so i don t think its the difference in orientation that is causing the problem  so then i thought maybe its because the freeimu is mounted central to the rotation axis and the external magnetometer is mounted about   cm above  i tested this by rotating only the external magnetometer around itself and i still got the same result   this is all seems strange  do you think its possible that the external magnetometer i have brought is faulty  any way to confirm it is working properly on its own  thanks edit managed to get circles plotting by changing the gain from   to    it seem my new magnetometer was being saturated  now i just need to work out how to change my values around so the orientation is correct  ,quadcopter imu calibration magnetometer
6662,how to track robot position,i m a software researcher  who in my spare time mentors a robotics team  helping on the software side of things   for years  i keep coming back to the same question   how to determine the robots position  and heading during our competitions   we have tried a number of things with varying degrees of success failure  encoders on the drive wheels  accelerometers  gyroscopes  etc   i recently bought an imu with a   axis accelerometer    axis gyro  and   axis magnetometer  all preprocessed by an arduino  and outputting the value to a serial port   i thought surely there must be a way to take all these measurements  and get a composite view of position and heading   we are using mechanum wheels on this particular robot  so wheel encoders are not particularly useful   i ve looked around and there s a lot of talk about orientation using quaternion with sensor fusion using similar boards  but it very unclear to me how to take the quaternion and the estimation and come up with x y distance from the starting position   now my time window for these measurements is small      seconds  but i need it to be pretty accurate within that window   i m about ready to abandon using the imu  and try something else   one idea is to use a usb ball mouse to try and track robot motion but i m certain that the mouse is going to get banged around way too much leading to noise and invalid results   as a side note  robot s about  ft x  ft base weighting in at     lbs   any thoughts or suggestions appreciated  ,imu sensor-fusion
6667,heavy omnidirectional platform suspension,i m planning to build an omnidirectional platform that will support about    kg robotic arm  the platform will be equipped in meccanum wheels  i would like to have some kind of suspension to avoid wheels loosing contact with the floor on small bumps  let s say  cm    the first suspension type i thought about was rocker bogie type  but i m afraid  that changes of arm center of mass during its movement will introduce too much stress on rocker bogie mechanism   what other choices would you recommend  or maybe rocker bogie will be fine after all  ,mobile-robot wheeled-robot design mechanism
6672,the uncertainty is big while the sensor is rather accurate at measuring a landmark in ekf slam,i ve a  d sensor which provides a range  and a bearing  to a landmark  in my  d ekf slam simulation  the sensor has the following specifications    sigma  r          text m        sigma   phi           text deg    the location of the landmark in x axis is     ekf imposes the gaussian noise  therefore the location of the landmark is represented via two quantities namely the mean  and the variance   in the following graph   the green is the mean  which is very close to the true location  i e       the black is the measurements and red is   i don t understand why the uncertainty is big while i m using rather accurate sensor  the process noise for the robot s pose is  which is small noise  i m using c      edit  for people who ask about the measurements  this is my code   r    sqrt   m  j y    y         m  j x    x          mathcal n      sigma  r           phi    text atan    left   frac m  j y    y  m  j x    x   right     mathcal n      sigma   phi         where normalized gaussain noise generator   is   i e   double robot  normalized gaussain noise generator         double noise      std  normal distribution double  distribution      noise   distribution generator        return noise     for the measurements  i e  the black color   i m using the inverse measurement function  given the estimate of the robot s pose and the true measurement in polar coordinates to get the location of a landmark  the actual approach is as follows    bar  mu   j x     bar  mu   x    r  cos  phi    bar  mu    theta       bar  mu   j y     bar  mu   y    r  sin  phi    bar  mu    theta    this is how it is stated in the probabilistic robotics book  this means that the measurements in the above graph are indeed the predicted measurements not the true ones   now under same conditions  the true measurements can be obtained as follows   text m   j x    x   r  cos  phi    theta      text m   j y    y   r  sin  phi    theta   the result is in the graph below  which means there is no correlations between the true measurements and the robot s estimate  this leads me to the same question   why the uncertainty behaves like that    ,mobile-robot slam ekf noise
6673,do you have to have a rate controller for a quadcopter ,most academic papers characterise the rate of rotation along the x axis as       jx     as far as i cant tell  this characterises the rate and not the actual angle   itself and yet the pid controllers academics use to control this takes  setpoint  measured as its error signal  should the error signal not be   setpoint   measured  using gyro values  instead  why are they using the euler angle instead of its second derivative to control the rate  is it possible to stabilise a quadcopter using euler angles only  ,control quadcopter pid
6674,drive motor voltage   other specifications of roomba    ,i salvaged some parts off my dead roomba      and i m trying to use the drive motor assembly   i got the pinout of the connector but i don t know what voltage   pwm   other specifications are there for this motor   i ve attached the picture of the drive motor assembly  any help would be appreciated  thank you  pratik  edit  the image is here  drive motor module ,motor pwm irobot-create h-bridge roomba
6680,i am doing a project on robotic surgeries  can anyone help me and give me some details related to this topic ,can anyone help me  because i am doing a project on robotical surgeries and i would like someone to help me and advise me  i wonder if anyone could give me some data on tests he or she has run in a surgical robot    thank you for your attention  anything else will be much appreciated  ,sensors robotic-arm automatic
6683,what is the difference between motion planning and trajectory generation ,what are the major differences between motion planning and trajectory generation in robotics  can the terms be used interchangeably  ,motion-planning
6686,irobot create   and open interface   spec not syncing up with incoming data,i have the create   and have it hooked up to an arduino  almost all the commands work fine except when retrieving sensor information  if i send a request for packet    i get back values that while consistent don t match up  unless i am missing something  so if i press the clean button i get     or          and if i then press spot i get something like           i might be messing up my endianness but regardless the data isnt formatted how i expected it to be according to the spec sheet  i have   create  s and they all do the same thing  any ideas  i am using a  n     along with the tutorial from the site but i dont think that has anything to do with the formatting of the byte  this is the library i am using   sorry to take so long to get back on this  anyways the data we get is always formatted this way  it is not a baud rate issue since it understands the commands properly    note that the schedule and clock buttons return nothing ,arduino irobot-create
6694,how to find the body jacobain  for each link in a robot manipulator ,the links twist could be obtained  and thus the spatial manipulator jacobian could be done  but when it comes to the body jacobian  it is becomes difficult  moreover  the adjoint transformation relates both jacobain  but however that is     while the jacobian is   n  how does it works  as in the picture  he is getting a body jacobian for each link  not one jacobian matrix for the whole robot  i don t know  any help is highly regarded  like this example or here for full details ,robotic-arm kinematics inverse-kinematics manipulator jacobian
6696,dc motor pid control with unstable velocity feedback,currently i am building a omnidirectional robot with   dc motors with embedded incremental encoder  however  with a constant pwm input  i am not able to control the motor to rotate in a  relatively stable  state  refer to the figure  it can be observed that the linear speed of the motors can varied in   cm s range  i believe one possible reason is the pwm signal generated from my arduino mega controller is not good enough  and my problem is how can i implement a stable pid controller in this case  as the speed of the motor varies even with the same input  i believe extra work like adding a filter is needed  any advice is appreciated     thank you  ,motor pid
6700,help me in quadcopter controlling,   ,pid
6701,drones and camera streaming,how do you stream video feed from a camera on a drone  i would think that at high altitudes wi fi won t work   so what would you usually do  and how  ,quadcopter cameras
6703,angles in a rocker bogie system,how do you select the following two angles in the design of a rocker bogie system   angle between two arms of the main rocker  and  angle between two arms in the bogie   ,mobile-robot wheeled-robot
6705,detect human in proximity ,i m looking for ways to detect human presense behind walls in close proximity  around    feet  in whatever way possible  problem is i can t code   i hope it s ok i m posting here    i know there are different sensors but they all seem to be for detecting by motion of target humans   how do you detect still persons  is there a sound amplification device that magnifies human breathing x     or detect body heat  or pick up radiation waves or something off humans  ,sensors sensor-fusion ultrasonic-sensors
6706,converting a linear acceleration command into a dc motor command ,i m constructing a   wheels balancing robot which uses a pid controller   i ve tuned my parameters on numerical simulations based on a continuous inverted pendulum system so that the simulated inverted pendulum balances by controlling the horizontal  linear  cart acceleration   now that i ve done this  i want to take the next step and turn my pid control commands into electrical commands onto a dc motor to give the desired linear acceleration   however i m not sure how exactly to do this for my specific robot s motors   are there experimental tests should i run to determine how to convert pid commands into dc motor acceleration commands  or is there a formula to do this based on the motor s specifications  update the non linear dynamic equation i m using is l ddot  theta  gsin  theta   ddot x  t cos  theta  ld t  where  is the linear acceleration   is the acceleration due to gravity  and  is the angular acceleration  and  is an external disturbance to the system  to simplify things  i ve linearized the equations around   yielding l ddot  theta  g theta  ddot x  t  ld t  i ve assumed that the only control input is the cart s linear acceleration   and chose this control command as   where  are the pid gains  ,motor control pid actuator dynamics
6708,i need help with choosing a computer on the board,i need a computer on the board like raspberry pi for vending machine  i want to replace the original controller   this is list of some requirements     it should have pins to connect to the mdb protocol   other stuff through gpio     good performance  there will be a display with browser showing rails application running  i ve tried a raspberry pi b   but it s too slow  it can t even run a browser with speed like a laptop pc   so  i want to choose a more powerful system like odroid  wandboard etc     custom video output  sometimes i need to display fullhd     x       sometimes i need to show at    x      yes  the computer should simply rotate video output     i don t want to connect microcomputer to display directly  not through hdmi  dvi or something like this   this is not required  but very desirable   please help me choose  nowadays i try to choose from odroid  wandboard or pandaboard  are there any other computers  what version of the computer is advisable  ,arduino raspberry-pi
6714,what is the cheapest way to make led sensitive to sound around ,there is always a way to do this using arduino  rasberry pi etc   however  in many cases in discussion in forums i ve come across things where whole  logic  can be uploaded to    dollar part  drastic change  this defines a line between a one time thing that you made as a hobby  and something you can sell around   so basically if i want led to get brightest at loud sound and almost off on silence  or with button that switch to      on all the time   ,design circuit
6715,is it possible for a robot to navigate through predefined coordinates ,i am a total newbie in robotics so please bare with me   i have a school project where my team has to design a robot that is capable of picking up   golf balls in different sizes at predefined locations  then it has to drop these balls into their respective holes   we are using an arduino chip in our robot   i thought i could perhaps define a path for the robot  an invisible virtual path you may call  so imagining the platform as cartesian plane  can i tell the robot go to where i want it to go  for example  go to        or do i need some sort of sensors so the robot figures it out by itself  thanks for your time    ,arduino sensors navigation
6720,raspberry pi quadcopter thrashes at high speeds,i am attempting to build a raspberry pi based quadcopter  so far i have succeeded in interfacing with all the hardware  and i have written a pid controller that is fairly stable at low throttle  the problem is that at higher throttle the quadcopter starts thrashing and jerking  i have not even been able to get it off the ground yet  all my testing has been done on a test bench  i have ruled out bad sensors by testing each sensor individually  and they seem to be giving correct values  is this a problem with my code  or perhaps a bad motor  any suggestions are greatly appreciated  here is my code so far  quadserver java   sensor java  package com zachary quadserver   import com pi j io gpio gpiocontroller  import com pi j io gpio gpiofactory  import com pi j io gpio gpiopindigitaloutput  import com pi j io gpio pinstate  import com pi j io gpio raspipin  import com pi j io i c    import com pi j io gpio gpiocontroller  import com pi j io gpio gpiofactory  import com pi j io gpio gpiopindigitaloutput  import com pi j io gpio pinstate  import com pi j io gpio raspipin  import com pi j io i c     import java net    import java io     public class sensor       static i cdevice sensor      static i cbus bus      static byte   acceldata  gyrodata      static long accelcalib     new long         static long gyrocalib     new long          static double gyrox          static double gyroy          static double gyroz           static double accelx      static double accely      static double accelz       static double anglex      static double angley      static double anglez       public sensor               system out println  hello  raspberry pi             try               bus   i cfactory getinstance i cbus bus                  sensor   bus getdevice  x                  sensor write  x b   byte   x                sensor write  x c   byte   x                system out println  calibrating                    calibrate                 thread sensors   new thread                        public void run                            try                               readsensors                              catch  ioexception e                            system out println e getmessage                                                                            sensors start              catch  ioexception e                system out println e getmessage                          private static void readsensors   throws ioexception           long time   system currenttimemillis            long sendtime   system currenttimemillis             while  true                acceldata   new byte                 gyrodata   new byte                 int r   sensor read  x b  acceldata                     accelx      acceldata          acceldata    accelcalib                               accely      acceldata          acceldata    accelcalib                               accelz       acceldata          acceldata    accelcalib                                    accelz       math abs accelz                    double hypotx   math sqrt math pow accelx     math pow accelz                   double hypoty   math sqrt math pow accely     math pow accelz                     double accelanglex   math todegrees math asin accely hypoty                double accelangley   math todegrees math asin accelx hypotx                   system out println  int gyrox       int gyroy                  system out println  accelx      accelx   accely      accely   accelz      accelz                r   sensor read  x    gyrodata                     if system currenttimemillis   time                                     gyrox      gyrodata          gyrodata    gyrocalib                             gyroy      gyrodata          gyrodata    gyrocalib                             gyroz      gyrodata          gyrodata    gyrocalib                              anglex    gyrox  system currenttimemillis   time                        angley    gyroy  system currenttimemillis   time                        anglez    gyroz                   anglex        anglex        accelanglex                  angley        angley        accelangley                   time   system currenttimemillis                                system out println  int anglex       int angley                 system out println  int accelanglex       int accelangley                        public static void calibrate   throws ioexception           int i          for i      i         i                          acceldata   new byte                 gyrodata   new byte                 int r   sensor read  x b  acceldata                     accelcalib        acceldata          acceldata                 accelcalib        acceldata          acceldata                 accelcalib        acceldata          acceldata                  r   sensor read  x    gyrodata                     gyrocalib        gyrodata          gyrodata                 gyrocalib        gyrodata          gyrodata                 gyrocalib        gyrodata          gyrodata                 try                   thread sleep                   catch  exception e                   e printstacktrace                                    gyrocalib       i          gyrocalib       i          gyrocalib       i           accelcalib       i          accelcalib       i          accelcalib       i          system out println gyrocalib         gyrocalib         gyrocalib                 public double readangle int axis                switch  axis                        case                    return anglex              case                    return angley              case                    return anglez                     return               public double readgyro int axis                switch  axis                        case                    return gyrox              case                    return gyroy              case                    return gyroz                     return               public double readaccel int axis                switch  axis                        case                    return accelx              case                    return accely              case                    return accelz                     return             edit  i have re written my code in c   to see if it will run faster but it s still running at about the same speed about    ms per cycle or about    hz   this is my new code in c     include  wiringpi h   include  wiringpii c h    include  sys socket h   include  netinet in h    include  string h   include  string   include  iostream   include  unistd h    include  boost thread hpp    include  time h    include  cmath    define axisx    define axisy    define axisz     define kp     define ki    define kd     define frequency       define mode   x    define mode   x    define subadr   x    define subadr   x    define subadr    x    define prescale  xfe  define led  on l  x    define led  on h  x    define led  off l  x    define led  off h  x    define all led on l  xfa  define all led on h  xfb  define all led off l  xfc  define all led off h  xfd     bits  define restart  x    define sleep  x    define allcall  x    define invrt  x    define outdrv  x     define billion           l  using namespace std   double accelcalx      double accelcaly      double accelcalz       double gyrocalx      double gyrocaly      double gyrocalz       double px  double py   double ix      double iy       double dx  double dy   double lasterrorx  double lasterrory   int throttle          int sensor   wiringpii csetup  x     int pwm   wiringpii csetup  x      array int    motorval   struct timespec now  then   int tosigned int unsignedval        int signedval   unsignedval      if unsignedval                        signedval            unsignedval                    return signedval     double getaccel int axis        double x    tosigned  wiringpii creadreg  sensor   x b        wiringpii creadreg  sensor   x c                double y    tosigned  wiringpii creadreg  sensor   x d        wiringpii creadreg  sensor   x e                double z    tosigned  wiringpii creadreg  sensor   x f        wiringpii creadreg  sensor   x                   x    accelcalx      y    accelcaly      z    accelcalz      z       abs z            switch axis                case axisx              return x          case axisy              return y          case axisz              return z           double getgyro int axis        double x    tosigned  wiringpii creadreg  sensor   x          wiringpii creadreg  sensor   x                  double y    tosigned  wiringpii creadreg  sensor   x          wiringpii creadreg  sensor   x                  double z    tosigned  wiringpii creadreg  sensor   x          wiringpii creadreg  sensor   x                   x    gyrocalx      y    gyrocaly      z    gyrocalz        switch axis                case axisx              return x          case axisy              return y          case axisz              return z           void calibrate         int i      for i      i         i                  accelcalx     tosigned  wiringpii creadreg  sensor   x b        wiringpii creadreg  sensor   x c                    accelcaly     tosigned  wiringpii creadreg  sensor   x d        wiringpii creadreg  sensor   x e                    accelcalz     tosigned  wiringpii creadreg  sensor   x f        wiringpii creadreg  sensor   x                       gyrocalx     tosigned  wiringpii creadreg  sensor   x          wiringpii creadreg  sensor   x                      gyrocalx     tosigned  wiringpii creadreg  sensor   x          wiringpii creadreg  sensor   x                      gyrocalx     tosigned  wiringpii creadreg  sensor   x          wiringpii creadreg  sensor   x                      usleep                   accelcalx    i      accelcaly    i      accelcalz    i      accelcalz              gyrocalx    i      gyrocaly    i      gyrocalz    i       cout    accelcalx           accelcaly           accelcalz      n      int calculatepulsewidth double millis  int frequency        return  int  floor        millis   frequency            void add double value  int i        value   calculatepulsewidth value       frequency       if motorval i  value           motorval i  value                       motorval i     value       else if motorval i  value                         system out println  low            motorval i               else if motorval i  value                         system out println  low            motorval i                   void getthrottle         int sockfd n      struct sockaddr in servaddr cliaddr      socklen t len      char mesg             sockfd socket af inet sock dgram          bzero  servaddr sizeof servaddr        servaddr sin family   af inet      servaddr sin addr s addr   htonl inaddr any       servaddr sin port   htons            bind sockfd  struct sockaddr    servaddr sizeof servaddr         while true                len   sizeof cliaddr           n   recvfrom sockfd mesg         struct sockaddr    cliaddr  len           mesg n               string message mesg           string values              int valindex              int lastindex              for int i      i   message length    i                          if message i                                        values valindex    message substr lastindex    i                   lastindex   i                  valindex                                    values valindex    message substr lastindex    message length              throttle   calculatepulsewidth   stoi values                       frequency            void setallpwm int on  int off        wiringpii cwritereg  pwm  all led on l   on    xff        wiringpii cwritereg  pwm  all led on h   on             wiringpii cwritereg  pwm  all led off l   off    xff        wiringpii cwritereg  pwm  all led off h   off            void setpwm int on  int off  int channel        wiringpii cwritereg  pwm  led  on l       channel   on    xff        wiringpii cwritereg  pwm  led  on h       channel   on             wiringpii cwritereg  pwm  led  off l       channel   off    xff        wiringpii cwritereg  pwm  led  off h       channel   off            void setpwmfrequency double frequency        double prescaleval                   prescaleval                prescaleval    frequency      prescaleval             double prescale   floor prescaleval             int oldmode   wiringpii creadreg  pwm  mode        int newmode    oldmode    x f     x        wiringpii cwritereg  pwm  mode   newmode       wiringpii cwritereg  pwm  prescale   floor prescale         wiringpii cwritereg  pwm  mode   oldmode       usleep             wiringpii cwritereg  pwm  mode    oldmode    x         void initsensor         wiringpii cwritereg  sensor   x b   x        wiringpii cwritereg  sensor   x c   x       void initpwm         setallpwm            wiringpii cwritereg  pwm  mode   outdrv       wiringpii cwritereg  pwm  mode   allcall       usleep             int mode    wiringpii creadreg  pwm  mode        mode    mode     sleep      wiringpii cwritereg  pwm  mode   mode        usleep             setpwmfrequency frequency      double millis timespec time        return  time tv sec        time tv nsec    e       double intpow  double base  int exponent         int i      double out   base      for  i     i   exponent   i                   out    base            return out     int main  void         initsensor        initpwm         cout     calibrating          n       calibrate         boost  thread server getthrottle        clock gettime clock monotonic   then        while true                motorval fill throttle            clock gettime clock monotonic   now            double dt    millis now  millis then                  then   now           double accelx   getaccel             double accely   getaccel             double accelz   getaccel              double hypotx   sqrt intpow accelx     intpow accelz               double hypoty   sqrt intpow accely     intpow accelz                double accelanglex               asin accely hypoty            double accelangley               asin accelx hypotx             double errorx    getgyro             double errory   getgyro              px   errorx          py   errory           ix    errorx dt          iy    errory dt           ix        ix      accelanglex          iy        iy      accelangley           dx    errorx lasterrorx  dt          dy    errory lasterrory  dt           lasterrorx   errorx          lasterrory   errory           double outputx   kp px ki ix kd dx          double outputy   kp py ki iy kd dy           add outputy        outputx          add outputy        outputx          add outputy       outputx          add outputy       outputx           setpwm    motorval                  setpwm    motorval                  setpwm    motorval                  setpwm    motorval                   in addition two of the motors seem like they are lagging when i turn the quadcopter fast in one direction  also for some strange reason the quadcopter seems less responsive to p gain  i have it at    in the c   version and it is working about the same as when i had it at     in the java version  edit  after doing some more testing i have determined that reading from the mpu     and writing to the pca     board that i am using to control the escs is the source of the delay  does anybody know how to speed this up  edit  i managed to speed up my code to about     hz by changing the i c baud rate  but the quadcopter is still thrashing  i have spent hours trying to tune the pid controller  but it doesn t seem to help at all  ,quadcopter pid raspberry-pi
6721,how feasible is the idea of operating a robotic arm in a non sophisticated way ,i and my team have to design a robot using an arduino chip  the objective of the robot is to grab golf balls at a set of golf pins at different heights and pre defined locations  we couldn t figure out a possible mechanism that could collect the balls and drop them into the trailer except for a robot arm  however  we don t have experience and time in designing a sophisticated system for the arm like recognizing where the ball is and then grabbing it accordingly  what would a feasible option be compared to a non sophisticated  robot arm  note the robot must be autonomous  ,arduino control robotic-arm
6733,minimising lateral drift in a pid  arduino  controlled quadcopter using a  dof imu,i m developing a stabilisation system for an  off the shelf  quadcopter by using an arduino mega and an imu  the imu is reading the angle of the quad  calculating motor commands by using a pid controller and applying them to the motors  it works well when constrained in a test bed  however in reality  although the quad is straight and level  it s drifting to one side because of its recent motor commands correcting the pitch yaw  is there any way i can  without using a vision system  keep the quad in one place without drifting  i ve looked into obtaining velocity by integrating the acceleration value  however it s extremely noisy and doesn t give a meaningful reading  ,arduino quadcopter pid imu rcservo
6739,turning an epilog laser into a  d printer ,we have an epilog laser cutter around here and i was wondering if it would possibly work as a base for a  d printer  here is a dropbox photo album of the laser cutter  i am thinking i will have to get a new control system but i am unsure if i will be able to use the motor controllers or if they are embedded in the current control s board  i am also unsure if it has fine enough control on the z axis but if not that can be modified  what would be a good head to look at  any other thoughts  ,laser 3d-printing
6740,in the pid equation k   s a     s  what values correspond to the pid coefficients kp  ki  kd ,i m trying to understand how to obtain the kp  ki  kd values after finding a combination of k and a that works for me  do i just expand the equation and take the coefficients   ,control pid tuning
6741,how many methods can i use to acquire depth data ,i am a newbie in robotics  as far as i know  there re generally two ways to acquire depth information of a scene  one is the stereo vision method which applies two cameras  the other is the rgbd sensors such as kinect and primesense  it seems that both methods are in use currently  however  i do not know what are their advantages against each other  i think the kinect is a perfect solution over stereo vision ignoring its expense  so i have two questions here   is there advantages of binocular methods over kinect besides expense  as i know  both the two methods are confined with a limited distance detection range  in real world applications  we sometimes also need depth data at distance  is there a method that we can acquire or estimate data information at far distance  not considering  laser based detectors     further more  my application may be a small flight vehicle  which method and equipment should i choose  will the traditional binocular camera be too slow for my application  ,computer-vision stereo-vision
6750,does an electronic compass work underwater,i m building a submersible rov  so i need a way to navigate  so using a compass would help but this brings up the question  does an electronic compass work underwater  my thoughts are the water might act as a faraday cage  and therefore interfere with the magnetic field  therefore it might not even work  maybe a gyroscope might be a better solution  ,sensors compass
6754,why i m getting very long terms in the inertia matrix  or dynamics model  of the robot using matlab script ,i m working on the dynamics model of a rrrr articulated robot  i m following euler lagrange approach and developing my code in m file in matlab  i m looking for dynamic model of this form   d q   ddot q    c q  dot q   dot q   g q     tau  where  and  are  matrices and  and   torque  are  vectors  by formulating the kinetic and potential energies   the problem is that  i m getting very long equations  and the term in  matrix are very huge and nonlinear  involving sin and cos  i m talking about a several pages per equation  after i published the code     pages   and the output i got around    pages in total  i searched around there was some guy he faced the same problem before  but there was no helpful proposal  any suggestions     ,robotic-arm kinematics dynamics matlab
6764,how do i get mpu      gyroscope data using  mpu      axis motionapps   h  library,i m currently calibrating the mpu     chip using an arduino mega       i am using the j rowberg   c dev libraries  i can get it to print raw accelerometer and gyroscpe values  very unstable  wildly changing values   in the digital motion processing chip library  i can get it to print euler angles  quaternions  real world acceleration and actual acceleration but there is no option to get gyroscope data   can i use the dmp library to get gyro data or is it only possible to get raw unprocessed gyro values  ,arduino imu accelerometer gyroscope
6765,open source software for quadcopters,my question is general so please bear with me  i m now interested in buying a quadcopter and develop some functions that it does for example an android app to control it  or objects detection   so my question is what are the available quadcopters which has a software that allows me to do such things not just a flying toy  p s  i m asked to buy a kit within      and not build it by myself ,quadcopter
6767,magnetometer to measure high angular velocity in small object,i have to measure the frequency of a little circle in rotation  you can image this circle flying in air  because this circle can t touch anything that is not in rotation  so i can t use some simple trick to count the number of complete rotation in an amount of time  so i supposed my only chance was to use an accelerometer  a gyroscope  or a magnetometer  the accelerometer can detect the centripetal acceleration  and the gyroscope and the magnetometer with some calculus directly the frequency  the problem is the high frequency of this circle  can reach up to    hz   doing some simple calculus we know we need a gyroscope that can measure big angular velocity          s           s  also the accelerometer need big range of values  the radius of the circle is only   cm   w  angular velocity                              rad sec acc centr   w     r                      m s        g now i have seen there are some accelerometer or gyroscope for industrial purposes with enough range  but my question is  how i can understand if a magnetometer can used is this kind of application  considering there is no magnetic field near the circle  can a magnetometer be used to measure quickly change in inclination  in the datasheet i can read how ofter the sensor can communicate with my arduino  but nothing about how quick the rotation can be  is the reason that a magnetometer don t have the limits of a gyroscope or an accelerometer  ,electronics
6772,is the crazyflie control board considered a microcontroller,i am currently doing a project for school and we are told that we must use a micro controller that ends up controlling some external hardware  now i know the crazyflie is controlling the motors which counts as external hardware but is it a micro controller  my second question is i want to purchase the kit so i can assembly it myself however i saw that you can use an expansion board so you need not solder and also i plan on not buying a remote its possible to control the crazyflie via my iphone correct  i would appreciate it if someone could answer my questions  thank you in advance ,quadcopter
6776,iron man jarvis like robot,i m very passionate about robots from my childhood i m a java developer  i love sci fi movies i have a little bit knowledge in embedded systems and electronics  my ambition is to build a robot like jarvis  in iron man movie  which is a voice controlled robot i would like to implement that in my house as a home automation system it would take voice as input and take appropriate action   please help me to do this   any kind of help is appreciated   ,mobile-robot quadcopter microcontroller mechanism embedded-systems
6782,sending commands to roomba from pc,i m trying to send some commands to the roomba  however is behaving strange  this is the manual that i m using    first of all  i have consulted several manuals  some of them say that the default baudrate is         however it works for me at         i m trying to get a response from the roomba sending the following comand  examples    to turn on irobot create s play led only                    however  the roomba goes crazy and start going around  any idea what s happening or what i m not doing  or what should i do first   thank you   ,irobot-create roomba
6783,what equipment has been used to design this robot,look at this robot here  i can see rods which have a lot of holes and planes which also have holes  this seems to be a way to create flexibility in how the things are connected together to create the final robot  is there a name for this type of equipment  metals with holes  where can i get it  i am aware of people using lego blocks to create robots  but am not sure about what these metal rods and plates with holes are  is there a free application in which i can design a mechanical structure like the one in the image and add gears and then simulate it to see how it will rotate and bend should a real robot like that be created  what would be the quickest way to create a robot like this  edit  thankyou  frank and lanyusea  if one wants to do a simulation of the mechanical model  in others words play with the robot on the computer before actually building it  with all those gears in action   which software is most suitable for that purpose  ,robotic-arm
6784,how to know what type of stepper motors to use when designing a robot,i am talking about robots like this one   how would a person know what type of motor to use in design of such a robot  what i want to understand is that stepper motors have different step sizes  different torques among other things  how do we determine what type of stepper motor is most suitable to be used in a given robot  ,robotic-arm stepper-motor
6787,is it tough to make a robotic workshop of your own,i want to make a robotic workshop   i recruited    members to work     please give some tips about robotic workshop ,irobot-create
6791,does anyone have any walking patterns for a biped scout   lynxmotion ,i recently got a lynx biped scout and found that it is really hard to actually come up with a working  gait  or walking pattern   making a servo move is easy  that s not the problem  i previously built a robotic arm from scratch  i have pictures if anyone is interested  and that one can be controlled via arduino and a few potentiometers as it only has   degrees of freedom so it s not too hard to keep track of the different limbs  however the scout is a different beast entirely  it s a purpose built kit with    servos and to control them i m using the lynx ssc    sequencer which is distributed freely on their website  the only problem is that making them all move in sequence to produce a convincing walking motion is actually really hard  has anyone got any patterns for this robot they would be happy to share   ,walk
6792,how can i know which system is easier to control using pid controller ,i have a inverted inertia wheel pendulum  i suppose that if i have a wheel with larger inertia at its top  the system would be more stable  how can i prove or disprove my conjecture  ,control pid stability
6801,unilateral torque constraint on the foot ground interface,i was studying the basics of legged locomotion and came across the unilateral force and torque constraints at the foot ground interface  i understood the implication of the unilateral constraint on the force   the ground can only push the foot but not pull it  but i am unable to understand what does the unilateral torque constraint translate into physically in this case  can anyone clarify it  ,mechanism motion force legged walk
6804,how can i filter gyroscopic data ,i am using an arduino mega with an mpu      i can get gyroscopic data as well as euler angles  the problem is my gyro data keeps going back and forth between   and    despite me not moving it at all  it stays on    the most   what can i do to filter what i assume is noise  i am going to use the gyro data for a quadcopter pid rate controller so i cant really have it telling me i am rotating at    deg sec  that would be catastrophic for the quadcopter ,arduino imu accelerometer gyroscope
6807,driver board to control    brushed dc motors,i am building a humanoid robot with dc motor actuated fingers  there are    brushed dc motors to be position controlled with help of hall effect sensors implanted at the joints of each fingers  i need a developed driver board to control these       watt     v dc motors  also each motor is equipped with an incremental encoder for speed control   thank you ,motor servomotor driver
6808,provides a    degree of freedom imu reduntant data ,basic question concerning sensor fusion  a standard    dof imu  i mean this cheap things for the tinkerer at home  provides    values    accelerometers   gyroscope   magnetic field measurements   pressure sensor      temperature   i know that the accel data provide long term stability  but are useless for short term and the gyroscope is more or less vice versa   so there are tons of strategies to  marry  this values  but how does the magnetic field measurement fit into this framework  basically the magnetic field measurement should provide an attitude  too  like the other two sensors combined  i guess this measurement alone is neither reliable  so how do all these sensors fit together  br  ,imu sensor-fusion
6810,particle filter sampling step,i emphasize that my question is about sampling  not resampling    i m reading the probabilistic robotics book by thrun et al  chapter   on non parametric filters   the section on particle filters has an algorithm which states that for each particle index   see line       sample  the text s explanation of this step is quoted as   line    generates a hypothetical state  for time t based on   the particle  and the control    the resulting sample is   index by   indicating that it is generated from the  th particle   in    this step involves sampling from the state   transition distribution    to implement this step    one needs to be able to sample from this distribution   the set of   particles obtained after  iterations is the filter s representation   of    if i understand correctly  this step says that the m th sampled particle  is obtained by advancing the previous m th particle with control command    i assume that the motion is not deterministic  so the result of this motion is a conditional probability  based on the particle s previous position     however  i m confused over how exactly to construct this conditional probability    is this information usually given   or is it constructed from the distribution of the other particles    ,particle-filter
6816,determine current roomba state   operating mode,using the sci messages  i would like to determine the current operating mode or state of a irobot roomba      finally  i would like to detect and separate four states    cleaning in docking station returning to docking station error  e g  trapped on obstacle   what is a fast and reliable way to detect those states using sci data  the roomba sci sensor packets  remote control command  and  buttons  seem to return the currently called commands and not the currently executed ones  ,roomba
6817,basic general question about controllers,suppose i have a mechanical system which is free to move on a given rail    m   m  like a motorized cart  the whole system can be mathematically expressed through a linear timeinvariant system equations  if i need to control only the position  for example saying the controller   move to        i can simply design a pid controller that  given a set point moves the cart to that position  now i need much more and i want to control the position and the velocity of the cart  so i need for example to say   move to      with a specific velocity s profile   of course the vel     at the end position  question  how should i design such a controller  do i need specifically a special type of controller  or i have a huge choice  any help  graph  link and example is really appreciated  regards ,control pid
6818,remote control relative to driver,is it possible to remote control a  robot  relative to the driver with an angle sensor  or any other sensor    for example  if the robot starts in this position  and the joystick is in this configuration                   forwards       joystick       backwards                   then if the robot turns around                      back                                         robot       front                     pushing the controller forwards will still make the robot go forward                                  joystick       backwards                                                                                    robot       front                     even though from the robot s pov  he s going backwards  any ideas solutions  ,control sensors
6821,is motor current proportional to thrust ,so i was making sure my circuit for an airboat i was working on was safe  and checking a motor  it has    amps max current running     v at        however my esc has a    current     burst amps    the recommended tested prop for this is a   x    blade and runs the motor at    amps  doing some quick calculations via on online calculator  it appears to give a value of    lbs of force  way off to the      lbs measured  but regardless      when i type in a prop i want    x   it gives a thrust value of        now  if the motor current is proportional to the thrust      lbs      amps          running amps  and therefore the amount of amps the prop would be  in theory a little less than    if this is indeed the case  thus safe for my application   this would also make sense in physics terms as power   current voltage which is proportional to thrust  but just need to make sure  so does this thought process work for choosing a prop  my device will  be doing very short runs  less than    seconds   so near boundaries should be safe    ,quadcopter brushless-motor
6822,what is the link between a quadcopter transmitter pulse and the roll pitch yaw angles ,i want to design a data logger for my quadcopter using the arduino mega board  i want to record the roll  pitch and yaw angles each second or   seconds  so they can be viewed later after a flight has ended  there s just one thing i don t understand  and that s how to translate the pitch roll yaw angles into a pulse of a specific length that the flight controller receives  for example  when i press the control for the pitch  the transmitter sends out a pulse to the receiver of the drone and the speed of the drones  motors change accordingly for it to pitch either forward or backward  i can tap into these commands between the flight controller and the transmitter  and be able to record the length of the pulse that was sent out  however  what is the link between the pitch angle and the size of the pulse  basically  how can i convert the pulse that was recorded by the arduino board and convert it into the pitch angle in degrees   generally  for the transmitter i use  a     us pulse means zero pitch  from           means pitch forward  and from           means pitch backwards  of course  the actual values vary slightly  but this is just a general reference for this question   so for instance  if i sent a pulse of     us  how would that translate into an angle in degrees  what s the formula to convert it  i hope i m clear  and if this question sounds stupid  please excuse me  but i haven t been able to find good information on it  thanks  ,arduino quadcopter
6824,how to tune a piv controller , how could i tune the above piv controller  i am trying to get the system to have a settling time of     second  p o       and zero steady state error    ,control
6826,difference between planetary and precision gear motors,i m working on a building a rover and would like some advice on selecting motors  in particular  i want to understand the difference between precision and planetary gear motors   my robot will way about      lbs i think and would like it to be responsive and quick  i have two sabertooth  x   motor controllers  which can supply up to   amps   i have been looking at these motors and i am not sure which is better choice for my application    these are the two sets of motors i am thinking about    googling does provide some info on planetary gears  but the application of these two is still is unclear to me  thanks ,mobile-robot motor gearing
6829,robotics slam datasets   scaling factor,there are several robotics datasets for slam  like this one  in this webpage you can see that the depth image is scaled by a factor of       so that float depth images can be stored in    bit png files   i do not understand why this value is chosen  why not simply       so that there is a conversion of meters to millimeters   ,slam
6831,where can i get openinterface py ,i am trying to program the create  irobot using python  there is a script called openinterface py  where can i download this script  ,software irobot-create python
6833,can t connect to beaglebone webserver ,i m following this getting started tutorial  connected the board to usb and it s detected as mass storage  got the driver installed  win      and at the third step i wasn t able to connect to beaglebone webserver at              anything i did wrong  please help  here is some troubleshooting info from getting started page  i ve followed them all  i m using chrome  tried the node webkit based application  not in a virtual machine  not using ssh just trying to access the webserver   troubleshooting do not use internet explorer  one option to browse your board is to use this node webkit based   application  currently limited to windows machines     beaglebone getting started zip  virtual machines are not recommended when using the direct usb   connection  it is recommended you use only network connections to your   board if you are using a virtual machine  when using  ssh  with the provided image  the username is  root  and   the password is blank  visit  for additional debugging tips   update    i tried to install ubuntu on my machine and connect the beaglebone  it need not any driver and i can immediately access the webserver after ejecting the mass storage  enabling the  usb to ethernet interface   however in windows ejecting the mass storage still does nothing  still trying to make it connect in windows  ,beagle-bone
6835,internal pullup sufficient for i c in beaglebone black ,i plan to use p     and p     of the beaglebone in a i c bitbang mode  do i need to use external pull up resistors in my circuit  or can i use the internal pull up which is available on the beaglebone black itself  ,beagle-bone circuit
6837,controlling an esc for brushless motors with an rpi,i m looking to build a new  first  quadcopter without the conventional flight controller and radio  with an onboard rpi and applying some newfound knowledge on autonomous control to improve my coding skills  although  since i ve never actually built a quadcopter  i don t actually have any experience in using brushless motors  i ll be using a rpi b   so controlling them over i c was something i looked into  the b  though only has two i c interfaces  it also only has two hardware pwm pins and i m unsure whether software pwm would be enough  i found the afro simonk based escs from hobbyking which have i c  intended for the mikrokopter   i ve looked around and people have used the adafruit    channel pwm servo drivers to control them  is this an option to look into  or is there perhaps a better way  also  would be it particularly safe if the rpi is run off the esc s bec  it s confusing because  when the esc is powered on  well  it ll be powered on before the rpi comes up  what do escs do when they have bad input  ,quadcopter raspberry-pi brushless-motor esc multi-rotor
6838,implementation of wall and obstacle avoidance,i have a task of developing a simulation of an adaptive robot control system but i don t seem too have anyone to discuss my uncertainties with  i want to keep the simulation as simple as possible as i have a very tight deadline and it s only a one off project that most probably will never be used in my life again   the minimal behaviour that the agent is supposed to exhibit is wall and obstacle avoidance  it can be extended to avoiding small objects and exploring large ones   i ve decided to go with a simple feedback control system   to begin with i m struggling to decide how to represent the map of agent s environment  what i mean is  what if i want a wall to be from coordinate       to        i could hard code it  e g  have a matrix with coordinates of all obstacles but how small units do i make    i e  what if i have two neighbouring coordinates          and          but the agents gets a  clear to go  to coordinate           in this case it doesn t know that it actually is about to walk into a wall  i ve heard of something called occupancy grid map but i don t exactly get how it works and how to implement it   another thing that i am struggling with is how do i distinct between a wall and an obstacle  and then  how do i let the agent know how big that obstacle is so that it can either avoid it or explore it   eh  i m really puzzled with this project  i would really appreciate any thoughts or directions  thank you      ,control localization simulation
6842,how to calculate the center of mass jacobian matrix of a robot arm,i have a   dof robot arm system with   revolute joints arranged in an open chain fashion like below    assume that each link s mass is a point mass located at p i and each link s center of mass is at p i  what i am trying to do is calculate the center of mass jacobian matrix of the arm  i found some related materials online center of mass jacobian but i am still not very sure about how to calculate it  could anybody give me some hint  thanks  ,robotic-arm jacobian
6843,sporadic sensing rates for hc sr   ultrasonic distance sensor,been working on a robot recently which uses ultrasonic sensors for an integral part of the navigation  while testing the sensors i noticed a strange behaviour  the sensors seem to frequently stop functioning and bring the entire arduino mega i m working with to a stop  the strange part is that these stops seem to be entirely random  on some occasions the sensor will read values consistently  at maybe    vals per second  for     seconds  then all of a sudden the sensor will slow to reading only     values per second with stalls between  i have tested several sensors and different codes for pinging distances yet the problem has persisted  this leads me to believe the issue is with the arduino mega itself  but i am unsure how to verify this  any advice  thanks in advance  ps  other pins on the mega seem to be working fine  i e  analog pins for ir reflectance sensors and pwm pins for driving   dc motors  ,arduino ultrasonic-sensors
6844,aerodynamics of quadcopter,i want to build a quad copter  i want to know how do we calculate thrust or lift generated by using a motor  i am not aware about the capacities of motor  so can you explain how to calculate thrust or lift generated by assuming a motor  and what is the maximum payload that a quad copter can lift for a given thrust   ,quadcopter
6845,recommendation for good source of robotic components,im looking for a good source for robotic components like sheel tracked robot chasis  motors  sensors  communication and mechanics  i thought about using raspberry and arduino as platforms for automation  is that an good idea  im asking as i dont know yet much about the motors drives uses for powering robots  thanks  uli ,mobile-robot motor
6846,datalogging from arduino mega to dropbox,i have an arduino mega board and the adafruit ultimate gps logger   gps module shield  i have these two connected together using headers and have the entire thing mounted on my drone  currently  i have a code that i found online and modified slightly to get gps coordinates in nmea format and parse them for the information i actually want  i can store these in an sd card  the thing is  i want to use the arduino gsm shield to somehow send this data  either from the sd card or directly  to a folder in dropbox  i have no idea how to do that  if it s possible at all  i just started working with arduino about a month ago  so i apologize if my question sounds particularly noob ish  could anyone on this forum at least guide me on how to approach this problem  thanks  ,arduino gps
6849,graph optimization with g o,i m trying to do graph optimization with g o  mainly in order to perform loop closure  however finding minimal working examples online is an issue  i ve found this project  as well as this one  the second one though has the form of a library  so one cannot really see how the author uses things   in contrast to online loop closure  where people update and optimize a graph every time they detect a loop  i m doing graph optimization only once  after pairwise incremental registration  so in my case  pairwise registration and global  graph based optimization are two separate stages  where the result of the first is the input for the second  i already have a working solution  but the way that works for me is quite different from the usual use of g o   as nodes i have identity matrices  i e  i consider that my pointclouds are already transformed with the poses of the pairwise reg  step  and  as edges  i use the relative transformation based on the keypoints of the pointclouds  also the keypoints are transformed   so in this case i penalize deviations of the relative pose from the identity matrix  as information matrix  inverse of covariance  i simply use a  x  identity matrix multiplied by the number of found correspondences  like this case    the result of the graph is an update matrix  i e  i have to multiply with this the camera poses    although this works in many most cases  it is a quite unusual approach  while one cannot draw the graph for debugging  all nodes are identities in the beginning  and the result after optimization is a  d path   which means that if something goes wrong getting an intuition about this is not always easy     so i m trying to follow the classic approach   the vertices nodes are the poses of the pairwise registration the edges are the relative transformations based on the keypoints features of the raw pointclouds  i e  in the camera frame  not transformed by the poses of the pairwise registration  the output are the new poses  i e  one simply replaces the old poses with the new ones drawing the graph in this case makes sense  for example in case of scanning an object with a turntable  the camera poses form a circle in  d space  i m trying to form all the edges and then optimize only at one stage  this doesn t mean only   lm iteration though    however i cannot make things running nicely with the  nd approach  i ve experimented a lot with the direction of the edges and the relative transformation that is used as measurement in the edges  everything looks as expected  but still no luck  for simplicity i still use the information matrix as mentioned above  it is a  x  identity matrix multiplied with the number of correspondences  in theory the information matrix is the inverse of covariance  but i don t really do this for simplicity  plus  following this way to compute the covariance is not very easy      are there any minimal working examples that i m not aware of  is there something fundamentally wrong in what i describe above  are any rules of thumb  e g  the first node in both approaches above is fixed  that i should follow and i might not be aware of them  update  more specific questions  the nodes hold the poses of the robot camera  it is unclear though at which reference frame they are defined  if it is the world coordinate frame  is it defined according to the camera or according to the object  i e  first acquired pointcloud  this would affect the accumulation of the pose matrices during incremental registration  before the g o stage   i try to form and optimize the graph only once at the end  for all the frames pointclouds   the edge  src  tgt  constraints hold the relative transformation from pointcloudsrc to pointcloudtgt  is it just the transformation based on the features of the two in the local coordinate frame of pointcloudsrc  is there and tricky point regarding the direction  or just consistency with the relative transformation is enough  the first node is always fixed  does the fixed node affect the direction of the edge that departs ends up from at the fixed node  is there any other tricky point that could hinter implementation  i m working in millimeter instead of meter units  i m not sure if this will affect the solvers of g o in any way   i wouldn t expect so  but a naive use of g o that was giving some usable results was influenced   ,slam
6852,i need the specifications for irobot create  ,i need the specifications for the create    i need it for research purposes  so i think i m going to need a high computational computer on board  please suggest some nice configuration   ,irobot-create
6853,dock command does not seem to work,we bought a new create  robot and started using it  but when we issue the dock command the robot moves for a bit and does not go back to the base  the base is not hidden or obstructed and the create  is just a couple of feet away  we need help to figure out why it does not see the base  just to clarify that even using the dock button on the create  does not make the create  go back to the base ,irobot-create
6854,the specifications graph showing the battery discharges in volt per time,my name is dylan we are doing a project on irobot create and we would like to know the specifications graph showing the battery discharges in volt per time and my robot is the irobot ceate    the battery is the roomba advanced power   it s a     v nickel metal hybride battery pack and she deliver     mah  ,irobot-create
6859,how to implement tracking problem with pid controller,i m trying to implement the tracking problem for this example using pid controller  the dynamic equation is   i   ddot  theta    d  dot  theta    mgl  sin  theta    u  where     joint variable      joint torque    mass      distance between centre mass and joint      viscous friction coefficient    inertia seen at the rotation axis   in this problem  the desired angle  is constant and   and   as    for pid controller  the input  is determined as follows  u   k  p    theta  d     theta t     k  d    underbrace      dot  theta   d       dot  theta  t       int  t        theta  d     theta  tau   d tau  the result is   and this is my code   clear all clc  global error  error       t             x              t  x    ode    odesolver   t  x     e   x         pi       error theta  plot t  e   r    linewidth       title  regulation problem   interpreter   latex    xlabel  time  sec     ylabel      interpreter   latex    grid on  and odesolver m is  function dx   odesolver t  x   global error    for pid controller  dx   zeros         parameters  m                mass  kg  d         e      viscous friction coefficient l                arm length  m  i       m l      inertia seen at the rotation axis   kg m    g                acceleration due to gravity m s       pid tuning kp      kd        ki            u  joint torque u   kp  pi     x       kd   x       ki error  error   error    pi     x       dx      x     dx        i  u   d x      m g l sin x        end   now i would like to implement the tracking problem in which the desired angle  is not constant  i e     therefore    and   as    the input is   u   k  p    theta  d     theta t     k  d    dot  theta   d  t      dot  theta  t       int  t        theta  d  t     theta  tau   d tau  now i have two problems namely to compute  sufficiently and how to read from txt file since the step size of ode   is not fixed  for the first problem  if i use the naive approach which is    dot f  x     frac f x h  f x   h   the error is getting bigger if the step size is not small enough  the second problem is that the desired trajectory is stored in txt file which means i have to read the data with fixed step size but i v read about ode   which its step size is not fixed  any suggestions   edit  for tracking problem  this is my code  main m clear all clc  global error theta d dt  error        theta d   load  trajectory txt     i         t i       dt          numel theta d  while   i   numel theta d       i   i         t i    t i      dt  end  x            options  odeset  reltol  dt  stats   on     t  x    ode    odesolver  t  x   options     e   x        theta d    error theta   plot t  x        r    linewidth       title  tracking problem   interpreter   latex    xlabel  time  sec     ylabel      interpreter   latex    grid on  odesolver m function dx   odesolver t  x   persistent i theta dprev  if isempty i      i          theta dprev      end  global error theta d dt     dx   zeros         parameters  m                mass  kg  d         e      viscous friction coefficient l                arm length  m  i       m l      inertia seen at the rotation axis   kg m    g                acceleration due to gravity m s       pid tuning kp         kd         ki         if   i             i       end   theta d first derivative theta ddot      theta d i    theta dprev     dt  theta dprev   theta d i       u  joint torque u   kp  theta d i    x       kd   theta ddot   x       ki error  error   error    theta ddot   x       dx      x     dx        i  u   d x      m g l sin x        i   i      end  trajectory s code is  clear all  clc  a            pi      file   fopen  trajectory txt   w      for i     length a      fprintf file    f  n  a i    end  fclose file    the result of the velocity is   is this correct approach to solve the tracking problem  ,control pid dynamics
6860,dynamixel mx     r burnt,i am using a mx     r dynamixel servo for a project that i am making   i am making a robotic arm controlled by this servo   i accidentally moved the horn of the servo while it was on and hence due to excess current input  it wont work anymore   i suspect that the h bridge inside the motor got burnt   can somebody tell me what exactly went wrong   how can i test the motor   how can i repair it  if possible  or else where can i find a service centre  i live in india   i am in deep trouble right now  please help   ,robotic-arm servos h-bridge
6862,how to calculate the real time rpm of motor with rotary encoder ,i want to measure the real time rpm of the wheels  i think incremental rotary encoder would be good  but i am confused on how to interface it with dc brushless geared motors  from the images i am not quite sure if only one rotary encoder would suffice or do i need any other sensor also with it  i am doing my project on arduino uno    ,motion forward-kinematics quadrature-encoder
6863,what wireless technology to use to control robots in classroom ,i want to build a cheap robot programmable in scratch graphical language  that could be employed during lessons in school  scratch code is interpreted on a pc  so on the robot there should be only the code that receives specific commands  i e  drive forward  and transmits sensors  measurements   i m looking for a wireless technology that will allow me to exchange information between robot and pc with at least   hz rate  it should also allow to work at least    robots simultaneously in the same room and have a range of at least   m   i did tests with bluetooth  but sometimes there are connectivity issues  and pairing devices can be a hassle in a classroom  i have also tried wifi modules  but pinging it showed average time of   ms  but maximum of more than    ms  so i m afraid that it won t be able to control linefollower robot for example   can you point me to some other  preferably cheap  under     per module  wireless technologies  or maybe my worries about wifi are exaggerated  ,mobile-robot radio-control wireless wifi
6869,roomba create   problem reading distance traveled,i am trying to work with the create   in using the  get distance traveled  command  id      i am getting back incorrect data  my simple test case logic is i am working with the create  tethereddrive py example and adding this  i consistently numbers near     for moving forward  and     for moving backward  if i wait for   seconds  i get     for moving forward  and     for moving backward  the documentation says it should return the distance traveled in mm  so these numbers seem to be off by a factor of     anyone have any suggestions  thanks  p s  i had to add this function to the example as well def recv basic the socket       the socket settimeout          total data        while true          try              data   the socket recv                   total data append data          except              break     return    join total data   ,irobot-create
6870,controlling the irobot create   with matlab,i teach a university sophomore level matlab programming class for engineers  and i am planning on using the create  for their final project  there is a nice simulator and matlab toolbox for the create  but the toolbox utilizes some of the commands that no longer exist on the create    thus it doesn t work correctly  and of course is doesn t support any of the newer commands  in addition  i want to be able to  cut the cord  so i am using a raspberry pi on the create to pipe data to the serial port  and tcpip sockets to send the data from a remote computer running matlab to the pi create  if anyone is working on a similar configuration  i d love to trade notes and share the pain  ,irobot-create
6880,monocular vs  stereo computer vision robustness for object detection,are there some genaral rules for the robustness between monocular and stereo vision when considering object detection  i am especially interested in the automotive field   considering distance obstacle car detection  see video links below   someone told me monocular vision is more robust than stereo  i guess this may be true if the monocular algorithm is well written  and especially verified over lots of input data     but once you input  image  data that has not been verified it may probably provide unexpected results  right  with stereo vision one does not really care about the contents of the image as long as texture lighting conditions allow stereo matching and the object detection is then done within the point cloud  i consider following usage   monocular stereo  the monocular sample video seems to have sometimes problems detecting the cars in front  the bounding boxes disappear once in a while   the stereo sample seems to be more robust   the car in front clearly is detected in all of sequnce image frames  ,computer-vision stereo-vision
6882,calculating acceleration and velocity,i m writing some quad copter software and beginning to implement an altitude hold mode   to enable me to do this i need to get an accurate reading for vertical velocity  i plan to use a kalman filter for this but first i need to ensure that i m getting the correct velocity from each individual sensor  i have done this but i m not      sure its correct so i was hoping to get some confirmation on here  my first sensor is a lidar distance sensor  i calculated acceleration and velocity using the following code   the second sensor is an accelerometer  i calculated acceleration and velocity using the following code  imu  acceleration imu  getacceleration           get quaternion     float q          freeimu getq q          get raw data     float values          freeimu getvalues values          extract accelerometer data     float acc         acc     values       x     acc     values       y     acc     values       z        gravity compensate      freeimu gravitycompensateacc acc  q          convert acceleration from g to cm s s      acceleration x   acc                      acceleration y   acc                      acceleration z   acc                      return  acceleration    cm s s      time since last update float time            float flight controller frequency                 hz      s    get accel imu  acceleration imuacceleration    imu  getacceleration       get velocity currentzvelocity    imuacceleration z   time    cm s  it would be great if someone could confirm if this is correct  or not  thanks joe ,sensors accelerometer lidar
6890,verifying motor selection calculations,i m trying to select a brushed dc motor for a project  i tried following the advice on sizing electric motors  mentioned in this question  but a few details were missing  and i m unsure if i properly followed the procedure  for my application  i need   nm   number of motors     wd   wheel diameter      cm wp   estimated weight of platform     kg minc   maximum incline under load     degrees vmax   maximum velocity under load     km hr fpush   maximum pushing force        kg ur   coefficient of rolling friction          these are my calculations  step    determine total applied force at worst case   step    calculate power requirement  vradps   maximum velocity under load in radians second                 radian   second  pmotor   required power per motor    ftotal   vradps   wd    nm                 kilogram   meter   radian   second  step    calculate torque and speed requirement  tmotor   required torque per motor   pmotor vradps                 centimeter   gram                inch   ounce rpmmin   required revolutions per minute per motor   vradps                               rev   minute  are my calculations correct  intuitively  the final tmotor and rpmmin values seem right  but my calculation for pmotor doesn t exactly match the one used in the link  which doesn t explicitly do the conversion to radians   second and therefore doesn t result in the proper units  here s my python script for reproducing the above calculations  from math import     from pint import unitregistry  ureg   unitregistry    def velocity to rpm v  r       kph   v to kilometer hour      r   r to kilometer      d   r       rpm    kph      pi r         hour       minute     rev     return rpm  def velocity to radps v  r       return velocity to rpm v  r  to radian second     units km   kilometer   ureg kilometer meter   ureg meter newton   ureg newton cm   centimeter   ureg centimeter hr   hour   ureg hour mm   millimeter   ureg millimeter rev   revolution   ureg revolution minute   ureg minute sec   second   ureg second kg   kilogram   ureg kilogram gm   gram   ureg gram deg   degree   ureg degree rad   radian   ureg radian oz   ureg oz inch   ureg inch    conversions  km per mm      km            mm  hour per minute      hour       minute  minute per second      minute      sec  minute per hour     hour per minute gm per kg         gm     kg  cm per km           cm     km     constraints target km per hour      km     hour    average walking speed estimated platform weight     kg maximum incline degrees     deg maximum incline radians   maximum incline degrees     pi rad       deg   maximum pushing force   estimated platform weight    maximum velocity at worst case      km     hour  rolling friction           rubber on pavement velocity under max load   target km per hour number of powered motors        variables wheel diameter mm       mm wheel radius mm   wheel diameter mm   wheel radius km   wheel radius mm   km per mm rev per minute at  v unloaded      rev    minute  rev per minute at  v loaded   rev per minute at  v unloaded    mm per rev    wheel diameter mm   pi     rev  target rpm   velocity to rpm target km per hour  wheel radius mm  target radps   velocity to radps target km per hour  wheel radius mm     calculate total applied force at worst case  total applied force worst case   estimated platform weight    rolling friction cos maximum incline radians    sin maximum incline radians     maximum pushing force print  ftotal   total applied force worst case    calculate power requirement  vel in radps   velocity to radps velocity under max load  wheel radius mm  print  vradps   vel in radps required power   total applied force worst case   velocity to radps velocity under max load  wheel radius mm    wheel radius mm to meter  required power per motor   required power number of powered motors print  pmotor   required power per motor    calculate torque and speed requirement  required angular velocity   velocity under max load wheel radius km   hour per minute   minute per second   rad  rad sec required rpm   required angular velocity                  rev rad     sec minute  required torque per motor    required power per motor required angular velocity  to gm cm  print  tmotor   s   s     required torque per motor  required torque per motor to oz inch   print  prmmin   required rpm  ,mobile-robot motor design torque force
6895,rgb d slam   compute information matrix,currently im working on a rgb d slam with a kinect v  camera  in the front end the slam estimates the pose with ransac as an initial guess for the icp  with the pose estimation i transform the pointcloud to a pointcloud scene which represents my map  to smooth the map im trying to implement a graph optimizing algorithm  g o    until now  there is no graph representation in my frontend  so i started to integrate that  im trying to build a  g o file with the following fromat  vertex se  i x y z qx qy qz qw where x  y  z is the translation and qx  qy  qz  qw ist the rotation in respect to the initial coordinate system  and  edge se  observed vertex id observing vertex id x y z qx  qy  qz  qw inf    inf       inf    inf       inf    translation and rotation for the edge is the pose estimate that i compute with ransac and icp  visual odometry    now im getting stuck with the information matrix  i read the chapter     the information filter in thrun s probabolistic robotics and several threads in this forum  such as  the relationship between point cloud maps and graph maps and information filter instead of kalman filter approach from the second link  i got this here    the covariance update   p        i kh p   can be expanded by the definition of k to be  p       p   khp    p       p   ph t  hph t r       hp now apply the matrix inversion lemma  and we have  p       p   ph t  hph t r       hp    p        p        h tr     h       which implies     p            p        h tr     h the term  is called the prior information h tr     h    is the sensor information  inverse of sensor variance   and this gives us    which is the posterior information    could you please point this out for me   what data do i need to compute the information matrix   ,slam kinect matlab
6896,jacobian transpose  how to calculate orientation error,i m confused about how to compute the error in orientation  all the documents i ve read don t explain how to do it  the error in position is simply the difference between the points   let s assume we have the orientation along the effector axis  and we represent the rotation with quaternions  i have two questions   is describing the orientation with quaternions a good approach  how can we compute the error in orientation with the quaternions to use this in jacobian transpose   ,inverse-kinematics jacobian
6900,low power to motors    motor power jumper issue,i m currently working on my first robotics project using the initio kit from  tronix powered by raspberry pi  the setup was fairly simple  and i ve been testing it out over the last couple of days  all of the sensors work as expected  however  my motor tests are failing  when i input commands to actually move the robot  i can hear the dc motors running but they re not getting enough power to do anything  in the instructions  it says if this issue is encountered  that the power selection jumper might not be set correctly and provides this diagram   for comparison  here s how i have the wiring for the motors setup   i m not entirely sure what it means to have the power selection jumper being set incorrectly and would greatly appreciate it if someone could explain this to me or point out if they see anything wrong with my setup  ,mobile-robot motor raspberry-pi first-robotics
6905,slam noob here  a few questions regarding ekf slam,i ve recently been learning about slam and have been attempting to implement ekf slam in python  i ve been using this great article as a guide  some progress has been made  but i m still confused by certain stages  firstly  does the inverse sensor model have to compute range and bearing  as opposed to cartesian coordinates  why is this approach used  secondly  what format should my robot provide its heading in  currently i just use a running offset from the origin angle      without wrapping it between   and      turning right yields positive degrees  and left negative  i ask this as i assume the sensor model expects a certain format  thirdly  when computing the jacobians for adding new landmarks   page     is jz simply the absolute rotation of the robot       degrees for example  plus the bearing the landmark was detected at  and finally  what s the best approach for managing the huge covariance matrix  i m currently thinking of a good way to  expand  p when adding new landmarks  here s my current implementation   any help would be much appreciated  thanks  ,slam ekf python
6906,quadcopter propeller size   motor,i would like to build quad that uses bigger propellers like       my question is what kind of motor shall i use   low or high kv  do all motors support this kind of propellers   will they burn because of it  i found they say cw and ccw motors does that mean you can t set way they spin   i m totally new in this so thank you for answer   okey so given this one it should be able to hold     prob since it s in description shall i get   a esc since on    size prob they used max     or shall i get   a esc cause max continous is      ,quadcopter brushless-motor
6908,ekf slam  how best to manage the  p  covariance matrix  programatically,i ve recently been learning about slam and ekf slam   i ve began my implementation in python  but have had trouble managing the updating of p  especially when it comes to adding new landmarks  currently there is no  p  but just a few separate matrices that i have to stitch together when needed  my implementation can be seen here    how best should i manage the large covariance matrix  should i be using one matrix  like the algorithm suggests  thanks in advance  ,slam ekf python
6909,ekf slam computing the jacobians for landmark updates,i ve been working through this informative guide on ekf slam but i m having difficulty understanding the jacobians required for the  landmark update   on page     what exactly is jxr and jz taking as input  is it taking the the current rotation of the robot  plus the addition of the odometry update  ie  the rotation that is now stored in the  x  state vector  or are they taking the angle from the inverse sensor model  and if so  what s the  delta  angle from  thanks  ,slam ekf python
6910,how to find theta  to theta  after d h parameter, i am confused about the right way to look for my theta  theta   probably from the offset limit of the angles or calculation from x  to x  angle rotation or from atan  x y   ,robotic-arm dh-parameters
6913,what is the reduced form of this block diagram ,what is the reduced form of this block diagram  i can t see any solution way     ,control
6918,how do i work out the kinematic solution of a robot arm ,i draw a robotic arm in solidworks  but i m not so sure about how to find out the dof  forward and backward kinematic   could anyone help me understand how to work out the kinematic solution of this robot arm  ,robotic-arm kinematics automatic matlab
6922,how is it possible to maintain the total thrust when controlling yaw of a quadcopter ,i m working on the control of a quadcopter and i d like to understand how come controlling the yaw does not increase the overall thrust  my understanding is that the control is carried out through   pids per axis  roll  pitch and yaw   the output of the last pid is sent as a pwm signal to correct the rotor speeds of the propellers  the mixing looks something like that      all the quadcopter controls seem to work that way from what i could gather  so the basic idea to control yaw is to add  to the clockwise motors and substract the same amount  to the counterclockwise motors to make the quadcopter turns clockwise  which translates into a increase of speed of clockwise motors and a decrease of speed for counterclockwise motors from the same amount  but we know that each motor produces thrust and torque according to those equations    where  is thrust   is torque   and  are system dependent constants   is the air density   is rotor speed  and  is rotor diameter  which means that the thrust produced by each motor is proportional to the propeller speed squared   so if  is the speed of all propellers before correction  the thrust of the clockwise propellers after correction will be proportional to  and the thrust produced by the counterclockwise propellers to   the total thrust for these   propellers will be proportional to   as you can see  there is an increase of  in the overall thrust produced by those   propellers  and  when we take the   propellers into account   of course  in real life  when we control the yaw the quadcopter does not go up  so what am i missing    the same stands for roll and pitch control but since the quadcopter turns around the roll or pitch axis  the total thrust is no longer entirely on the vertical axis and i could imagine that the projection on the vertical axis is not increasing  but that does not work with yaw  ,control quadcopter torque
6927,how important are events like  robocup  to the advancement of robotics in general ,are events like robocup advantageous to the development of robotic  advancement   or is it merely entertainment which advances robotics by allowing entry level participation which helps maintain interest   do the darpa grand s provide a better vehicle for advancement   pun intended     ,design
6929,how to send commands to create   over bluetooth,i m very new to create    i want to send commands using bluetooth  i have already bought the bluetooth usb radio  what other devices do i need to get or how can i set up sending commands over bluetooth  any help is appreciated   thanks  ,irobot-create
6931,simulate imu   d gyro and accelerometer  data,if i have a robot path in  d space   i e  a vector of  x y  locations  and i need to generate artificial imu data  simulate them   how would i go about it   how do i model equations to generate the values given a time frame and positions  i ve come across imusim i d like to know how to model them and generate using matlab or something similar  ,imu accelerometer gyroscope simulation
6934,glasses with eye sensors,someone could tell me if there are wearable devices such as glasses  with sensors that can detect eye movement  in particular  i would need a device like google glass  having a sensor or a camera that is facing the eye  and it can capture the movement  possibly interfaced with a mobile device  alternatively  are there micro cameras on the market  which can be connected via bluetooth or usb to a mobile device  ,sensors motion
6936,joint positions of a robot,i would likte to find the joints positions using joint angles  link lengths etc  how can i define the position of the each joint using dh parameters  ,robotic-arm joint dh-parameters
6942,how to set up binocular cameras on a car ,i am trying to set up my stereo vision system on a car  however  i meet several problems and do not know how to solve them   how to select the baseline  i want the distance measurement to be far at    or    meters and near at around     m  is it possible to choose a baseline that meets my requirement  i have tried stereo calibration of two cameras and also learned how to compute depth value from disparity map  however i don t know how to compute depth value if the focal lengths of the two cameras are different  it seems all the theorems i can find on the web only concern cameras of the same focal length    ,stereo-vision
6944,dynamically detect changing obstacles,so the idea is that there would be one robot acting as overwatch  which would detect all of the obstacles in an area  which are not necessarily static   and then send the data about the obstacles  positions to another robot that would navigate around the obstacles to a goal  my initial thought was to have the overwatch robot be in an elevated position in the centre of the area  then sweep around using an ultrasonic sensor  this way  it could keep track of the obstacles in a set of polar coordinates  distance  angle   but then i realised that this method doesn t account for collinear obstacles  so the question is  what is the best way to detect a bunch of non static obstacles within an area  as a side note  i have seen a system similar to this  where there was a robot detecting obstacles  in that case  a crowd of people  and another robot pathfinding around the obstacles  the people   but i m unsure exactly how that system was detecting the obstacles  ,sensors computer-vision sonar ultrasonic-sensors
6945,help to dimension the right controller for the following tranfer function,i have a generic problem to create a controller for the following system   ddot x  t    a y t   where  is a constant real value  the system could be seen as an equivalent of a mass spring damper system  where damper and spring are removed  also  is the  dimension and  is simply the force moving the mass  but in this case i need to drive the force using  and not the contrary  transforming according laplace i get   y t     frac    a  ddot x  t   y s     frac    a s    x s   g s     frac y s   x s      frac s      a  considering that  i implemented a possible example in simulink    please not that i put the output given by the scope for showing up the resulting answer of the system  so i have   questions   is it possible to develop such a system  as far as i know the degree of the numerator should be  the degree of the denominator  so is the above system possible  is it possible to create a pid or pd controller to stabilize the output of the system   regards ,control pid matlab
6946,square with hinge on all four sides,i want to make a component that will be a square plate that will behave like it has a motorized hinge on all four sides  that is  it can  open  by pivoting around any one of its four sides  i want it to pivot by up to    degrees   i thought about designing it so that   hinges could be detached while one pivots  but i wonder if there s a simpler way to do this   ,design motion
6952,using a bitmap maze image to navigate the maze,i m working on an robot that would be able to navigate through a maze  avoid obstacles and  identify some of the objects in it  i have a monochromatic bitmap of the maze  that is supposed to be used in the robot navigation  i am just a first year electrical engineering student  and so need help on how i can use the bmp image  i will be making my robot using the arduino mega microcontroller  so how should i get started on it  if you need me to elaborate on anything kindly say so   link   ,arduino control localization
6953,how to calculate euler angles from gyroscope output ,i am using a tri axis accelerometer and tri axis gyroscope to measure the linear acceleration of a body  i need to get the orientation of the body in euler form in order to rotate the accelerometer readings from the body frame into the earth frame  please help i m so stuck ,accelerometer gyroscope frame
6955,how to make a robot move using arduino other than timing to predefined locations ,how to make a robot move using arduino other than timing to predefined locations  and without the use of sensors   i want to make my car move to different loactions on a board  want to know the possible options without using sensors and encoders    and how does cartesian robot work for predefined locations  does it require sensor too  ,arduino navigation
6956,using range only sensors for mapping in slam,slam noob here but trying to implement an algorithm that fuses odometry data and mapping based on wifi signal strengths for a  d robot     after various readings of different resources  i came across this    that explained what sensors are used in mapping and how they are categorized  there are range bearing sensors  stereo cameras rgb d cameras  that provide both distance and angle  range and bearing   from which is easy to locate  x y  coordinates of landmarks      i can develop a map  but in case i m using wifi signal strengths  received signal strengths  etc  in which case it is range only  meaning  i can only establish from a robot pose x y theta  as to how far this signal is coming from   how am i developing a map at all  my question is similar to this   what algorithm can i use for constructing a map of an explored area using a number of ultrasound sensors  but not quite same  even if i were using imu gps  how am i using gps to develop a map  what is my state space there  if i am getting gps signals   wifi signals  radio signals  am i estimating the transmitter ap s location as the map  or the walls of a room i m navigating in  as a map  a lot of slam literature talks about motion model and measurement model  the former gives me the pose of the robot quite easily because of the odometry and imu   the latter though is more for development of a map  am i right in understanding this  if yes  say  a  i have walls in a room and i m using lidar scanner    this still gives me the location of the wall using the number of beams that give me bearing  and the average distance from all the beams  b  or if i have just a single laser scanner  i can still use a camera  distance  and the heading of the robot to calculate the location of wall  the map    but if i have wireless signal strengths  i have a distance  distance of the transmitter from which i m getting the rss  not the distance of the wall  as to where they are coming from  but how am i estimating the location of walls here     what does the term  correspondences  mean in slam literature   ,localization slam artificial-intelligence mapping wireless
6957,micro quadcopter pid problem,i designed a mini quadcopter which is about    x   cm main body   the main body is the pcb     enter image description here     it weighs about     grams with the battery  i m using the mpu     with the dmp using the i cdevlib  i am using raw radians for pitch  roll  and yaw these measures are read from the mpu     s dmp  the motors are attached to the body using electrical tape black thing  around motors   the motors are    mm in diameter and are driven by a n channel mosfet  the mode of control right now is bluetooth hc    module   the code being used is my own  i have a control loop on all axes  the pitch and roll have the same values since the quadcopter is symmetrical  the problem i have is that pid tuning is next to impossible  the best i got was a    second flight   video in slow motion       at first i was using my own code for the control loop  but it wasn t as effective as the arduino pid library   the output of the pid loops are mapped to     to    on all axes  this can be seen in the code  my full code is below  but what do you think the problem is  code  ,arduino quadcopter pid
6969,shallow underwater wireless sensor network,i need to make shallow  max  m  underwater wireless sensor network  data payload is about   kb s  i know that vlf band       khz could be the best solutions for that  but cause of time to market i cannot make hardware and software from the ground  maybe someone could share own self experience in this filed  if band        mhz could be enough to send   kb s from one device to another   from  m underwater to over a dozen cm from water surface  maybe some ic for ultrasonic communication exist  another ideas  ,sensors wireless communication
6979,question about dynamic window approach ,i have a my mobile robot and plan to use the dynamic window approach to collision avoidance  i have read the paper  but have one inequality i can t derive it   could you tell me  thanks  ,navigation motion-planning
6980,beaglebone not accessible through lan ,since the day i bought it i always use ethernet over usb connection  now i need to use rj   lan cable to connect beaglebone from my laptop  but my laptop can t even detect lan connection from it  what could go wrong  do i need straight or crossover cable  do i need to configure something first on my beaglebone   update  managed to connect it through crossover cable and assign it ip   address by running dhcp server on my laptop     as seen above my laptop assign ip                 but when i tried to   connect to that ip using putty it gives me connection refused    please help  ,beagle-bone
6982,ekf over correcting ,i ve been implementing an extended kalman filter  following thrun s probabilistic robotics implementation  i believe my correct step may be wrong  as the state appears to be corrected far too much  here s a screen capture showing the issue   note  the bottom status reading is the  corrected  pose coordinates  this is my correct step   h   the range and bearing of state landmark  q    landmark x   self x          landmark y   self x       my sensor covariance errors are  cm per meter  and pi     for the bearing  my assumption was that the correction should be relative to the size of the robot s pose error  which is very small in this example  as it only moved forward less than   cm  is the kalman gain applied correctly here  and if yes  what other factors would result in this  over correcting   thanks  ,slam ekf python
6984,mapping algorithm without noise,i have a simulated robot moving in a discretized  d grid world that  for various simplification and time restriction reasons  has no noise  the problem is how the robot creates its initial map of the world  algorithms like slam and occupancy grid mapping are based on uncertainty  but in this case there is no uncertainty  so i m wondering if there is a relatively simple algorithm for mapping the environment with noiseless position  ,mapping
6985,enable bluetooth adapter for beaglebone black,i recently bought a usb     bluetooth adapter  it claims to have support from linux kernels of versions     and higher  i have a beaglebone black with debian gnu linux   image and kernel      i am developing on beaglebone black by hosting it through usb with   i have tried both hot plugging and  plugging in before boot and failed   then  i tried this tutorial  however  i cannot find the connman directory on my beaglebone black device  i looked up and assumed i needed to install the connman package  but my beaglebone black has no internet access  i have also tried lsusb  v  as suggested by an answer of a similar question to this  with no luck  the weird thing is  while lsusb itself prints  bus     device      id  d b      linux foundation     root hub    bus     device      id  d b      linux foundation     root hub  lsusb  v only prints  bus     device      id  d b      linux foundation     root hub  then hangs  information regarding bus      which i believe the device is connected to  is not printed  i have to restart the ssh connection to get back to work   how should i approach to get the dongle to work on my beaglebone black  if the connman package is sufficient  how do i install it on my beaglebone black without internet access  why does lsusb  v hang  any help is appreciated  ,beagle-bone
6987,calculating thrust generated from electric engines,i wanted to calculate the amount of thrust generated from the engines  i am using the blade     cfx model   after some research i have found a way to calculate the thrust using  t     pi d   rho p      where p is the power multiplier and can be calculated using  p  prop constant    rpm      power factor i am unable to find the values for the prop constant and the power factor  is there a way i can get this information  or an alternative way to calculate the thrust generated  ,power
6990,detect polyethylene,first of all  i am in high school to tell you that i am a newbie and lack knowledge  what i want to achieve for now is a thing that can differentiate between poly bags polyethylene  and other stuffs  or a thing that could detect polyethylene  i have to built a robot and therefore we have only a few method accessible  anyway any knowledge or suggestion or external links provided by you  about this topic would be welcomed by me  ,mobile-robot sensors
6992,my pid controller in java is not operating correctly,i was looking for an implementation of a pid controller in java and i found this one   so  for what i could understand about it i am using it this way   but he never stabilizes  he doesn t behave like a pid at all    this is the output i get  input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error        input         output          error       input          output         error         can someone help me tell me what i am missing  thank you  ,control pid
6999,quadcopter frame design,quadcopter frames seem to consistently follow the same x design  for example   i m curious to know why that is  it certainly seems like the most efficient way to use space but is it the only frame design that would work for quadcopters  for instance  would a design like this work   why or why not  ,quadcopter design frame
7002,easiest way to submit a longer non standard character string via mavlink,i want to submit my gains for the pid regulator via mavlink   unfortunately  i am not very used to mavlink and there are several functions which may be used for that purpose  i think   my string is currently json formatted and i was directly sending it to the serial port before   is there a straight forward way to submit the data like it is  see below  with mavlink  or is it better not to transfer a json string with mavlink and submit each single value  if yes  what is the function of choice   so far i noticed that for most of the sensors  there are already mavlink function defined  for the pid gains i found not so much   ,c++ mavlink
7004,euler s method or ode   for solving ode for control systems,the dominant approach for solving ode in control systems books is  since the majority of these books use matlab  i m not acquainted with how the ode   works but lately i started reading about euler s method in this book numerical methods for engineers  if the step size is very small  then the results are satisfactory  for simulation  one can actually set the step size to be very small value  i ve used ode   in here for regulation and tracking problems  i faced some difficulties for using ode   for tracking problem since the step size is not fixed  now for the same experiment  i ve used the euler s method with step size       sec  the results are amazing and so friendly in comparison with ode    this is a snapshot from the result    and this is the code  clear all  clc   dt           t         initial values of the system  a        angular displacement da        angular velocity     pid tuning kp       kd         ki          error         system parameters  m                mass  kg  d         e      viscous friction coefficient l                arm length  m  i       m l      inertia seen at the rotation axis   kg m    g                acceleration due to gravity m s      generate desired trajectory  y     dt    pi     angdes   y    ang  angle   des  desired angdesprev       for i     numel y        get the first derviative of the desired angle using euler method     dangdes       angdes i    angdesprev    dt     angdesprev   angdes i         torque input    u   kp   angdes i    a     kd   dangdes   da     ki error       accumulated error    error   error     angdes i    a         store the erro    e i      a   angdes i        t i    t       dda     i  u   d da   m g l sin a          get the function and its first dervative    da   da   dda dt      a   a     da dt       store data for furhter investigation     a i    a     da i    da      t   t   dt    end  plot t  angdes   b   t  a   g    linewidth        h   legend          set h   interpreter   latex    my question is why ode   is preferred in many control books assuming the step size is very small   ,control
7008,how to decide between lipo or lifepo for robot battery,when choosing a battery for a robot  should you use a lipo or lifepo  for lifepo  the pros   can deliver higher sustained amps many are built to be drop in replacements for lead acid batteries and can use the same charger  the cons   enormously expensive  about     watt hour kg  over twice the energy density than lifepo  around     watt hour kg   the cons   more complicated and unsafe to charge  see videos of lipos catching on fire  most can t safely deliver high amps  is there anything i m missing  i see lifepo batteries used on a lot of larger platforms  probably due to the higher continuous amp rating  i see ebay flooded with tons of cheap high capacity chinese lipos  but almost none of them have documentation  which probably means they re junk  when should i use lifepo vs lipo  ,battery
7012,algorithm simple stereo vision,i m working in a project implementing a vision system  i m a student and this is the first time i m doing something like this  it has been a challenge  i m using a controller  netduino     net microframework  and a camera  cmucam    pixy  and for now it s working well  i m communicating with the robot fanuc m   ia  using modbus  and aquiring the data from the camera using i c   but  the next challenge is using   cameras to implement stereo vision and i m not shure how to achieve that  i m reading a lot about that and i understand the process and generally how it works  but i think my case is very specific  my cameras detect the center of an object and give me the coordinates  so  i have that  and that s good   what do you think it s the more reasonable approach   sorry for my english  let me know if i m not being explicit  i ll edit the question if i see there s not enough information  ,microcontroller robotic-arm cameras stereo-vision
7014,what main factors features explain the high price of most industrial computer vision hardware ,i am a student who is currently working on a computer science project that will require soon computer vision and more specifically stereoscopy  for close depth detection   i am now looking for a great camera to do the job and i found several interesting options     a custom built set of two cheap cameras  i e  webcam      the old  classic  economic and proven kinect     specialized stereo sensors  i found a couple months ago this sensor   i tought it was interesting because it is small  stereoscopic and brand new  encouraging a fresh usa company   however  if we take apart the additional apis that come with it  i just don t understand why you would buy this when a kinect  or  cheap  cameras  are at least     times less expensive and still have great if not better specifications  same applies for this one   can someone please explain to me why i would need such a device and if not  why they are needed for some  ,sensors computer-vision kinect
7016,simple way of  d perception,i wonder is there any simple  can be computed in microcontroller level  option which is suitable for  d object perception  depth  position  pose or coordinate estimation  of flying robots except lidar  stereovision  omnidirectional camera  laser scanner or any other machine vision based techniques  ,mobile-robot sensors cameras stereo-vision lidar
7018,irobot create   c  connection,my department recently purchased irobot create    we want to recreate the code from the csharp create   driving tether program to use as a base for our intro to computer science course  currently the code we are using to talk to the irobot is   not sure if the irobot is getting the commands as well as if the serial port is making a connection  we are using visual studio      as the programming environment  any recommendation and or input would be appreciated  thank you  ,irobot-create roomba
7024,rover   with   encoders help,am   weeks old to arduino projects  i had been using timing all this while to control my rover   now  i wanted to shift to using encoders  am facing quite some problems  am using arduino uno and a two amp motor shield  this is code i am trying to use  am using a  v li po battery   link to rover    link to motoshield  my question is there are four pins coming out of encoders from each side   what i did was connected the red and black to  v and gnd respectively and the white and yellow of the first encoder to pin   and the white and yellow of second encoder to pin     is what am doing correct   and sometimes when i use this code  in the motorshield both the green and red light starts thereby stalling the motor  why does that happen  can anyone of you suggest a link to a simple encoder code to make the motors move forward in a straight using feedback   thanks    interupt      pin      interupt      pin   volatile unsigned long positionl         vehicle position count from left encoder volatile unsigned long positionr         vehicle position count from right encoder int motorla      int dirla      int motorra      int dirra      void setup      pinmode  motorla  output   pinmode  dirla  output   pinmode  motorra  output   pinmode  dirra  output   serial begin          void loop      movefwd        delay        moverev        delay        while       void encoder      positionr      void encoder      positionl      void movefwd unsigned int x    positionl    positionr    attachinterrupt    encoder   change      attachinterrupt    encoder   change   digitalwrite dirla  low      left a forward  digitalwrite dirra  high     right a forward while  positionl    x      positionr    x           stop all motors analogwrite motorla      analogwrite motorra         disables the encoders interrupt detachinterrupt     detachinterrupt       void moverev unsigned int x    positionl    positionr    attachinterrupt    encoder   change      attachinterrupt    encoder   change   digitalwrite dirla  high      left a forward  digitalwrite dirra  low     right a forward while  positionl    x      positionr    x     if  positionl   positionr         analogwrite motorla          analogwrite motorra                else if  positionr   positionl         analogwrite motorra          analogwrite motorla           sets the motor speed at a value of             else        analogwrite motorla           sets the motor speed at a value of            analogwrite motorra                    serial print positionl      this prints the current value of positionl in the serial monitor on the computer   serial print   t       this creates a tab on the monitor   serial print positionr    serial println       this creates a new line to print on         stop all motors analogwrite motorla      analogwrite motorra         disables the encoders interrupt detachinterrupt     detachinterrupt       ,arduino sensors
7040,how to get the projection matrix from odometry tf data ,i would like to compare my results of visual odometry with the groundtruth provided by the kitti dataset  for each frame in the groundthruth  i have a projection matrix  for example   here the instructions provided by the readme   row i represents the i th pose of the   left camera coordinate system  i e   z   pointing forwards  via a  x    transformation matrix  the matrices   are stored in row aligned order  the   first entries correspond to the first   row   and take a point in the i th   coordinate system and project it into   the first    th  coordinate system    hence  the translational part   x    vector of column    corresponds to the   pose of the left camera coordinate   system in the i th frame with respect   to the first    th  frame  but i don t know how to produce the same kind of data for me  what i have for each frame in my case   the tf transformation from the init camera  the fix one from the          to the left camera which is moving  so i have the translation vector and the quaternion rotation  the odometry data  the pose and the twist camera calibration parameters  with those data  how i compare with the groundtruth   so i need to find the projection matrix from the data above but don t know how to do it  can someone help me   thank ,mobile-robot odometry stereo-vision
7043,how to tune the two pids for quadrotor,i m trying to implement two pids for stabilizing quadrotor for position tracking  the inputs are  and   for position tracking  usually the small angle assumption is assumed  this assumption allows for acquiring  and   these are the results   the x axis position is driving me crazy  after alot of attempts for tuning the pids  i felt something wrong is going on  is this a normal behavior for pid controller  also  what i ve noticed is that once  reaches to zero  the platform starts oscillating  after     second in the figure      for solving odes and computing the derivatives for the velocities  i use euler methods    it is simulation in matlab   ,pid quadcopter
7048,depth of view for a hypercatadioptric camera,i am trying to determine the depth of view for a hypercatadioptric camera  camera lens system and a hyperbolic mirror  based on     the following illustration seems pretty clear  for an image point   we are looking for a virtual point   given the parameters of the optical system    i have troubles finding the right equations in the paper  though  there is  which seems to be connected to   but is not defined anywhere  my goal is to replicate the diagrams they have later in the paper  like e g  this one   which for a mirror  blue  gives the virtual image points of the scene  red   i would like to calculate the depth of view  so the area at which the image blur is below a threshold    zhang  s   zenou  e   optical approach of a hypercatadioptric system depth of field  in    th international conference on information sciences  signal processing and their applications ,computer-vision cameras
7050,questions regarding  d scanning and camera choice,a few days ago  i just shared my concerns about the price of computer vision hardware on this same exact forum  see what main factors features explain the high price of most industrial computer vision hardware   and i think a new but related post is needed  so here we go  here are some details to consider regarding the overall scanner i want to build   restricted space  my overall scanner can t be larger than   feet cube  small objects  the objects i will be scanning shouldn t be larger than   foot cube  close range  the camera would be positioned approximately   foot from the object  indoor  i could have a dedicated light source attached to the camera  which might be fixed in a dark box   here are the stereo cameras sensors i was looking at  ordered by price    two logitech webcams  no model in particular   cheap harder to setup and calibrate need to create your own api built for  what you want to achieve  intel realsense        low resolution  for depth sensing       x     unworkable minimum range      m excellent fov      horizontal      vertical built for  body tracking  structure sensor       extreme resolution with high fps capability     k      fps  even for depth sensing  and    p      fps unviable minimum range      m outstanding fov       built for  human vision simulation  duo mini lx        maximum if possible   my main criteria is a camera that would be able to generate an accurate depth map from close range points   thanks for your help  ,sensors computer-vision kinect
7052,how to select the parameters of the sliding mode control of a robotic arm ,i working on sliding mode control  smc  of a   dof manipulator  i don t know how to select the discontinuity gain matrix     the surface constant  the diagonal gain matrix   components   ,control robotic-arm industrial-robot
7056,locating omni directional robot,i have an omni directional robot  such as a x drive or mecanum drive that i need to track the position of  i can put encoders on the wheels  but that is all i can do in terms of the sensors  i have no external beacons that i can link to  the issue is that i needed to keep track of x y position  including strafing  and my heading  does anyone have any resources that could help me with this  ,localization
7057,how to control brushless motor esc with beaglebone ,i can t really find a real straightforward tutorial for that  there are a lot for arduino but i only have an original beaglebone  an esc  and brushless motor with me  please help  ,brushless-motor beagle-bone
7059,how to approach an object,my question is more on a basic conceptual level  i m looking into a way to approach an object in map  that i have detected earlier  my robot is localized in a map using slam  and object position is  d point that i recieve from my algorithm   object is actually a face picture on a wall   is there a smart way to approach the point and  look  at it  ,mobile-robot mapping
7062,create  angle  packet id    ,how to convert the value you get for the angle  packet id     into degrees  i am using the create  robot and when i did not understand the data i am getting back  the documentation it says it s in degrees but what i get back is a huge number like      when i turned the robot just    degrees  ,irobot-create
7066,what is the technology used for no resistance robot arms ,i saw a high end robot arm once that i could move and bend it to any form i wanted with no resistance  as if the robot arm didn t have any weight  i d like to know more about them  what is this class of robot arm design called  where can i get some more information about its design and applications  ,control robotic-arm joint
7067,how can i communicate wirelessly between a raspi and servo ,i want to use a raspberry pi to pan a camera mounted on a servo wirelessly from      feet away  what are some good servos and transceivers for this  to clarify  there should be no physical connection between the raspi and servo  do i need an additional raspi on the servo end  ,motor raspberry-pi wireless
7068,how does the strategy changes in a robcup soccer competition without connection to outside ,how is a new team strategy during a robocup competition sent to each player of a robot team  robots in the standard platform league  i e  spl   for example  are fully autonomous and there is no connection with non team members  except pulling from the gamecontrol   ,soccer
7069,is gmis really a breakthrough ,the gmis  general machine intelligence system  from a new article posted at codeproject com looks interesting   do you think that it could be a breakthrough in the field of robotics ,mobile-robot robotic-arm
7070,jacobian for point on robotic arm,currently i am programming for a robotic simulation  i have a endeffector which aproaches a target  on the way to the target is an obstacle  now i redirect my endeffector  so that it does not hit the target  when i want to do the same for the whole arm i want to push the arm away from the obstacle as well  now i have it working so far that i can redirect the arm  but my calculation for the jacobian seems to be faulty  for my setup  and what i need for that  i have a robotic arm   dof  let  be the closest point on the arm to the obstacle  and  the corresponding jacobian  also i have given the following term     are my joint angles  i can calculate the jacobian for the endeffector  but do not know on how to calculate it for a point ob the arm  does anybody have an idea on how to calculate the corresponding jacobian  cheers ,robotic-arm jacobian
7073,make hc sr   receive from another one,i have   ultrasonic sensor  hc sr     i want to use one of them as transmitter  and the other as receiver  i want to let the first one send ultra sonic waves and the other receive these waves from the same transmitter  how can i do that    i tried to send trigger for each ultrasonic and connect them on different pins on pic  but its now work  its something like this project but using hc sr    ,microcontroller ultrasonic-sensors
7080,building a quadcopter using stm  f  discovery board,how do you calculate the pid values and stabilise the quadcopter using the on board sensors the gyro accelerometer and magnetometer ,sensors
7089,programable drone with robotic arm and hand ,i was just wondering if it was possible to buy or build a programmable drone with a robotic arm hand  knife  i want to program a drone to harvest crops   object recognition from live video stream to server  identify and grab objects with arm  make cut if necessary  transport produce to collection site i know this would take much knowlege from many fields but do any you have any forsight into the limitations of doing this other than energy for power  estimates on cost of hardware  ,robotic-arm design quadcopter dynamic-programming
7091,design and construction of universal robotic arm   kg   m ,i am working on my master s thesis about design and construction of universal robotic arm   goal of my work is to design   dof robotic arm  something like on the picture   i need it to be able to lift a weight about  kg  it has to move in  action radius   m  rotation speed should be about  m s  the conclusion of my work should be like   you can buy abb robotic arm or you can but this  it can lift that much  can turn that speed and weighs that much   basic construction should be done too  maybe with some simulation  first of all   i picked really bad master s thesis for me  i know that know  second   i have like month to finish it  i would like to ask someone how to proceed   i know that first step is to pick servos actuators gearboxes  but which one  what is realistic weight of the whole arm which should lift another   kg of weight  how strong motors should i pick or with what gearboxes   is anyone able to help me via maybe emails   ,robotic-arm servos actuator arm
7095,depth image sensor for integration into robot,i know there are lots of consumer depth image sensors  kinect  primesense  structure io  leap motion      but i m looking for something that is more suitable for integration into robot  something without case or with proper mount  compact and available for at least next five years if robot is going to production  something similar to the sensors used in this drone  ,sensors kinect
7097,connecting usb xbox controller to national instruments crio,i have a first robotics spec national instruments crio   i would like to connect a usb wireless xbox controller to it in order to control it from a distance with minimal extra hardware  which is why i am not using the more traditional wifi radio method    to this point i have been able to find either a  a sidecar for the crio which allows it to act as a usb host or b  a method that does not use ni specific hardware to connect the two together if someone who is knowledgeable on the subjects of industrial system and robot control could provide some assistance that would be greatly appreciated  thanks  ,control industrial-robot wireless usb first-robotics
7099,got difficulty in reading specification ,guys i am making a home automation system very simple one with infrared remote ccontrol of tv remote now the problem is i wanna buy a some relays to switch    v ac using my arduino board but can t understand which one to buy i don t want to buy relay module but i wanna buy relay  ,arduino
7105,is it possible to use ros on rpi with controller like multiwii or similar ,i have a quadcopter using a multiwii arduino mega  controller  i am curious if there is any way to connect it with ros capable rpi   that i could add to the quad itself   ,arduino ros quadcopter
7109,building industrial like robotic arm,i would like to build a   cm articulated robotic arm  not a scara one  that can lift between   kg and   kg    kg would be awesome already  this payload includes the weight of the arm gripper  and moves at   m s  dreaming again      the goal is to make it similar to an human arm since i want to control it  remotely   so the joint should not be able to rotate more than my arm    so i know that i cannot uses servos available  like the overpriced dynamixel ones     with that payload  i also already excluded common linear actuators and less common ones like the pneumatic actuators  because of latency   from what i read arms like the baxter ones uses elastic series actuators  so i guess that i should go that way  but there aren t a lot of details on how that works  getting a lot of    x    photos where you see nothing  and i have a lot of questions   the only thing i could understand is that it uses   motors and a spring  do they use brushed or brushless motors  dc motors or steppers   i read that steppers aren t that good to handle collisions and have difficulties when used at their limits  also  how is the spring mounted on the motor   to sum up  i m collecting any experience  diagrams  intel  or documents that you have on that topic    ps   my budget can t exceed           for that arm  ,motor robotic-arm stepper-motor servomotor actuator
7110,read from ultrasonic hc sr  ,i want to run two hc sr   on one pic  f   a and send the value mesured by the two ultrasonic to serial port  this is my code using pic c compiler    but the computer received random values    what is the problem   ,microcontroller programming-languages ultrasonic-sensors
7111,dh forward kinematics for a cartesian robot  cnc mill ,i am implementing a denavit hartenberg forward transform for a   axes cnc mill  i know that the kinematic for such a machine is trivial and doesn t need dh  but i need to make appliable for other robots too  my implementation does the math correctly i ve verified that with another tool   but the transformation doesn t give me the results i would expect   i assume that for   axes cartesian robot with orthogonal prismatic joints  cnc mill  the resulting transformation matrix should give me the input parameters d  d   back in its translation vector  but it somehow doesn t  also  the resulting orientation matrix should have some  nice  values               etc   and no odd ones                 etc      is my assumption wrong  ,forward-kinematics cnc dh-parameters
7112,what is the robotc type for motors ,i m trying to create a function that allows me to more easily start a motor  but i m running into a problem  i don t know the type to use for the  argument  i m using a vex     motor  here s the function  void runmotor motortypehere motorname  int speed  int time      startmotor motorname  speed     wait time      i just don t know what type to put for the motorname argument  what type would it be  ,robotc vex
7116,accelerate a stepper using arduino accelstepper starting with a pre defined speed,i ve read the accelstepper documentation on airspayce com and it seems to be not possible to accelerate a stepper starting with a speed greater    acceleration always starts from speed    i tried it with several variations of the code below     i also tried to set the speed in the library s method void accelstepper  computenewspeed   directly  but i m not that good in c   and don t get it to work  anybody any ideas   update i tried to write some custom code in accelstepper cpp s method void accelstepper  computenewspeed    my idea was to set the speed manually during acceleration deceleration if the speed is below my intended value  at first i thought it couldn t be a big deal  but now i see that my cpp skills seems to be not good enough or i don t understand the library quite well   i tried void accelstepper  computenewspeed         long distanceto   distancetogo        ve is clockwise from curent location     long stepstostop    long    speed    speed            acceleration       equation            now here goes my modification     if   speed             speed                setspeed                     i did no modification below this comment  this results in a very slow stepper movement   ,arduino control stepper-motor c++
7120,measuring angular displacement using the ti sensortag,i ve looked around but can t find the answer  to what i hope is a simple question  i m working with a ti sensortag  and i want to be able measure the rotation around the unit s z axis  basically i want to attach the tag to a clock pendulum  lie the clock on a table so the tag and clock face point up  and to measure the angular displacement of the pendulum as it swings back and forth  i m hoping the mental image translated well   my understanding is that i can solve for displacement by multiplying my gyroscope readings by my sampling period  but i m not sure how to compensate for drift  so my questions are  is my approach sound  and is the answer to drift to use the changing x and y accelerations  or would i need to somehow incorporate the magnetometer readings  thanks  ,sensors kinematics gyroscope
7121,irobot create    angle measurement,i have been working on trying to get the angle of the create    i am trying to use this angle as a heading  which i will eventually use to control the robot  i will explain my procedure to highlight my problem  i have the create tethered to my computer    i reset the create by sending op code     using realterm  the output is   bl start   str      bootloader id   x          c   fff   bootloader info rev   xf      bootloader rev   x                       l   roomba by irobot    str                      l   battery current zero         the firmware version is somewhere in here  but i have no clue what to look for  let me know if you see it      i mark the robot so that i will know what the true angle change has been  i then send the following codes               x    x b  xff  xf          this code starts the robot spinning slowly in a circle and request the sensor data from the sensors in the group with packet id    the output from the create seen in realterm is  x              which makes sense  i wait until the robot has rotated a known     degrees  then i send         to request the angle difference  the output is now  x           b   the oi specs say that the angle measurement is in degrees turned since the last time the angle was sent  converting  x b to decimal is     which is certainly not     as expected   what am i doing wrong here  is the irobot create   angle measurement that atrocious  or is there some scaling factor that i am unaware of  are there any better ways to get an angle measurement  ,irobot-create roomba
7124,using accelorometer and gyroscope to get velocity  spin   flightpath of a ball in projectile motion,i m working on a project to make a smartball that can detect the velocity km h    spin degrees per second  and flightpath trajectory  of the ball using intel edison with the  dof block  lsm ds      axis accelerometer    axis gyroscope  and   axis magnetometer    the battery block  i m reading values from the  dof block by rtimulib library for imu chips   i ve been working on integrating the acceleration data from the accelorometer to get the velocity then get the position  i know that this method is not really accurate as the integration error cumulate very fast but i rely on that my calculations will be done in a very short time  about   seconds  then i re calculate again from the beginning after every kick so that error doesn t cumulate hardly  also i only need an acceptable accuracy not a very high one  i discovered then that i m dealing with projectile motion ball kicking   so after considering this   searching in projectile motion equations i found that i must know the initial velocity and the angle of projection theta  to be able to get my requirements  my problem that i don t know how to get any of these   i tried different approaches like getting the horizontal distance   getting the height to get their resultant using pythagoras  then get the angle assuming it s a right angle  in a very small time at the beggining of the projection   but i still couldn t get the height  the gyroscope outputs roll  pitch   yaw angles related to the sensor orientation but i m still not using this as i m assuming that the sensor will be fixed inside the ball so it s orientation will not be the same as the projection angle now what i really want is any approach idea on how to get velocity   flightpath of a projectile using accelorometer and gyroscope data  hope i made it clear   any help on how to get my requirements is really appreciated  thanks so much  ,gyroscope
7125,keeping   motors common for three circuits,i am beginner in robotics and i want to create a line follower  obstacle avoider  remote controlled robot and i am using the drive differential algorithm but i want to keep   common motors for the three circuits  i have got the three circuits ready and i want it to switch among these   circuits wirelessly  please tell me a solution     ,motor wireless line-following circuit
7128,determining a robot s distance from a certain point when the robot s position is constantly changing,i was wondering how i could determine a robot s distance from a fixed point when the robot itself is constantly changing positions  i can keep encoders on the wheels and can also get data from a gyroscope and an accelerometer  ,localization
7129, dynamixel  inverse rotation direction,i m wondering if there s a feature to  flip  the rotation direction with dynamixel  i m using mx       for example  if i give       to the motor  then it interprets it as   and the other way around  i m using its ros driver package that doesn t seem to explicitly claim that there s a feature to do this  although there is a question where a user reported he was able to do this from source code  but i failed to replicate  so i first wanted to ask about the capability of the device itself since i don t know if the limitation comes from the dynamixel device or from ros driver  thank you    update  usecase of mine is that i have multiple robots where the direction of how dynamixel is attached is different per robot  and ideally like to flip the motor s direction at driver s level so that i can keep using the same controller software  ,servomotor dynamixel
7137,understanding the various attitude estimation methods,i am building a quadcopter using the arduino uno with a  dof accelerometer and gyro  i will be adding a separate   axis magnetometer soon for heading  i have successfully implemented the code that reads the data coming in from these sensors and prints them out   i have also checked for bias by averaging     measurements  my code calculates the pitch from the accel and pitch from the gyro respectively  pitchaccel   atan   accelresult      biasaccely          accelresult      biasaccelz                  pi    pitchgyro     gyroresult      biasgyrox            dt  i am then using a complementary filter to fuse the two readings together like this  pitchcomp         pitchgyro     pitchaccel        i am stuck on how to proceed from here  i am using the same procedure for roll  so i now have readings for pitch and roll from their respective complementary filter outputs   i have read a lot of articles on the dcm algorithm which relates the angles from the body reference frame to the earth reference frame  should that be my next step here  taking the pitch and roll readings in the body reference frame and transforming them to the earth reference frame  repeat the entire procedure for yaw using the magnetometer  if yes  how should i go about doing the transformations   i understand the math behind it  but i am having a hard time understanding the actual implementation of the dcm algorithm code wise   any help is appreciated  ,arduino quadcopter accelerometer gyroscope
7138,pins in openrov that control the motors ,i m working on my own rov project  but i find openrov have a ready to use image for my bb so want to use that instead of making my own program  and i already deployed the image  but i can t find which three pins find that send pwm signal for esc s  please help  ,mobile-robot beagle-bone
7139,determining transfer function of a ptu for visual tracking,i have a ptu system whose transfer function i need to determine  the unit receives a velocity and position  and move towards that position with the given velocity  what kind of test would one perform for determining the transfer function    i know matlab provides a method  the problem  though  is that i am bit confused on what kind of test i should perform  and how i should use matlab to determine the transfer function  the unit which is being used is a flir ptu d  e      more about the system  the input to the system is pixel displacement of an object to the center of the frame  the controller i am using now converts pixel distances to angular distances multiplied by a gain   this works fine  however  i can t seem to prove why that it works so well  i mean  i know servo motors cannot be modeled like that  the controller is fed with angular displacement and its position now    added together give me angular position i have to go to   the angular displacement is used as the speed it has to move with  since a huge displacement gives a huge velocity  by updating both elements at different frequency i m able to step down the velocity such that the overshoot gets minimized   the problem here is  if i have to prove that the transfer function i found fits the system  i have to do tests somehow using the  function in matlab  and i m quite unsure how to do that  i m also a bit unsure whether the ptu already has a controller within it  since it moves so well  i mean  it s just simple math  so it makes no sense that i ll convert it like that  ,control
7140,what is the difference between sam and slam ,what is the difference between smoothing and mapping  sam  and simultaneous localization and mapping  slam   these general approaches seem closely related  can someone describe the differences  ,slam
7146,estimating angular speed from position for control purpose,i am new to robotics  however i am designing a pid to control the angular velocity  azimuth  elevation  of a couple of faulhaber motors  the input to the pid control is the actual angular velocity  which is not observed though  since it is derived from the position of each motor at time   the pid sample period is aprox    whereas the input data rate from the joystick is aprox      samples s  corresponding to a sample period of      ms  the joystick input gets transformed into the desired angle speed  that the pid will control  i was initially filtering position data using a normal  d linear kalman filter  but the angular velocity is not linear  by formula   hence i switched to extended kalman filtering  my questions are the following   is this latter approach that makes use of ekf correct  which are the parameters that i have to check in order to properly set the update rate of the pid loop   thx in advance  ,pid ekf
7148,an easy way to exert desired load on a motor shaft ,i am trying to exert a desired load of      n m on a bldc motor shaft whose length is      in and diameter is       in       m   i can go to a machine shop and get a small adjustable cylindrical coupling made for my shaft  but i need it to exert close to desired torque at a speed of      rpm      rad s   i tried doing some calculations  according to the formula  torque   speed   mass    radius    if i solve this equation with t        n m  speed       rad sec  radius         m  i get around    kg for mass  which is huge     it is more than the mass of the motor  can you please suggest a convenient way to load the motor  thank you  ,motor brushless-motor
7153,is it possible to have a v feed and serial communication on an rf transceiver at the same time on an arduino ,is it possible to transmit live audio video feed and at the same time  receive commands through uart using only   rf transceiver connected to the arduino board  i want to control the arduino through serial communication  uart  which can be accomplished by using rf connection to control it from a remote  i also want to transmit live audio and video feed from the arduino using the same rf transceiver  is this possible  i found avctp  but i m not sure if it enables serial communication  also  i don t like to use bluetooth for some reasons  thanks in advance  ,arduino microcontroller radio-control serial communication
7156,stm  f  timers   computing,i have an stm  f  discovery board  i want to go to the next step and i want to try to use timers in a few configurations   how can i calculate variables  such as prescaler  period   i looked in all datasheets  manuals and didn t find anything that can describe these values as    input capture mode  op  pwm  etc   i think that prescaler is for downgrading a frequency from           so if i have fcpu   mhz and want to generate a signal of frequency   khz  am i supposed to do    mhz   khz        now should i subtract this prescaler with     ,microcontroller
7158,c   and create  ,i am trying to use c   to talk to the create   robot  does anyone have basic code to write read from the create   using c   or c  i am having trouble with converting create   commands  like   into one char  ,irobot-create c c++
7159,do structured light camera sensors work outdoors ,do structured light camera sensors like the structure io  intel realsense or microsoft kinect work outdoors  i read these sensors wont work outdoors because of ambient ir light  can someone provide this with proper references tests  i mean what degree of ir illumination is needed for the sensor to stop working etc  there are videos on youtube that show microsoft kinect working outdoors   prairie dog ii  ugv kinect sensor outside   limited outdoors range outdoor kinect data collection   heavy interference with direct sunlight  however  the  not yet released  new intel realsence r    specification says  range up to     meters indoors  longer range outdoors  while the older f    says      meters       meters  indoors only   i am really interested in seeing if the r    will really work outdoors  ,kinect cameras
7161,odroid xu  speed issue with image processing,currently working on a uav using an odroid xu  lite as the center core running the out of box sd card image of ubuntu  this is  supposedly  an upgrade from the previous xu that we were running  we re using opencv functions houghcircles  lines  and rgb color detection  searching for shapes and color blobs of   different colors  white  red  green  for a competition  this is all running a lag time a little over   seconds on the opencv playback frame with an output every second or so on the terminal when that s off  the xu  is running even slower  though  despite being a better machine  what could i do to improve the speed or is the xu  not fitting the power requirements  one thing i think is an issue could be that the stock ubuntu version is bloated and i ve been looking around for other images  and i d like to avoid using android   ,computer-vision software uav c++ linux
7163,hand eye calibration,i m trying to use a dual quaternion hand eye calibration algorithm header and implementation  and i m getting values that are way off  i m using a robot arm and an optical tracker  aka camera  plus a fiducial attached to the end effector  in my case the camera is not on the hand  but instead sitting off to the side looking at the arm  the transforms i have are   robot base    end effector optical tracker base    fiducial  the transform i need is   fiducial    end effector   i m moving the arm to a series of    points on a path  blue line   and near each point i m taking a position  xyz  and orientation  angle axis with theta magnitude  of camera  fiducial and base  endeffector  and putting them in the vectors required by the handeyecalibration algorithm  i also make sure to vary the orientation by about      degrees or so in roll pitch yaw  i then run estimatehandeyescrew  and i get the following results  and as you can see the position is off by an order of magnitude                              real                         estimated with handeyecalib here is the full transforms and debug output   am i perhaps using it in the wrong way  is there any advice you can give  ,robotic-arm stereo-vision calibration
7165,how to implement pid control for robotic arm ,i m wondering that  pid control is a linear control technique and the robot manipulator is a nonlinear system  so how it is possible to apply pid control  in this case  i found a paper named  pid control dynamics of a robotic arm manipulator with two degrees of freedom  on slide share page  is this how we use pid control for robotic arm  is there any name for this approach  and how to remove the ambiguity that pid is linear control technique and the robot is nonlinear system  any suggestions  ,control pid robotic-arm industrial-robot dynamics
7167,is this rubber pvc coupling a good enough for small torque      n m ,i am working on a project that involves speed regulation of a bldc motor under no load and load conditions  i wish to use another machine operated as generator  acting as load on the motor  as shown in this video   the coupling used in this motor generator arrangement looks handmade out of a rubber tube or somethhing  i am considering using it as an alternative to a flexible coupling  purchasing an actual flexible coupling is not an option for me  moreover  i need the coupling on an urgent basis   my question is  can this arrangement  or something similar  be used to couple a   w motor to a similar rating machine  if the rated torque is not exceeding     n m  ,control brushless-motor
7175,need suggestion about which microcontroller processor and language to be used in my project,i am very new to robotics  but i will be writing algorithm for my robot to move around and gather information from its surroundings and process it  it will also process audio visual signals  but i am in confusion about which micro controller to use so it would be performance efficient and consumes less power  the controller should also be capable of communication with wireless network  internet through wi fi  and should also support memory integration  also i know to program in java and c  please suggest which would be the best language to use for programming  thanks  p s  i would really like to use a microprocessor as it is highly customizable  please suggest the best to use ,artificial-intelligence
7176,using    servos at once  with raspberry pi,i have recently been asked to review a raspberry pi hat  from a programming view  that will allow pwm control of upto    servos  however i am hoping to use this time to work on a hexapod idea i have been thinking about for a while  which requires a minimum of    servo s  and preferably     camera sensor pan and tilt   my question is  what is a relatively cheap and uncomplicated way of extending my control over those extra   servo s  it would appear most servo controller hat shiels for arduino and raspi are upto    servos  and can be extended by buying another shield  are there any other options  any advice in this subject would be greatly appreciated  preferably dumbed down a bit  and i don t know a great deal about micro controller hardware  more of a software guy  ,raspberry-pi servomotor rcservo
7177,how to test gazebo works properly  save windows don t show any component,how can i test whether my gazebo installation works properly or not  i m trying to  save myworld  and  save as  options but no window is shown  ,gazebo
7178,is ros  robot operating system  mandatory ,do we have to build ros for robotic researchs applications  what is the main advantage  when or in which situations ros is mandatory  ,ros
7181,is the geometric inverse problem s solution  continuous  for a redundant robot ,let s say my redundant robot is at an operationnal position   is the set of all possible joint configuration  continuous   which would mean that it is possible to explore all the possible configurations without moving the end effector  is there a way to show that it is true or false  i am using a kuka lbr robot with   dof so maybe there is a specific answer for this one  i have been searching it and did not find any result but i will gladly accept any link or answer that you may have  ,control inverse-kinematics
7186,what would i need to control a dc servo using a     ma linear analog signal ,i m looking to find a way to operate a small servo using a     ma linear analog signal generated by a plc in an industrial setting   the purpose of this is to allow for automation for a task that currently is done by manually turning and adjusting a potentiometer with removable dial  basically  i m trying to ghetto together an oldschool motor operated potentiometer  mop  so it can be removed quickly and easily without affecting the operation of the original process  i ve spent hours looking for servo controllers encoders that are capable of this  but i haven t been able to find any  any way i could get pointed in the right direction would be fantastic  surely such a thing must exist  thanks so much  ,rcservo
7188,can a jacobian matrix be used to derive joint angles from end effector linear and rotational velocity  without a filter  ,i have a   link    degree of freedom robotic arm  that only measures linear acceleration at each link through an accelerometer   and rotational velocity on each joint  through a gyroscope   i know that through using the jacobian matrix  i can compute link velocity and acceleration from joint angles  and through the inverse of the matrix i can compute joint velocities from joint angles and link acceleration  however  i am not sure if i can compute joint angles using only the link linear and rotational acceleration  i am aware that the joint angle could be estimated by integrating the joint velocities  and applying some sort of filter   but is there an algebraic way this can be computed  it doesn t seem likely to me   ,robotic-arm accelerometer gyroscope jacobian
7189,create  reading sensor date does not always work,i noticed that the create  does not always provide sensor data while it s moving  am i supposed to stop the robot  request sensor data then start it again  or am i missing something  it seems to work most of the time but once in a while i get no data back  i am trying to make it move from one point to another by starting it and then reading distance to see how far it travels every    seconds but sometimes it i just keeping getting no data  i noticed this using python and c code as well  i am using the usb port with the bit rate they recommend           ,irobot-create
7190,cheap and efficient  d sensor ,i m searching for a cheap  under       and efficient  d sensor  which detects obstacles and moving objects  for robot applications like quadrotor navigation  swarm robotics  etc  can you suggest a sensor that can be either a commercial product or a  do it yourself  project  ,mobile-robot sensors swarm
7194,beginner question about software for calculations,i m a complete beginner in robotics with background in programming    i started thinking about a robot project yesterday and want to order some motors to test with  i saw the specs for the motors  torque etc  and i think i remember enough physics from high school to do simple calculations  for example  if the motor rotates an arm  then given the torque and the length of the arm  how much could it lift  also  if it doesn t lift it straight up  but at an angle  i could with a bit of thinking tweak the calculations a bit    if there would be several joints attached to each other  the calculations would be more complex  but i could then probably create a program in node js  for example  to be able to experiment with different values  however  i would assume that these kinds of calculations would be very common when designing robots  so i would assume there are already programs for these types of calculations created  i don t know exactly what i mean with  these types of calculations   because i don t know yet what i don t know  so would like to ask which programs are there that you guys use for making calculations when you design your robots  preferable they should be open source    ,robotic-arm mechanism software
7198,dynamic model of a tank like robot,i am planning a tank like robot for hobby purpose  i have control engineering background  however i never applied on robotics   i would like to test different control theory  namely mpc  i saw a lot of publications regarding the kinematics and inverse kinematics of such a robot  however i am wondering if somebody can point out regarding the dynamics modelling of such a system taking into account the forces  mass etc  ,wheeled-robot
7199,pole placement gains tuning,given my control system   i have found the region of the complex space that satisfies my specifications  determining poles position in           i    now i want to find the gains that fix the desider pole  with matlab   but i have not understand well how to do it  anyone can suggest me an example on how to do that  with or without matlab  thanks edit  in the first image the sum blocks are     not    ,control pid tuning matlab
7203,education sources for robot building ,i teach ftc robotics to high school students  and while i m a proficient programmer and can teach them coding fairly well  my mechanical skills are a bit soft   i m looking for good sources for myself and the students to go through that gets a little more in depth than  this is a gear  this is a chain  this is gear ratio  etc    but maybe not quite the level of building professional   industrial robots    i ve used the vex robotics curriculum as a starting reference      but it doesn t go through some more advanced topics  for example  how to drive a single gear   drive shaft with multiple motors to achieve more power without having to gear down and lose speed   are there any good intermediate sources like this   do i need to just bit the bullet and get a college level mechanics text  ,mechanism
7206,building my first quadcopter,i am trying to build a quadcopter from scratch  i have selected few parts but i have no idea whether the quadcopter will come together and fly  i would appreciate your feedback on whether the parts i have selected are compatible  ubec  motor   if not  i would appreciate suggestions  the frame for my quadcopter is in the x configuration and i am making my own  i am expecting the average weight of the quad to be around    g  i hope the motors and prop combination can hover it well  ,multi-rotor
7210,recommendation of robot for special education,i saw a video of a robot used in special education with children on the autism spectrum      my son isn t autistic  he has tourette syndrome  adhd  executive function problems  and ocd   a robot could be quite helpful for him   where can i buy one   i don t need it to look like a human being   it just needs to be interactive and reasonable cute   as my son is getting ready for bed  he needs someone to talk him through his steps  give him positive feedback  and ask questions like  okay  you re in your pajamas   great   what else do you need to do to get ready for bed    and the robot would have a mental list  preprogrammed  of everything that s needed  brush teeth  wash face  put on eczema ointment  put dirty clothes in hamper    my son is    and would like to get ready by himself    without mama or papa    but he gets sidetracked when he s in his room on his own   the robot doesn t need to be able to  see  him brushing his teeth   he just needs to be able to hear my son saying   i brushed my teeth    because when the two of them together decide he has made it through his routine  then they can call me in  and i ll check  and then we ll do our bedtime reading  that s an example of what i have in mind   there are other situations where i could imagine a robot being helpful for him  ,artificial-intelligence
7212,estimate transfer function of stepper motor ,i have a stepper motor which has an internal controller   i would like to determine them both  but don t know how i should approach the problem   the system receives a input velocity and position  and moves toward that position using that velocity  the input could also just be a velocity   the plant is a pan and tilt unit  which has   stepper motors  i tried with ident but only got a fit of         my input was a noisy signal  and output  was the position it writes out   ,control
7215,arduino create    reading sensor values,over the past few weeks  i have been attempting to interface the irobot create   with an arduino uno  as of yet  i have been unable to read sensor values back to the arduino  i will describe by hardware setup and my arduino code  then ask several questions  hopefully  answers to these questions will be helpful for future work with the create    hardware  the irobot create   is connected to the arduino uno according to the suggestions given by irobot  instead of the diodes  a dc buck converter is used  and the transistor is not used because a software serial port is used instead of the uart port  software  the following is the code that i am implementing on the arduino  the overall function is to stop spinning the robot once the angle of the robot exceeds some threshold  a software serial port is used  which runs at the default create   baud rate   questions   am i loading the sensor values into the array correctly  this same code works when a bump and run program is implemented  but that requires knowing only one bit rather than two bytes  how many bytes can be read over the serial connection at a time  a previous post  help sending serial command to roomba  highlights that one byte can be sent at a time  does this imply that the reverse is true  if so  would a solution be to use a char array to read the values instead and then to append two chars to form an signed int  is serial communication synchronization a problem  i am assuming that synchronization is not a problem  but is it possible for the bytes to be split on the nibble boundaries  this would present a problem because there is not a nibble datatype    ,arduino irobot-create roomba
7216,what are the different ways to control distance to be covered by a robot ,i want to move a robot to a certain distance say   meter  what are the different ways that i can implement to do so  for example i can measure the circumference of the wheel and assign time of rotation to move it  what are other techniques to achieve this  ,wheeled-robot movement
7219,issue with multiple bytes from irobot create  ,i was having problems reading sensor information from my irobot create   and sent an email asking for help from the irobot staff  they were super helpful and gave me an answer the next day     that helped push along my project  i was requesting data from the create  to print to the screen so i could figure out how to write a code that would read the data  i started with this section of code that was not working for me  i trimmed some of the code off that controlled other functions    they told me that the code was actually working fine but i was trying to print out the value of the sensor packet without parsing it in any way  they then recommended i change the code in program  to this  while true       def tohexfrombyte val           return hex ord val       rjust         upper        x   connection read       for b in x          print tohexfrombyte b   this works beautifully and prints to the screen if the bumper is pressed or a wheel drops  my question is how to deal with responses that are longer than one byte  ie packet id     for voltage    when i try packet id     it prints to screen and it sends the high byte of  f and a low byte of d   i can manually combine them to get  fd  and convert it to a decimal of        volts but i would like to figure a way to print to screen the the voltage by having my program do this for me  many of the sensors send data in   bytes and i need a way to make sure that it is combined automatically   robb  ,irobot-create python roomba
7221,what is the difference between positioning and localization systems,i would like to know what are the differences between positioning and localization systems  in most review papers they are used interchangeably  are they the same   for example  gps global positioning system   gives coordinates of receiver and slam simultaneous localization and mapping   constructing or updating a map of an unknown environment is difference   positioning  only gives information about receiver coordinates no information about enviorement localization  gives information about receiver coordinates and also enviorement  positioning is a subtopic of localization ,localization slam gps
7225,robotic winch force sensor,i have a requirement for a motor that pulls a piece of rope until the rope is taught  however i m at a loss as to how to achieve this  i m sure it must ve been done before but i m not sure how to best describe this in a way that would get me more results  i wondered if there are any sensors or pre established methods for sensing resistance to motion in electrical motors  ,motor
7226,at what frequency should i input and read values ,i am at the moment trying to identify a system using frequency sweep  i have been using mathematica and have created a frequency sweep as such   the max frequency is    hz  i sample the data using      hz  but at what rate should i input it to the system  and what rate should i read from it  ,control
7227,building a micro cnc machine,i am building a micro cnc machine  probably from   cd roms as the x and y axis and a floppy drive as the z  or   hard drive as the x    cd drive as the y and   floppy as the z  but i am not sure how i wire this to work with emc   a linux cnc program that works with your parrallel port  do i connect my steppers directly to the control drivers the board i buy off ebay right   and then connect to my pc or do i need to interface the board instead then go to the driver and them my parralel port  i also am wondering why people opt for x y at the bottom and z at the top  why not put x y z stacked  so you could place it upside down for a top down view  i would do this but it might be done for accuracy   layers of potential failure  ,driver stepper-motor cnc
7229,irobot create    encoder counts,this post is a follows from an earlier post  irobot create    angle measurement   i have been trying to use the wheel encoders to calculate the angle of the create    i am using an arduino uno to interface with the robot  i use the following code to obtain the encoder values  a serial monitor is used to view the encoder counts   the code above prints out the encoder counts  however  when the wheels are spun backwards  the count increases and will never decrement  tethered connection to the create   using realterm exhibits the same behavior  this suggests that the encoders do not keep track of the direction of the spin  is this true   ,irobot-create roomba
7230,system identification on a physical system with constrains,what kind of input output test can be peformed on at physical system which has constraints to identify the transfer function   the system which is being discussed is a pan tilt unit    the input it receives is either both a position and velocity or only a velocity    ,input
7234,are lipo really     times more energy dense than model rockets ,lately i ve been interested in comparing the energy density of model rocket engines to lithium polymer batteries  attached to motors and propellers  for propelling things upwards  to get a feel for this  i decided to compare an estes c    motor to a  dr iris   quadcopter  estes c    has initial mass of     g  and produces    n s total impulse  so  the  impulse density  is about    n s       g        n s g      dr iris  weighs     g without battery     ah battery weighs    g and will power hover for about    minutes  so about     a draw   thrust produced to hover on earth is    n kg            kg       n   impulse density  is     n       s      g        n s g      so  according to my math here  the lipo is about                 times more energy dense than the model rocket engine  of course  the model rocket engine will lose      g of propellant by the end of the flight so it will be effectively a little lighter  but that s not going to affect things by a factor of      does this seem right to you  am i missing anything  ,quadcopter rocket lithium-polymer
7235,how to implement and code inner and outer pd controllers for quadrotor for position tracking,the quadrotor system is  multi odes equations  the linearized model is usually used especially for position tracking  therefore one can determine the desired x y positions based on the roll and pitch angles  as a result   one nested loop which has inner and outer controllers is needed for controlling the quadrotor  for implementation  do i have to put  inside ode   for the inner attitude controller  i m asking this because i ve read in a paper that the inner attitude controller must run faster  i e   khz  than the position controller  i e          hz   in my code  both loops run at  khz  therefore inside ode   there is no while loop  is this correct for position tracking  if not  do i have to insert while loop inside ode   for running the inner loop  could you please suggest me a pseudocode for position tracking  to be more thorough  the dynamics equations of the nonlinear model of the quadrotor is provided  here  if we assume the small angles  the model is reduced to the following equations    begin align   ddot x           frac u      m     theta  cos psi    phi  sin psi      ddot y           frac u      m     theta  sin psi    phi  cos psi      ddot z           frac u      m    g       ddot  phi        frac l  i  x   u         ddot  theta      frac l  i  y   u         ddot  psi        frac    i  z   u         end align   the aforementioned equations are linear  for position tracking  we need to control  and   therefore we choose the desired roll and pitch  i e      begin align   ddot x   d      frac u      m     theta  d   cos psi    phi  d   sin psi      ddot y   d      frac u      m     theta  d   sin psi    phi  d   cos psi      end align   therefore  the closed form for the desired angles can be obtained as follows   begin bmatrix   phi  d      theta  d    end bmatrix     begin bmatrix   sin psi    cos psi      cos psi    sin psi   end bmatrix        left   frac m  u      right    begin bmatrix   ddot x   d      ddot y   d   end bmatrix   my desired trajectory is shown below  the results are   and the actual trajectory vs the desired one is   my code for this experiment is                              position controller                                 clear all  clc   dt           t         initial values of the system  x      dx       y      dy       z      dz          phi        dphi       theta      dtheta         psi   pi      dpsi         system parameters  m                 mass  kg  l                 arm length  m  jx               inertia seen at the rotation axis   kg m    jy               inertia seen at the rotation axis   kg m    jz               inertia seen at the rotation axis   kg m    g                 acceleration due to gravity m s    errorsumx      errorsumy      errorsumz       errorsumphi        errorsumtheta       pose   load  xytrajectory txt     desiredx   pose       desiredy   pose       desiredz   pose        ddesiredx      ddesiredy      ddesiredz       desiredxpre      desiredypre      desiredzpre       ddesiredphi      ddesiredtheta      desiredphipre      desiredthetapre         for i                torque input                   ux                        kpx       kdx      kix          ux   kpx   desiredx i    x      kdx   ddesiredx   dx     kix errorsumx      errorsumx   errorsumx     desiredx i    x          ddesiredx     desiredx i    desiredxpre     dt     desiredxpre   desiredx i                      uy                        kpy        kdy       kiy          uy   kpy   desiredy i    y      kdy   ddesiredy   dy     kiy errorsumy       errorsumy   errorsumy     desiredy i    y          ddesiredy     desiredy i    desiredypre     dt     desiredypre   desiredy i                        u                         kpz        kdz       kiz          u    kpz   desiredz i    z     kdz   ddesiredz   dz     kiz errorsumz       errorsumz   errorsumz     desiredz i    z           ddesiredz     desiredz i    desiredzpre     dt     desiredzpre   desiredz i                                                                                                                                                                                                                                             desired phi and theta    r      sin psi  cos psi              cos psi  sin psi         dangles   r    m u    ux  uy          wrap angles    desiredphi     wraptopi  dangles             desiredtheta   wraptopi  dangles                           u                         kpp        kdp       kip         u    kpp   desiredphi   phi     kdp   ddesiredphi   dphi      kip errorsumphi      errorsumphi   errorsumphi     desiredphi   phi          ddesiredphi     desiredphi   desiredphipre     dt     desiredphipre   desiredphi                                                                 u                          kpt        kdt       kit         u    kpt   desiredtheta   theta     kdp   ddesiredtheta   dtheta     kit errorsumtheta       errorsumtheta   errorsumtheta     desiredtheta   theta          ddesiredtheta     desiredtheta   desiredthetapre     dt     desiredthetapre   desiredtheta                                                                  u                         kps       kds         kis            u    kps       psi     kds       dpsi                               ode equations of quadrotor                                               x                           ddx    u  m    theta cos psi    phi sin psi          dx   dx   ddx dt       x    x    dx dt                           y                           ddy    u  m    theta sin psi    phi cos psi          dy   dy   ddy dt       y    y    dy dt                            z                           ddz    u  m    g       dz   dz   ddz dt       z    z    dz dt                            phi                           ddphi     l jx   u        dphi   dphi   ddphi dt       phi    phi    dphi dt                            theta                           ddtheta      l jy   u        dtheta    dtheta   ddtheta dt       theta     theta    dtheta dt                            psi                           ddpsi       jz  u        dpsi   dpsi   ddpsi dt       psi    psi    dpsi dt       store the erro      errorx i        x   desiredx i          errory i        y   desiredy i          errorz i        z   desiredz i          errorphi i        phi   pi           errortheta i      theta   pi           errorpsi i        psi             x i    x     y i    y     z i    z      t i    t        drawnow       plot  desiredx  desiredy  desiredz   r        hold on      plot  x  y  z   b      t   t   dt     end   figure    figure     set figure   defaulttextinterpreter   latex     set figure   units   normalized   outerposition               subplot        plot t  errorx   linewidth      title  error in  axis position  m    xlabel  time  sec    ylabel      linewidth       subplot        plot t  errory   linewidth      title  error in  axis position  m    xlabel  time  sec    ylabel      linewidth       subplot        plot t  errorz   linewidth      title  error in  axis position  m    xlabel  time  sec    ylabel      linewidth        subplot        plot t  errorpsi   linewidth      title  error in   m    xlabel  time  sec    ylabel     fontsize       grid on    figure    figure     set figure   units   normalized   outerposition               figure    plot  x y z   b   grid on  hold on  plot  desiredx  desiredy  desiredz   r    pos   get figure   position    set figure   paperpositionmode   auto   paperunits   inches   papersize   pos    pos       print figure   output     dpdf    r      legend  actual    desired    the code of the desired trajectory is  clear all  clc   fileid   fopen  xytrajectory txt   w      angle    pi  radius      z      t       for i              if   z                z   z                x               y          end     if    z                angle   angle                angle   wraptopi angle           x   radius   cos angle           y   radius   sin angle           z          end      x i    x      y i    y      z i    z       fprintf fileid   f  t  f  t  f n  x  y  z   end  fclose fileid   plot  x y z  grid on  ,quadcopter matlab microcontroller
7242,underwater rov variable ballast,how would you guys recommend making a variable ballast system for an underwater robot  i was thinking about this problem earlier and i was trying to figure out if there was a way to make one that didn t require a tank of compressed air   ,underwater
7243,fast c   library for stereo vision disparity computation,i am looking for a library for disparity map   stereo vision computation  these are my requirements   c   multi platform  linux  windows  osx   preferrable but not mandatory  not cuda based suited for robotics  e g  it should work even if the images are not perfectly rectified and the cameras are not perfectly calibrated  suitable for tracking purposes    fps or more  performing even with low res images  e g     x   px  open source  ,computer-vision stereo-vision
7244,conceptual problem regarding electronic shutters,i have been looking at ccd and cmos sensors and cameras to decide which one to use in the process of automatic control of a printing process  by now i am getting the grips on almost all the essential numbers and abbreviations but there remains a problem with shutters  i understand that there are different types of shutters  both mechanical and electronic  and i can understand how they work  my problem concerns shutter speed  if i use a mechanical shutter  well then the maximum shutter speed depends on that particular element in the assembly  but how does it work for electronic shutters  i have never read  max shutter speed  in any specs  the only thing i usually see floating around are frames per second  but those do usally not pass a limit of about     fps  depending on how the sensor it is built one could think that the maximum shutter speed therefore is       or       if it uses half frames  can this be right  it seems really slow  i will be faced with the task of recording crisp and clear images of paper which moves at about    m s  that is never possible with shutter speeds that slow  will i be forced to use a mechanical shutter or am i misunderstanding something  ,computer-vision cameras
7245,how many quadcopters would it take to lift a burrito ,i am investigating a possible business opportunity in which quadcopters perform high precision nutritional delivery via a burrito medium  i have never used a burrito  but i have read on the internet that they typically weigh         grams      this is much too heavy for commercially available platforms  how many quadcopters would it take to lift a single burrito        ,quadcopter distributed-systems
7249,quadcopter   is iphone the ultimate flight controller ,iphone contains  gyroscope gps two photo and video cameras self sufficient battery that outlives the motor battery wifi backup connectivity  cellular  bluetooth  programmable computer real time image processing capabilities and face detection general purpose io  with something like this   and old models are available very cheap  what is the main benefit of having a separate dedicated flight controller and camera on hobbyist rotorcraft rather than a general purpose device like the iphone  ,quadcopter
7251,is there a bug in the encoder counts packets       ,i think i have just found another bug   there was one that was mentioned in another post about the angle and distance  this one is about reading the encoder s counts  i was using them as a workaround for the other bugs but what i found in one instance is that the counts i was reading from the right encoder were incorrect  i was reading in a loop sleeping for    msec while turning the create   here is part of the counts where it definitely shows a problem   this kept on going until i stopped  it seems that it has a problem when it reaches the max  has anyone else ran into this or can explain or provide another workaround   ,irobot-create
7254,cool robotics projects,i m a robotics student but very new to this field  can you suggest any websites which provide projects helpful info that i can learn from  thanks ,mobile-robot
7256,sensing the level of a liquid in a tube,i m looking to build a sensor which will detect the level of liquid in a tube  it does not have to be precisely accurate  just detect whether the level is approximately above a certain height   the liquid level can be seen in the red oval  i thought about monitoring this with a webcam and using opencv to detect the liquid level  but this seemed a bit overkill  especially if i have to have a dedicated pc to process the images  surely there s a simpler solution  perhaps a component i can attach to a raspberry pi or arduino board      i m not very familiar with laser sensors so i don t know what is suitable   as long as it s reliable     edit i should add that the tube contains toluene which is flammable  and it is vacuum sealed  so we can t just drill into it  some kind of optical laser sensor might be  ok  as long as it can recognise a clear liquid   ,arduino sensors raspberry-pi laser
7265,pid over another module that implements a pid control ,i m in charge of a module to control the smoothness with which a platform should move  the platform already implements a closed loop control on its own but this firmware is closed and i do not have access to source code  it is therefore requested that a closed loop control should implemented on top of that pid  in a superior layer  above a module that already implements a closed loop control  so i have several question   it s conceptually correct implement a pid control in an upper layer to closed loop control that implements it  what features may be loose in the lower close loop  maybe loop control closed negatively be influenced by the pid that implements the top layer  estimate the angular speed  yaw and pitch  based on the position of the motors using kalman filters can generate values too far from the actual values reported  ,pid
7266,how can i make a quadcopter avoid obstacles using infrared ,i have a quadcopter built  and i need to be able to make it to autonomously follow a route and avoid obstacles where possible  my general plan is to have an array of sensors on a pre defined  front   the quadcopter will only go forward  generally i d like to make  it so that if the sensors pointing at a higher angle detect something getting closer as the bot moves forward  the quadcopter will stop  descend until the distance to that detected object decreases  and then continues forward  similarly  i d like the opposite event to happen if the sensors pointing at a lower angle detect something getting closer to the quadcopter  i m thinking of having something like   small infrared distance detectors  pointing up  forward  down    left  forward  right   basically a  x  matrix  would anyone have any ideas of the feasibility of this  i d like to use a raspberry pi  but it will probably also need an additional board to read in the values from its sensors  in addition  i have no idea which sensors to use  or if infrared can even work  any suggestions are more than welcome  i was also thinking about ultrasonic sensors  but having   of them could get cluttered  and i d worry about their short range when a crash means death for the quadcopter  i also fear they would cause interference with each other  ,mobile-robot quadcopter sensors
7270,what is load current and load speed  which battery is best suitable for this motor ,these are the specifications of the motor        rpm no load speed at   v no load current    a  stall current     a     kgcm torque  what is the definition of load current and load speed  which battery would be most suitable to power this motor  ,motor
7271,how would i implement a following drone with a camera using gps ,as the title states  is there any way to make a following drone that tracks a gps unit  and follows orients camera to that  similar to this ,cameras gps line-following
7277,assuming i have the angle with respect to two beacons  and know the distance between them  can i localize myself ,let s assume i have the following situation  and need to find  x y     is it possible  there does not appear to be more than one solution to the system  but my trigonometry is a bit rusty  i feel like i need one more distance  ,kinematics inverse-kinematics
7278,adding an actuator or force to a  featherstone  articulated rigid body model,i m working on a project where i need to model a system that is essentially comprised of a series of ball and socket joints attached to a base  which is attached in turn to a prismatic joint  rail    i ve read roy featherstone s rigid body dynamics algorithms cover to cover  and i ve also read the dynamics section from the springer handbook of robotics  also written by featherstone    it took me a long time to get acclimated to using his  spatial vector  and  spatial matrix  notation  but after re creating all of his notation by hand as an exercise it works out to just be a nice way of concatenating  x  and  x  matrices and vectors into  x  and  x  matrices and vectors  the maths he invents to perform operations can be a bit tedious to read as he hijacks some standard notation  but overall everything is very compact  very easy to implement in matlab   my problem is this  how do i add actuators to the model  he walks through explicitly configuring the joint definitions  link definitions  etc   but when it comes to actuators or applied forces he says something like   just add a  here and bob s your uncle     it s not discussed at all  in the handbook of robotics he suggests introducing a false acceleration to the fixed base to add the gravitational force term  but doesn t show how to add it in local coordinates nor does he mention how to add the actuator input   any help would be greatly appreciated  i ve considered starting over with a different book  but it s going to be a great expense of my time to re acclimate myself to a different set of notation  i d like to move forward with this  but i feel like i m just a few inches shy of the finish line   ,actuator dynamics joint
7287,odometry vs dead reckoning,in terms of robotics  what are the differences between odometry and dead reckoning  i read that odometry uses wheel sensors to estimate position  and dead reckoning also uses wheel sensors  but  heading sensors  as well  can someone please elaborate on this point for me  thanks ,odometry deduced-reckoning
7288,linear motion control for quadrotor  clarification ,i ve posted a question regarding this matter that i couldn t solve  i m reading this paper  the authors state   linear  and  motion control  from the mathematical model one can see   that the motion through the axes  and  depends on   in fact  is   the total thrust vector oriented to obtain the desired linear motion    if we consider  and  the orientations of  responsible for the   motion through x and y axis respectively  we can then extract from   formula      the roll and pitch angles necessary to compute the   controls  and  ensuring the lyapunov function to be negative   semi definite   see fig       the paper is very clear except in the linear motion control  they didn t explicitly state the equations for extracting the angles  the confusing part is when they say   we can then extract from   formula      the roll and pitch angles necessary to compute the   controls  and   where formula      is  u  x     frac m  u        cos phi  sin theta  cos psi    sin phi  sin psi     u  y     frac m  u        cos phi  sin theta  sin psi    cos phi  cos psi      it seems to me that the roll and pitch angles depend on  and   therefore we compute the roll and pitch angles based on the  and  to control the linear motion   ,control quadcopter
7291,stereo vision in matlab,i am working on a project about robot soccer vision   how i utilize two webcams as a stereo vision in matlab for robot soccer matters  ,stereo-vision matlab soccer
7294,dispensing precise quantities of liquid and powder,i ve been toying around with the idea of automating the process of testing aquarium water for certain chemicals  very briefly  salt water aquariums  reefs  specifically  require almost daily testing for     chemicals  calcium  alkalinity  ammonia  phosphate   this is typically done by hand  using various kits  there are two main types   you combine several powders with a fixed amount of aquarium water  and then compare the color the mixture turns with a chart you combine several liquids together with the aquarium water  and then add another liquid until the mixture turns a color  you then record how much of the final liquid you had to add for the color change to occur  titration    both methods are straightforward  but tedious  to maintain an aquarium well  you really do need daily readings of all of those metrics  which easily adds up to    minutes  daily  so   i d like to be able to automate the process  the biggest question is  how do i reliably dispense the materials needed  we re talking in gram and milliliter uom here  the kits come with plastic syringes and spoons of correct volume for the powders  i need a way to measure out and dispense both of these  and a way to queue up several days worth  refilling daily defeats the purpose   any ideas  edit this is different from how to measure and dispense a finite amount of powder or liquid because of the units of measure involved  i need to be able to reliably dispense    g        of a powder  or  ml        of liquid  ,electronics
7295,help with ultrasonic sensors on obstacles avoiding robot,well  i will start directly in my problem  i m working on a project and i only have    days left  the idea is simple  a wheeled robot with   ultrasonic sensors to avoid obstacles  i ve developed a code and it s working fine  i m using  arduino uno  l   d driver for the   dc motors    hc sr   ultrasonic sensors and the newping library  i ve made some kind of a shield where i soldered common points for gnd and  v in order to connect the l    ic and the sensors pins easily  the problem is that the ultrasonic sensors only functioned once in the expected behavior  after that they were always sending the zero result and sometimes a number is showed when i disconnect the sensor   is it a power problem  i m using the usb cable to power the arduino and the sensors  motors are powered using   li po batteries  kindly provide me with guidance ,arduino power ultrasonic-sensors
7297,arm to disassemble and assemble notebook at home ,suppose i have perfect ai to control robotic arm   what characteristics should it fulfill to be able to take such common tools as screwdriver and linesman s and disassemble and then assemble conventional notebook computer  are there such models available  is seems to me  that such arms as owi     are only toys  i e  they can just relocate lightweight objects and that s all  am i right  update also suppose that my ai can look at assembly area with multiple hd cameras and can perfectly  understand  what is sees  ,robotic-arm
7308,how to control a dc motor,i have   of these   v motors and a   v battery  i would like to know what the best solution for controlling this motor with an arduino uno would be  does the motor controller need to have a maximum current of    a  i though of a    a transistor connected to the pwm pin of arduino  and then  control the motor with pwm  is voltage regulator better than pwm  ,motor esc pwm microcontroller
7311,how can i make a compact soft robot,i want to make a compact  actuators motors and sensors are all in one  soft robot  actuators can be pneumatic or dielectric  i need suggestions about manufacturating  i m open to new ideas  ,actuator manufacturing
7315, nm small motor,currently designing a spherical wrist  i want to manipulate a    gr payload  the design has a    mm span  so i m guessing at a    nm  considering the weight of structure   motors    i ve looked at maxon  faulhaber  but can t find any motor gearbox encoder under a    gr  any suggestion   ,motor actuator torque
7316,how can i make a motion tracking camera ,i m looking into cctv  and am interested in minimising costs by having a motion tracking camera cover an area that would otherwise utilise multiple cameras  there is already something like this on the market manufactured by a company called nightwatcher  i think    however  it does not track  it merely senses using   pir s and points the camera in   of   positions  ping ponging between them if the subject is between sensors  i like the idea of this  but not the drawbacks  and was wondering if there was anything i could do with an arduino or similar to achieve a better result  i stumbled across this  but am not entirely sure about it  also this is for outside application  and that thread is for indoor  if that makes a difference    edit    just in case i have mislead you  i want to have a unit where sensors detect movement and then a camera to face that position  ,cameras
7317,vacuum lifter  moving playing cards,i d like to buy a small vacuum lifter so that i can move playing cards around with robotics  but my  google fu  is failing me  i don t really know what search terms to look for    or what webpages to look to find this kind of component  in essence  i want an electronic version of a vacuum pen  i don t really know where to search for this kind of component  i ve found pneumatic valves and other complicated machinery    but ideally i d want a self contained electronic vacuum pen  since i m only planning to move playing cards around  anyone have an idea where to look for something like this  thanks  ,robotic-arm actuator
7320,position estimation from photo fingerprinting,i want to make  d position and position change estimation from photos taken from flying robot  i need suggestions for fast photo matching   ,localization
7327,how to transfer signed integers with libusb ,folks at programmers stack exchange asked me ask here  i want to communicate with an arduino and sent integers it  i code this program in c    i initialy used bulk transfer    but it sends only char data  this in the api reference for libusb   here is the prototype of bulk transfer   int     libusb bulk transfer  struct libusb device handle  dev handle  unsigned char endpoint  unsigned char  data  int length  int  transferred  unsigned int timeout  as you can see  data is an unsigned char pointer  that is  a pointer to a buffer containing length unsigned chars  i can successfully transcieve strings  how do i transfer integers with sign  currently i am thinking about a system in which the arduino asks for the digit by sending a character and my program sends the number as reply followed by the sign  which is requested next  is this solution viable  or should i transfer the integer as a string  is there a better way  ,arduino communication usb c++
7331,position control for linear model of quadrotor  problem with tracking task ,lately  if you notice i have posted some questions regarding position tracking for nonlinear model  i couldn t do it  i ve switched to linear model  hope i can do it  for regulation problem  the position control seems working but once i switch to tracking  the system starts oscillating  i don t know why  i have stated what i ve done below hope someone guides me to the correct path   the linear model of the quadrotor is provided here which is    begin align   ddot x        g  theta                            ddot y          g  phi                            ddot z         frac u      m    g     ddot  phi      frac l  j  x   u         ddot  theta      frac l  j  y   u         ddot  psi      frac    j  z   u         end align   in this paper  the position control based on pd is provided  in the aforementioned paper  from     and     the desired angles  and  are obtained  therefore     begin align   theta  d       frac  ddot x   d   g       phi  d           frac  ddot y   d   g   end align   where    begin align   ddot x   d     kp x  d    x    kd   dot x   d     dot x        ddot y   d     kp y  d    y    kd   dot y   d     dot y       u        kp z  d    z    kd   dot z   d     dot z       u        kp  phi  d     phi    kd   dot  phi   d     dot  phi       u        kp  theta  d     theta    kd   dot  theta   d     dot  theta       u        kp  psi  d     psi    kd   dot  psi   d     dot  psi        end align   with regulation problem where  and   the results are    now if i change the problem to the tracking one  the results are messed up     in the last paper  they state   a saturation function is needed to ensure that the reference roll and   pitch angles are within specified limits   unfortunately  the max value for  and  are not stated in the paper but since they use euler angles  i believe  in this range  and  in this range  i m using euler method as an ode solver because the step size is fixed  for the derivative  euler method is used   this is my code   for the trajectory code clear all  clc   fileid   fopen  xytrajectory txt   w      angle    pi  radius      z      t       for i              if   z                z   z                x               y          end     if    z                angle   angle                angle   wraptopi angle           x   radius   cos angle           y   radius   sin angle           z          end      x i    x      y i    y      z i    z       fprintf fileid   f  t  f  t  f n  x  y  z   end  fclose fileid   plot  x y z  grid on  ,control quadcopter matlab
7333,why do my escs stop working ,i m new to robotics and this is my first time building a quadcopter   i m unable to work out why i keep losing escs  most recently in testing  i ve managed to calibrate all   escs and accurately control the speed of all   motors   but after neatly securing them to the frame    motor didn t work   i recalibrated the escs again and  when running them again  the motor still didn t work   however  the other   motors continued to run at first  but also suddenly just stopped altogether  research suggested that escs have a cut off voltage  indicating that my battery might be too flat  so i immediately looked to recharging it  to my surprise  the  still very new  battery appeared to have bulged out  indicating that it had been damaged  further research suggested that the size of the battery i was using is insufficient for the amount of current drawn by the motors   so  without any pwm applied  i reconnected a new fully charged battery in the hope of listening for any beeps to diagnose  and one esc immediately coughed up a huge puff of smoke  before all of this happened  i only managed to get   of the escs to run their motors   despite several attempts at tweaking pwm signals and calibrating them  i ended up replacing the other    unless there s some obvious reason for my escs to keep dying on me  i can only assume that these specific escs are badly made and i should ask for my money back  these are the components i m using   raspberry pi   model b adafruit    channel    bit pwm servo driver   i c interface   pca     rctimer mini esc   a opto blheli firmware  oneshot     support    s  rctimer            kv outrunner brushless motor gens ace     mah     v   c  s p lipo battery pack  the raspberry pi is powered through its micro usb interface by a  v step up voltage regulator connected to a     mah    v lipo battery   the pwm controller is powered to its vcc pin by the gpio      v  pin from the raspberry pi  that also happens to power other sensors  at the time  when all   motors worked   i was able to accurately control them at either   hz or    hz with     millisecond duty cycles  ,quadcopter power esc pwm
7334,mechanical design for base of robotic arm,i am using dc motors to build a robotic arm   i want to make the base shoulder  which rotates and lifts  more stable and stronger   how should i design this using dc motors  also i would like to put the motor for the elbow in the base for efficiency   which design best suits this   update i am building a robotic arm for a payload of approx      kg and using dc high torque motors  in this model  i am using only a shoulder with a gripper  the gripper is self made by me weighing approximately     grams  i want to have a proper design and material choice so that the shoulder part remains less heavy and more stable  in addition to this i want to operate the movement of the gripper  i e  the up and down motion  by using the motor in the base part  what should be my design and better alternative  ,robotic-arm design
7339,driving a non circular timing belt,i d like to create a camera slider similar to this one   the only part i m not sure on is how to setup the camera drive   it looks like i can buy a similar timing belt here  but i m not sure how to set up the servo to drive the slider   particularly how to keep the belt in contact with the drive pulley   my fabrication skills are very limited so i need a simple or out of the box solution  ,servos
7344,image based  d position estimation with one camera,there is too many  d position estimation with one camera  is there any  d position estimation application or technique with one camera  if there is no application or technique why  ,localization
7349,arduino triggers a camera to start recording,i ve already made an arduino device which detects the trigger event  but now i want it to trigger the recording and storage of video when this event occurs   if the camera could be wirelessly triggered a few feet away from the arduino unit  that would be optimal  but i can settle for running wires if need be  i m looking for suggestions because i m on a limited budget for this project  i want to avoid reinventing the wheel and ordering parts which i can t get to work with an arduino  i m considering the use of this camera   this is my first arduino project   any help is very welcome  ,arduino wireless
7358,suggestion for a camera,are there good low cost cameras that are frequently used in robotics  i am assuming there are cameras that are good fit for robotics      works well with opencv pc windows support   usb  usb   gige  usb  vision cameras seem pricey  good image sensing performance adjustable focus   manual or motorized  fine focus control would be great   do ip cameras make good cameras for robotic vision projects  ,computer-vision cameras
7359,interfacing gpu image processing with motor control at    hz,i would like to make a robotic system which takes as input a video feed  runs some gpu based image recognition on the video  and outputs commands to a set of motors  the goal is to have the motors react to the video with as little latency as possible  hopefully of the order of   s of ms  currently i have a gtx    m on a laptop running ubuntu        which is connected to the camera and doing the heavy image processing  this takes frames at   hz and will output motor commands at the same frequency  after a few days of looking around on the web for how to design such a system  i m still at a loose end whether  a  it is even feasible  b  if so  what the best approach is to interface the laptop with the motors  the image processing must run on linux  so there is no leeway to change that part of things  ,control real-time
7361,idea for web application in robotics,i am learning and i am interested robotics  but also i need to update my web development skills so the question is   is there any idea for good web application that could be connected with robotics   service robots  industrial robots etc  maybe there already is some open source ongoing web application projects for robotics in which i can make contribution  thanks  ,design software
7363,what is the difference between multiple robots and swarm robots ,what is the difference between multiple robots and swarm robots  what is the key point  also what is multi agent systems  do multi agent systems works only for computer simulations or games  these terms are used similar applications  ,simulation multi-agent swarm
7378,electric piston  longitudinal electric motor  ,are there electric motors  which apply force not in rotational motion  but in longitudinal motion  they should have electromagnetic design and no gears and worms  such motors would be great for linear actuators  they could transfer both force and feedback  what is the name of such devices  ,motor actuator
7383,determine the configuration space for a robotic arm,i m working with a  dof parallel mechanism arm  i m interested in writing planners for this arm  prm or rrt  in the configuration space  but i m not sure how to identify obstacles collisions   when writing planners for mobile robots in a  d workspace  it was easy to define and visualize the workspace and obstacles in which the planner robot was operating  this website  link  shows a great example of visualizing the workspace and configuration space for a  dof arm  but how can i do this for higher dimensions  ,robotic-arm motion-planning
7384,how can a memory alloy be used as an alternative to a compressor found in a refrigerator ,i m curious about this alloy and how they say it can be used as an alternative to a traditional compressor  can anyone explain how this would work  my goal is to understand that use case so i can adapt alloys in other robotic projects   my gut tells me this is perfect for some kinematics  or other mechanisms  but i m missing some pieces in this puzzle  how would it work   ,kinematics mechanism
7385, d scanner from phone camera,   d software can construct a  d model from photos taken from your phone  it doesn t process the photos in your phone   instead  it sends them to the cloud to create  d model  how can i construct a  d model like this  only with one camera   i searched it but i can only find information on laser procetor scanners  simple and desktop use only   i think    d uses only imu sensors and camera why do they use the cloud   can a beaglebone or rasperry pi create  d models like this  ,computer-vision 3d-printing 3d-reconstruction 3d-model
7386,introduction to robotics mechanics   control  john j craig    rd ed   forward transformation problem examples     and    ,i am reading the book  introduction to robotics mechanics   control   john j craig    rd ed   forward transformation problem examples     and      ex       page      frame  b  is rotated relative to frame  a  about x axis by    degrees clockwise  translated    units along y axis and    units along z axis  find p in frame  a  where p in frame  b            the book s answer is                   but my answer is                    ex       page      vector p  has to be rotated by    degrees clockwise  about x axis and translated    units along y axis  and    units along z axis  if p  is given by          find p   essentially ex     and     are the same problem  however  the transformation matrix for ex      has         as translation vector  the  th column of t  instead of            and  the given answer is                   i am not sure if it is just typo  or i am missing some genuine operation  please let me know your opinion  thanks  ,forward-kinematics books
7387,hector slam  matching algorithm,i m trying to understand the scan matching part of hector slam  ppt summary   it seems a little difficult to understand  in some cases  how is it possible to actually perform the alignment of the scans  can anyone explain about it  in my case  i m working with a simulation  i m moving my robot in a corridor like featureless environment  only two walls  and i don t get a map  nevertheless  if i move in a sinewave motion  i m able to get a map  moreover  if i have an additional feature  the algorithm even shows the real path as long as this feature is seen  right part of the image   otherwise it shows a very weird looking oscillatory path which does not resemble a sinewave at all  something important to notice is that the width of the map is pretty accurate  real  m  map s      m   and the length of the movement is also somehow accurate  real   m  map s          i m using a hokuyo urg   lx laser range finder  no odometry  no imu  i m running in ubuntu       and using ros indigo   i more or less understand how hector works  but i have no idea about why i m getting this map and specially trajectory  thank you  ,localization slam ros mapping rangefinder
7388,fingerprinting  model matching algorithms for localization,this paper mentioned the fingerprinting model matching case  but i could not find an image based algorithm  any suggestion about image based localization ,mobile-robot localization
7389,robotic arm for playing chess,i wish to build a chess playing robot with robot arm as shown on youtube  can anyone please tell me which robot arm would suit my purpose and whether it can be bought second hand or alternatively anybody willing to sell used chess arm robot  please help out  ,robotic-arm
7395,simple wireless connection between two circuits,i m relatively new to robotics  and i m building a project for which i need a simple wireless connection between two circuits such that when the first circuit is switched on  the other circuit gets switched on too  i m looking to preferably build something like this on my own  but i have no idea about wireless connections  i only know basic wired robotics  i also know c   programming if that helps  apologies if such a question has already been asked  regards  hanit banga ,wireless
7397,selecting hardware  stereo camera for beginners,i m looking for some cheap hardware that would offer me results decent enough to continue my experimentation  i ve been looking into how to obtain hardware for learning about stereo vision and  d reconstruction  i found two basic ways    buy   cheap webcams and diy   buy a stereo camera for what i understood little variations in distance and inclination can easily compromise the diff map and so the diy version might end up requiring constant calibrations  however on the other end  so buying  professional  stereo camera range from     euro to infinite  for the moment i trying something in between  like the minoru  d  however the overall performance of the camera looks a bit poor also because it s a      product  however i can t find any more recent product offering a similar solution  can you suggest me what would be the best way product guide to archive decent results without spending a fortune   thank you very much    ,stereo-vision
7398,matlab toolbox  windows  for sick lasers ,does anybody know where i can get a matlab toolbox or functions to work with a sick laser scanner  windows os   i m using a sick ldrs     with ethernet cable  but sopas software does not allow me to program recording times and other specific tasks  any tips are more than welcome   thanks  ,laser matlab
7400,quadcopter force torques duty cycle conversion,after having been determined my control loops for my quadcopter project  i m going to determine the motor commands  pwm duty cycle  from the motor forces torques  i was following the guidelines of this document but when i was trying to do the inverse of the matrix m  page     it has determinant equal to    the procedure is correct  anyone can suggest me some other link for doing this conversion  i have searched in the internet but i haven t found so much about that  thanks the part of the document that i m referring is the following   ,control quadcopter pwm
7403,ekf slam c   code on openslam org,i have been recently working on code for a robot maze solver using laser sensors and odometry data  i went through the pdf available online  and understand the process conceptually  i am a master s student in control so that part wasn t hard but writing the code in c   is the difficult task  the ekf slam codes available on the site  seem a bit advanced since i am a beginner  i couldn t find on the site  maybe missed  the simplest ekf slam algorithm for  d implementation   could anyone guide me to an open source code in c   for  d implementation so that i can build up on it to suit the robot i am working on  ,slam
7406,how do i program the create  ,i just un boxed and set the create   to charge over night  how do i program it  where is the software  daniel ,irobot-create programming-languages
7409,libusb and arduino communication not working,i am doing a line following robot based on opencv  i have my onboard computer an old pandaboard  running opencv  it will calculate the offset from the required path and communicate it to the arduino via usb  then it will do pid optimisation on the data  and adjust the speed of the left and right motors  to my dismay the communication part is not working  and i ve tried hard for a day to fix it with no result  here is the relavent code running on the pandaboard   where imgvalue is the data to be send  this is the code running on the arduino  void loop       serial write  s      if serial available          input tmp   serial read      if serial available          input tmp   input tmp    serial read            input input tmp    mypid compute        adjust the motor speed     what happens when i run is that it will pause at the libusb read operation as the timeout is zero infinity   at this point i ve tried resetting the arduino  but this doesn t help  so how do i make my program respond to this start byte send my the arduino  where did i go wrong  ,arduino communication usb
7411,what is the cheapest way to detect and identify vehicles entering a gate in real time ,i want to detect and identify each of the vehicles passing through a gate   i have the live video feed of the gate which i initially thought to process and detect the number plates with the help of opencv or any other graphics library freely available  the problem is  the size of number plates may vary very widely  and the language the number plates are written with bengali  does not have a good ocr performance at all  the next idea was to put a qr code in the windshield of the vehicles   yes the vehicles supposed to enter the area are private and enlisted vehicles   but i am not confident that i will be able to detect and identify all the qr codes in real time with      accuracy  as the qr codes might get pixelated due to low resolution of video  so can anyone suggest any other cheap way we can adopt to detect and identify the vehicles  can nfc or any other cheap sensors be used for this purpose  ,sensors design computer-vision
7415,quadcopter pid output and duty cycle conversion,i m trying to design two pd controllers to control the roll and pitch angle of my quadcopter and a p controller to control the yaw rate  i give to the system the reference roll  pitch and yaw rate from a smartphone controller  with wifi  in the case of roll and pitch the feedback for the outer  p  loop is given by my attitude estimation algorithm  while in the inner  d  loop there is no reference angle rate  and the feedback is provived by a filtered version of the gyroscope data  as far the yaw rate is concerned  is only a p controller  the reference yaw rate is given by the smartphone  and the feedback of the only loop is provived by the smartphone  this is to illustrate the situation  my sampling frequency is    hz  imposed by the attitude estimation algorithm  that is a kalman filter  that i m using   i have tuned my controller gains with matlab  imposing a rise time of     seconds and a maximum percent overshoot of    with root locus  matlab is able to found me a solution  but with very large gains  like      for p and     for d   i was doing the tuning  using a quadcopter model  for each euler angle  based on the linearized model for quadcopter or instance    ddot  tau  phi   i x ddot  phi        g  phi s     frac i x    s     only in order to have a  reasoned  starting point for my gains  and then re tune it in the reality   the transfer function above is continous  in my model i have obliviously used the discrete version at    hz of sampling rate    this is to do a premise of my following questions  now  i have to map my controller outputs to duty cycle  since i m using a pwm at   khz frequency  my period  in the tim channel configuration  is of       i have checked the activation threshold  after which the motor starts move  and the threshold after which it stops increasing its speeds  and the first is     and the second is       i was following the very good answer of quadcopter pid output but i still have some questions     as far the throttle mapping is concerned  i have to map it in such a way that the values coming from my smartphone controller  in the interval           are not mapped in the whole             interval  but i have to  reserve  some speed in order to allow the quadcopter to have an angular movement exploiting differences in the   motor speeds even with      throttle     coming back to the fact that matlab propose me huge gains for my controllers  this leads to the fact that i cannot directly sum the controller output to the duty cycle as stated in the metioned answer  because i will certainly go out of the             bound of my tim pulse   doing a proportion will result in altering the gains of the systems  so placing somewhere else the poles of my systems and the procedure done with matlab will became useless  right  so  what i m doing wrong  i have tried to enforce matlab to bound the gainsm for instance in the         interval  but in this case it cannot find gains such that my constraints are verified  thank you ,control quadcopter pid matlab
7416,artificial intelligence software packages  professionals  university education is oft  a step behind  what s actually being used ,currently using windows    what software packages for artificial intelligence programming  robotics branch  are used in today s professional environment as standard  lots of internet suggestions  but companies seem to keep this a closely guarded secret  and are the internet rumors true  would switching to ubuntu offer me more in terms of depth  context  educational field  computer science and artificial intelligence  current focus  though obviously experience in others  in programming languages stands at c    c and python  looking to build  program and develop a human like bot  not aiming for singularity at this point    and am asking this question in order to build my toolbox a little   ,design software artificial-intelligence programming-languages
7423,many to one bluetooth communication link,i have an application that requires data to be streamed from multiple bluetooth modules to one host controller  somewhat like multiple clients and one server   the throughput i am looking at is around      bits per second per module   the spbt    c a at  module only supports spp profile in which i can have a single link  one client one server   my application needs multiple modules   max    to send information to one server    is there a way to have one receiving station and have multiple transmitting module using spp   all modules being the spbt    c a   or i need a different higher end module on the server side which supports multiple spp links  it advisable to look into a module like the bcm     and have a driver run system  ,electronics
7429,is ros hard real time safe ,i know that is a question that has been asked too many times  but still its not clear to me  i read online that it isn t but some people say that they control their robots under ros in applications with hard real time constraints  so  because i need some technical arguments  rather than a plain  ros is not real time   i will be more specific  suppose we have ros under a rtos    i read that ros uses a tcp ip based communication for ros topics and i know that tcp ip is not reliable  that means i cannot use topics in a real time loop  for instance send a control signal to my system publishing it to a topic  and the system sending me some feedback via a topic  if i have a rtos  eg linux xenomai  can i build a real time control loop for a robot using ros  or ros will be a bottleneck   maybe the above are naive or i lack some knowledge  so please enlighten me  note  i define as a hard real time system  eg in  khz   the system that can guarantee that we will not miss a thing  if the control loop fails to run every  ms the system fails   ,ros real-time
7434,what is the achievable stiffness of a impedance admittance controlled robot  incl  haptic devices   given its structural and control stiffnesses ,edit  i realised i missed the point of the paper completely  thanks to very skim reading       so  this part of it i m relating to is about how much damping   not how much stiffness   should we display to obtain stability  given a structural stiffness  i changed the question accordingly   what is achievable stiffness of a impedance admittance controlled robot  given its structural and control stiffnesses   stiffness compliance is  of course  mathematically just one of the terms in total impedance admittance  let us consider a haptic device with mechanical and control parts  and mechanical part is not infinitely rigid  compliant   basically  it would be a robot with impedance or admittance control  i thought perceivable stiffness can be just as simple as serial connection of two stiffnesses   and so the stiffer mechanical structure is  the better it can display control stiffness   where  is stiffness control  still  i cannot find any confirmation to this  although something very similar is stated in samur s  performance metrics for haptic interfaces   i would be very grateful if you could refer me to some sources or just plain prove it wrong or right    in a paper  here  p       i only found stability condition for virtual damping value in relation to virtual stiffness  given structural stiffness  ,control mechanism reference-request
7438,how to make a directed graph ,i m working on an robot that would be able to navigate through a maze  avoid obstacles and identify some of the objects in it  i have a monochromatic bitmap of the maze  that is supposed to be used in the robot navigation   up till now  i have converted read the bitmap image of the maze into a  d array of bits  however  now i need guidance on how to use that array to plan the path for the robot  i would appreciate if you could share any links as well  because i am new to all this stuff  i am just a  st year bs electrical engineering student  and would be happy to have a more detailed explanation  if you need me to elaborate on anything kindly say so  i would be grateful  here s the image of the maze   this is just a sample image  the robot should be able to work with any maze  image  with similar dimensions  and you are welcome  thank you chuck  update heres the code for sub ind in c    kindly see if the output is correct    heres the link to the output file   ,arduino mobile-robot localization mapping planning
7440,matlab control toolbox root locus,i m using the control system toolbox provided by matlab to estimate the gains of my controller  using root locus design i get a graph like this one   my question is  what is the x on the x axis  maybe a pole position at a previous iteration of the optimization procedure that i have run to find a gain value that satisfies my requirements  it shouldn t be the open loop pole position  because my system is formed by two integrators multiplied by a constant    inertia   thanks edit  i add the requested details  i start from the following simulink diagram   my trasfer function is g  theta s     frac y s   u s      frac  theta s    tau  theta      frac    i y s    with iy           another little question  the point in which i m taking out the torque is correct   and then i select analysis   control design  compensator design  i select kp and kd as the gains to be tuned  and i use the root locus for specifying the constraints  then i click in siso design task  automated tuning  optimize compensator  which automatically tries to find gain values to satisfy my constraints  the white are is the area that satisfies the constraints  and i think that the pink squares are my poles position after having been completed the optimization procedure  this is correct  but in this case  what is the x pole  shown  thanks ,control matlab
7445,why pd controllers for quadcopter angles control ,my question is  in a lot of cases it is possible to find in internet pd  instead pid  to control the euler angles of quadcopter  why the integral part is often neglected in this kind of applications  thanks ,control quadcopter pid
7449,changing behaviour roomba    ,i ve seen that it is possible to use some micro controller to send commands to the roomba through the sci but i was more interested in changing the behavior of the roomba operation  e g  change the priority of the behaviours  is there some ide for roomba  regards ,roomba
7450,which math course will be most beneficial ,let me know if this should be on academia instead  but i posted it here to get responses specifically from people active in robotics development  i m currently an undergraduate student completing majors in both mechanical engineering and computer science  i m still fairly new to the field  but my interest is firmly in electronic and mechanical systems  next year i can take one of the courses below   i want to take all three and likely will eventually  but for the time being my schedule only allows for one  therefore  i was wondering if you could explain a little bit about how each is applied to the robotics field and which you believe will be most helpful for me to learn now thanks in advance  ,beginner theory
7454,how to use an imu to hover at a fixed location in a quadcopter in the presence of gravity ,there s an accelerometer in the imu  the output can then be integrated to estimate the position  at least in theory  but in practice  there s a huge acceleration from gravity  which varies rather randomly across locations  vibrations etc can be filtered out with low pass filters  but how do you filter out gravity  is it simply the case that the vertical vector is ignored when doing any calculations  my application is  i want to build a quadcopter that could hover in one place even in the presence of  reasonable  winds  the quadcopter ideally would tilt towards random gusts to maintain a certain position  every single tutorial i could find on the internet only uses the accelerometer to estimate where down is when stationary  and simply assumes that using the gyroscope to hold the quadcopter level is enough   i also want to use the imu to estimate altitude if possible  of course as an input to something like a kalman filter in conjunction with a sonar system  obviously  for my application gps is far too slow  ,quadcopter imu
7456,human arm inverse kinematics,hi i want to implement an human arm robot and a task such as moving a glass between two points  using robotic toolbox for matlab  by peter coorke  i m a student and i m a newbie in this kind of things so i would find a good reference for solving the inverse kinematics of the human arm and  an algorithm that implements some kind of obstacle avoidance exploiting the redundancy of the manipulator   dof  using null space motion   anyone can suggest me a good reference to follow in this implementation with the toolbox  thanks ,robotic-arm inverse-kinematics manipulator matlab
7457,cognitive architectures  how do you perform qualitative and quantitative comparisons ,i couldn t find a sub stackexchange for artificial intelligence  but i think robotics comes close  and so i m posting here  i recently saw ted talks on ai and the google car  with these being the most interesting to me   hod lipson   building  self aware  robots  juan enriquez   the next species of human ray kurzweil   get ready for hybrid thinking  the third one led me to the  criticism  section  labeled  on that wiki article  though it certainly at least partially reads as a criticism section as well  of kurzweil  theory  of the brain  namely  pattern recognition theory of mind   prtm    after some link surfing on the people who have performed analysis of prtm and their respective academic contributions  i came to learn about cognitive architecture    a cognitive architecture can refer to a theory about the structure of   the human mind  one of the main goals of a cognitive architecture is   to summarize the various results of cognitive psychology in a   comprehensive computer model  however  the results need to be in a   formalized form so far that they can be the basis of a computer   program  by combining the individual results are so for a   comprehensive theory of cognition and the other a commercially usable   model arise  successful cognitive architectures include act r    adaptive control of thought  act   soar and opencog    it appears that there are several interesting architectures  including the   mentioned above   i read a bit about act r  soar  opencog  dual  chrest  and clarion   the list is not comprehensive   it also appears that there are two main types of such architectures  connectionism and symbolic  though i have many questions  my main question is this  what are some quantitative metrics and qualitative properties to measure and compare between the two architecture types  other questions  can all architectures be categorized as one  the other  or some combination of the two  or is there a third  fourth  etc   how are two main types alike  how are they different  what are some recommended further readings on this topic   what centres and organizations are leading development in this  what are some of the computer programming languages  related skill sets  and cross domain knowledge set utilized in r d and product offerings of such systems   ,artificial-intelligence
7460,how to calculate quadcopter lift capabilities ,i m looking for an equation  or set of equations  that would allow me to predict  with fair accuracy  how heavy a payload a quadcopter is capable of lifting  i assume the main variables would be the weight of the copter as well as the size   power of the   rotors  what general approach can one use to make such a determination  ,quadcopter
7462,how do safety cages around quadcopter rotors blades affect lift capabilities ,i am interested in building a quadcopter from scratch  because i like to err on the side of caution  i m considering adding  safety cages  around each propeller rotor  to hopefully prevent  at least minimize  the chance of the spinning rotor blades coming into contact with someone  without knowing much about the physics behind how  lift  works  i would have to imagine that cages present two main problems for rotors   they add weight to the copter making it harder to lift the same payload  and they re sheer presence surface area makes it harder for the spinning rotor to generate lift and push down away from the ground  the former problem should be obvious and self evident  for the latter problem  what i mean by  surface area  is that i imagine that the more caging around a spinning rotor  the more difficult it will be to lift effectively  for instance  a spinning rotor might have the ability to generate enough power to lift  say   kg  but if we were to construct an entire box  not cage  around the entire rotors  with   sides and no openings  i would imagine its lift capability would drop to  kg  so obviously  what i m interested in is a cage design that provides adequate safety but doesn t  box in  the rotor so much that it causes the rotor to be ineffective or incapable of providing lift  so i m looking for that optimal tradeoff of safety  boxing caging around the spinning rotor  and lift performance  i would imagine calculating and designing this is a pretty huge undertaking with a lot of math behind it  i m just wondering if anyone has already figured all this stuff out  or if anyone knows of a way to model this safety vs lift performance trade off in some way  ,quadcopter
7463,stewart platform as robotic wrist joint,i m planning the design of a wrist for a humanoid robot  i would like to choose a design that is sturdy while allowing for dexterity comparable to a human wrist  one option that was presented to me was to use a stewart platform  this setup appears to correctly recreate all possible movements of the human hand  my immediate concern is that this platform will use a total of six actuators which will require additional power and computational requirements  i don t want to commit to this design until i am certain that there isn t a better alternative  is a stewart platform a good choice for replicating the dexterousness of the human wrist  if not  what is a better solution  ,robotic-arm design actuator joint humanoid
7470, dof inverse kinematics spherical wrist,is it possible to apply kinematic decoupling for a   dof  r manipulator with spherical wrist   if it is possible  can anyone suggest a reference on how to apply this approach with a redundant manipulator with spherical wrist  or explain why it is not possible   i m working with robotic toolbox  matlab  and the numeric algorithm can find the inverse kinematics solution without a problem if i don t specify the orientation   and i was thinking about solving the problem a second time considering the spherical wrist   will this approach work  ,inverse-kinematics manipulator matlab
7472,wiring   driving towerpro sg   servos,i got my hands on a few tower pro sg    g servos but cannot find their schematics or datasheet anywhere  besides that link   i have the following concerns   looks like they re rated for    v  but will they tolerate a  v supply  how do i determine the current they require  in amps  ma  etc   there s   wires  brown  red   yellow orange  what do each of these guys do   if i had to guess i d say that red is power  another one is direction  and another one is the position to rotate to   ,rcservo wiring
7474,how do i accurately calculate the speed of a rotary encoder at a high sample rate ,i m aiming to control a motorized joint at a specific speed  to do this  i m planning on attaching a rotary encoder to do this  i ll be controlling the motor with a pid controller  with this pid controller  i need to control the joints based on their velocity  since   it would make sense to do something like this  double getcurrentspeed         return  currentangle   lastangle    samplingrate     however  there s an issue  the encoder doesn t provide a high enough resolution to accurately calculate the speed  the sample rate is too high   i want to have updated data every      ms  somewhere in that range as my current motors seem to be able to respond to a change in that range  some more information      bit precision  roughly              degrees per  step  of encoder i d like to be able to calculate as small of speed differences as possible as the motors will be going fairly fast       degrees second at highly variable speeds and directions   so the feedback has to be accurate and not delayed at all  so  a couple of ideas   i can find encoders that i can sample at a very high rate  i was thinking about sampling the time between the changes of the encoder s value  however  this seems finicky and likely to be noise prone i could do some sort of rolling average  but that would cause the data values to  lag  because the previous values would  hold back  the output of the calculations somewhat and this would play with my pid loop some noise filter of some sort  although i don t know if that would work given the rapidly changing values of this application  however  none of these seem ideal  is my only option to get a    bit  or higher   encoder  or is there another method combination of methods that i could use to get the data i need  ,motor pid algorithm
7475,can i control more than    servo motor with a raspberry pi,i m trying to make an hexapod with    servo motors and i m asking how to control them with a raspberry pi   never used it   i saw lot s of stuff to control    but           currently i m working on an arduino mega  and a ssc    board  but i found the result to slow and jerky  at this end  i want to add a camera and processing the image  i know an arduino can t handle that process but a raspberry pi can   thank for all information about that subject     ,arduino raspberry-pi cameras servomotor
7483,how to transform x y z coordinates to tx ty tz ,i need to get coordinates of the specific points from  d cad file and transform them so that i could use them to move the robotic arm to those points  the problem is that i only get x y z coordinates and the robotic arm needs x y z tx ty tz coordinates to move to the certain position   any suggestions  edited  my task  i need robotic arm to go through certain points on pcb board and heat soldering paste  i could do it manually by setting points with pendant  but a much easier way would be to get coordinates of those points from cad file and write a code using pc   this is how code for linear motion to a certain point looks like i only could find this manual  this is pendant manual maybe it will be helpful  i am second year student in  robotics and mechatronics   i m currently in a internship at the scientific research institution  i really appreciate your help  ,robotic-arm
7485,matlab  system simulation with dynamic state matrix   input matrix,i have the following system   dot x    a t x b t u y   x  and  are actually scalar  but time dependent  if they would be constant  i could simulate the system in matlab using   lsim sys u t x    however  it would be nice to simulate the system with dynamic state and input matrix  the matrices are based on measurement data  this means i would have for each discrete time step  another matrix   any suggestions how to do that  ,dynamics matlab simulation
7486,how to determine how long a battery will power a robotic circuit for ,obviously robotic circuits draw different amounts of power current  so given the same battery  say  a  v  then connecting it to   different circuits will deplete it at two different rates  robot circuit    might drain the battery in   minutes  robot circuit    might drain the battery in    minutes  what ratings do batteries have that allows us to figure out how long it will power a circuit for  bonus points  does this same rating uphold for solar panels and  in deed  all power supplies  not just batteries   ,power battery circuit
7489,understanding how solar panels can supply power to robotic circuits,say i have this solar panel that outputs  v at    ma  or       watts  if i connect that to arduino  which expects a  v supply at  roughly    ma  then the arduino as a whole requires  v      a        watts to power it  to me  if i understand this correctly  then in perfect weather sunlight  the solar panel will power arduino all day long  no problem  now let s say we wire up   motors to the arduino  each of which draw     watts  now the arduino     motors are drawing       watts  but since the panels are still outputting      watts  i would think that  again  under perfect sunlight  the panel would power the arduino and motors all day long  no problem  now we add   more motors to the arduino circuit  for a total of   motors  the circuit is now drawing      watts     w        watts  i would expect the solar panel to no longer be capable of powering the circuit  at least properly  my first concern here is  am i understanding these   scenarios correctly  if not  where is my understanding going awry  assuming i m more or less on track  my next question is  can solar panels be  daisy chained  together to increase total power output  in the third case above  is there a way to add a second solar panel into the mix  effectively making the two panels output      watts            watts  which would then make them capable of powering the arduino and its   motors  yet again  assuming perfect weather sunlight conditions   ,power circuit
7491,wiring necessary to route power from any one of several rechargeable batteries,i m looking for my robotics project to draw its power from one of   rechargeable batteries  basically whichever has the most  juice  in it  from the initial research i ve already done  i believe i could connect each rechargeable battery  probably lipo  to a diode  and then wire each of the   diodes in series  however  being so new to robotics electronics  i guess i wanted to bounce this off the community as a sanity check  or to see if there is a better way of achieving this  again  what i am looking for is a way for the circuit to automagically detect that battery    has more power than battery     and so it  decides  to draw power from     the instant    is depleted or deemed  less powerful  than     the    battery takes over  thoughts criticisms  ,power battery wiring
7493,discover vector angle between stereo camera pose and vehicle body,i have a calibrated stereo camera system that is mounted in a passenger car which means i am able to retrieve a point cloud from my stereo image  however  i need to find how well is the camera aligned with the vehicle   read  if the camera is perfectly facing forwards or not  i guess it will never perfectly face forwards so i need to get the angle  or rather  d vector  between  perfect forwards  and  actual camera pose   what came to my mind is to drive the vehicle possibly perfectly forwards and use stereo visual odometry to detect the angle of vehicle movement as seen by camera  which is the vector i am looking for   the libviso library for visual odometry can output a  d vector of movement change from one stereo frame to another which could be used to detect the needed vector  the only problem may be to actually be able to drive perfectly forward with a car  maybe an rtk gps could be used to check for this or for correction  will anyone have a suggestion on how to proceed  the stereo camera i use consists of   separate point grey usb cameras  each camera is mounted on a windshield inside the car with a mount like this one  the cameras were calibrated after mounting  the stereo baseline  distance between the cameras  is about    cm  ,stereo-vision odometry
7494,spring with electronically adjustable stiffness,i would like to build a mechanical module that acts like a spring with electronically controllable stiffness  spring rate   for instance  let s imagine a solid  metallic cube      m each side  on the top side of the cube  there is a chair sitting on top of a solid mechanical spring  when you sit on the chair  it would go down proportionally to your weight  and inversely proportional to the spring s rate   what i want is that this spring s rate be electronically adjustable in real time  for instance a microcontroller system might increase the spring s rate when it detects a larger weight  i m using this example to best describe what i want to achieve because i m not a robotics specialist and i don t know the inside terms  is there already an electro mechanic module as the one i m describing   obviously nevermind the cube and the chair  it s the spring i m interested in   ,actuator
7497,torque of coreless dc micro motor,i would like to build a small two wheeled robot similar to the one shown here  in order to keep the robot small  i intend to use two coreless micro motors like the one shown bellow  the power source would be   aaa or aa batteries  in order to reach   v  these batteries would represent the bulk of the weight of the robot  the rest of the robot would be virtually weightless  the specifications of one of such motor are   my question is if small dc motors of this type have enough torque to even make the robot start moving  i have been unable to find torque info on these kind of motors and i suspect the weight of the robot could be too much for them to handle  do you know the typical torque of such motor  is there another type of  cheap  motor more appropriate for this project   ,mobile-robot motor wheeled-robot torque
7498,measurement and physics model fusion,i am combining two position measurements of a ball from two sensors in real time to obtain one triangulated position in x y z coordinates  as the data exchange of the measurements carries some latency  the data has to be extrapolated be able to obtain the current position  due to extrapolation an error appears in the triangulated data  i know that when the ball is in the air  the velocity of the ball should be constant in x and y directions and the velocity in the z direction should decay with g  the velocities in x and y however oscillate as function of time around a mean value which is the actual x respectively y velocity  the same goes for when i compute the acceleration in the z direction  it oscillates as function of time around g  given that i know how the ball should behave  i e  that vx and vy should be constant and that the acceleration in the z direction should be z  how can i impose these conditions to better estimate the triangulated position   ,sensor-fusion
7499,can i use bipolar stepper motor driver to drive unipolar motor in unipolar configuration ,can i use bipolar stepper motor driver to drive unipolar motor in unipolar configuration   ,stepper-motor stepper-driver
7502,control both velocity and position  linear actuator ,i am trying to control the velocity position of a linear actuator  at this moment i am able to control the position or the velocity  but i m trying to control both  what the control has to do  let the linear actuator drive to a position i e    to     cm with a constant velocity of  cm s  i control the actuator using a pwm signal  and i measure the velocity and position using a position sensor on the shaft  what kind of control is preferred  pid in cascade  if so what would the code look like  any other kind of control would function better  thanks in advance  edit  a more describing picture   i want a velocity controlled position controller  hopefully this will make it clear edit my first try is with a trapezoid wave  maybe there is an easy way without to much calculation power to change it a s curbe  then the accelartion jerk will be alot smoother          i let the microcontroller calculate   different formulas afterwards it will calculate it using loop iteration  this way i can use one pid for the position  the parameters in the following code will fictional   a big problem with the code above is that the amount of accelartion loops is a constant  it can not be changed except when you already know the amount of loops it will take  i will be using two separate arduinos  they will be connected using a can bus connection  anyway  they won t communicate through it unless the load becomes too high  this will make master slave impossible  also the system has to be modular  adding another actuator to circuit won t be a problem  the actuator is speed controlled by using a pwm signal  the linear sensor will deliver a     v signal which i will reduce to    v by a simple voltage divider  the loop will be around   to    ms  will depend on the maximum looptime  arduino has a    bit       adc but use of oversampling i will probably try to increase it to    bit  to not decrease the reading speed i will decrease the prescaler of the adc  the pwm output is   bit       i am trying to find a way to further increase  because i think     steps are too low for my application  because the arduino has limit internal memory  pre calculating all the positions is impossible  thank you all for the help so far  ,arduino pid microcontroller
7506,converting a  d array of bits to a connectivity map  code debugging ,i m working on an robot that would be able to navigate through a maze  avoid obstacles and identify some of the objects  boxes in which it has to pot the balls   in it  i have a monochromatic bitmap of the maze  that is supposed to be used in the robot navigation  up till now  i have converted read the bitmap image of the maze into a  d array of bits  right now i am writing a code that should convert the  d array  that represents the maze  into a connectivity map so that i could apply a path planning algorithm on it  mr   chuck has helped me by providing a code in matlab  i have converted that code into c    however the code isn t providing the right output  kindly see the code and tell me what i am doing wrong  i am sharing the link to the  d array that has been made  the matlab code  and my code in c   to convert the array into a connectivity map  link to the  d array    matlab code    code in c     int   digraph   null  digraph   new int           for  int i      i         i          digraph i    new int           for  j      j       j          for  z      z       z                  currentpos   sub ind j  z           digraph currentpos  currentpos               new addition                 if   z                                  destpos   sub ind j  z                   digraph currentpos  destpos    bitarray j  z    bitarray j  z                      if   z                                  destpos   sub ind j  z                   digraph currentpos  destpos    bitarray j  z    bitarray j  z                      if   j                                  destpos   sub ind j      z               digraph currentpos  destpos    bitarray j  z    bitarray j      z                  if   j                                  destpos   sub ind j      z               digraph currentpos  destpos    bitarray j  z    bitarray j      z                       ofstream connectivitymap  connectivitymap open  digraph txt     for  int l      j        l       printing only     elements       for  int k      k        k                  connectivitymap    digraph l  k                   ,mobile-robot localization mapping planning
7507,circuit design and simulation,i want to design some circuits of my own  my area of expertise is in computer science engineering  i have listed out the components which are essential in the circuit  i want a software which can be used to design and simulate circuits for real time projects  please suggest me the best among them  thank you   akhilrajagopal ,software electronics
7510,improving velocity estimation,i have a sensor reduction model which gives me a velocity estimate of a suspension system velocity      this suspension system estimate velocity is used to calculate another velocity velocity    via a transfer function plant model  can i use velocity   to improve my velocity estimate  velocity    through kalman filtering or through some feedback system     v  is  estimated  using these two sensors that is fed into a geroter pump  fs in diagram  which pumps fluid to manupulate the damper viscous fluid thereby applying resistance to the forces applied to the car body  there is no problem did i have an velocity sensor on the spring i could measure it accurately but now i only have an estimate  i am trying to make the estimate better assume i have a model plant or transfer function already that gives me the v  given a v   ,control sensors pid kalman-filter
7513,what are the frequencies used for within drones ,what are these frequencies used for within the drone technology  and why these values      mhz     mhz     mhz     ghz     ghz  ,quadcopter wireless radio-control
7517,need help regarding ekf in monoslam,i am trying to understand the implementation of extended kalman filter for slam using a single  agile rgb camera   the vector describing the camera pose is    begin pmatrix  r w    q w     v w     omega r    a w     alpha r  end pmatrix   where         d coordinates of camera w r t world      unit quaternion describing camera pose w r t world      linear velocity along three coordinate frames  w r t world      angular velocity w r t body frame of camera  the feature vector set is described as    begin pmatrix  y      y        vdots    y n  end pmatrix   where  each feature point is described using xyz parameters  for the ekf acting under an unknown linear and angular acceleration    the process model used for predicting the next state is    begin pmatrix  r w   v w delta t    frac       bigl a w   a w bigr  delta t      q w  bigotimes q w bigl  omega r delta t    frac       bigl  alpha r    psi r bigr  delta t   bigr       v w    bigl a w   a w bigr  delta t    omega r    bigl  alpha r    psi r bigr  delta t    a w   a w     alpha r    psi r  end pmatrix    so far  i m clear with the ekf steps  post this prediction step  i m not clear how to perform the measurement update of the system state  from this slide  i was under the impression that we need to initialize random depth particles between    m to  m from the camera  but  at this point  both the camera pose and the feature depth is unknown   i can understand running a particle filter for estimating feature depth if camera pose is known  i tried to implement such a concept in this project  where i read the camera pose from a ground truth file and keep triangulating the depth of features w r t world reference frame i can also comprehend running a particle filter for estimating the camera pose if feature depths are known   but both these parameters are unknown  how do i perform the measurement update  i can understand narrowing down the active search region for feature matching based on the predicted next state of the camera  but after the features are matched using ransac  or any other algorithm   how do i find the updated camera pose  we are not estimating homography  are we  if you have any idea regarding monoslam  or rgb d slam   please help me out with understanding the ekf steps   to be more specific  is there a homography estimation step in the algorithm  how do we project the epipolar line  inverse depth or xyz  in the next frame if we do not have any estimate of the camera motion  ,slam ekf
7519,structuring ekf to estimate pose and velocity with odometry inputs,i have a differential drive robot for which i m building an ekf localization system   i would like to be able to estimate the state of the robot  where  represent the pose of the robot in global coordinates  and  are the translational and rotational velocities  every mobile robot kalman filter example i ve seen uses these velocities as inputs to prediction phase  and does not provide a filtered estimate of them   q  what is the best way to structure a filter so that i can estimate my velocities and use my measured odometry  gyroscope  and possibly accelerometers  adding  and  to my state  as inputs   my intuition tells me to use a prediction step that is pure feedforward  i e  just integrates the predicted velocities into the positions   and then have separate updates for odometry  gyro  and accelerometer  but i have never seen anyone do this before  does this seem like a reasonable approach  ,localization kalman-filter gyroscope odometry
7521,calculate required motor torque through harmonic drive,i have a term project which is controlling a two link manipulator with harmonic drive installed at each joint  to control  i used computed control method to determine the torque needed for each joints based on the formula     tau i  m  theta   ddot  theta i  k d dot e  k pe  v g   to calculate the torque that each motor needs to produce through harmonic drive  i use    tau  motor    j m j g  rho ddot  theta i   frac  tau i   rho eta g  where    and  are gear ratio and efficiency of the harmonic drive   and  are the motor and gear inertia  respectively   after these calculation  i can see the effect of harmonic drive in the system by comparing input torque from motor in the model with harmonic drive    to that torque in the model without harmonic drive     but my professor doesn t agree the formula  i used  he want me to include the stiffness  of the harmonic drive  this is what i have done p s  this model which consists of two link manipulator harmonic drive at each joint is built in matlab    can anyone suggest me the formula about it   thank you so much  ,actuator manipulator
7522,highspeed with gearbox or low speed for brushless motor ,i m attempting to control a small vehicle at relatively slow     m s     m s  speeds  but with extreme accuracy   mm   for the drive system  i m considering using brushless motors as they have a much greater power   volume ratio than i am able to find with brushed motors  especially at this small size  i will be using wheels between    and    diameter  so the rpm i will be looking for is between           rpm at max  this would suggest either driving the motors at a low speed directly  or driving them at a high speed and gearing them down  as i understand it  both setups will give high torques  as brushless motors decrease torque with speed  with brushed motors  it s quite obvious that a gearbox is necessary as otherwise there is no torque in the system  but here the choice isn t as clear  which is why i am asking  tl dr use brushless motors at high speed with gearbox or low speed  ungeared  for high torque   low speed   high precision application  ,motor brushless-motor
7533,which middleware for ipc and multi threading in a autonomous robot ,aim  to use multi threading and inter process communication ipc  when coding an autonomous robot  platform  embedded linux  yocto  constraints   limited cpu power  we are building an autonomous underwater vehicle  to compete in the robosub competition  this is the first time i am doing something like this  i intent to use a middleware like ros  mira  yart  moos etc  the purpose of using one is that i want to modularise tasks  and divide the core components into subsystems  which should be run parallel by multi threading   but i have limited computational power  a dual core omap soc   and the middleware  while robust should also be very efficient  i need to use a middleware  because i don t want the program to be run on a single thread  my cpu has two cores  and it would be great if i could do some multi threading to improve performance of the program  the middleware will provide for me the communication layer  so i don t have to worry about data races  or other problems associated with parallel processing  also i have no prior experience writing multi threaded programs  and so using parallel processing libraries directly would be difficult  hence imo  middlewares are excellent choices  in your experience  which is the best one suited for the task  i don t really want to use ros  because it will be having a lot of features  and i wont be using them  i am a computer science student under graduate freshman  actually  and don t mind getting my hands dirty with one which has not that much features  that s true if only it will take less toll on the cpu  ,ros communication underwater operating-systems
7534,on board monocular odometry for quadcopter stabilization,has anyone done this with ekf pid on a small microcontroller  or know of code snippets to help implementing this  ,quadcopter odometry stability
7535,detecting the presence of a person in a room,i am working on my first hobby project and i m not very familiar with sensors yet  i am trying to build a system which detects the presence of a person in a small room with a single entrance exit door  the idea is when the first person enters the room  the lights turn on and any following person doesn t affect state of the lights  after the last person leaves  the lights should turn off  in a programmatic sense  the lights should turn on when present person count is greater than    i have explored my options and found out that infrared sensors are usually used for this type of problem  what i am not sure is how to detect whether person has entered or left  so i would like to ask for some help with this  ,sensors
7537,inverting a transform  reading j craig s book on robotics ,from introduction to robotics by j j  craig  chapter    page no      could anyone explain how that equation was derived formed  i am stuck on this page due to failing to understand where the equation came from  thank you   ,design theory books
7542,starter looking for advice,i m no professional  at    i just became seriously interested in robotics a few months ago and have been researching everything i can since  now that i ve come to understand how far robotics have truly come i have a desire to try to make my own  granted  i know nothing about coding or programming  i have no idea where to begin  and i know it ll probably  the first time at least  be something small rather than a huge life altering project  thus  if anyone could suggest to me good resources for a beginner i d massively appreciate it  ,beginner
7547,lagging sensor data for pid,let s say a pid is implemented and the errors are calculated using the sensor data  but the sensor data lags by certain amount of time because of the overhead  and the lag time is smaller than the sampling period  how well does pid performs  what i am thinking is that pid will calculate errors based on past data  and use that to control  how will using a kalman filter to estimate the actual sensor data help   ,pid kalman-filter
7549,question for those who have experience using stereo cameras module  e g  zed  duo m  bumblebee  etc  ,this is a question for those of you who have experience using stereo cameras modules like the zed  duo m  bumblebee cameras  etc   not tof cameras   i can t find any sample disparity outputs out there on the internet  and i can t find any information on how they perform  basically here are a few things i d like to know to those of you who used any of the cameras mentioned above  and others   what resolution and no  of disparities did you work with   how was the framerate   on what hardware  did the camera have an asic of some sort to produce the disparity maps  or did it require a host  how was the quality   for those who used the zed camera  there is a promotional video on youtube  are the disparity maps really that good  ,cameras stereo-vision
7552,pull down resistor for inter chip and sensor to chip communication,i understand the concept of using a pull up pull down resistor when implementing a button switch with arduino to avoid a floating state  and in fact i have implemented this quite often  but i am not too sure if a pull down resistor is necessary in chip chip or chip sensor communication  i am connecting a coin acceptor to the arduino  common ground   the coin acceptor s output pin gives a short pulse each time there is a coin inserted  so far i am connecting the output pin of the coin acceptor directly to an arduino pin and it works without any problem  is a pull down resistor  on this line  usually required as precaution in this case  also i have the same question when connecting   pins of   separate arduino s  also common ground  so that one arduino can read pulses from the other  thanks in advance for any experience shared  dave ,arduino
7556,mini recorder from rc heli parts,i had a rc helicopter  with video picture  and audio taking capabilities  that recently  died   unrelated to short circuit   the reciever board short circuted  but the board that sent data to micro sd card and had camera mic was fine  i can access the data on the micro sd card through the circuit  with a usb cable  the reciever board sent data via a   wire bundle to the camera board to make it take pictures record audio  is there any way to still do this from my computer  from the usb   and turn it into a mini spy camera   not remotely  jst through a cable  i got this heli a while back so i don t have the heli number but the camera board number is   and the reciever board number is     b rev a reciever board image  camera data board image  ,control cameras circuit
7557,troubleshooting xbox kinect    ,i recently got libfreenect running on my mac and was able to test out  which uses some of the  d capabilities of the depth sensor  i noticed that the kinect would only respond   pick up movement that happened within a range of about     inches in front of the sensor  i thought this may be because the lights where on so i turned them off  it seemed to get a little better but it still only  works  if something is block the sensor almost completely  does anyone know if this is something that can be solved  i know it s an old sensor but i got it for     so i could do some prototyping with it  notes   laser project is on light starts out blinking then goes solid green when not level light goes red rgb camera works but is a little choppy and sometimes shows tears in the picture   freenect glcplview output  snippet    stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected max      data bytes  but got       dropping     stream     expected max      data bytes  but got       dropping     stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      freenect regview output  snippet   stream     invalid magic  dc   stream     invalid magic aaf   stream     invalid magic dddb  stream     invalid magic       stream     invalid magic       stream     invalid magic  b b  stream     invalid magic   eb  stream     invalid magic   f   stream     invalid magic   ee  stream     invalid magic ffff  stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     lost   packets  stream     lost       total packets in     frames            lppf   stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     expected      data bytes  but got      stream     invalid magic  b    stream     lost   packets  found this which gives me the idea that this may be a usb issue  regular receipt of undersized packet  ,kinect
7558,problems about complementary filter imu tuning,i m developing a project consists of an imu controlled by arduino through which you can send via a radio module  the data to the pc of the three euler angles and raw data from the sensors  for filtering i used the code made available by sparkfun  razor ahrs   dof  the code does not provide radio transmissions and is tuned for    hz sampling rate  in fact its parameters are   in this project data is read every   ms    hz  and records of the sensors are set to the accelerometer odr   hz and    bandwidth  with the gyroscope    hz odr  in my project i used a gyroscope different  namely that i used l g    d frequency odr starting at    hz  i set then registers with the    hz  my global data rate is   hz max  beacouse the use of a radio  i read the complete date with a frequency of   hz  how can i tune the ki and kp of my setup  the kp is the period  i have to consider the frequency odr that i set to register in the individual sensors or i have to set the global system sample rate limited to   hz by the radio transmission  ,arduino imu gyroscope sensor-fusion
7560,digital controller design for system with variable sample time,basically i got system with a sensor and an output  i want to apply a digital implemented feedback controller  the problem in this setup is the sensor  the specifications of the module says that the sampletime of the sensor does change in wide range  depending on the usecase  from     second to    second  but it stays constant until the system is disabled  my first approach was tuning a digital pid controller for the longest sampletime  this works fine  even if i change the sampletime to the shortest the system stays stable  which was expected because i m still in roc  the problem now is that the system s response is pretty slow  if i design the controller for my fastest samplingrate the results are satisfying but become instable for the slowest samplerate  which can be explained again by the roc i could use some kind of adaptive predefined gains which i change depending on the samplerate but i was wondering if there are  control strategies which are able to handle the sampletime changes  edit   to give a better overview i will add some details   i m talking about a heating system which heats with radiation  as a sensor i use a pyrometer module with a samplingrate of up  khz  the problem is  that the pyrometer is not able to produce reasonable readings whenever the radiator is turned on   yes there are other alternatives to the pyrometer  but they start at    k and are too expensive   the radiator has to be pulsed to operate it  so to maintain a decent heat up time and steady state temperature the  duty cycle  has to be at a decent rate target is       the minimum  off time  of the radiator is     seconds before the measured values are reasonable  so at the end my sensor got an effective sampletime of     seconds  by varying the duty cycle   the hardware is hard too change  radiator and sensor have been evaluted for months right now  therefore i try to improve the results by  just  changing the control algorithm  ,control
7564,how to localise a underwater robot ,i am building an autonomous underwater robot  it will be used in swimming pools  it should be capable of running in any normal sized pool  not just the pool in which i test  so i cannot rely on a particular design or feature  it has to know it s position in the pool  either with respect to the initial position or with respect to the pool  i have a imu  which is a pololu miniimu but finding the displacement with an imu is a near impossible task   what sensor can i use for this task  it should not be very expensive   below       tank size    x  x    meters ,sensors localization sensor-fusion underwater
7565,how to determine the trajectory reference on the real robot trajectory tracking,i know that we can use some algorithms like lqr  mpc  or even pid to make the robot follows the trajectory references  in the simulation like matlab  i usually specify the trajectory reference by a function  let say  given a sequence of points generated by a path planning algorithm  then i want to do a real experiment of trajectory tracking over those sequence of points  my question is    how to specify the errors towards the path in real situation  my impression is the generated path by path planning algorithm is uncertain due to the error of the robot sensing  and unlike the line following robot which has a real physical line for the reference  the generated path from path planning is virtual  e g  it does not exist in the real world  i am really confused about these matter  ,mobile-robot control
7570,homogenous transformation matrix for dh parameters,i m studying introduction to robotic and found there is different equations to determine the position and orientation for the end effector of a robot using dh parameters transformation matrix  they are      example  puma      all joints are revolute forward kinematics  given  the manipulator geometrical parameters  specify  the position and orientation of manipulator  solution   for step     for step    here i m confused  here we should calculate the transformation matrix  for each link  and then multiply them to get the position and orientation for the end effector  i ve seen different articles using one of these equations when they get to this step for the same robot puma      what is the difference between them  will the result be different  which one should i use when calculating the position and orientation  ,dh-parameters
7575,dh parameters for forward kinematics for translatory motion only,i am fairly new to the dh transformation and i have difficulties to understand how it works  why are not all coordinates  x y z  incorporated into the parameters  it seems to me that at least one information is useless goes to the trash  since there is only a  d  translatory information  and alpha  theta rotatory information    example   the transition between two coordinate systems with identical orientation alpha    theta    but with different coordinates x   x   y   y   z   z     dh only makes use of a maximum of two of these information  please enlighten me   greetings  edit   to clarify which part of the dh transform i don t understand  here is an example   imagine a cnc mill cos   on a stand cos   without any variable length  no motion  between cos  cos   for some reason i need to incorporate the transformation from cos  cos   t     into the forward transformation of my cnc mill    dh parameters for t    would be a  mm  alpha      d  mm and theta      assuming this is correct  the dx   mm information is lost during this process  if i recreate the relation between cos  and cos  according to the dh parameters  i end up like this    as far as i understand  on non parallel axis the information is not lost because the measurement of a d would be diagonal  therefore include either dx dy  dx dz or dy dz pythagorean theorem  in one parameter   where is the flaw in my logic  ,forward-kinematics dh-parameters
7578,orientation parameter for quadcopter with madgwick fusion algorithm,i recently decided to build a quadricopter from scratch using arduino and now i m faced with an orientation estimation problem  i bought a cheap   dof sensor with   axis magnetometer    axis accelerometer    axis gyro and a barometer and the complementary filter that i use to get orientation returns usable but noisy values  i tried the madgwick fusion filter too  but it returns unstable values that diverges from the ones i get with complementary filter  given that the madgwick filter implementation is correct  i pass acceleration values measured in gs  gyro values measured in rps  radians per second  and magnetometer values measured in ut  while sampling time is the same of my loop cycle  is there anything i have missed  is there any advantage using kalman filter  edit   my problem was due to an wrong choice of sampling time and now seems to work  but convergence is very very slow  i e  it takes about   seconds to reach the right value after a quick flip of the imu   rising value of kp adds to much noise  i also tried to repeat filter update step more than once per cycle but it requires too much time exceeding the sampling time  here some graphs  from top to bottom complementary filter  madgwick filter and madgwick filter with high kp     edit   different values probably are caused by cable plug and unplug  anyway raw data example from my sensor can be downloaded here ,arduino quadcopter kalman-filter imu
7580,sensors  field of view in car driving,i want to develop an autonomous driving rc car  for detecting obstacles  i plan to mount     ultrasonic sensors in the front and in the back the car  what is the  minimum necessary combined field of view of the sensors so the car never hits an obstacle  i e  what is the minimum angle of detection of the combined sensors the car should have to detect any obstacle in its path  some data about the car   i don t know whether all the data is relevant   separation between right and left wheel        cm wheelbase  distance between the front and the back wheels        cm steering axle  front  maximum angle of steering  around    degrees  the car uses ackermann steering  ,mobile-robot sensors wheeled-robot
7588,is lego mindstorm a good start ,i would like to start experimenting with robots  is lego mindstorm a good start  should i consider other platforms  ,platform
7592,imu rotate about one axis  other two angles change too,i am trying to use invensense s mpu      i am using provided library to read euler angle  when the imu rotates about one axis  angles about other two axes change too  what could be potential cause to it   ,imu
7595,stm   oc timing and irqhandler,i created a program to simple time base delay  in seconds   i have problem  how to read a interrupt flag from channel   etc   when i use  an error occurs  when the interrupt occurred   uc should clear flag and set blue led in discovery board  here is my program  main c    includes   include  stm  f xx hal h       private variables  br      tim handletypedef htim           private function prototypes  br    void systemclock config void   br    static void mx gpio init void   br    static void mx tim  init void   br       int main void           mcu configuration                                                             br          reset of all peripherals  initializes the flash interface and the systick     br     hal init          configure the system clock    br      systemclock config    br          initialize all configured peripherals    br      mx gpio init    br      mx tim  init    br           infinite loop       while               hal gpio writepin gpioe gpio pin    gpio pin reset              system clock configuration    void systemclock config void       rcc oscinittypedef rcc oscinitstruct  br      rcc clkinittypedef rcc clkinitstruct  br       rcc oscinitstruct oscillatortype   rcc oscillatortype hse  br      rcc oscinitstruct hsestate   rcc hse on  br      rcc oscinitstruct hsepredivvalue   rcc hse prediv div   br      rcc oscinitstruct pll pllstate   rcc pll on  br      rcc oscinitstruct pll pllsource   rcc pllsource hse  br      rcc oscinitstruct pll pllmul   rcc pll mul   br      hal rcc oscconfig  rcc oscinitstruct   br       rcc clkinitstruct clocktype   rcc clocktype sysclk rcc clocktype pclk   br      rcc clkinitstruct sysclksource   rcc sysclksource pllclk  br      rcc clkinitstruct ahbclkdivider   rcc sysclk div   br      rcc clkinitstruct apb clkdivider   rcc hclk div   br      rcc clkinitstruct apb clkdivider   rcc hclk div   br      hal rcc clockconfig  rcc clkinitstruct  flash latency     br       hal systick config hal rcc gethclkfreq          br       hal systick clksourceconfig systick clksource hclk   br           tim  init function    br    void mx tim  init void       tim clockconfigtypedef sclocksourceconfig  br      tim masterconfigtypedef smasterconfig  br      tim oc inittypedef sconfigoc  br       htim  instance   tim   br      htim  init prescaler             mhz       br      htim  init countermode   tim countermode up  br      htim  init period          br      htim  init clockdivision   tim clockdivision div   br      hal tim base init  htim    br       sclocksourceconfig clocksource   tim clocksource internal  br      hal tim configclocksource  htim    sclocksourceconfig   br       hal tim oc init  htim    br       smasterconfig masteroutputtrigger   tim trgo reset  br      smasterconfig masterslavemode   tim masterslavemode disable  br      hal timex masterconfigsynchronization  htim    smasterconfig   br       sconfigoc ocmode   tim ocmode timing  br      sconfigoc pulse                   s               s  delay  br       sconfigoc ocpolarity   tim ocpolarity high  br      sconfigoc ocfastmode   tim ocfast disable  br      hal tim oc configchannel  htim    sconfigoc  tim channel     br       sconfigoc ocmode   tim ocmode timing  br       sconfigoc pulse          br       sconfigoc ocpolarity   tim ocpolarity high  br       sconfigoc ocfastmode   tim ocfast disable  br       hal tim oc configchannel  htim    sconfigoc  tim channel     br      hal tim base start it  htim    br        hal tim oc start it  htim  tim channel      br         hal tim oc start it  htim  tim channel      br           configure pins as  br              analog  br              input  br              output br              event out br              exti br         pc            i s ckin br       void mx gpio init void  br       br      gpio inittypedef gpio initstruct  br          gpio ports clock enable    br        gpiof clk enable    br        gpioc clk enable    br        gpioe clk enable    br         configure gpio pin   pc     br      gpio initstruct pin   gpio pin    br      gpio initstruct mode   gpio mode af pp  br      gpio initstruct pull   gpio nopull  br      gpio initstruct speed   gpio speed high  br      gpio initstruct alternate   gpio af  spi   br      hal gpio init gpioc   gpio initstruct   br     br            configure gpio pin   pe  blue led       br      gpio initstruct pin gpio pin    br      gpio initstruct mode gpio mode output pp  br      gpio initstruct pull gpio nopull  br      gpio initstruct speed gpio speed high  br      hal gpio init gpioe  gpio initstruct   br       gpio initstruct pin gpio pin     br      gpio initstruct mode gpio mode output pp  br      gpio initstruct pull gpio nopull  br      gpio initstruct speed gpio speed high  br      hal gpio init gpioe  gpio initstruct   br     br          configure gpio pin   pe   green led      br      gpio initstruct pin gpio pin     br        gpio initstruct mode gpio mode output pp  br        gpio initstruct pull gpio nopull  br        gpio initstruct speed gpio speed high  br        hal gpio init gpioe  gpio initstruct      low level implementation   br    void hal tim base mspinit tim handletypedef  htim base  br       br      if htim base  instance  tim   br          br           peripheral clock enable    br          tim  clk enable    br         peripheral interrupt init   br        hal nvic setpriority tim  irqn         br        hal nvic enableirq tim  irqn   br              void tim  irqhandler void     br         user code begin tim  irqn      br         hal gpio writepin gpioe gpio pin   gpio pin set   br            hal gpio togglepin gpioe gpio pin      br      hal tim irqhandler  htim    br      this function is implemented by stmcubemx   what is this     so how should my tim  irqhandler look like  each channel generate delay in    sec  when i am debugging this program  when led is set the period is equal to  s  time for set led    ,microcontroller
7598,extend robotic arm with wrist rotation,i got an owi robotic arm  but was slightly disappointed at it having only horizontal position for gripper  what would be the easiest way to extend with gripper wrist rotation  i e   th degree of freedom    ,robotic-arm
7600,kuka robotics api ide,i ve got robotics api library  demo program and a robot  i want to develop app for it  the best solution is offline development on some kind of simulator  i m completely new in such tasks   is there any ide for this  or a way do deliver byte code to machine  thanks in advance  ,robotic-arm dynamic-programming
7607,can esc be programmed to run full throttle only on one side of a quadcopter ,can esc in quads be programmed in such a way that only one side has throttle and no throttle at all on the other  this would cause the quad to flip i suppose   with that  is there a way we can program the controller to like trigger a switch when we want the quad to flip  because i was thinking of doing a waterproof quad  so initially  it flies in the air normally with the   channel  and then i set it to float on water  after that  i was thinking of maybe triggering a switch on the controller so that this time it s just going to flip and nothing else  after it flips  i would trigger the switch back to normal operation  is that possible  ,quadcopter
7612,raspberry pi hexapod   dof  best servo control board ,recently i ve bought a hexapod kit and    towerpro mg    servos  my objective is to apply also the pi camera  sensors and perhaps a claw    so i ve been researching and i haven t found a clear answer when comes to the servo control board  which servo controller board shall i choose to complete my project  ,mobile-robot raspberry-pi servomotor rcservo hexapod
7613,how to efficiently do  d mapping of an area on a mav ,i have been researching on a cost effective way to scan an area on a mav  exploraton  and later use it for cad civil purposes use the point cloud data for cad  but the major sensors available have their own problems  kinect   can t use outside high computation power stereo   high computation power somewhat expensive lidar   very expensive   not real time   heavy i need a system on the mav quadrotor  that can work over wifi wireless  can scan outdoors   not very expensive and that gives data real time please suggest a system that can be as close to the above requirements  also can stereo be operated over wifi   ,kinect mapping stereo-vision 3d-reconstruction
7615,problem with acceleration sensor,i m using the bma     from elv  with my arduino mega     and trying to read acceleration values that doesn t confuse me  first i connected the sensor in spi   mode  means csb     pb   ss  sck     pb   sck  sdi     pb   mosi  sdo     pb   miso  also gnd and uin are connected with the gnd and  v pins of the arduino board  here is the self written code i use  and now here is what really confuses me  i got   of this sensors  one is working with this code perfectly fine  the data i get is what i expect  i measure earth gravity in z component if iay the sensor on the table  if i start turning it i measure the earth gravity component wise in x   y  and z  direction depending on the angle i turn the sensor  from the other   sensors i receive data that is different  the values jump from       about      g  to       about    g   with the same code  the same wires and the same arduino  i checked the register settings of all sensors  they are all the same  i checked the wire connection to the first component at the sensors  they are all around     ohm  i used an oscilloscope and made sure csb  sck and mosi work properly  am i missing something  what causes this similar but wrong behavior of   out of   sensors  ,arduino accelerometer
7617,using  x uarts on stm  f   rb,i am trying to use  x uarts with chibios on the stm  f   rb nucleo board   i initialized uart  but i am still getting output on uart  pins  which is totally weird   the line uartstartsend  uartd       soom  r n    gives output on uart    is there anything else i need to do  mcuconfig h reads  define stm   uart use usart                true  define stm   uart use usart                true  define stm   uart usart  irq priority         define stm   uart usart  irq priority         define stm   uart usart  dma priority         define stm   uart usart  dma priority         ,microcontroller serial c
7622,virtual model in plc discrete   continuous,how does one implement virtual model  continuous  while control system itself is discrete  plc   i ve done this in practice but what about theory  how does one explain this topic to a stranger   lets say myself  ,control
7626,what are methods to compare pid controller performance ,if there are input and the sensor measured outputs  what are the objective methods to compare performance besides looking at inputs and outputs matching or not  ,pid
7632,project   building a electric skateboard,during the vacation here i wa thinking it could be fun to make an electric skateboard longboard     i haven t decided on which longboard i want to use  but is nearly done with selecting the parts   the board will be driven by one out runner  turnigy aerodrive sk            kv      and to mount the motor i use this  kit      as for esc i was recommended to  this      and  this     as battery   which seems like be good seem to be an ok setup for my application   the problem is a bit that i don t have any reason for why i have chosen the esc and the battery pack  surely they deliver the needed amps and the esc can withstand the max current but other than that  i don t see why i couldn t buy an other set   especially if it is cheaper     what cheaper alternative do i have  and what the drawbacks do they have  ,brushless-motor battery esc
7633,brushless dc motor   electronic speed control   quadcopter,i m a student who is doing electrical and electronics engineering  i m currently doing my final project which is a quadcopter  one of my objectives in that is to make a electronic speed controller  esc  for the brushless motors that are being used   i made a design for the esc using proteus and i made the pcb also  i have attached the schematic  i used pic  f   a for the esc and wrote a small code in mikroc for the esc to work when powered up  unfortunately it didn t work properly  i tried sensorless control of brushless motors without getting any feedback  can i know how much of current that i should provide for the motor  according to some articles that i read the brushless dc  bldc  motor requires around   a at the startup for around    ms  i have posted the code also  i used two codes to run the motor  one with pwm and other without pwm       duty cycle    i am a rookie to the subject of bldc motor controlling  i am very grateful if anybody can help me to clear out the doubts and figure out the mistakes in my design to make it work properly   below given is the code that i tried  please help me to figure out the right way to program the chip   when i uploaded the above given code and when i set the delay to around       s  the motor spun but at each time one of the mosfets got heated up until i cannot touch it anymore  here is the video of this scenario  this is the other code  pwm   const delay          const delay          int count      int cnt  int arr        x     x     x     x b   x     x d   int i      int x     x       void init void       trisb    x     portb    x       option reg    x       intcon    xa    ccp con       cmcon    x          void main        init       while         for  cnt      cnt       cnt                      portb   arr i            delay us              portb    x             delay us                      i              if  i                           i                             ,quadcopter brushless-motor esc
7634,arduino original or generic for a beginner ,i m new to the robotics and electronics world  but i m willing to dive into it  i m a software developer and i want to create a project that uses gps and accelerometer data to show as a layer on google maps after transferred to pc  my doubt is about which controller to get  in my country  there are generic controllers based on the atmega    that are being sold with a massive difference of price from the original arduino  talking about the uno model    should i start with an original model   should i expect to break the controller  fry it  or break any components by connecting them wrong   would the experience with a generic controller be less exciting than with the original arduino one  ,arduino beginner
7640,pid gains for motor position and velocity control,i have a servo motor with quad optical encoder and i m trying to control its position and velocity  by controlling both i meant that if i input that the motor should reach     at    rpm then it should  how can i do that  i am using an arduino uno  kindly share some code if possible   though i have implemented the pid  i don t think it is correct because i didn t implement the feedforward controller  because i have no idea what that is  and i have not been able to find suitable gains for pid  the gains i find for small steps  or say degree rotation  do not work out well for large steps and vice versa  i have also not used a limit for integral sum  because i don t how much it should be   i am using a pittman motor  ,robotic-arm
7641,mapping formats for small autonomous robots,i have some robot software i m working on  java on android  which needs to store a pre designed map of a playing field to be able to navigate around  the field s not got any fancy  d structure  the map can be  d  i ve been trying to find a good format to store the maps in  i ve looked into svgs and dxfs  but neither one is really designed for the purpose  is there any file format specifically designed for small  geometric  robotics oriented maps  the field i d be modelling is this one   ,mapping
7644,how to use a pomdp based planner on top of a probabilistic filter,pomdps extend mdps by conceiling state and adding an observation model  a pomdp controller processes either  action observation histories or a bayesian belief state  computed from the observations  belief mdp transformation   in a complex  real world system like a robot  one usually preprocesses sensory readings using filters  kalmann  hmm  whatever   the result of which is a belief state  i am looking for publications that discuss the problem of fitting a  probably more abstract  pomdp model on top of an existing filter bank    do you have to stick to the belief mdp  and hand over the filtered belief state to the controller  is there any way of using history based pomdp controllers  like mcts  how do you construct find the abstract observations you need to formulate the pomdp model   ,kalman-filter particle-filter planning filter
7645,how do i choose the best filter for dead reckoning with an imu ,i m searching filter to reduce noise and smooth the signal while dead reckoning with an imu   dof gyro accelerometer   what are the differences advantages disadvantages of the following filters   kalman complementary moving average mahony   i applied kalman and complementary filters to an imu and both of them gives time lag to actions with respect to filter parameters  also kalman filter works slower than moving average and complementary  how can i choose right filter and filter parameters  ,mobile-robot localization kalman-filter imu
7647,ros calibration camera problems,i am trying to calibrate a monocular camera using ros with the help of this website  how to calibrate a monocular camera  when i run   i get   left  right  rosout  rosout agg  usb cam image  when i run rosservice list  i get   cameracalibrator get loggers  cameracalibrator set logger level  rosout get loggers  rosout set logger level  finally  when i run  rosrun camera calibration cameracalibrator py   size   x    square       image   usb cam image camera   usb cam   it says    waiting for service     usb cam set camera info          service not found  i even added the parameter at the end    no service check  but that just makes the terminal stall indefinitely   could someone please help me figure out what is going wrong and how i can fix it  also if it is important  usb cam is saved at catkin ws src usb cam  ,ros cameras calibration
7648,irobot create   sensors,can someone please provide me with a list of sensors on the create     i am hoping to get one soon  but want to be sure it has ultrasonic sensors and not just bump sensors before i do  ,irobot-create roomba
7652,how do i control the robotic arm motion ,i have a robotic arm mounted on a car  there s a camera attached to it  suppose the camera takes the image of a room  and finds that there s something  say an object  that has to be picked up  say it s    feet away from the robot  my question is that how will the robot reach the object in the first place  and secondly  when it has reached the object  how will it know the real world co ordinates of the object  to pick the object up  using inverse kinematic equations  any help would be appreciated  thanks ,mobile-robot robotic-arm
7656,how does the cliff sensors on roomba work through a glass wall ,i want to use ir sensors to detect whether my dustbin is full but i want to protect it from outside dust  i am planning to use the ir sensors on roomba   how are they working despite a plastic wall  also  what is the range of the sensor  can they detect obstacle at about    cm  why is there a wall between the ir sensors  is there a reason they are positioned at certain angle   ,sensors roomba
7659,ptam cameracalibrator error,i am trying to run the  using ptam according to this camera calibration tutorial  however  when i do so  i get the following error  error  cannot launch node of type  ptam cameracalibrator   can t locate node  cameracalibrator  in package  ptam   i source my devel setup bash before i run the code as well and it still does not work  here is my launch file   launch       node name  cameracalibrator  pkg  ptam  type  cameracalibrator  clear params  true  output  screen            remap from  image raw  to usb cam image raw              remap from  pose  to  pose             rosparam file    find ptam  ptamfixparams yaml          node    launch   here is what i get for rostopic list   rosout  rosout agg  svo dense input  svo image  svo image compressed  svo image compressed parameter descriptions      tf  usb cam camera info  usb cam image raw  usb cam image raw compressed      usb cam image raw theora  usb cam image raw parameter descriptions  usb cam image raw parameter updates  the path where the cameracalibration launch file is catkin ws src ethzasl ptam ptam launch   i am not sure why this error keeps coming up because when i run roslaunch ptam cameracalibrator launch  it says  nodes         cameracalibrator  ptam cameracalibrator   so i m thinking that ptam does include cameracalibrator  if someone could please point out my error  that would be really helpful  i ve been using this post as a guide  but it s not been helping me much  ros dynamic config file  as it says in the above link  i tried find    executable and i could not find cameracalibrator  i could only find the below  how do i proceed    include   include ptam   cfg       launch   src   src ptam   src ptam cfg      ,ros cameras calibration
7660,implementing a boustrophedon algorithm in a given room with obstacles,i have a mobile robot which is navigating around a room  i already have the map of the room  i am using the navigation stack of ros  i am using rotary encoders for odometry  i am fusing the data from rotary encoders and imu using robot pose ekf  i am using amcl for localization and move base for planning   now  i have to write a complete coverage path planning algorithm and i am following this paper and i would like to ask what is the best way to generate the boustrophedon path  simple forward and backward motions  in a cell  can be rectangular  trapezium  etc   with no obstacles  i read a paper where they use different templates and combine them in a certain way to come up with the boustrophedon path  is there any other way by which we can generate the boustrophedon path  if someone can suggest how to implement it in ros  that will be great  please let me know if you need more information from me  any help will be appreciated  ,ros navigation motion-planning coverage
7662,how do i work out the specifications of motors and propellers for a quadcopter ,what will be the specifications of motors and propellers that can approx produce a thrust of    kg in a quadcopter  we are planning to lift a total weight of    kg along with the    kg weight of the quadcopter itself  so at     throttle the total thrust produced by it should be     kg with a per motor total thrust of      kg  i have looked at this answer to how to calculate quadcopter lift capabilities  but don t understand how to use this information to work out the specifications of motor and propeller required for my application  the answer given in previous question is limited for small quad   i require the specifications of bldc motor such as kv torque imax v power etc and of propeller suitable for such motor  ,quadcopter
7664,what actuator types exist that remain locked in their last position like hydraulic piston ,i would like to find an electronic actuator that mimics the characteristics of a hydraulic actuator  in that the position remains fixed without power drain when the actuator is not moving  which actuators exist that match these criteria  ,electronics actuator
7666,where to get this reference about kalman filter  technical report,i m sorry for this question that might not fit in here however  i would like to give it a shot  i ve chosen this stack since the question is somehow related to mobile robots  i ve came across a paper in mobile robot localization that has cited the following reference    c  brown  h  durrant whyte  j  leonard  b  rao  and b  steer   kalman   filter algorithms  applications  and utilities  technical report   ouel          oxford u  robotics research group         i couldn t find this reference  nothing show up in google not even in google scholar  in my university which allows me to access to a massive database  also nothing show up  since this is a technical report  i m interested to read it to have more appreciation about kalman filter  has anyone came across this reference  ,mobile-robot localization kalman-filter
7670,kinect v  vs kinect v ,from a technical standpoint what are the differences between the kinect v  and the kinect v    i m interested both in the hardware equipment and the format of the data  ,kinect
7671,kinect vs stereo cameras,as i m advancing in my project i realized i need better hardware  particularly for video input and processing  from an intuitive feeling sounds like stereo cameras offers a more powerful and flexible solution  on the other hand the kinect looks like a great out of the box solution for depth sensing and it also takes away a lot of computational complexity as it output directly the depth  so i would like to know what are the upsides and downsides of the   solutions and if they have any well known limitation and or field of application and why  thank you  ,kinect cameras stereo-vision
7672,extending icreate battery power for auxilliary equipment,i plan to use the icreate as a platform to carry a tablet  or notebook pc and want to have power for some time so i need more than the      mah battery  i want all to be powered from same battery system and use same charging source  so i need info as to how to wire in additional     v nimh batteries in parallel with the existing and how to deal with the additional temperature sensors  i could ignore of course but      can the built in power control deal with this  do i need to upgrade it somehow  i would appreciate suggestions as i do not want a completely separate power system for aux devices  charging all from standard home base is the goal even though it will take longer  i can deal with adapting the     v to whatever aux devices i add  thanks  ,power battery roomba
7678,how to reduce battery power   v    a to  v    a,what s least complex way to reduce power from a   v    a battery to  v    a thank you  ,battery
7680,arduino compatible sensor for motion detection and positioning,i am working on a project that requires motion detection and positioning  i ve worked substantially with a camera but the issue with this is that i need something sleek  small and not heavy at all  cameras also tend to rely on luminosity and they don t work well in poorly lit spaces  i need someone who s worked on something like this or who knows the best sensor for this purpose  ,arduino
7682,object grasping robot arm control,i have a   dof robot arm with a camera attached to it  it takes an image and there s an object in that image  say a glass  of course  in order to move the arm to the required position to grasp the object  i have to solve the inverse kinematic equations  in order to solve them  i need the x and y  the coordinates where the arm has to reach to grasp the object  my question is how can i find the x and y of say the midpoint of the object from the image  thanks  ,mobile-robot robotic-arm
7685,what is required to build a simple xy stage ,in the scope of my phd  i would like to build an automated microscopy set up that should take images of a sample of  cm by  cm  this should be done by taking pictures of     micrometers by     micrometers  therefore i need to design an xy stage moving my sample over the optical setup  i would use a raspberry pi to steer all the hardware   could you direct me to material about how to best make an xy stage   my questions are about what types of motors to use  stepper    how many  how to create a good sliding mechanism to avoid jerky steps  etc   simple links to basic engineering of such set ups would be more than enough for me to start  as i am a complete layman in this field  edit  i have found this blogpost  it does what i require  if i get small enough angle step stepper motors  edit   i need a maximal range of motion of    cm in both directions  the overall size should not exceed   x   cm    step sizes should not exceed    microns  i do not care about moving speed  based upon the design in the link  buying a stepper motor with a       gear box could allow my very small radial steps        deg  which would result in about   micron steps  assuming a rotor radius of about  cm  as far as price goes  it should not exceed commercially available options which start at about  k usd ,raspberry-pi stepper-motor
7691,is anybody using robot simulators ,do you use simulators for developing your robot algorithms or do you test directly in your robot  i would like to get introduced into the simulators world  but don t know from where to start    can you recommend me one  regards ,simulator
7694,degree of freedom,a robotic arm should pick a cuboid up of a table  rotate it around its vertical axis and put it down on all possible positions  how many degrees of freedom are at least necessary   all coordinates  that should be reached by the robotic arm  are in its workspace  it is not allowed to put the cuboid down and pick it up  once the robot has it    the answer is       translatory and   rotatory    but i don t understand why  i thouhgt that it should be      prismatic joints     to pick the cuboid up   and another one to move it anywhere on the table    revolute joint to rotate the cuboid around its vertical axis       translatory and   rotatory   ,robotic-arm
7698,voltage rpm relation,i measure the voltage esc drawing while increasing the dc motor speed  multimeter shows that as long as the speed increases the voltage value decreases  can anybody explain why this is happening   ,brushless-motor electronics esc
7703,increase pid sampling rate on embedded system,my robotic project is running at every  ms and the processes are taking about    ms  i am running pid so my max clock rate is  khz  about half of the processing time are taken by spi peripherals  imu and encoders  is there any recommendation on how i can run faster pid sampling rate  ,pid embedded-systems
7705,low variance resampling algorithm for particle filter,for my particle filter  i decided to try using the low variance resampling algorithm as suggested in probabilistic robotics  the algorithm implements systematic resampling while still considering relative particle weights  i implemented the algorithm in matlab  almost word for word from the text   as would be expected given the while loop structure  i am getting an error for accessing weight i   where i exceeds the array dimensions  to solve this  i was considering circularly shifting my weight array  putting the first index used as the first value in weight  so that i never exceed matrix dimensions   however  i wasn t sure if this would negatively impact the rest of the algorithm  seeing as i m having trouble understanding the purpose of the u calculation and while loop  could anyone help clarify the purpose of u and the while loop  and whether or not a circular shift is an acceptable fix  ,mobile-robot algorithm particle-filter probability
7708,how to make door opening to the top,i need to make this construction  door is closed by default  door is opened to the top   this is the scheme   red rectangle on the picture is the aperture  blue rectangle is the door  weight is about     kg   which moves top when door need to be opened  green stripe on the picture is the rail for the door  which electrical engine should i use  estimated time of door opening is about    seconds  i want to send signal to up the door  it should be drop down when power is lost or i should send a signal to drop it down  ,design electronics actuator
7710,formationing algorithm for multiple robots,i m looking for an algorithm for formationing multiple robots in  d simulation  can you suggest resources about this topic  also i need suggestions and comments about these topics   can i recruit algorithm from optimization algorithms like particle or ant  is there any way except  go to goal  for each robot is patter formationing algorithms feasible  suggestions about a fast way of formationing  aligning  notes   im not using a robotics simulator or physics engine for this   robots are represented as dots  multi robot system is homogeneous every robot can sense obstacles and other robots in a sense range circle around the robot    number of obstacles and robots can vary from   to      multi robot system is not a central   ,mobile-robot multi-agent swarm
7712,prototyping with irobot roomba,for a project i am building a tele op robot using the irobot s roomba as my drivetrain  in order for my robot to work  i need an extra castor  irobot provides  stl and  stp files for me to use and i used them and printed the files   the file i printed was from this link  create    bin modification  this file is a new part to the drivetrain to allow another caster  and i downloaded the first link called  full bin bottom with caster mount  the piece was great but it made the castor a different height then the wheels  i was wondering if anyone had this file but saved as something different so i can edit it in preferably solidworks  i was on the phone with irobot for over   hours today and they told me to post here  so please help        ,irobot-create roomba
7718,optimal hardware for linear algebra operations,i ve been working lately on slam algorithms implementing extended kalman filtering to brush up on some localisation techniques and i have been thinking forward to the hardware side of things  are there embedded chips such a microcontroller that are optimised for large linear algebra operations  what sort of embedded options are the best for processing these sorts of operations  ,slam kalman-filter
7720,reading crazy large numbers from naze  ,i hope someone can help me here   i am reading very large numbers from my naze     what is the max and min values from pitch  roll and yaw  how would i then convert them to degrees or radians  ,quadcopter
7722,what type of control law is used in  reaction control system  of apollo lunar module or space shuttle ,reaction control systems  rcs  on these vehicles are implemented by using small rocket thrusters  for me it looks like these thrusters work in some kind of  pulse  mode  and i can t understand   do they use some optimal control to calculate in advance the required impulse to reach the new desired state of the system or they use  pulse  mode just for precise magnitude variation of provided thrust  like average voltage in pwm pulse width modulation   in a classic pid control loop  ,control automatic rocket
7723,matlab  d simulation with solidworks model,i m learning  to make a  d simulation in matlab based on a model designed from solidworks  there is an example  simulink solidworks the way used here is    create a  d model in solidworks create a xml file applicable to import to matlab via simmechanics link import the model to matlab simulink  a simulink system is created   after these steps  controlling the system will be implemented in simulink  but i feel simulink is kind of strict to control  i want to be more flexible  apply any algorithm to the model  and using matlab   m file to control is more efficient way   so my question is this  is there any way to do  d simulation  matlab solidworks  by using only   m file to control  no simulink anymore   all model information will be contained in the  m file  maybe the step   and   are inherited  but step   is different  ,matlab simulation
7724,determine what the rotation axis is given a rotation matrix,how do i find out around which axis the coordinate system has to rotate  if the rotation matrix is given            for  i thought  that it has to be a rotation around the z axis  because    the values at the positions  of  and  are identical  so i solved            rotation around z axis  but how do i solve it  if there is more than   rotation  like for     ,joint
7728,where to make changes for simulation project bullet gazebo ros orocos,i am starting to develop robotics project which involves simulation  and maybe real world programs  of soft body dynamics  for food processing  and clothes garment handling  for textile industry or home service robots   it is known that soft body dynamics and garment handling are two less explored areas of robotics and simulation  therefore i hope to make some development of  contribution to  projects that are involved  the following projects are involed   bullet physics engine   for dynamics gazebo   simulation environment ros   robot os  i hope to use universal robot ur  or ur   arms and some grippers  not decided yet  orocos   for control algorithms  initially i hope use  ros indigo igloo preinstalled virtual machine   from nootrix com   but apparently i will have to make updates to the bullet  gazeboo  add new ros stacks and so on  the question is   how to organize such project  e g  if i am updating bullet physics engine with the new soft body dynamics algorithm then what executable  so  files should i produce and where to put them into virtual machine  the similar question can be asked if i need to update gazebo   there seems to be incredibly large number of files  is it right to change only some of them  sorry about such questions  but the sofware stack seems to be more complex than the robotics itself  ,ros software programming-languages dynamics gazebo
7729,is it possible to simulate vision  perception  in gazebo  or other simulators ,vision is important part of robotics and frequently it is unavoidable component of control loop  e g  many clothes garment handling algorithms rely on visual cues in deciding how to proceed  the question is   does simulation environments  gazebo or some others  allow one to design world with robot and garment and simulate not only garment dynamics but simulate also what robot sees  how robot perceives garment in each simulation step  if it is not possible to simulate vision then how to simulate algorithms with vision as component of control loop  maybe simulation of vision can be good research theme  are here some trend or good articles about it  some initial projects that could be expanded  actually   it can be stated as more general question   is it possible to simulate sensors in gazebo  e g  food handling  soft body handling  can involve tactile sensors  in principle gazebo can calculate deformation and forces of soft body and format these data as the simulated values of sensor readings  maybe similar mechanism can be used for simulation of vision as well  ,computer-vision simulator research simulation gazebo
7731,comparing industrial robot arms,i d like to study the capabilities of industrial robot arms  for example  to answer the question how does price vary with precision  speed  reach and strength  is there a database of industrial robot arms including information like the price  precision  speed  reach and strength of each model  ,robotic-arm industrial-robot
7735,estimation of battery life time from pwm signals in a quadrotor,is there any way of estimation the battery life from pwm outputs which goes to motors in microcontroller level  i m planning to estimate path range with this  microcontroller  sensor and other electronic device should be neglected   ,quadcopter battery
7737,building parts  and keeping laser alignment steady,i am building a laser gun for pentathlon targets  also doing one   i would like to know how build a part of the gun and if i can count on a steady laser if it is attached to a motor  the question is about the laser  i want it maybe attached to a small  servo motor to try to implement some cheat just for fun  assuming the motor has a good torque  can i assume that the laser will not move  not the sightliest bit  when the motor is turned off   i don t have any to test  this is for precision shooting  so small vibrations and a moving pointer would be really prejudicial  in case it does  what can i do to minimize the problem  is it all about ordering the motor with the highest torque  i also have a second question which is slightly off topic  yet related  and robotics people usually have solutions for such problems  i also need to build the sights  here s a gun   as you can tell  its sights are a fixed plastic point in the front  and an adjustable large back  there are two bolts  one on each side  one makes the sight higher or lower  and the other makes it point more to the right or left  how can such part be built with simple tools  thanls ,motor stability laser
7739,navigating through a maze using path planning  dijkstra ,i m working on an robot that would be able to navigate through a maze  avoid obstacles and identify some of the objects in it  i have a monochromatic bitmap of the maze  that is supposed to be used in the robot navigation  up till now i have processed the bitmap image  and converted it into an adjacency list  i will now use the dijkstra s algorithm to plan the path  however the problem is that i have to extract the entrance point node and exit node from the bmp image itself for dijkstra s algorithm to plan the path  the robots starting position will be slightly different  inch or two before the entrance point  from the entrance point of maze  and i am supposed to move to the entrance point using any  arbitrary method  and then apply dijkstra algorithm to plan path from maze s entrance to exit  on the way i have to also stop at the  x s  marked in the bmp file i have attached below  these x s are basically boxes in which i have to pot balls  i will plan the path from entrance point to exit point   and not from the entrance to  st box  then to second  and then to the exit point  because i think the boxes will always be placed at the shortest path  since the starting position is different from the entrance point  how will i match my robot s physical location with the coordinates in the program and move it accordingly  even if the entrance position would have been same as starting position there may have been an error  how should i deal with it  should i navigate only on the bases of the coordinates provided by dijkstra or use ultrasonics as well to prevent collisions  and if we yes  can you give me an idea how should i use the both  ultrasonics  and coordinates    ,arduino mobile-robot localization motion-planning mapping
7741,mathematical moddeling of elastic robots,we can easily compute the rigid robot kinematics and dynamics  there is many resources  simulators and modelling tools about it  but i couldnt find any of these for elastic robots  can you suggest resources and modelling tools  ,kinematics simulator dynamics
7757,calculus in robotics, i am still in high school and am a part of the robotics club that competes in the ftc  first tech challenge   i am just about finishing my first calculus class  calc     and would be ecstatic to be able to apply this someway in a real world example such as robotics   besides pid  it seems like only approximations anyways   so far  i ve only been working with  fabricated  math problems  would deriving an equation from real life situations be too complicated   thank you  ,control software
7760,create a simple c   client application to control kuka s robot arm lbr iiwa via fri,until now i have been programming the robot using java on kuka s ide  kuka sunrise workbench   what i want to do is control the robot arm via my c   net application  i would use a camera or kinect to get commands    i m reading the documents provided by kuka  but as i m a bit in hurry  i want to understand how a c   client application  running on my laptop  can send receive information to from the robot s controller  kuka sunrise cabinet   running the server application  via fri  i still have issues grasping the whole mechanism  a simple application  server client  source code with explanation  or a schematic  would be more than helpful   ,robotic-arm c++
7763,why do we generally prefer dh parameters over other kinematic representations of robot arms ,i am specifically interested in dh parameters versus other representations in terms of kinematic calibration   the best  clearest  source of information i could find on kinematic calibration is in the book  robotics  modelling  planning and control  by bruno siciliano  lorenzo sciavicco  luigi villani  giuseppe oriolo  chapter        which requires a description of the arm in dh parameters  multiplying out the kinematics equation  partial differentiation w r t  each dh parameter  then a least squares fit  with the left pseudo inverse   then iterate    is there some fundamental reason why dh parameters are used instead of a different representation  like xyz   euler angles    i understand that there are fewer parameters    versus   or more   but for a calibration procedure like this i will be taking much more data than unknowns anyway   all the robotics textbooks i have read just present dh parameters and say  this is what you should use   but don t really go into why   presumably this argument can be found in the original paper by denavit  but i can t track it down  ,robotic-arm kinematics calibration dh-parameters
7764,blade    qx  what does this red wire do ,i have a blade    qx quadrotor   quadcopter and i had to move a red wire shoved under the circuit board when i fixed a broken power wire  now the red wire shown out straight from the circuit board is not in the right configuration   or at least as it was  if i understood what it was for i might know how to place it  is this a horizon sensor  temperature   ever since i had to move this wire  the quadrotor goes unstable when flying  the only appreciable change is the wire position  the red wire was not attached anywhere else on the board  it was shoved under the circuit board inside the battery holder   ,quadcopter
7765,drone battery question,background     propeller drone w   c  s      mah      lipo battery   propeller drone w   c  s      mah      lipo battery  behavior   drone   flies with ease drone   struggles hover     inches above ground  question  the microcontroller  all props  escs  and motors are the same  i m thinking the reason the drones are flying so differently is because of the difference in batteries  if the batteries are the reason  what would be the property that is most responsible for the difference in flight  ,battery
7766,duty cycle mapping,i need to build a conversion mapping algorithm from a controller  pid etc   output to the duty cycle in order to command my bldc motor via esc  i couldn t do it yet because l think l dont know the meaning of controller output  anybody highlights my way  ,arduino motor esc microcontroller
7772,how to cut throttle signal to esc properly ,i have a    channel servo driver board from adafruit  see here   and i communicate to it via i c using a raspberry pi  the servo board is controlling a qbrain by sending a pwm pulse between  ms to  ms and it works great  problem is  i m trying to create a kill switch such that the signal from the servo board would cease  and the esc would stop because it detects no pwm signal  i have placed a toggle switch that cuts the vcc to the servo board  so technically it should no longer produce any pwm signal  however when the power is cut  the esc jumps to      throttle  i can only assume this is because the esc believes the signal is      duty cycle  but how do i solve this  ,raspberry-pi esc
7774,modeling a robot to find its position,the task of the robot is as follows  my robot should catch another robot in the arena  which is trying to escape  the exact position of that robot is sent to my robot at  hz  other than that i can use sonsor to identify that robot  is that possible to estimate the next position of other robot using a mathematical model  if so  can anyone recommend tutorials or books to refer    ,arduino kalman-filter automatic probability
7778,electric motor speed control   pwm vs analog voltage ,i m working on a   wheeled robot and have connected up a raspberry pi to an l   n motor driver  i m sending the enable pin of a particular motor a software generated pwm signal at    hz with a     duty cycle   i observe with an osciloscope   a fairly clean square wave going into the enable pin as expected  a fairly dirty square wave across the output motor terminals   the motor turns at about     speed torque as expected  i find myself wondering if it would be better to control the speed of the motor by placing a flat lower constant voltage across its terminals  rather than oscillating a square wave   ie to do     speed torque   instead of oscilating between  v and  v   just put a constant    v across the motor terminals   i wonder if the oscillation is a waste of power energy  is this true   or doesn t it make any difference   do high end motor drivers use a variable flat analog voltage to control speed torque  or do they use a pwm   if a pwm  does the frequency make any difference  ,motor
7781,how do i decide the size of the time steps between sensing and control actuation ,my background  my experience is in solid mechanics and fea   so i have zero experience in robotics controls    problem description i m developing a control strategy to stabilize a complicated   legged dynamical system   torques ti from each leg s joints will be used to create a net moment m on the body  stabilizing the system   this moment m is known from the pre determined control strategy    side note  the dynamical solver is of the nonlinear computational type  due to my lack of background  i have a fundamental confusion with the dynamical system   i want to use joint torques ti to create this known net moment m on the body   this moment m is a function of the  current positions angles of all the leg segments reaction forces and moments  that cannot be controlled  of each leg controllable joint torques ti of each leg time   at a given time t      from the control strategy  the desired net moment m is computed known   one can read sense the legs  positions  angles  reaction forces  and reaction moments  say  from well placed sensors   at this time t      from this information  vector algebra easily yields the desired joint torques ti required to create the net moment m   at the time t     one applies the previously determined joint torques ti  determined at t  to create the desired moment m    of course these torques ti are applied at the immediate proceeding time step because they cannot be applied instantaneously  so this is exactly where my fundamental confusion exists   the torques ti were calculated in   based on data of angles positions reactions in   with the objective to create moment m   however  these torques ti are applied in   where the data  angles positions reactions  are now different   thus the desired net moment m can never be created  unless you an magically apply actuation at the instantaneous time of sensing    am i understanding the controls problem correctly    questions  am i understanding the robotics problem correctly   what are the terms and strategies around this dilemma  of course i could create the time steps between the sensing and the actuation to be infinitely small  but this would be unrealistic dishonest   what is the balance between a realistic time step  but also performs the task well   ,control actuator stability legged
7782,is it possible to do slam with few ir sensors like buddy ,i saw buddy s page and want to purchase for my slam research  however  i wonder is it possible to program buddy for slam   according to buddy s spec  they re only few ir s  sonars and a camera  as i know  most slam algorithms are implemented with powerful sensors such as rgbd stereo camera  or even laser range finder  are there any pepers mention about ir based slam  ,mobile-robot localization slam mapping rangefinder
7786,which joints to discretize for ik,i am using ikfast in openrave for my inverse kinematics   this is an analytical solver  so if your robot s dof matches the ik type s dof  then you get all possible solutions   but if your robot has more dofs  then you need to pick some joints to have a constant value    however  if you use openrave s python interface it will discretize that joint for you   i e  give you a set of solutions for every     radians of that joint   but my question holds for either interface    i have a   dof anthropomorphic arm with joints  roll pitch roll pitch roll pitch yaw as seen in this image   the discretized joints are call  free joints  in openrave s terminology   if i let ikfast decide  it picks joint    upper arm roll  to be the free joint   however  i have been using joint    elbow  to be the free joint because it is easier for me to think about   but then i realized that perhaps joint       or   would be better to discretize because they are closer to the end of the chain   won t the ik solutions suffer if joints closer to the start of the chain have a large discretization   or is openrave picking the optimal joint to discretize  i was just wondering if there is some standard practices or known conventions for this sort of thing  put simply  i want a set of ik solutions for the end effector at some pose   i will fix a joint either near the start or end of the kinematic chain   and what i set it to isn t going to be perfect   lets say it is off from some  ideal  position by some epsilon   now you can imagine that if i want the hand in front of the robot  and i pick a bad angle for the shoulder  like straight up for example   the rest of the joints will have a hard time getting the end effector to the target pose  if at all   but if i fix the wrist to be at some awkward angle  there is still a good chance of getting the end effector there  or at lease close   what kind of trade offs are there   which will have a  better  set of solutions  ,inverse-kinematics
7790,how to control motor speed via neural network on a dspic ,i would like to seek some advise on how i should go about implementing a neural network on a dspic to control the motor speed of a robot  if it is at all feasible   currently  i am deploying a typical pid control loop to control the speed of the motors that have encoders attached to them   here are some thoughts on what i think the set up should be like  inputs    desired speed  current speed output    pwm hidden    not sure how many nodes are needed and how many layers i also face a contradiction on how to do supervised learning for this  assuming i pass in a desired speed and the current speed  the output if using sigmoid function  would be from      i would take this an multiply by the maximum pwm value then compare to the pwm value required to generate that speed  is this the correct way to determine the error  i am a little unclear on this part  technically  i could manually determine the pwm values required for certain speeds  but that would result in a very small data set for training   alternatively  i considered passing the pwm values into the motor function  wait short period  then capture the current speed of the motor then compare that with the desired speed to get an error   i only just started coding some basic neural nets and i hope to get some ideas   thanks  ,motor pid pwm
7791,thrust measurement,i try to find out the relation between rpm vs  thrust for a battery motor propeller combination  the image shows my setup and also the measurement result  can anyone explain how l should use this datas  i know kv v gives the rpm but my voltage values decreasing because of p v i relation etc    ,quadcopter brushless-motor esc
7794,why is my robot not working,i have a spektrum dx e transmitter and a ar    receiver  i believe that they are paired because when i turn on the transmitter the receiver s light turns on  however i lost the bind plug but i somehow managed to bind them  i plugged in my servos and batteries into the correct slots but nothing happens when i move the sticks  what am i doing wrong  i have a y splitter for two power hd servos  contentious rotation  and another power hd micro servo for the steering but none of them are responding  ,wheeled-robot
7795,can i connect a udoo to a pc using a straight through ethernet cable or do i need a cross over ,can i connect a udoo board to a pc using a straight through ethernet cable  or do i need a cross over cable  as far as i know  most modern devices can use the two interchangeably  however  i am not sure if a udoo can do that  anyone with any experience  thank you for your help   ps  i don t have a udoo on me at the moment  so i can t test it myself  couldn t find any information in the documentation either   ,embedded-systems
7796,calculating required torque,say i had an object with   motors wheels attached  in a fairly standard arrangement   i need to calculate the amount of torque required from the motors to be able to move the object of x kilograms consistently  without skipping any steps  at a velocity of y  travelling up a slope of angle z  i m guessing this would also depend on factors like the grip of the tyre and such  fairly straightforward question  i hope the answer is that way too   thanks in advance  ,motor motion torque wheel
7802,ekf slam initialize new landmark in covariance matrix,i am trying to implement an ekf slam using the algorithm for unknown correspondences proposed in the book  probalistic robotics  by sebastian thrun in table         by now i understand actually all of the algorithm except of the initialization of new landmarks in the covariance matrix    in that algorithm when a new landmark is detected the procedure is just the same as if a normal measurment update for an already observed landmark is done  the kalman gain  is calculated for the new landmark and then the covariance is updated with that kalman gain and the jacobian  of that new landmark like this     in my understanding a just new observed landmark would not have any effect on the rows and columns that correspond to already mapped landmarks or the robot pose in the covariance matrix  instead i think that just two rows and columns for x and y should be created with some uncertainity like proposed here  the uncertainty of initializing new landmark in ekf slam   i tried to split down the calculation of  via claculating it blockwise to see if i could somehow come to the same initialization as shown in the link above  but i end up having a different covariance matrix where apparently the new landmark is effecting the rows and columns of the parts of the old covariance  which in my view can t be right  i hope i don t understand the pseudo code of the book wrong or i did a mistake in my try to come to the same initialization  any advice how the initialization of new lnndmarks work in that code or if it actually is the same as in the link will be appreciated  edit so basically what i am asking is  why would they do a normal kalman update of the covariance matrix in line    of table      for a new observed landmark  why is there no explicit case for the initialization of new rows columns of new observed landmarks in the covariance matrix  it seems to me like they just do a normal measurement update even for a just newly observed landmark  ,mobile-robot slam ekf
7803,gyroscope   how can i remove low frequency component with a high pass filter only ,i m using matlab to suppress low frequency components with a high pass filter   objective  filter angular velocity measurements affected by high frequency noise and bias in order to get the best estimate of the angular position   the output when the gyroscope is still looks like this   first approach the easiest way to remove baseline is to remove the average and can be achieved with matlab using one line of code   second approach we can design a high pass filter to attenuate low frequency components  if we analyze the frequency components of the signal we will see one peak at low frequency and  infinite  small components in all frequencies due to noise  with a second order butterworth filter with normalized cutoff freq wn       we will get what we are looking for   filtered data  tilting the gyro when we tilt the gyroscope the situation changes  with a sampling frequency of    hz we get the following plot   the first half of the dft is shown below in a normalized scale   you can find the sample mat file here the first approach works great  i would like to apply the second one to this particular case but here there are other low frequency components that make to job harder  how can i apply the second approach based on the high pass filter to remove the bias  edit    you can find more information here edit   how can we filter this signal to remove bias while keeping the angular velocity information  from     th to     th sample  intact  if gyroscopes have the bias problem only when they are not experiencing any rotation  then the offset is present only in the first      samples  if the above hypothesis is correct  maybe if we apply high pass filtering only in the first     samples and desactivate the filter during rotations of the gyro  the estimated angular position will be more accurate  ,gyroscope matlab filter
7809,robot structure kit or materials,i have an arduino  wires  resistors  all of that good stuff  however  i don t have materials to build the structure of the robot  what do you guys recommend  i don t have a place to solder yet so i can t solder but is there a kit or material that you guys recommend  will it work well with motors and other stuff  thanks   p s  i plan on building a standard driving robot  but i want to be able to make other robots with the same materials kit  i don t want a kit that only makes one robot  i want a lego esque approach to building the structure where i can build whatever i want with it   bump   ,arduino beginner
7815,are there off the shelf solutions for gps ins  accelerometer gyro magneto  sensor fusion for getting filtered fused location and speed output ,i am working on a project that needs tracking location and speed of pedestrians runners athletes  so not really robotics  but i see a lot of related usage and posts in the robotics domain  and an answer to this question could help with follower robots   i m interested in just the  d location  latitude longitude   using just the gps position has noisy jump samples and also the degradation due to multi path near trees etc  from reading about filtering solutions  i understand that sensor fusion that fuses gps with the data from inertial sensors  ins  helps improve a lot of these issues  also  this kind of sensor fusion seems to be used in a lot of places    robotics  wearables  drones etc  hence i think there might be off the shelf chips modules solutions for this  but i couldn t find any  i found a sensor hub from invensense that integrates the   dof inertial sensors and comes with the fusion firmware  but it doesn t seem to have hookups and firmware for fusing gps and providing filtered latitude logitude   so  what should i be looking for  are there any off the shelf chips modules solutions that come with the built in sensor fusion software firmware for doing gps ins fusion   i understand that it will still need tuning some params as well as some calibration  ,localization kalman-filter sensor-fusion gps
7816,displacement with accelerometer,i want to use a sensor to find displacement with accelerometer  how can i use accelerometer to find displacement  i want to use this for a quadcopter  ,quadcopter imu accelerometer uav
7819,deciding length of quadcopter arms,how quadcopter s arm length affect stability  as per my view i ll have better control on copter with longer arms but with stresses in arms and also it doesn t affect lift capabilities  ,control quadcopter stability
7823,which sensor type most accurately measures position ,we re building an  dof joystick  and we need to accurately measure the displacement of our central device  we can easily use a mechanical connection to the edges  but there has been some discussion about what the best way to achieve this is  the range of motion will be fairly small  but accuracy is incredibly important for us  which sensors are most easily and accurately measured  my impulse response is that rotational and linear potentiometers are the most reliable  but others have been arguing for using gyros accelerometers  i ve also heard that hall effect sensors can be used to great effect  ,control sensors accelerometer
7825,what device do i need to project a laser to point at a specific location ,i m searching for a  commercial  projector that just projects a single laser point into the world  e g  using two moving mirrors   however  i m struggling because i m not sure what such a thing is called  i either find area projectors that use lasers  party equipment or laser pointers   what is the name for such a device   ,laser
7828,how is a brushless gimbal motor different from a regular brushless motor ,how are the brushless motors in a gimbal assembly designed  obviously it doesn t need continual rotation  but it does need accurate control of precise position  i ve noticed that the motors in my gimbal don t have the usual magnetic  snap  positions that my other motors do   what are the primary design differences in these kinds of motor  if any  ,motor
7829,how to program three wheel omni,i have created a three wheeled omni robot like the diagram below  now i am unsure of how to program it  i want to use a single joystick so one x and one y value  the values for x and y are between    and    also the motors can be set anywhere from    to    how do i use this data to make the robot move based on the joystick without changing orientations  after doing some initial research this seems like a complex problem  but i am hoping there is a formula that i can   ,wheeled-robot
7831,complementary and kalman filter don t work for y angle,i m working on a python script which reads the data from the mpu     imu and returns the angles using sensor fusion algorithms  kalman and complementary filter  here is the implementation  class mpu     reads the data from the sensor  processes it  class kalman is the implementation of the kalman filter  the problem is the next  none of the kalman  neither the complementary filter returns appropriate angle values from the y angle  the filters work fine on the x angle  but the y angle values make no sense  see the graphs below  i ve checked the code million times  but still can t figure out where the problem is     edit  i ve added some information based on  chuck s answer   self result list    contains the temperature in my opinion the compl  filter is implemented correctly  gyro x scaled and gyro y scaled are angular velocities  but they are multiplied by dt  so they give angle  acc   scaled are accelerations  but acc x angle and acc x angle are angles  check my comment  where the complementary filter tutorial is  yes  there was something missing in the kalman filer  i ve corrected it  i totally agree with you  sleep dt  is not the best solution  i ve measured how much time the calculation takes  and it is about       seconds  the y angle filters return incorrect values  even if sleep        or sleep calculatedtimedifference  is used   the y angle filters still return incorrect values  ,kalman-filter
7832,kalman filter for estimating position with  direction  measurements,i am currently working on a pose estimation problem for which i would like to use filtering  to explain the system briefly  it consists of two cameras and each has its own gps imu module  the main assumption is that camera  is fixed and stable  whereas camera  has a noisy pose in  d  i am using computer vision to obtain the pose  metric translation and rotation  of camera  w r t  camera   so that i can improve upon the inherent noise of gps imu modules  the problem here is that the translation obtained through the vision method is only up to an arbitrary scale  i e  at any given instant  i can only obtain a unit vector that specifies the  direction  of the translation and not absolute metric translation  the camera based estimation  although accurate  has no idea about how much actual distance is between the cameras  which is why i have the gps  which gives me position data with some noise  example  camera   is   m to the east of camera    the pose from my vision algorithm would say               m north east to camera    it would be something like               hence  would it be possible to consider the gps estimate of the metric translation as well as its covariance ellipse  and somehow link it with the normalized camera measurements to obtain a final  more accurate estimate of metric translation  i am not sure what kind of filters would be happy to use a measurement that has no absolute value in it  thanks  ,kalman-filter cameras pose
7837,type of servo and torque calculation required for a  axis robot arm,i am trying to build a   axis robot arm with pan and tilt mechanism  the gripper holder will hold an object weighing     grams  the total weight of the arm including the motors will be around   kg  i have decided to use     degree servo motors  the maximum arm reach will be     mm   what i want to ask is   what kind of servos  analog digital  will be suitable to support the total weight    kg  and the object weight      g   how do i calculate the required torque  how many servos should i use to make sure that my arm doesn t flip over   please suggest me if there is a better approach to designing the robot  i am fairly new to electronics and this is the first time i am building a robot  thanks in advance   ,robotic-arm design servos
7838,mcu architecture design,are there any standards regarding single vs multiple mcu in a robotic system  more specifically  if a single mcu can handle all of the sensor data and actuator controls  is it better to use a single mcu or multiple mcus in a hierarchical manner  are there any references papers regarding this topic  what are the arguments towards one or the other  i am looking for facts  not personal opinions  so pros  cons  standards and such  ,design
7841,real time camera localisation in known environment,i am young researcher developer coming from different  non robotic  background and i did some research on camera localisation and i came to the point  where i can say that i am lost and i would need some of your help  i have discovered that there is a lot of slam algorithms which are used for robots etc  as far as i know they are all in unknown environments  but my situation is different  my problems and idea at the same time is   i will be placed in an known room indoor environment  dimensions would be known  i would like to use handheld camera i can use predefined landmarks if they would help  in my case  i can put some   unique stickers  on the walls at predefined positions if that would help in any way for faster localisation  i would like to get my camera position  with its orientation etc  in realtime    hz or faster    for beginning i would like to ask which slam algorithm is the right one for my situation or where to start  or do you have any other suggestions how to get real time camera positions inside of the known room environment  it must be really fast and must allow fast camera movements  camera would be on person and not on robot  thank you in advance  ,localization slam real-time
7850,emax esc simon series with arduino,i want to control a brushless motor with the  emax simon series   amp esc  and arduino  leonardo  board  i am really confused how to do that  i can t understand which beep sounds mean what  i have tested many code examples but they weren t useful    ,arduino brushless-motor esc
7852,olf futaba rx   tx with apm micro       ,hi there i just found this old rx   tx in my loft and need to know weather it is compatible with my apm micro        i already have telemetry but that does not give me manual control  my guess is i need a new rx because the current one will make a hash of the electronics on the apm  thanks in advance   enter image description here            enter image descriptere           ,quadcopter
7853,how to tune pid for a y t    k x t  system ,could i have your opinions on pid type selection   system description  here comes a very simple system     is constant and  is a system variable which may change according to time  the goal of the whole system is to maintain system output at   it has to be as close to zero as possible  the controller has to compensate the   the change     is modeled by a very slow ramp   controller description  the controller s input is the output of the system  however  the measurements are always noisy  and i modeled band limited white noise into the measurements  after pid controller  the output goes into an integrator  since the pid controller always calculates the  change  of the plant input    questions  my original thoughts  add a pid controller with p   k is enough  since every time the controller gets an error   it can be calculated back that the compensation on controller output shall be   however  matlab auto tuning always give me a pid  why is that  what is the relation between p of pid and measurement noises  if p is large  the system will tend to be rambling largely  due to the noises  if p is small  the system will tend not to converge to the correct value or very slow  how to make the trade offs  or how to prevent system from rambling largely and get quick system responses    thanks a lot  ,control pid
7855,how is the absolute flash size calculated in a microcontroller ,i am working with an stm  f   c  which has a flash size of   kbytes  now i am using chibios     and the build file is a binary file of   kbytes  using st link utility  the program is getting dumped into the microcontroller s flash   my question is how come a   kb code fits in the   kb flash  how is the size of that  bin calculated  i am attaching a picture of the display   i did a compare ch bin with device memory and it doesn t report any errors found  all parts of the code work just fine  i don t see any problems anywhere tried all the features of the code  nothing breaks or behaves abnormally  could someone please explain this  thanks   ,microcontroller
7860,irobot create serial cable for turtlebot i,i need an irobot create serial cable  one end   pin mini din connector and the other end is usb  for turtlebot i   how can i connect my bot to my pc  ,mobile-robot irobot-create serial roomba
7864,can rc servo motors continually rotate ,i know that rc servo motors are designed for precise movement  rather than a d c  motors  continual rotation  are most rc servo motors limited to movement within one rotation or can they actually be made to continually rotate  that is to say  is their movement limited to a specific arc  or does it depend on the type of rc servo motor  i have seen videos of industrial size steppers rotating constantly  but  more specifically  i was wondering whether a mg    can   i don t own any rc servo motors yet  so i can t actually test it myself  i just want to make sure before i make a purchase  i keep seeing conflicting information  for example the instructable  how to modify a rc servo motor for continuous rotation  one motor walker robot   implies that a rc servo motor will not continually rotate  else otherwise  why would there be a need to modify it   addendum i have just realised  after further digging about on google  and as highvoltage points out in their answer  that i have confused steppers and servos  in addition  i found out how to hack the towerpro mg    servo for continuous rotation  ,stepper-motor rcservo
7870,simple sensor fusion for pose estimation,i am currently working on a balancing robot project  which features fairly low cost sensors such as an   dof imu with the measurement states   currently i use the accelerometer and gyroscope readings  fused by a complimentary filter to get the angular deviation of the robot s upright  stable  position  the magnetometer values are tilt compensated and yield the robots orientation with respect to the earth magnetic field  awful when close to magnetic distortion   furthermore i have pretty decent rotational encoders mounted on the wheels which deliver information on a wheel s velocity    given these measurements i want to try to get the robots pose  position   heading    i do have minor theoretical knowledge on ekf or kf  but it is not sufficient for me to actually derive a practical implementation  note that my computational resources are fairly limited  raspberry pi b  with rtos  and that i want to avoid using ros or any other non std libs  can anybody help me on how to actually approach this kind of problem   ,sensors kalman-filter imu sensor-fusion odometry
7872,simulation environment for conducting visual servoing experiment,i want to conduct the following experiment  i want to set up a scene with a kuka lwr   arm  a  d model of an object and a camera overlooking them  i want to find the pose of the object using some pose estimation algorithm and move the arm towards the object   in general i want a piece of software or a combination of cooperating software that can do all that without having to reinvent the wheel  is there anything available  ,software simulation visual-servoing
7874,what commands make the irobot create   go left and right not just forwards and backwards ,i am new to the create   and i downloaded real term to program  opened an interface to the robot and send numbers with it to the robot  i can only get the drive command to work  i only know how to make the robot go faster  turning around or slower  i would like to know how to make the other commands work along with making it go left and right  ,irobot-create
7877,original paper of kalman filter,recently we ve encountered kalman filter algorithm for state estimation in a course of probabilistic robotics  after taking several days to try to read kalman s original paper published in        a new approach to linear filtering and prediction problems   it firstly feel a bit difficulty to read  and it seems the majority is to show the orthogonal projection is the optimal estimation under certain conditions and solutions to wiener s problem  but i did not find the exact algorithm in this original paper as the one in the textbook    for example  is there an explanation of  kalman gain  in this paper   does kalman s paper provide a mathematical derivation of kalman filter algorithm   ,kalman-filter
7879,forward kinematics  why   should remain same ,can anyone please explain me these lines found on page   of  kinematics equations for differential drive and articulated steering by thomas hellstr m   note that plugging in  and  for both left and right wheel result in the same   otherwise the wheels would move relative to each other   hence  the following equations hold    begin align   omega   left r  frac l     right     v r    omega   left r  frac l     right     v l    end align  where  is the distance between icc and the midpoint of the wheel axis  and  is the   length of the wheel axis  see figure       figure            when left and right wheel rotate with different speeds  the robot rotates around   a common point denoted icc   my questions are    how do these equations come to be  why does  have to be same if we want to analyse the behavior after changing the wheel velocity relative to other  how do we know about the circle  in which the robot rotates by doing variations in one wheel velocity  surely passes through the center point between two wheels   ,mobile-robot
7881,how do i dispense a greasy fluid ,i m a agricultural engineering student and complete newbie trying to build a simple mechanism attached to a drone that dispenses a grease type fluid  however  since i m not familiar with the field  i m having a hard time googling because i don t know the correct terms to search for   i m looking for a mechanism that will remotely push the grease out  the problem is carrying the necessary weight for an hectare     g to    kg of fluid  and the dispenser mechanism within the drone  so i m looking for a lightweight dispenser mechanism capable of deliver small amounts of this fluid   g  distributed on the trees canopy  the grease do not need to be heated as it flows naturally in normal temperatures  like a toothpaste   both pump or syringe type arrangement would be fine as long as i can control it remotely  ,motor quadcopter design battery actuator
7882,how to determine x axis if the two z axis are intersecting in denavit hartenberg representation,suppose i have a   link   dimensional  chain in which all the joints are revolutes  the axis of first revolute joint is along z axis global  and axis of second joint is along x axis global   the first link is along x axis global  and second link is along z axis global   now in order to use dh representation i introduced a local frame for link   at joint   z axis along z and x axis along x  and another frame at joint   here z axis is along axis of rotation global x  and here i am clueless how to determine x axis for joint   because the two z axis are intersecting  standard procedure is to find common normal between two z axis  thanks for your time  ,robotic-arm dh-parameters
7883,how can i get the values of a imu from the serial message received in simulink via uart ,i try to read imu sensor data from an arduino mega      uart with serial receive block of arduino support package for simulink  the imu can send binary packets and also nmea packets and i can configure it to any output  when the serial recieve block output is directly used  it displays just the numbers between        l need help about how to parse the coming data which contains the euler angles that i want to use  here is binary structure    s   n   p  packet type pt  address data bytes  d    dn    checksum   checksum   the pt byte specifies whether the packet is a read or a write operation  whether it is a batch operation  and the length of the batch operation  when applicable   the pt byte is also used by the um  to respond to commands  the specific meaning of each bit in the pt byte is given below  packet type  pt  byte    has data    is batch    bl     bl     bl     bl     hidden    cf packet type  pt  bit descriptions      has data  if the packet contains data  this bit is set      if not  this bit is cleared           is batch  if the packet is a batch operation  this bit is set      if not  this bit is cleared           batch length  bl   four bits specifying the length of the batch operation  unused if bit   is cleared  the maximum batch length is therefore               hidden  if set  then the packet address specified in the  address  field is a  hidden  address  hidden registers are used to store factory calibration and filter tuning coefficients that do not typically need to be viewed or modified by the user  this bit should always be set to   to avoid altering factory configuration      command failed  cf   used by the autopilot to report when a command has failed  must be set to zero for all packets written to the um   the address byte specifies which register will be involved in the operation  during a read operation  has data       the address specifies which register to read  during a write operation  has data       the address specifies where to place the data contained in the data section of the packet  for a batch read write operation  the address byte specifies the starting address of the operation  the  data bytes  section of the packet contains data to be written to one or more registers  there is no byte in the packet that explicitly states how many bytes are in this section because it is possible to determine the number of data bytes that should be in the packet by evaluating the pt byte  if the has data bit in the pt byte is cleared  has data       then there are no data bytes in the packet and the checksum immediately follows the address  if  on the other hand  the has data bit is set  has data      then the number of bytes in the data section depends on the value of the is batch and batch length portions of the pt byte  for a batch operation  is batch       the length of the packet data section is equal to    batch length   note that the batch length refers to the number of registers in the batch  not the number of bytes  registers are   bytes long  for a non batch operation  is batch       the length of the data section is equal to   bytes  one register   the data section lengths and total packet lengths for different pt configurations are shown below  the two checksum bytes consist of the unsigned    bit sum of all preceding bytes in the packet  including the packet header  read operations  to initiate a serial read of one or more registers aboard the sensor  a packet should be sent to the um  with the  has data  bit cleared  this tells the device that this will be a read operation from the address specified in the packet s  address  byte  if the  is batch  bit is set  then the packet will trigger a batch read in which the  address  byte specifies the address of the first register to be read  in response to a read packet  the um  will send a packet in which the  has data  bit is set  and the  is batch  and  batch length  bits are equivalent to those of the packet that triggered the read operation  the register data will be contained in the  data bytes  section of the packet  here is an example binary communication code   ,arduino electronics embedded-systems matlab
7884,using blob detection in v rep,i was trying to reproduce this youtube tutorial in v rep and i came across some problems concerning blob detection  there are some complaints on this matter under the video  i don t believe that blob detection stopped working in recent v rep versions  but i was unable to make it work  as a new v rep user myself   has anyone any idea how to properly implement it   more specifically  i have a vision sensor named  and i want it to follow a red ball  the vision sensor will detect the position of the ball and i will use it to control the joints that steer the sensor  yaw and pitch   my script follows threadfunction function       yaw simgetobjecthandle  yaw       pitch simgetobjecthandle  pitch       cam simgetobjecthandle  cam       while simgetsimulationstate    sim simulation advancing abouttostop do         result pack  pack  simreadvisionsensor cam          if result   then             xtarget pack                 ytarget pack                 simauxiliaryconsoleprint out string format   n x      f  y      f  xtarget ytarget               simsetjointtargetvelocity yaw        xtarget               simsetjointtargetvelocity pitch        ytarget           end     end end  simsetthreadswitchtiming    out   simauxiliaryconsoleopen  debug       res err xpcall threadfunction function err  return debug traceback err  end  if not res then     simaddstatusbarmessage  lua runtime error     err  end  when i run the simulation i can see that the sensor sees the red ball at some point but result is always   meaning that no detection takes place    here is my scene ,simulator visual-servoing
7886,how to numerically calculate the jacobian ,i m trying to calculate the jacobian for days now  but first some details  within my master s thesis i have to numerically calculate the jacobian for a tendon driven continuum robot  i have all homogeneous transformation matrices as i already implemented the kinematics for this robot  due to it s new structure there are no discrete joint variables anymore but rather continuous parameters  therefore i want to compute the jacobian numerically  it d be awesome if someone could provide a detailed way how to compute the numerical jacobian for a   dof rigid link robot  only rotational joints    rrrrrr   from that i can transfer it to the continuum robot  i ve already started computing it  let t be the homogeneous transformation matrix for the endeffector  tip   with t  begin bmatrix r   r           end bmatrix   with r   rotational matrix  contains orientation  and  endeffector position  my approach is to compute the first three rows of j by successively increasing the joints  computing the difference to the  original  joint values and dividing it by the increment delta  the joint space is                and so on  i do the same for the y and z coordinates  so i get the first   rows of j   now i don t know how to compute the last three rows as they refer to the rotational matrix r  since it s a  x  matrix and no scalar value i don t know how to handle it   ,jacobian
7889,forward kinematics of constrained double pendulum,i was wondering whether maybe you could help me with this problem  i have a double pendulum  i have set the origin of cartesian coordinates to be the  head  of the first arm  which is fixed  the end of the second arm is attached to a block that slides along the x axis  what i want to do is to derive the equations relating the pendulum s angles with the distance from the origin to the block   now  i know how i could go about deriving the equations without the constraint   x     l  cos a    y     l  sin a    where  and  is where the first arm joins the second arm and  is the angle between the horizontal and the first arm   similarly  i can derive the equations for the end of the second arm   and  now then  if i attach a sliding block to the end of my second arm  i don t know whether my equation for  would change at all  i don t think it would but  would i have to somehow restrict the swing angles so that the block only moves along the x direction   well  basically the problem is finding the equation of  if it s attached to a block that only moves along the x  direction   ,forward-kinematics
7894,beginner soldering question,so  i need to know a couple of things about soldering  my primary workspace  robotics and otherwise is a desk with a computer and only a little bit of free space   ft  by   in    i am wondering if it is safe to solder in such a small area  also  what level of ventilation do i need to solder safely  my desk is in a normal house room and my desk is write next to an air vent  my house has heating and a c  do i need a fan or a fume sucker thing  i plan to only solder a little to get things to stay in my solder less bread board  soldering header pins onto wires and such   so  basically  what are the minimum requirements for soldering safely  space and ventilation   also  if anyone could point me to some hobby beginner level soldering must haves on amazon that would be great  thanks  ,beginner
7895,irobot create    powering up after sleep,i ve notice the irobot create   does not respond to the app s commands when it has been sleeping   if i press the clean button and re run the app then the robot is responsive to the commands  my initialization sequence  android java  using usb serial for android   the physical architecture is irobot create   connected by irobot serial cable to google project tango tablet  how can my app wake up the roomba from it s sleep  ,irobot-create
7896,how to rotate a dc motor at a fixed rpm,i am using      microcontroller and a dc motor what to do if i have to rotate the motor at any fixed rpm  let s say    rpm  and if it is possible by generating pwm how to do the calculations for the relation between duty cycle and rpm  ,control motor microcontroller
7903,how can i tell if a servo motor is capable of being controlled degree by degree ,i want to create a rotating control mechanism that can turn a surface to face any direction in a sphere  my dad  an electrical engineer  said i can probably do it by connecting two servo motors together   i am looking for a servo motor that can do what i want to do  which is moving the sphere with decent precision  within    degree  but i don t know which kinds of motors are able to handle such precision   another challenge is that one servo will have to hold the second servo on top  as i understand it  the torque rating determines the maximum amount of force the servo can exert on its load so i can figure out if the servo is strong enough through some math  ,control servos
7910,how can i recognize animals in a video stream or static images with opencv or other library software ,i m a software developer not experienced in ai or machine learning  but i m now interested in developing this kind of software  i want to develop software that recognizes some specific objects  specifically  animals from a video stream  or a sequence of static images   i saw there s a library called opencv which is often commented in this forum  but what i saw so far is this library is a helper for working with images  i didn t find the object recognition or self learning part  is opencv a good starting point  better go for some theory first  or there are other already developed libraries or frameworks aimed for object recognition  edit to give some context  i will have ona camera checking a landscape  mostly static but some leaves may move with the wind or some person may step in  and i want to get an alert when some animal is into view  i can reduce the  animals  to only birds  not always i will have a nice bird sky contrast   i did some work with supervised neural networks some    years ago and studied some ai and machine learning theory  but i guess things have improved way too much since then  that s why i was asking for some more practical first steps  thank you ,computer-vision
7912,powering a project tango tablet with irobot create  ,project tango development kits come with a mini dock  see picture below     i am controlling the irobot create   by the mounted tablet using the usb cable provided plugged into the mini dock   see docs    the usb     port on the mini dock is only functional when the tablet is docked  the port can be used to attach an external memory drive or standard peripherals to the tablet   i wish to recharge the tablet using the power from the irobot  the mini dock comes with a port for external charging   the mini dock accepts a power adapter for faster charging  not provided   the power adapter output must be   v   a  and the connector must be a barrel plug with    mm outer diameter     mm inner diameter  center positive   ideally the charging would happen only when the irobot is also charging  but charging all the time is acceptable   is this possible   if so  how   ,irobot-create
7913,non linear control system ,i have a dual  sequential  loop control system controlling the angle of a rotational joint on a robot using an absolute encoder  i have tuned the inner control loop  for the motor  and am now working on tuning the outer loop  for the joint   example of a dual loop controller  when i disturb the system the response isn t what i would expect  kp        kp       kd          i didn t add a ki term because i don t have any steady state error  i m confused by the fact that the second overshoot in the first plot is larger than the first one  no matter how i adjust the parameters i can t seem to get rid of the oscillation in the velocity of the joint  seen in the second plot   one limitation i have is if i increase both kp and kd too high the gearbox of the becomes very noisy because the noise in the encoder signal creates larger adjustments in the position of the motor  i m working on adding a filter to the output using the method described here  the code i m using for the outer loop is   i m beginning to think that the system might not be able to be modeled by a first order equation  but would this change the implementation of the control loop at all  any advice is appreciated  ben ,pid
7915,arduino mega shield v    compatibility with arduino due,like the title says   will it work  i know about the due     volt limitations  i want to build a hexapod with    servo s  the shield i am looking at   if it isn t compatible  is there an alternative shield which will work  i can t seem to find much for the due  ,arduino
7919,telemetry with apm     and xbee,the transmission of telemetry data between the ground base station and apm   x  arducopter   using xbee  is not well documented  the only documentation is telemetry xbee  but it does not specify what xbee version is used  i have been checking and i guess is version    this one has p p link and the others not   but i am not sure  i would like to know  what xbee modules people use for flying drones  do they have problems with the apm connection  how can i control the drone remotely using the xbee link with mavlink protocol  ,quadcopter radio-control mavlink
7920,inverse kinematics solution for  dof serial arm,my   joint robot arm structure doesn t meet the requirements for a closed form solution  no   consecutive axes intersecting at a point or   parallel axes        what would be best method to adopt to get solution in  ms or less  estimation accuracy of  mm  i m assuming the computation is done on an average laptop intel core i      ghz   gb ram ,inverse-kinematics
7921,robot localization without any sensors,is it possible to localize a robot without any sensors  odometer and servo motors  assume robot has dc motors and no obstacles  ,localization mapping
7925,positioning sensor,i would like to locate the position of a stationary autonomous robot in x y z axis relative to a fixed starting point  could someone suggest sensors that would be suitable for this application  i am hoping to move the robot in  d space and be able to locate it s position wirelessly  the rate of position update is not important as i would like to stop the robot from moving and relay the information wirelessly  the range i am looking for is roughly   km    the more the better  with accuracy of        cm  is there any system that could do this  thanks for your help  ,sensors imu
7928,robot path planning,my goal is to move robot in certain points as shown in the figure  it s initial position is  x  y   and move along other coordinates   i am able to track robot position using a camera which is connected to pc and camera is located at the top of the arena  i ve mounted a ir beacon on the robot  camera find this beacon and locates it s coordinate in cm  in the arena  using this coordinate how can i move my robot to another position  say new position  x  y   my robot has arduino mega      with two dc motors  communication between pc and robot is done using bluetooth update  thanks  chuck for the answer  however i still have few doubts regarding turning angle  my robot position setup is as shown in the image   xc  yc  is the current position and  xt  yt  is the target position   if i want to align robot in the direction of the target coordinates  i ve to calculate atan  between target and current coordinates  but the angle remains same since it s current position is not changing with respect to the target point  so i assume robot simply makes      rotation at current position  update  the path points is as show below in the image  is my initial heading angle assumption is correct       is the starting point   update thank you for your patience and time  i m still struck at turning  my code goes like this  since angle is always      robot only makes right turn in loop at current point  since angle is not changing  i think i m missing something here  ,arduino navigation
7930,can i charge a lipo nano tech battery over imax b  charger,can i charge a lipo nano tech battery over imax b  charger      mah      c  s is the battery ,battery lithium-polymer
7937,multiple ekfs or one big,let s say i would like to use an ekf to track the position of a moving robot  the ekf would not only estimate the position itself but also variables affecting the position estimate  for example imu biases  wheel radius  wheel slip and so on  my question is  is it better to use one big ekf  state vector containing all estimated variables  or multiple smaller ekfs  each one responsible for tracking a subset of all variables to be estimated   or is there no difference  as for the example above  the ekf could be split into one for tracking position  one for estimating wheel radius and slip and one for estimating imu biases  the position ekf would of course use the estimations output from the other concurrent ekfs and vice versa  to me it seems it would be easier to tune and test multiple smaller ekfs rather than just one big  are there any other advantages disadvantages  execution time  ease of debugging etc   assuming the resulting estimates are equal in the two approaches  or close enough at least   thanks  michael ,kalman-filter ekf
7940,recommendation for really high precision attitude measurement sensors,i am new in this field  i am looking for some high precision gyroscopes and accelerometers for attitude measurements the precision requirement is around         deg s dynamic      i have done some digging myself  not a single integrated mems sensor can do that without costing too much  so some heavy math is needed but that s fine i need to make sure the prefect sensors are chosen  the budget is less than    usd      can any one help  thanks in advanced  ,sensors research
7942,wall following using hokuyo lidar and sharp ir sensors,i have a mobile robot and i would like it to follow the walls of a room  i have   a map of the room   wheel encoders for the odometry  a kalman filter for fusing data from wheel encoders and imu   a hokuyo lidar for localization and obstacle avoidance a kinect to see obstacles which can not be seen by the hokuyo   amcl for localization  a couple of sharp sensors on the side for wall following    i am not planning to use the global or local costmap because the localization of the robot is not perfect and the robot might think that it is closer  or further away  to the wall than it actually is and therefore  wall following might fail  so  i am planning to just use the data from hokuyo lidar and sharp sensors to do wall following and maintain constant distance from the wall  say    cm    now  i would like to know what is the best technique for doing wall following in this manner  also  how can one deal with the issue of open gaps in the wall  like open doors  etc    while doing wall following using the above approach  i know this is a very general question but any suggestions regarding it will be appreciated  please let me know if you need more information from me  update  i am just trying to do wall following in a given room  i have the vertices of the room in a global reference frame  for example  lets say i have a map of a room  shown below   i want to make the robot follow the wall very closely  say    cm from the wall   also  if there is an open space  on bottom left   the robot should not go in the adjacent room but should keep on doing wall following in the given room  for this  i have the boundary limits of the room which i can use to make sure the robot is within the given room   the approach which i am thinking is to come up with an initial global path  set of points close to the wall  for wall following and then make sure robot goes from one point to the next making sure that it always maintains a certain distance from the wall  if there is no wall  then the robot can just follow the global path  assuming localization is good   i am not sure about its implementation complexity and whether there is a better algorithm  approach to do something like this   ,sensors localization navigation
7944,compatibilty of my setup ,i m building my first quadcopter  and these are the components i intend to buy   motor  emax bl          kv brushless outrunner motor around     kg thrust   flight controller  multiwii v    flight controller  propellers  i don t know which one to get  fut electronics propellers collection  gps  skylab uart gps module skm      small form factor  radio communication  radio telemetry     mhz   dr   is there an affordable alternative to buying a radio telemetry maybe using wi fi    escs   x  esc   x  a    speed controller for quadcopter  battery  i don t know which one to choose  my questions are   are the components compatible  what battery to choose  if i m not planning to do gps planned missions  would the gps be important for anything else   by the way i intend to attach a camera or a smart phone to it for video capturing i think it is about an extra     grams  ,quadcopter multi-rotor uav
7945,why the name  combinatorial  ,why are  cell decomposition  methods in motion planning given the name   combinatorial  motion planning  ,motion-planning
7950,axis of rotation via imu,using an imu  gyro  accelerometer and magnetometer   as found in most smartphones  can i detect the differences between tilting the device  say forward  along different  parallel  axis positions   to clarify  if the axis of rotation is far from the sensor  the the motion contains a translational component  can the distance and position of this axis be extracted from the imu data and if so how  is there some data fusion algorithm that can do all this  ,imu accelerometer gyroscope magnetometer
7953,hand eye calibration solver,i have a rig for which i have a pretty good estimate of the static transformation between the camera and a joint based off of the cad  it has some errors though and i was hoping to fix it by doing a hand eye calibration  so  i started off with generating some data based off of the transformation that i have already  from the papers that i have been reading  they all want to solve the ax   xb problem by either converting    to dual quaternions or simplifying the equation to something like   n a   xn b  where    are the eigenvectors corresponding to the eigenvalue of   for the  and  rotations  after generating the data  i tested if my data collection was correct and i validated it by checking if  for all of the s and s that i generated  i used the camodocal library to try and solve the problem but i got this    the actual transform is the one that i had based my  and  data on  then i tried implementing the tsai lenz and horaud and dornaika s nonlinear optimization techniques using lm solver but to no avail  i do not get the correct transformation out of any of the solvers  so  i was wondering if you could point me to a hand eye calibration library or paper that has worked  ,kinematics calibration
7954,book on mechanisms,i wanted to know if there is any sort of archive of mechanisms that contains a brief description of mechanisms like there type of motion and forces involved  not lengthy derivations and other stuff   ,mobile-robot mechanism
7959,tuning pd for line follower,i am trying to make line following robot  i am using atmega   p mcu  pololu      motors  pololu qtr  rc sensor   s li po  here is my code   and here is my qtr library       ifndef qtrrcsensors  define qtrrcsensors   define slow           define fast           static inline void initqtrs void         tccr b         cs        uint   t qtrtime qtrcnt   qtrmax qtrcnt   qtrmin qtrcnt    static inline void readqtrs uint  t forceslow        uint  t lastpin  i  done           for  i      i   qtrcnt  i                          clear out previous times         qtrtime i            readddr     b                                      set pins to output     readport     b                                     drive them high       delay us                                          wait   us to charge capacitors      readddr     b                                      set pins to input     readport     b                                     turn off pull up registers      tcnt                                               start   bit timer at       lastpin   readpin       while   tcnt    maxticks       done   qtrcnt     forceslow          if forceslow  always take maxticks time               if  lastpin    readpin                         if any of the pins changed                       lastpin   readpin              for  i      i   qtrcnt  i                                  if   qtrtime i              lastpin       i           did pin go low for the first time                                       qtrtime i    tcnt                       done                                                        if  done   qtrcnt                                  if we timed out  set any pins that didn t go low to max         for  i      i   qtrcnt  i                if  qtrtime i                        qtrtime i    maxticks     void calibrateqtrs void        uint  t i  j       for  j      j       j                              take    readings and find min and max values         readqtrs slow           for  i      i   qtrcnt  i                  if  qtrtime i    qtrmax i                   qtrmax i    qtrtime i               if  qtrtime i    qtrmin i                   qtrmin i    qtrtime i                      void readcalibrated void        uint  t i      uint   t range       readqtrs fast        for  i      i   qtrcnt  i                          normalize readings        relative to min   max         if  qtrtime i    qtrmin i                      check if reading is within calibrated reading             qtrtime i               else if  qtrtime i    qtrmax i               qtrtime i                  else               range   qtrmax i    qtrmin i               if   range                                 avoid div by zero if min   max are equal  broken sensor                  qtrtime i                   else                 qtrtime i      int   t  qtrtime i     qtrmin i            range                     uint   t readline void        uint  t i  online          uint   t avg                                       weighted total  long before division     uint   t sum                                       total values  used for division      static uint   t lastvalue                          assume line is initially all the way left  arbitrary       readcalibrated         avg          sum           for  i      i   qtrcnt  i                          if following white line  set qtrtime i           qtrtime i          if  qtrtime i                                  only average in values that are above a noise threshold             avg     uint   t  qtrtime i      i                      sum    qtrtime i               if  qtrtime i                              see if we re above the line                 online                           if   online                   if it last read to the left of center  return            if lastvalue    qtrcnt                        return                if it last read to the right of center  return the max          else             return  qtrcnt                      lastvalue   avg sum                                no chance of div by zero since online was true      return lastvalue      endif  i am trying to find kp constant but when it s   then my robot just turns off the line always on the same spot  when kp is   then it follows staright line but wobbles a lot and can t take corners  i also tried to increase kd    to    times when my kp was   but it didn t change much  how can i get it working  here is my robot and the track i want to follow    ,pid line-following avr tuning
7964,total hand calculations procedure   formulaes of mega quadcopter,i am a student of be taking mega quadcopter as my final year project can u please help me with the total hand calculations of the mega copter i e its procedure and formulaes    i wanted to know how to calculate the dimensions of frame specifications of motor and propeller the rating of esc s and the power rating of the batteries and its total no s i do not want direct answers but its procedure and formulaes i want to lift aload of around       kgs  please feel free to help  ,quadcopter
7966,orthogonal projection of laserscanner data,i recently discovered this ros package     which is basically exactly what i need  however i am not using ros  so i need to do what is been done in this package myself  basically the information i have is the range measurement r and the angle theta for every measurement point of a     degree laserscan   i have the orientation in roll  pitch  yaw angles of the laserscanner  however yaw is not important for me and could be ignored  i really can t get my head around how to project those points to the ground plane  i mean it is easy for the measurement point which align with the roll and pitch axes  but i don t know what to do with the points in between  d one solution i thought of is this   convert the measurement point  r  theta  in cartesian coordinates  x y z    vector use rotations matrices  create rotation matrix for rotation around roll axis with roll angle  and adequately for the pitch axis  multiplay bot matrices and then multiply it with  x y z    vector  now the orthogonal projection of the of the measurement would be the  x y z    vector with z    convert  x y    vector back to polar coordinates  r  theta    however  especially step   is very complicated  because the rotation matrices change according to the sign of the roll and pitch angles  right  i would like to note that the absolute value of role and pitch angles will always be        so there should not be an unambiguity with rotations   is there an easier  or maybe more elegant  way to solve my problem  my guess is  that this problem must have been solved basically for every robot application which uses a  d laserscanner that is not fixed to one axis   but i can not find the solution anywhere  so i would be very glad if anyone of you could point me in the right direction  kind regards ,quadcopter slam
7968,what pid values should i keep,i have built quadcopter but the problem is of balancing  it doesnt goes up  i am using pid techniqe for balancing  but i am not finding the suitable values for pid tuning  i am using mpu     as a sensor  i get the accelerometer values of x and y axis and find the error from them  that is lets say if accel on x is not zero then it error cause it should be zero if balanced  i am using    g sensitivity scale of accelerometer  the motors i am using are dji     kva  what values for kp  ki and kd should i set  i cant set them while in flight cause it completely out of balance   this is the design  completely home made  i have modified it a little after this photo  accelerometer is at  g so at balance z will be            there are also few more questions  should i scale error or pid output  because error is from ranging from   to       at  g setting  so i am scaling it from   to     so should i divide error or pid by some value  ,quadcopter pid balance
7969,what erector sets will function with normal servo motors ,i need a basic erector set that the parts will fit with servo motors and dc motors  preferably below       i ve looked at minds i basic set and it looks good except i don t know if it will function with my servos without hot glue or extensive modifications   if it matters  i am making a bipedal robot so i don t require any wheels or anything pre built  i just need a basic set that i can add on to to build a whole bunch of different robots   ,mobile-robot rcservo
7970,firmware upgrade for irobot create  ,is there a firmware upgrade for available for the create    i had some issues in march when using these for assigning a university of tennessee  programming project  we are getting ready to use them again  we have    now  and i d like to get them all updated to the latest firmware  ,irobot-create
7972,air hockey with a robot as an opponent,i m not sure if this is the right place to post this but here goes  so  as the title states  i m planning on building a desk that doubles as an air hockey table which has a robot on the other side  the robot would be mounted on a rail which should be able to go left and right using a linear actuator  it should be able to  attack  the puck using two servos  the real problem is how should i detect the puck s location  my idea  since the table would have tiny holes in the corners of a every square    inx   in   i could fit in a laser on the bottom part of the table  a laser for ever  in so a  inx in square  the same location would be reflected on the  ceiling  of the table but instead of laser diodes  they would be replaced by an ldr   so i m planning on doing a matrix and reading the signals of the ldr s columns and rows then performing some logic to locate the center of the puck  problems  while i don t see any performance flaws in my plan  i see tons of flaws when done imperfectly even to the tiniest bit   i have to be exactly accurate regarding the laser diode s position  it has to be on the center of the holes  right below the z axis  this should be easy if i m just going to place   or    but i m not  according to my estimations  i m going to have to use         laser diodes  depending on if i m planning on putting the lasers only on the opponent s side or on the entire board  it would definitely be costly  imagine        this isn t really a huge problem  more like a hassle  wiring     of these  forget the pcbs  the project area is just to large   i have thought of numerous way to lessen these  like using a color sensor to get the x axis location and a laser situated on a negative x axis pointing to the positive x axis to locate the puck s y location  but i m still comparing ideas  advantages  i could get a  d like graphical representation with  d like controls   d like in reality but technically  d since the lasers are only plotted in the x and y axis though facing the z axis    since this project is going to be my room desk  situated in an automated room  i was thinking of making  desk modes  which should toggle between a game that takes advantage of the lasers and their controls  a control desk for my room  ordinary desk mode  and an air hockey mode  my question   more like a request  does anyone have another idea regarding how i should be able to locate the puck s x and y location accurately in real time  edit  the table is roll able and stored underneath a loft bed which has an under area height of       which means i can t go grande on the a vertical solution  edit     thanks to the helpful people here  i have come to the conclusion of using a camera  the camera will be that of a smartphone s  i ll create an app that tracks an object by color and a has fixed size comparison to identify the distance of the robot from the puck  the phone will then process this and send signals via bluetooth  the phone is anchored at the end of the robot s moving part so the camera is reminiscent of those games with a first person view  incoming problems  i m looking forward to some delay  given the delay in processing  ,sensors microcontroller design electronics laser
7983,magnetic  low insertion force connector,i m building a robotic tea maker watchdog robot and have a power problem  i would like to be able to have the robot approach a socket and insert the power cord of a cheap immersion heater     v     w  see links below  to turn the heater on  however  the power and precision required to plug it into the wall is beyond the capabilities of my stepper motors arduino   my solution was a magnetic breakaway power cord like the charger on a mac but at higher voltage  deep fat fryers have suitable ones     v  high power  see links below   however  the problem is i need both sides of the connector  and i can only find the magnetic breakaway power cord  not the opposite side  which would normally be built into the deep fat fryer  i don t fancy buying a whole fryer just to get one little part    any ideas  alternatives to a breakaway cord  anyone know of any  cheap     v induction chargers  i ll resort to a mechanical on off switch and just leave the robot plugged in if i have to  but i was hoping for something a bit sleeker  links   immersion heater fryer cord   ,untagged
7992,how to calculate vehicle detection distance,i would like to know how to calculate the distance to each car when i run my application for an autonomous vehicle in real time  in addition i want to know how implement the calculation in c     you can see in the images we can know the distance for each vehicle but i don t know what code i should use to make all these calculations for every vehicle   please check the photo to understand more about what i m trying to achieve    ,control sensors localization ros cameras
7993,why can two series   xbees only talk in x ctu ,i have two series   xbees that won t be in transparent mode because they are in at command mode when i m not in x ctu   i had asked for help elsewhere and no one had the answer except telling me about flow control  the xbees had been configured properly with the my and dl settings   i m thinking maybe i should shorten the timeout so they supposedly get out of at command mode but they both stay in at command mode   the only time i can get the two series   xbees to talk is under x ctu   i need the two series   xbees to automatically be in transparent mode when powered on    ,wireless
7995,ceiling depth with a monocular camera,having a camera mounted on my robot and looking upwards  i want to estimate the distance of the ceiling as the robot moves and also the position of landmarks observed on the ceiling  lamps for example   i know this is a structure from motion problem but i was very confused on how to implement it  this case is a much simpler case than bundle adjustment as the intrinsic calibration of the camera is existing  the camera pose changes just in x and y directions  and the observed thing is a planar ceiling  odometry might also be available but i would like to start solving it without  do you know any libraries that offer a good and simple api to do such a thing  preferably based on levenberg marquardt or similar optimization algorithms taking in more than just two observations   python bindings would be nice to have  ,cameras 3d-reconstruction
7997,why can t you buy continuous servos with absolute positioning ,i ve been looking at parts for a beginners robotics kit  i teach at a museum  and have been wondering about servos  you can buy continuous servos with relative position encoders  but i can t find continuous rotation servos with absolute position encoders  do these exist  if not  why not  i understand that some forums don t like shopping questions  but i suspect that this part doesn t exist and i d like to understand why  also  i understand that most servos use a potentiometer as a position encoder and that these don t turn more than   rotation  but there are other types of encoders that seem like they would do the job  thanks for the help  ,servos quadrature-encoder
7998,weave weld lincoln electric mig robot,this is a simple question that i can t seem to find the answer for but when setting up the weave function how exactly does frequency  hz  determine how fast it moves back and forth   in other words if i raise frequency will it move quicker or slower and what factors must i consider   ,robotic-arm industrial-robot
8001,add hardware reset button for create ,is there any way to add a reset button to the create  that would be the equivalent  of temporarily disconnecting the battery   ,irobot-create
8006,quadcopter accelerating or not,i am on the project quadcopter  so i have to use pid for stabalizing it  i think i am going wrong because i am adding the pid output to motors thrust  while the motors thrust means to be its acceleration  the reason of my previous statment is that when the quad is static in air not goin up nor below   that time the thrust is enough to cancel gravity  means thrust is negative gravity  that is acceleration  so if i add pid output to thrust that is acceleration of motors  it will be wrong  i have to add pid to speed of motors  which is not visible  my quad is not stabalizing the reason i see is this  that i am adding pid to acc  while it should be added to speed virtually   what should i do  should i derivate the pid output and add to thrust    this is the drawing of my circuit  i am giving the current from one esc to whole of the circuit  other esc s has only pwm wire connected to circuit  ,quadcopter pid
8008,image based visual servoing algorithm in matlab,i was trying to implement the ibvs algorithm  the one explained in the introduction here  in matlab myself  but i am facing the following problem   the algorithm seems to work only for the cases that the camera does not have to change its orientation in respect to the world frame for example  if i just try to make one vertex of the initial  almost  square go closer to its opposite vertex  the algorithm does not work  as can be seen in the following image  the red x are the desired projections  the blue circles are the initial ones and the green ones are the ones i get from my algorithm  also the errors are not exponentially dereasing as they should   what am i doing wrong  i am attaching my matlab code which is fully runable  if anyone could take a look  i would be really grateful  i took out the code that was performing the plotting  i hope it is more readable now  visual servoing has to be performed with at least   target points  because else the problem has no unique solution  if you are willing to help  i would suggest you take a look at the  function to check that the rotation matrix is properly calculated  then verify that the line ds   vc  in euler ode is correct  the camera orientation is expressed in euler angles according to this convention  finally  one could check if the interaction matrix l is properly calculated  function visualservo        global a d b d c d d d a b c d ad bd cd dd       coordinates of the   points wrt camera frame     a d                                 b d                                c d                                 d d                                 initial projections  computed here only to show their relation with the desired ones       a a d      a d         b b d      b d         c c d      c d         d d d      d d           initial camera position and orientation      orientation is expressed in euler angles  x y z around the inertial frame      of reference      cam                      desired projections     ad a              bd b      cd c              dd d       t           tf            s    cam        time step     dt           t   euler ode t   tf  dt  s     end   function ts   euler ode t  tf dt s        global a d b d c d d d ad bd cd dd       s   s       ts         for t t  dt tf         ts end    t          cam   s             rotation matrix r wcs ccs         r   calc rotation matrix cam    cam    cam              r   cam                   d coordinates of the   points wrt the new camera frame         a d cam   r   a d r           b d cam   r   b d r           c d cam   r   c d r           d d cam   r   d d r              new projections         a a d cam      a d cam             b b d cam      b d cam             c c d cam      c d cam             d d d cam      d d cam                 computing the l matrices         l    l matrix a    a    a d cam              l    l matrix b    b    b d cam              l    l matrix c    c    c d cam              l    l matrix d    d    d d cam              l    l  l  l  l               updating the projection errors         e    a ad b bd c cd d dd             compute camera velocity         vc        pinv l  e            change of the camera position and orientation         ds   vc            update camera position and orientation         s   s   ds dt        end       ts end    tf dt  end  function r   calc rotation matrix theta x  theta y  theta z       rx             cos theta x   sin theta x     sin theta x  cos theta x        ry    cos theta y    sin theta y           sin theta y    cos theta y        rz    cos theta z   sin theta z     sin theta z  cos theta z                  r   rx ry rz   end  function l   l matrix x y z       l       z   x z x y     x    y              z y z   y    x y  x   end  cases that work  a    a  b    b  c    c  d    d   a  a    b  b    c  c    d  d     a    a    b    b    c    c    d    d     cases that do not work  rotation by    degrees and zoom out  zoom out alone works  but i am doing it here for better visualization  a    d  b    c  c    a  d    b    ,control algorithm matlab visual-servoing
8014,arduino mobile robot,is there a way i can control my arduino robot from anywhere in the world  the robot goes out of range of my home wifi so my wifi shield can t help  is there a way to make sure the robot is always on the internet no matter where it goes   ,arduino mobile-robot raspberry-pi
8018,complete quadrotor tutorial  text book ,i m looking for a complete tutorial textbook for how to build and control a quadrotor  dynamics  control  etc    i m an engineer with a broad background in programming  mechanics  and control but it s been several years and i m rusty  i was just wondering if anyone knew of a great  from the ground up  tutorial for quadrotors  i found this book which looks interesting but thought i d ask here too  thanks  edit so  assume i ve taken a formal course on all necessary topics  system modeling  mechanics  control theory  state estimation  programming  etc  i m looking for a book that assumes the reader is familiar with the topics but also goes step by step  for example  instead of just stating  here are the system equations  i m looking for  let s derive the system equations   but assumes you are familiar with modeling kinematics   i d like to start a quadcopter as a side project but have precious spare time so i d prefer a single good reference instead of jumping from each individual topic textbook  maybe i m just being greedy    ,quadcopter
8019,indoor positioning system  which is better ,which method is better  in term of accuracy  for detection of indoor localization of a drone  camera based system or wireless techniques like wlan or bluetooth  ,slam
8024,pid quaternion contoller,i want to control the attitude roll  pitch  yaw  of a vehicle capable of pitching and rolling  to do this i have created a quaternion pid controller  first i take the current attitude of the vehicle converting it to a quaternion qc and do the same for the desired attitude with the quaternion qd  i then calculate the input of my pid controller as qr   qc  x qd  the imaginary parts of the quaternions are then fed as force requests on the roll  pitch  yaw axes of the vehicle  i test on a simulator and the control works but becomes unstable in some cases  request for r     p     y      i also want this to work around singularities  i e  pitch     does anyone know why i get this behavior and if so explain  thoroughly  what i m doing wrong  ,control pid stability
8027,how to sumarize kalman filter covariances for display ,i m implementing an extended kalman filter and i m facing a problem with showing the covariances to the user  the covariance matrix estimate contains all the information we have about the current value estimate  but that is too much to display  i would like to have a single number that says  our estimate is really good  when close to   and  our estimate is not worth much  when large  my intuitive simple solution would be to average all the values in the covariance estimate matrix  or maybe just the diagonal   except that in my case the values have different units and different ranges  is it possible to do something like this  ,kalman-filter
8028,what i need to learn to build robots,what subjects are involved in robotics  if i want to build robots then what necessary things i need to learn consecutively as a beginner  ,artificial-intelligence embedded-systems first-robotics
8033,continuous vs discrete simulation in robotics,as far as i know  a robot sends orders as discrete signals  however  isn t computer simulation based on continuous simulation  do you know if it may happen any important difference when comparing reality to simulation in some cases  i heard that cable driven robots were quite sensitive  ,control simulation
8038,raspberry pi quadcopter drifts like crazy,i have recently built a raspberry pi based quadcopter that communicates with my tablet over wifi  the problem is that it drifts a lot  at first i thought that the problem was vibration  so i mounted the mpu      more securely to the frame  that seemed to help a bit  but it still drifts  i have tried tuning the pid  tuning the complementary filter  and installing a real time os  nothing seems to help very much  below is my code written completely in java  any suggestions are appreciated  quadserver java   sensor java  package com zachary quadserver   import com pi j io gpio gpiocontroller  import com pi j io gpio gpiofactory  import com pi j io gpio gpiopindigitaloutput  import com pi j io gpio pinstate  import com pi j io gpio raspipin  import com pi j io i c     import java net    import java io     public class sensor       static i cdevice sensor      static i cbus bus      static byte   acceldata  gyrodata      static long accelcalib                    static long gyrocalib                     static double gyrox      static double gyroy      static double gyroz       static double smoothedgyrox      static double smoothedgyroy      static double smoothedgyroz       static double accelx      static double accely      static double accelz       static double accelanglex      static double accelangley       static double smoothedaccelanglex      static double smoothedaccelangley       static double anglex      static double angley      static double anglez       static boolean init   true       static double accelsmoothing          static double gyrosmoothing           public sensor             try               bus   i cfactory getinstance i cbus bus                  sensor   bus getdevice  x                  sensor write  x b   byte   x                sensor write  x c   byte   x                system out println  calibrating                    calibrate                 thread sensors   new thread                        public void run                            try                               readsensors                              catch  ioexception e                            e printstacktrace                                                                           sensors start              catch  ioexception e                system out println e getmessage                          private static void readsensors   throws ioexception           long time   system currenttimemillis            long sendtime   system currenttimemillis             while  true                acceldata   new byte                 gyrodata   new byte                  int r   sensor read  x b  acceldata                      accelx      acceldata          acceldata    accelcalib                               accely      acceldata          acceldata    accelcalib                               accelz       acceldata          acceldata    accelcalib                                    accelz       math abs accelz                     double hypotx   math sqrt math pow accelx     math pow accelz                   double hypoty   math sqrt math pow accely     math pow accelz                    accelanglex   math todegrees math asin accely hypoty                accelangley   math todegrees math asin accelx hypotx                   system out println accelanglex        accelanglex        accelanglex        accelanglex                     system out println  accelx      accelx   accely      accely   accelz      accelz                r   sensor read  x    gyrodata                      gyrox      gyrodata          gyrodata    gyrocalib                         gyroy      gyrodata          gyrodata    gyrocalib                         gyroz      gyrodata          gyrodata    gyrocalib                          if init                                smoothedaccelanglex   accelanglex                  smoothedaccelangley   accelangley                   smoothedgyrox   gyrox                  smoothedgyroy   gyroy                  smoothedgyroz   gyroz                   init   false                else                   smoothedaccelanglex   smoothedaccelanglex  accelsmoothing  accelanglex smoothedaccelanglex                    smoothedaccelangley   smoothedaccelangley  accelsmoothing  accelangley smoothedaccelangley                     smoothedgyrox   smoothedgyrox  gyrosmoothing  gyrox smoothedgyrox                    smoothedgyroy   smoothedgyroy  gyrosmoothing  gyroy smoothedgyroy                    smoothedgyroz   smoothedgyroz  gyrosmoothing  gyroz smoothedgyroz                       smoothedaccelanglex   accelanglex                  smoothedaccelangley   accelangley                   smoothedgyrox   gyrox                  smoothedgyroy   gyroy                  smoothedgyroy   gyroy                        smoothedaccelanglex     accelanglex smoothedaccelanglex  accelsmoothing                  smoothedaccelangley     accelangley smoothedaccelangley  accelsmoothing                   smoothedgyrox     gyrox smoothedgyrox  gyrosmoothing                  smoothedgyroy     gyroy smoothedgyroy  gyrosmoothing                  smoothedgyroz     gyroz smoothedgyroz  gyrosmoothing                                anglex    smoothedgyrox  system currenttimemillis   time                    angley    smoothedgyroy  system currenttimemillis   time                    anglez    smoothedgyroz               anglex        anglex        smoothedaccelanglex              angley        angley        smoothedaccelangley               time   system currenttimemillis                   system out println  int anglex       int angley                 system out println  int accelanglex       int accelangley                        public static void calibrate   throws ioexception           int i          for i      i        i                          acceldata   new byte                 gyrodata   new byte                 int r   sensor read  x b  acceldata                     accelcalib        acceldata          acceldata                 accelcalib        acceldata          acceldata                 accelcalib        acceldata          acceldata                  r   sensor read  x    gyrodata                     gyrocalib        gyrodata          gyrodata                 gyrocalib        gyrodata          gyrodata                 gyrocalib        gyrodata          gyrodata                 try                   thread sleep                   catch  exception e                   e printstacktrace                                    gyrocalib       i          gyrocalib       i          gyrocalib       i           accelcalib       i          accelcalib       i          accelcalib       i           system out println gyrocalib         gyrocalib         gyrocalib              system out println accelcalib         accelcalib         accelcalib                 public double readangle int axis                switch  axis                        case                    return anglex              case                    return angley              case                    return anglez                     return               public double readgyro int axis                switch  axis                        case                    return smoothedgyrox              case                    return smoothedgyroy              case                    return smoothedgyroz                     return               public double readaccel int axis                switch  axis                        case                    return accelx              case                    return accely              case                    return accelz                     return               public double readaccelangle int axis                switch  axis                        case                    return smoothedaccelanglex              case                    return smoothedaccelangley                      return               public void setsmoothing double gyro  double accel                gyrosmoothing   gyro          accelsmoothing   accel           ,pid raspberry-pi quadcopter
8043,how to convert between classic and modified dh parameters ,i currently have a description of my    joint robot in  classic  dh parameters   however  i would like the  modified  parameters   is this conversion as simple as shifting the  and  columns of the parameter table by one row  as you can imagine     joints is a lot  so i d rather not re derive all the parameters if i don t have to    actually  the classic parameters are pulled out of openrave with the command      ,kinematics dh-parameters
8044,what are the best ways to transmit force through air efficiently ,i am taking part in a robotics competition  where the challenge is to create a pair of robots which successfully navigate a series of obstacles  however  the rules state that of the two robots  only one must have a driving actuator  the other must somehow be moved by the other robot  without physical contact   i could think of either having sails on the non driving robot  and moving it with fans on the driving one or electromangnets on the driving one and permanent magnets with the opposite polarity on the non driving one  however the problem with both is that efficiency falls off drastically with distance  thus  i am looking for possible ways to overcome this problem  thanks    also  the driving robot has a cable power supply  while the non driving one may only have batteries  rulebook   ,force
8045,composition of rotation matrices,i am the moment learning about rotation matrices   it seems confusing how it could be that   is the rotation from coordinate frame a to c c to a  and a b c are different coordinate frames   must for a  x  matrix be defined as   r a c   left   begin matrix  xa xb     xa xb    ya yb    ya yb  end matrix   right    are coordinates for points given in different coordinate frame  i don t see how  using this standard  the multiplication stated above will give the same matrix as for   some form for clarification would be helpful here  ,frame
8047,what kp ki kd should i keep, the above is my program for my quadcopter  but now i have to tune the pid values  that is kp  ki and kd  my accelome is at  g  please point to me what is wrong with the program  is the error signal not appropriate  please also give me or help me choose correct pid tuning  my limitation is i always have to connect my arduino to pc and change kp ki or kd values  that is i have no remote control available currently  ,quadcopter pid
8050,irobot create   serial battery power,i don s seem to be able to get any battery power from create    i spliced the original cable it came with  and tried to use the power from red purple    and yellow orange    to power a raspberry pi   with no luck  while the serial to usb cable still works  and i am able to command the robot via python  there seems to be no power coming on the red purple cables  i tried with a multimeter with no luck  even as i moved the device from passive safe full modes  there is no power even when create   is charging docked  ,raspberry-pi irobot-create serial roomba
8051,maximum ball screw speeds,what is the maximum rotational velocity of miniature ball screw  diameters up to   mm  for approximately      thrust cycles  and which type brand would that be  if the speed is limited by the ball return mechanism  the fastest i could find was      rpm at      n thrust  but this was from a datasheet with a big safety margin  millions of cycles   i m looking for either experience and data  or a general method formula that can be used to find the maximum velocity  and load  as function of cycles or the other way round  similar to those of ball bearings   suggestions and knowledge about faster types and brands of ballscrews than the ones i have been able to find is welcome as well  some more background information  ball screws are very interesting transmissions for electrically actuated legged robotics  since they provide a high geared rotary to linear transmission that is accurate  precise  energy efficient and possibly backlash free  however  the big downside is their limited rotational speed  the maximum rotational velocity is limited by resonance and the ball return mechanism  the former limit is easy to calculate  eigenfrequency calculation   and mostly not problematic for small spindles  however  the latter is a bigger problem  the balls in a ball screw roll through the threaded spindle and have to be recirculated to the other end of the nut  the recirculation limits the rotational velocity of the ballscrews  the corresponding maximum rotational velocities are not calculate able  for as far as i know  and are provided by manufacturers in catalogues  either directly in rpm or via a so called  value  where the rotational velocity in rpm is  where d is the diameter of the ball screw  but even then  the maximum rotational velocity of ball screws is capped at      rpm or lower according to datasheets  depending on brand and ball return mechanism   the highest permissible rotational velocities i found were those of steinmeyer ballscrews  at      rpm  using an end cap return mechanism  note that for electrical motors  up to    w  ideal  maximum power  velocities are higher than      rpm  and even more than twice as high for many brushless motors  it appears however that ball screws can run at higher speeds than what they are specified for in reality  because the specifications hold for many millions of cycles  i can only find a single unofficial source where someone claims to have run their ball screws up to      rpm  and in missiles  one time use  up to      rpm  i m interested in a theory or more experimental data that backs this up  ,driver
8053,how to use the homogeneous transformation matrix ,i am trying to understand how to use  what it requires compute the homogenous transformation matrix   i know   points from   different frames  and   origins from their corresponding frames   i how transformation matrix looks like  but whats confusing me is how i should compute the   x   position vector which the matrix needs   as i understand is  this vector a origin of the old frame compared to the new frame   but how to calculate it  the obvious answer  i think  would be to subtract both      but it does not feel right   i know its a simple question but my head cannot get around this issue  and how can i prove it the right way  with the information i know  ,kinematics frame
8054,motor for diy remote controlled shades,i m currently undertaking a project to build remote controlled shades from scratch  i currently have every piece figured out except i don t know know much about the motors involved in something like this  i am looking for suggestions on what type of motor to search for  i imagine i need a type that can go forward and back as well as stop when the shade is fully retracted  i don t know what to search for though  any help is much appreciated   ,motor
8056,what factors should i consider when selecting a motor for a free wheeled cart pole balancing robot ,i m developing a small scale cart pole balancing robot consisting of two wheels driven by a single motor at the base  essentially like a unicycle  but with two wheels to constrain balance to a one dimensional problem   i m not sure what qualities to look for in that motor   i think the motor should be able to accelerate quickly in directions opposite of motion as dictated by the control system   however  i m not sure if this rapid acceleration should correlate with higher torque motors or faster speed motors   i think higher torque motors would be too slow to react to control commands   in contrast  fast speed motors may not be able to overcome the momentum of the cart  are there any design equations or other calculations i can make based on my robot s dimensions and weight to determine the right specs needed for my robot s motor   how can i determine the right motor specs for this application without resorting to brute force trial   error experiments  ,motor design balance
8058,optimal time acceleration sequence of a line following robot following a moving obstacle,say we have a line following robot that has a moving obstacle in front  that is a one dimensional problem  the moving obstacle is defined by its initial state and a sequence of  longitudinal  acceleration changes  the acceleration function is piecewise constant   let s say the robot can be controlled by specifying again a sequence of acceleration changes and its initial state  however  the robot has a maximum and minimum acceleration and a maximum and minimum velocity  how can i calculate the sequence of accelerations minimizing the time the robot needs to reach a goal  note that the final velocity must not necessarily be zero  can you briefly explain how this problem can be addressed or point me to some references where an algorithm is described  or point out closely related problems  furthermore  does the solution depend on the goal position or could the robot just brake as late as possible all the time  avoiding collisions  and still reach any goal in optimal time  a more formal problem description  given the position of the obstacle   and the velocity of the obstacle   where  is a known piecewise constant function  a b t     begin cases  a  b       text for   t    leq t   t      a  b       text for   t    leq t   t       dots       end cases  and given the initial state of the line follower  we search for piecewise constant functions   where    and   collision freeness  holds at all times  reasonable assumptions are e g   and   among the feasible solutions i would like to pick those minimizing  or a similar objective  approximation algorithms are also ok  some numbers for those who would like a test input   ,mobile-robot control motion-planning line-following
8062,ir   khz receiver,these days i m trying to build ir   khz long range receiver  i use ir phototransistor  i don t want to use components like tsop    i need to make daylight filter and intensify filtred signal because out of this sensor i wanna use with some microcontroller  can someone help me  any idea  thanks  ,sensors
8065,solution for ins and gps integration,i have a gps module and an imu  gyro  accelerometer and magnetometer  and i need to build an autonomous navigation system for a quadcopter  it must know its position at any time so that it can track a predefined path  i know that  in order to improve precision  i need to merge both sensors data through a kalman filter  or any other technique for that matter  the thing is that the kalman filter is way more common according to my research   the problem is that i am seriously stuck and i know this might be something very simple but i don t seem to find a solution or at least the answer for some of the most basic questions  as a start  i know how to get the position from the accelerometer readings  i have some filters that help eliminate noise and minimize the integration errors  i also have the gps readings in latitude and longitude  the first question is  during sensor fusion  how can i make both measurements compatible  the latitude and longitude from the gps won t simply mix with the displacement given by the accelerometer  so what is the starting point for all of this  should i calculate the displacement from the gps readings or should i assume a starting latitude and longitude and then update it with the accelerometer prior to applying the filter  i have once developed a simple kalman filter in which i could plug the new reading values to obtain the next estimate position of a two wheeled car  now i have two sources of inputs  how should i merge those two together  will the filter have two inputs or should i find a function that will somehow get the best estimate  average  maybe   from the accelerometer and gps  i am really lost here  do you guys have any examples of code that i could use to learn  it is really easy to find articles full of boxes with arrows pointing the direction in which data must flow and some really long equations that start to get confusing very soon such as those presented on this article    i have no problems with equations  seriously  but i have never seen a real life example of such implementation  any help on this topic would be deeply appreciated  thank you very much  ,kalman-filter sensor-fusion gps
8077,mobile robot path reconstruction by using imu acceleration and yaw angle,i hope you can help me with my project  i m using a skid steering wheeled mobile robot for autonomous navigation and i d like to find a way to be able to perform path reconstruction in matlab  by using only the robot encoders  installed on the robot  and the yaw rate information  which come from a very accurate imu sensor mounted on the robot frame   i can successfully do the path reconstruction   i m using xbow    cc sensor  the problem is that i would like to try to reconstruct the path by using only the imu yaw rate and the imu acceleration values for x and y axis  i m able to obtain velocity and distance by integrating two times the imu acceleration values but my problem is that i don t know how to use this data  do i have to use a rotation matrix to pass from the imu frame to the robot frame coordinates   i m asking this because i use a rotation matrix for the encoder values which come from the robot encoder  at the moment  i use these equations for robot encoders and imu yaw rate   do i still have to use r  matrix  thank you a lot ,mobile-robot kinematics imu navigation matlab
8080,could anyone tell me what are these things in a roomba robot and how to clean them  please ,i m really in doubt whether it is proper to ask this question here  so i m apologizing if it is not  i ll delete it  i have a roomba robot which has worked for me for more than three years  and now while it is working it is producing some strange sounds  so i ve decided to clean it thoroughly  but when i disassembled it down to this point    i got stuck with these sort of glass things  marked with the red rectangles at the picture   they are really filthy from the inside and i cannot figure out how to clean them  does anyone know how one can remove dust from the inside on these things  may be there are some roomba creators here  thanks in advance  ,roomba
8082,wifi module for zumo robot,i m a cs student trying to implement a clustering algorithm that would work for a set of robots in an indoor controlled environment  i m still starting on robotics and don t have much experiencing in figuring out what will work together  my plan is to get   of these zumo robots and plug in a wifi module like the wifi shield  then  i would use this to do inter communication and execute my algorithm  my question  can the wifi module just be plugged in and would it work  if not  how can i go about achieving this task  i see lots of arduino boards with different names and i m not sure which works with which  and whether they can be plugged in  any help would be appreciated  ,arduino wifi
8087,is it safe to give  v through  v pin of arduino uno r  while usb cable inserted,is it safe to give  v through  v pin of arduino uno r  while the usb cable is inserted  i have escs connected to it which aren t likely to start in other cases  the  v and gnd is coming from the bec circuit of a connected esc  please help me  thanks ,arduino esc
8094,what is the learning  control  algorithm inside cubli ,as in this video   in this new version  did not see the learning part in the past versions   with three to four trials  cubli can learn to balance on a new surface  ,control
8096,how can i control fast real time sensor     hz  with slow system display   hz ,we do some experiments of real time representation of sensor position on tv  in this experiments  we used sensors for collect real time position in  d at    hz and tv for display the sensor position at   hz  also  we used matlab and c   for programming with opengl platform  in programming  every iteration dat display on the tv  erase and draw the circle  object  which is represent real time position on the display   in this program i collect to only    points and loose other     points in every second  becuase  i think that refresh rate of tv is   hz  i have gone through the thread  how can i control a fast     hz  realtime system with a slow    hz  system   how can i control a fast     hz  realtime system with a slow    hz  system    but i don t understand  how to implement two loop on    hz and   hz  my question is  how can we implement in matlab c    so i can store     data of sensors as well as    points for real time display on the tv  if you help me through pseudo code  i appreciate your help  thank you in advance  please help me  p s  code  ,design communication matlab c++
8100,robotic legs technologies,what robotic leg technologies are available  i m sorry if this is a basic question i am a software developer looking to get into the field of robotics  i am particularly interested in robotic legs that are similar to those used on boston dynamics atlas robot  what is the mechanism required that allows it to move its joints so quickly  if you see any videos of many of boston dynamics robots they make an engine sound  presumably because it uses an engine   but i cant find any details in the configuration that is being used  ,legged
8103,overheating jamming mg   r servo,i have recently purchased my first ever servo  a cheap unbranded chinese mg   r servo  for       on ebay   i am using it in conjunction with a arduino servo shield  see below    as soon as it arrived  before even plugging it in  i unscrewed the back and ensured that it had the shorter pcb  rather than the full length pcb found in mg    servos  so  it seems to be a reasonable facsimile of a bona fide mg   r  i read somewhere  shame i lost the link  that they have a limited life  due to the resistive arc in the potentiometer wearing out  so  as a test of its durability  i uploaded the following code to the arduino  which just constantly sweeps from    to      and back to     and left it running for about    to    minutes  in order to perform a very simple soak test   when i returned  the servo was just making a grinding noise and no longer sweeping  but rather it seemed to be stuck in the    position  or the        i picked the servo up and whilst not hot  it was certainly quite warm  a quick sniff also revealed that hot  burning motor windings smell   after switching of the external power supply and allowing it to cool  the servo began to work again  however  the same issue occurred a little while later  again  after allowing it to rest  upon re powering  the servo continues to work   however  i am reluctant to continue with the soak test  as i don t really want to burn the motor out  just yet  is there a common  no no  of not making servos sweep from extreme to extreme  and one should  play nice  and just perform     sweeps  or is the cheapness of the servo the issue here  i am powering the servo from an external bench supply  capable of  a  so a lack of current is not the issue   please note that i also have a follow up question  should a mg   r servo s extreme position change over time  ,arduino rcservo
8104,should a mg   r servo s extreme position change over time ,this question is a follow on from my previous question  overheating jamming mg    servo  i have recently purchased my first ever servo  a cheap unbranded chinese mg   r servo  for       on ebay   after mounting the servo horn and the bracket  i realised that i had not mounted the horn in a tout a fait    orientation  rather the angle between the bracket and the servo side was approximately      however  after switching the servo on and off a couple of times  with each time allowing the servo to perform  say  about    sweeps each time  i quickly noted that the servo s extreme positions were changing over time  so that the initial extremes and then the extremes after about   on and off cycles  had changed by about      so that now     and      the bracket is now parallel with the body of the servo   i was quite surprised at this  as i had assumed that the    and      positions would be fixed  and not change over time  or vary each time that it was switched on and off  seeing as there should be a stop peg on the gear connected to the potentiometer inside  how is this even possible  ,rcservo
8106, d positioning of mobile robot,i am just starting to explore an idea and i am somewhat of a novice in robotics  i am looking to position a mobile robot as accurately as possible on a concrete slab  this would be during new construction of a building and probably not have many walls or other vertical points for reference  the basic premise behind the robot is to print floor plans straight on to the slab  i will have access to the bim  building information models  cad  revit  files of the building  i want the robot to position itself as accurately as possible on the blank slab using the bim files as a map  what would be the best avenue to track and adjust positioning of the robot in the open space of a slab  low frequency  lidar  wifi  lastly what sensors would be best  ,mobile-robot sensors localization
8107,are there systematic ways to tune the kalman filter in engineering practice ,including q  r  and initial states of x and p  ,kalman-filter
8108,how to use specific esc bldc motor through arduino uno r  ,attempt to clean up  i m trying to use this motor with this esc and an arduino uno r   typically  i used the pwm pins when i use the arduino and an esc  but i can t control the motor even if i use the servo library  and i ve also tried sample code from different websites  the esc has a beep i can t understand  sometimes it s high low high or high for   seconds  but i can t find anything on google   sometimes the motor spins periodically for a short time  but i don t know why  some sites recommend using flash or bootloader  but i d prefer to use arduino pwm or the servo library   original post specific esc is rctimer mini esc  a opto simonk firmware sn  a esc   i can only using esc discussed above    and rctimer          kv multi rotor bldc motor  typically  i used pwm pins              because similar signal frequency  when using arduino esc   but  i can control bldc motor even i used to servo library    i ve been used usual websites example code  just esc had unknowable beep    sometime di ri di or di for   seconds     i couldn t find that way   in google  or my country websites  sometimes  the motor spins in a certain value  periodically  for a short time but i don t know why the motor spins in google sites  just using flash or bootloader  but i ll use arduino pwm or servo   so   please  would you please help me  thank you for reading my thread    ,arduino brushless-motor esc pwm
8111,multiple control loops with overlapping effects,i m familiar with using pid to perform closed loop control when there is a single output and a single error signal for how well the output is achieving the desired set point  suppose  however  there are multiple control loops  each with one output and one error signal  but the loops are not fully independent   in particular  when one loop increases its actuator signal  this changes the impact of the output from other loops in the system  for a concrete example  imagine a voltage source in series with a resistor  applying a voltage across a system of six adjustable resistors in parallel   we can measure the current through each resistor and we want to control the current of each resistor independently by adjusting the resistance   of course  the trick here is that when you adjust one resistor s resistance  it changes the overall resistance of the parallel set  which means it changes the voltage drop due to the divider with the voltage source s resistance and hence changes the current through the other resistors  now  clearly we have an ideal model for this system  so we can predict what resistance we should use for all resistors simultaneously by solving a set of linear equations   however  the whole point of closed loop control is that we want to correct for various unknown errors biases in the system that deviate from our ideal model   the question then  what s a good way to implement closed loop control when you have a model with this kind of cross coupling  ,control pid
8112,do you know where to get the original irobot create ,does anyone out there know where i can get the original irobot create  the company no longer sells them   it was only   years ago that it was sold  it is white and its value is the physical design  that it has a large exposed deck for mounting armatures  it is preprogrammed to operate in different configurations  eg  spinning  figure    following the outline of a wall  etc  i have an ongoing art project using this model and as they are in operation everyday  i will eventually need to replace them with new ones  to see a video of one of my projects you can go to  i currently have it working in a spinning motion  ,irobot-create
8116,covariance and optimization,i am trying to build a map containing lamps as landmarks  i drive around with a robot and a monocular camera looking to the ceiling  the first step is detect the edges of each observed rectangular lamp and save the position in pixels and also the current position from odometry of the robot  after the lamp disappears from the field of view  there is enough base line to do a  d reconstruction based on structure from motion  once this reconstruction is done there will be uncertainty in the position of the lamps that can be modelled by covariance  imagine if the robot was driving for a while  its own position estimated from odometry will also have a relatively high incertitude  how can i integrate all of those incertitudes together in the final covariance matrix of the position of each lamp  if i understand well there would be the following covariances   noise from camera inaccurate camera calibration matrix inaccurate result from optimization drift in odometry  my goal is to manually do loop closure using for example g o  graph optimization  and for that i think correct covariances are needed for each point  ,slam cameras 3d-reconstruction
8118,what sensors and mcu does vectornav vn    use internally ,i m hesitant to open up a vectornav vn    to see what s inside   does anybody here know what underlying sensors it uses   the accel  gyro  and mag outputs are all very low noise compared to other  high end    axis mems devices  ie kionix kxr    maxim        st lis mdl    everything fits in such a small package so i m guessing they re using devices with integrated axes and adc s  rather than than  navigation grade  devices which tend to be analog  fewer than three axes  and enormous compared to to consumer level mems   likewise  automotive mems sensors  which they mention they are using in one of the web pages  tend to be single or dual axis  and not necessarily less noisy than consumer grade sensors    ,imu navigation
8120,device to generate screen tap response,i have extremely limited knowledge in the general topic of robotics and therefore this question is a shot in the dark  please let me know if the topic is unsuitable for the site  i am interested in creating a device that would generate a touchscreen tap  in a nutshell  i would like to replicate on a touchscreen the automated mouse functionality you can obtain with software like autohotkey in windows  since  without jailbreaking the phone  a software solution is basically impossible  it occurs that one of the first components would be a physical device that simulates a tap  do any options for such a component exist  i recognize that there are philosophical implications with creating such a device  i am assuming the entire conversation to be theoretical and solely related to the hardware design  thanks  alex ,automatic
8122,powering my robot with   v battery which is charged by a gas petrol generator while the robot is operating ,a have designed a robot to perform tasks in farms   but the problem now is i m not sure on the best way to supply continuous power to my robot   all the motors are rated at   v and only arduino and a few sensors work at  v or less    can i continuously charge a   v lead acid battery with an adapter  comes with the battery  plugged into the ac output of the generator while the robot is operating  do i have to worry about overcharging the battery  or should i use the generator s dc output which can supply   v and up to    amp  or is there any other suggestions  some information about the adapter which are stated on the package     built in over charge protection device     built in thermal protection device    output   v   v  amp this is the generator that i have    this is my first robot which is quite big that requires a lot of electrical electronic knowledge to power it  i do not have a lot of experience in this field  so any feedback is greatly appreciated  ,electronics power battery
8124,two exclusive inputs control,i have a system with two inputs  throttle and brake  and one output  speed   how does one design a controller in such a way that the two outputs of the controller  throttle and brake  are never both greater than zero  so that it doesn t accelerate and brake simultaneously   thanks ,control automation
8127,can i connect the arduino usb to laptop after the arduino is started,i have some sensors attached to arduino uno r  and an esc  i start the motor attached to esc through ardiuno with no usb connected to laptop  it starts correctly  there is a must that i will have to start the arduino from non usb supply so that esc is correctly started  means that my motor doesnt start with usb connected to pc  now how can i get the sensor values to laptop  if i connect the usb to pc after starting the motor  will this work  ,arduino esc
8128,how to calculate the current consumed by a brushless motor on a quadcopter,i want to create a virtual quadcopter model  but i am struggling to come up with a satisfying model for the brushless motors   props  let s take an example  based on the great ecalc tool   let s say i want to know how much current is consumed by the motor in a hovering state  i know the mass of the quad      g   so i can easily compute the thrust produced by each motor   thrust is produced by moving a mass of air at an average speed of v  thrust         rho   a   v   where rho  air density  is      kg m  and a  propeller disk area  is pi   radius         m       props   so i can compute v  v   sqrt thrust         rho   a         m s  all right  now i can calculate the aerodynamic power created by the propeller  p   thrust   v                      w  all right  now i can calculate the mechanical power actually produced by the motor  i use the pconst efficiency term from ecalc  pmec   paero   pconst                     w  here  ecalc predicts     w  it s not too far from my number  i imagine they use more sophisticated hypotheses    fair enough  from this post  i know that this power is also equal to  pmec    vin   rm   iin     iin   io   where i know rm       ohms  and io      a   so  finally  my question  how do you calculate vin and iin from here  of course  if i knew the rotation speed of the engine i could get vin from  n   kv   vin  where kv       rpm v  but unfortunately i don t know the rotation speed     note that vin is assumed to be averaged from the pulse width modulated output produced by the esc  thanks for your help  ,motor quadcopter brushless-motor electronics power
8129,why are bipedal robots difficult ,not sure if this has been asked  but there are lots of simulations of bipedal locomotion algorithms online  some of the evolutionary algorithms converge to very good solutions  so it seems to me that the algorithm part of bipedal locomotion is well understood  if you can do well on simulations  you should be able to do it well in the real world  you can model delay and noise  you can model servo s response curve  what i don t understand is then why is it still difficult to make a walking robot  even a robot like the big dog is rare  ,walk
8130,line following robot path planning,i have built a mobile robot with several ultrasonic sensors to detect obstacles and an infrared sensor to track a line as a path  i have written a simple algorithm to follow the line which works fine  but avoiding obstacles are a problem because the robot doesn t know the layout of the path  so even if it does move around the obstacle  it is not guaranteed that it will find the path line again unless the line is perfectly straight   therefore  i think i may need to use a path motion planning algorithm or find a way to store the layout of the path so that robot could predict where to move and get back to the path line and keep on following after overcoming an obstacle  i would like to hear suggestions or types of algorithms i should focus on for this specific problem  picture might help specifying the problem i m facing   thank you  ,motion-planning
8133, ambiguous up to scale    explanation required,i am reading  computer vision  models  learning  and inference  in which author writes at several points  like on page          that although matrix a seems to have  n  degree of freedom but since it is ambiguous up to scale so it only has  n    degree of freedom  can anyone explain what this thing means  why one degree of freedom is decreased  ,computer-vision
8134,interferences while using two tof cameras,im using two time of flight  tof  cameras  a ds    from softkinetic and a creative senz d  at the same time with the depthsense sdk and the point cloud library  on ubuntu         but i got strong interferences  is there a possibility to control the laser  software side  either to send the light in a special frequency or to turn it off and on alternating  or is there another way to get rid of the interferences  ,cameras laser 3d-reconstruction 3d-model
8140, thermal imaging  with arduino and or lego mindstorm nxt     ,i m trying to build a robot that can be sent into rooms buildings and detect people using nxt and or arduino  in addition to this i would like to be able to view what my robot is  seeing  in real time on my pc as an infrared image  the sensors i ve shortlisted for this are   thermal infrared nxt sensor from dexter industries       roboard rm g      x  thermal array sensor       omron d t mems thermal ir sensor        i believe the roboard and omron sensors are capable of thermography  so i was wondering if anyone here has experience with these sensors and give me some advice  i was also thinking about using an idea from this project    in this case i d use the data read from the sensor to plot a graph showing different temperatures     ,mobile-robot sensors nxt
8142,high traction thin tires vs wide moderate traction tires   sumo bot ,i am building a sumo bot and our competitors have thin sticky tires  while we have wider and less sticky tires  the diameter is the same  and the gearbox motor is the same  who will win  ps  sticky tires     wide tires   thanks  ,movement wheel two-wheeled
8144,using dc motor as a generator to recharge battery of my robot,i am trying to recharge my   v lead acid battery with a   v dc motor   i am using the battery to power the robot when it climbs  when it descends  i notice that i dont need to apply reverse voltage but the dc motor just backdrives instead  this can act as generator to recharge back the battery  am i right  i know that i need to step up the low voltage that is generated by the backdriven motor to   v needed to recharge the battery  this is the board that i think can do the job   is this all i need to make it work  with this method  should i be concerned about the   stages of battery charging  bulk  absorption and float  please advise  any feedbacks are greatly appreciated  ,mobile-robot battery
8146,using slam to create  d topography,i have a small mobile robot with a lidarlite laser range finder attached to a servo  as of now i have the range finder side sweeping in a    degree arc  taking continuous distance readings to the side of the robot  perpendicular to the robots forward motion   my goal is to have the robot drive roughly parallel to a wall  side scanning the entire time  and create a  d map of that wall it is moving past  the  d topography map is created post processing  i use r for much of my data processing  but i don t know is popular for this kind of work   from what i know of it  slam sounds like a great tool for what i want to do  but i have two issues     i know my robot will not have a consistent speed  and i have no way to predict or measure the speed of my robot  so i have no way to estimate the odometry of the robot       the robot will also move further and closer to the wall as it proceeds down it s path  so i can not depend on a steady plane of travel from my robot  so given that i don t have any odometry data  and my realtive distance to the wall changes over the course of a run  is it possible to use slam to create  d maps  i m looking into stitching algorithms that are used for other applications  and some of these can handle the variances in relative distance  but i was hoping slam or some other algorithm could be of use here  ,slam servos laser rangefinder
8150,sensor orientation of an external magnetometer,on many drones are already external magnetometers  unfortunately  the orientation of such sensors is sometimes unknown  e g  the sensor can be tilted       pitch roll  or x  in yaw  i was wondering  whether one could calculate the rotation of the sensor relative to the vehicle by application of the accelerometer and gyrometer  theoretically  the accelerometer yields a vector down and can be used for calculation of the coordinate system  the discrepancy between magnetometer and gyrometer then  may be used for calculation of the correct orientation of the compass  later the compass should be used for yaw calculation   below is the starting orientation of both sensors  just an example  the orientation of the compass can be anything   does someone know a good way to figure out the rotation of the compass    ,magnetometer orientation
8152,how should i tie my quadcopter to some thing  to adjust pid on one axis,i am stuck in adjusting the pid of my quadcopter  i cant adjust them on the fly because it just get out of control  i am adjusting them while attaching my quadcopter to something  is this method correct  will the pid values required will be different on the fly or same  please suggest me how to attach my quad to some thing  ,quadcopter pid balance
8153,can someone explaine to me this code , ,c++
8160,implement of a vocal interface on a arducopter,i m a student working on a robotics project  and i m a complete beginner in robotics  i m working on the arducopter structure  using the ardupilot mega associated with the ardupilot imu as my autopilot board  i have an easyvr module with an arduino uno for my vocal recognition stuff  i don t know how to give order to the autopilot board with my vocal module  do i need to change the arducopter source code  do i have to use mission planner software  the final aim is to do this  ,arduino quadcopter ardupilot
8162,when to use multiple batteries vs a ubec,when should you use multiple separate batteries vs a single battery with multiple ubecs  i m trying to design the power system for a small   wheeled robot  aside from the   main drive motors  it also has to power an arduino  a raspberry pi and a couple small servos to actuate sensors   the motors are each rated for  v with a peak stall current of    a the arduino uses about  v    ma the raspberry pi uses about  v    ma the servos each use  v and have a peak stall current of    a   so the theoretical max current draw would be       a  originally i was planning to use three separate lipo batteries   one   v using a step down converter to power the main drive motors for  v    a peak two    v lipos each with step up converter  rated for  v  a  to handle the servos and logic separately  then i discovered ubecs  which sound too good to be true  and they seem to be both cheap        and efficient        and able to handle my exact volt current requirements  should i instead use a single high current   v lipo with three ubecs to independently power my drive motors  sensor motors and logic  or will this still suffer from brown out and power irregularities if a motor draws too much current  what am i missing  ,battery bec
8165,what s confidence level  and how can we use it for vehicle detection using opencv ,i m working on project for the autonomous vehicle  and i want to know what s confidence level means and how can we use confidence level for vehicle detection in opencv   ,opencv statistics
8168,how much offset speed of motors on an axis is required before adjusting pid,for adjusting the pid for quadcopter  how much speed of motors are required before adjusting the pid  do we need to give so much offset speed so that it cancels weight  i am sure we cant start adjusting pid with zero speed of motors initially  ,quadcopter pid
8171,robot arm reachability of a pose in cartesian space,given a set of robot joint angles  i e   dof   one can calculate the resulting end effector pose  denoted as    using the foward kinematic map   let s consider the vice versa problem now  calculating the possible joint configurations  for a desired end effector pose   the inverse kinematics could potentially yield infinitely many solutions or  and here comes what i am interested in  no solution  meaning that the pose is not reachable for the robot   is there a mathematical method to distinguish whether a pose in cartesian space is reachable   maybe the rank of the jacobian  furthermore can we still find a reachability test in case we do have certain joint angle limitations   ,mobile-robot robotic-arm kinematics inverse-kinematics jacobian
8181,can digital servo motors be modified for continuous rotation ,in an autonomous mobile robot  we re planning on using digital servo motors to drive the wheels  servo motors usually don t rotate continuously  however  they can be modified to do so based on many tutorials online which only mention modifying  analog  servo motors  my question is  can the same method s  or any other ones be used to modify digital servo motors  thanks ,mobile-robot rcservo
8182,image processing,i am making a robot goalie  the robot is supposed to detect whether a ball has been thrown in its direction   sense the direction of the ball and then stop it from entering the goal post  a webcam will be mounted on top of the goal post  the robot is required to only move horizontally  left or right   it shouldn t move forwards or backwards  the robot will have wheels  the image processing will be performed by raspberry pi which will then send the required information to a micro controller which will be responsible for moving the robot in the required direction using servo motors   which image processing algorithm will be the best to implement this scenario  ,mobile-robot computer-vision algorithm beagle-bone first-robotics
8184,what is the difference between a cnc router versus a cnc mill ,people at the reprap  d printing project often mention cnc routers or cnc mills  both kinds of machines almost always have a motorized spindle with stepper motors to move the spindle in the x  y  and z directions  what is the difference between a cnc router versus a cnc mill   is there a better place for this sort of question    perhaps the woodworking stack exchange   ,industrial-robot
8186,robot wire follower   how to position on wire,i m designing my lawn mower robot  and i am in the perimeter stage   the electronic part is done  and works quite good  now comes the software  i need an advice on how to deal with the problem of line following  i mean  once the robot is on the line  parallel to the line  that s relatively easy   but how to manage the situation when the robot is driving around and approaches the line  wire   i have two sensors  left and right  turned     with respect to the forward direction   the robot could arrive from any angle  so the signal amplitude read from the sensor could be completely random    so i don t understand what to do in order to move it in the right position on the wire    what s the usual approach    the idea is the same as here   the wire is all around the yard  on the mower there are   sensors  left and right  that sense the signal emitted from the wire  a square wave signal at    khz  the signal amplitude read from the sensors on the mower is about   v when it s above the wire  ,line-following magnetometer
8187,is there a simpler way than ros for   dof dynamixel arm control,i will have a   or   dof arm build with dynamixel or herculex smart servos  i need  to move the gripper along cartesian trajectory  which i will calculate in my c   application  i looked at ros  but the learning curve is pretty steep and it looks like a major overkill for this use case  i don t need a distributed system with all the complexity it brings  preferably  i would like to call a standalone c   library or libraries to get the arm actuated   what are my options  what will be the limitations of not using a full blown robotics framework like ros or yarp in this case  edit here is how i would like to code it   the last line can be spread over several library function calls and intermediate data structures  if needed  the end result should be the gripper physically following cartesian trajectory given by way points and way poses  ,robotic-arm ros motion-planning c++
8188,how can i avoid roomba error    code ,i am trying to run my     series roomba in a large  open space       sf  and it does not recognize the large  open space and throws the error    code   it does not recognize an edge of          either  it will fall off the edge and become stuck   any suggestions  ,mobile-robot irobot-create roomba
8191,rotation matrix to euler angles with gimbal lock,how do i determine which angle i can negate when gimbal lock occurs   as i ve understood with gimbal lock that it remove one degree of freedom  but how do i determine which degree can be removed when a  value r        of a rotation matrix  size  x   has the value     is it the roll  pitch or yaw which can be taken out from the equation  ,motion-planning
8194,choosing motors for quadcopter frame,i bought this drone frame   q    glass fiber quadcopter frame    mm from  i m considering buying   ax         kv brushless quadcopter motor s from  will these motor s fit this frame   how can i determine what motor s will fit the frame   ,quadcopter
8196,camera calibration fails to run on ros,i am running ros indigo on ubuntu        i am doing a mono camera calibration and trying to follow the camera calibration tutorial on the ros wiki  i give the following command   rosrun camera calibration cameracalibrator py   size  x    square         image   my camera image camera   my camera  i get the following error   importerror  numpy core multiarray failed to import traceback  most   recent call last   file     opt ros indigo lib camera calibration cameracalibrator py   line       in  import cv  importerror  numpy core multiarray failed to   import  i thought it was to do with updating  and did a rosdep update but no difference  what is a possible way to solve this problem  update  i uninstalled and reinstalled ros completely from scratch  i still get the same error  should i have to look somewhere outside ros  ,ros cameras calibration
8199,wires or columns which contract on passing electricity,background  introductory robotics competition for college freshmen  bot has to open   jars  with two balls in each of them  in ten minutes and load the balls into a shooting mechanism  so  we were doing this project and we hit upon a challenge that the jar is not opening like we originally intended to  so we decided to get a rack pinion mechanism and use it for unscrewing the lid  however  it is too large and we are unable to fit the bot in the required dimensions the actual question  are there any wires or rigid columns things which can contract    cm when electricity is passed through it  and what would their price range be  our budget is also in the list of constraints for the bot edit  we can include a wire of length   m or a column of length     cm  also  the wire needs to contract only more than  mm ,mechanism
8202,ekf slam  shrink covariance matrix on one direction,i have implemented an ekf on a mobile robot  x y theta coordinates   but now i ve a problem  when i detect a landmark  i would like to correct my estimate only on a defined direction  as an example  if my robot is travelling on the plane  and meets a landmark with orientation   degrees  i want to correct the position estimate only on a direction perpendicular to the landmark itself  i e     degrees   this is how i m doing it for the position estimate   i update the x posterior as in the normal case  and store it in x temp  i calculate the error x temp   x prior  i project this error vector on the direction perpendicular to the landmark  i add this projected quantity to x prior   this is working quite well  but how can i do the same for the covariance matrix  basically  i want to shrink the covariance only on the direction perpendicular to the landmark  thank you for your help  ,mobile-robot slam kalman-filter ekf
8204,velocity of the end effector,the joint velocities are constant and equal to      and       how to  compute the velocity of the end effector when  and   ,robotic-arm
8207,quadcopter stability vs  pid error signal lag and sample time ,the question i am asking is that  what is the effect on stability of increasing or decreasing both the sample time and lagging of error signal to pid  does it helps in stability or degrade it  ,quadcopter pid stability
8209,two dc motors and single output ,i saw one old industrial robot year       end effector is having   dc motor for roll drive  after roll drive  yaw and pitch drives are connected and it has dc motors separately  but roll drive has two dc motors  why are they used like this  why not single with higher torque  all the roll  pitch and yaw motors are same spec  total   dc motors  two dc motor connected to single shaft using gears in roll  ,industrial-robot
8212,uwsim pressure sensor units,i am attempting to use the data underwater simulator  uwsim  provides through the ros interface to simulate a number of sensors that will be running on a physical aquatic robot  one of the sensors detects the current depth of the robot so  i want to simulate this with the data provided by the uwsim simulated pressure sensor  the problem is that nowhere in the uwsim wiki or source code can i find any reference to what units uwsim uses to measure pressure  that being said  what units does uwsim use to measure pressure  additionally  i would appreciate general information about what units uwsim uses for the data provided by it s virtual sensors  ,ros simulation underwater
8213,balancing robot control model,i am trying to find a control model for the system of a balancing robot  the purpose of this project is control  by the   motors in the wheels i e  through the torque  i started with the dynamic equations and went to find the transfer function   then i will find the pid gains that will control the robot and keep it balanced with the most optimum response  for the time being i am only interested in finding the transfer function for the dynamic model only  here is an example   however  i am not sure of my result here are the free body diagrams for the wheels and the inverted pendulum  robot body  and calculations below    dynamic equations    begin array  lcr  m    ddot x      f r   f         rightarrow           m    ddot x      f         rightarrow            j    ddot  theta      f r r    tau    rightarrow           j    ddot  theta       tau   mgl theta    rightarrow          mbox  linearized pendulum      end array   kinematics   x     r theta      x     r theta     l theta       equating     and       m    ddot x      f        f r     frac j    ddot  theta     r     frac  tau  r    f r  yields    frac j    ddot  theta     r    m    ddot x       frac  tau  r    f       rightarrow      equating     with        frac j    ddot  theta     r    m    ddot x       frac  tau  r    m    ddot x          rightarrow         using kinematic equations on        j     m   r     m   r     ddot  theta      m   l r  ddot  theta        tau  rightarrow         equating     with        begin array  ccc   underbrace  j     m   r     m   r      ddot  theta         underbrace  m   l r   j       ddot  theta         underbrace m   gl  theta       rightarrow        a    b     c       end array   using laplace transform and finding the transfer function    frac  theta     theta        frac bs     c  as        substituting transfer function into equation        j     m   r     m   r     frac  theta     theta    theta   s     m   lr theta   s       tau     yields    frac            frac      mlr b  s   c   simplifying    frac            frac    j   s   m   gl   comments   this only expresses the pendulum without the wheel i e  dependent only on the pendulums properties   poles are real and does verify instability  ,arduino control pid wheeled-robot
8220,balancing a plate with an imu offset from the center,i recently bought a imu   i am new at this   my question  does the positioning of the imu matter  are there any differences between placing it at the center of the plate or if it is offset from the center  i am still learning about this topic  so any help would be greatly appreciated  thanks  ,control sensors imu sensor-fusion
8222, d angular velocity to  d velocity to predict next state,i have a sensor that gives r  theta  phi  range  azimuth and elevation  as such   i need to predict the next state of the object given the roll  pitch yaw angular velocities given the above information  but the math is really confusing me  so far all i ve gotten is this   i worked this out by trigonometry  so far this seems to predict the pitching about the x axis and yawing about my y axis  sorry i have to use camera axis  but i dont know how to involve the roll  angularzvel  ,kalman-filter
8223,determining pose from ar track alvar message in ros,i am using the ar track alvar package in indigo to detect ar tags and determine their respective poses  i am able to run the tracker successfully as i can visualize the markers in rviz  i give the following command to print the pose values  rostopic echo  ar pose marker  and i get the following output indicating that the poses are determined     now i want to use these poses in another ros node and hence i need to subscribe to the appropriate ros message  ar pose marker    but i am unable to get enough information on the web on the header files and functions to use in order to extract data from the published message  it would be great if somebody can point to a reference implementation or documentation on handling these messages  it might be useful to note that ar track alvar is just a ros wrapper and hence people who have used alvar outside of rosmay also give their inputs  update  i tried to write code for the above task as suggested by  ben in the comments but i get an error  the code is as follows  include  ros ros h   include  ar track alvar msgs alvarmarker h   include  tf tf h     include  tf transform datatypes h   void printpose const ar track alvar msgs  alvarmarker  constptr  msg           tf  pose marker pose in camera            marker pose in camera  setorigin tf  vector  msg pose pose position x                               msg pose pose position y                               msg pose pose position z        int main int argc  char   argv        ros  init argc  argv   pose subscriber         ros  nodehandle nh       ros  subscriber pose sub   nh subscribe  ar pose marker         printpose        ros  spin         return        and i get the following error  home karthik ws ros src auto land src pose subscriber cpp  in function  void printpose const constptr      home karthik ws ros src auto land src pose subscriber cpp        error   const constptr  has no member named  pose      marker pose in camera  setorigin tf  vector  msg pose pose                                                           make          auto land cmakefiles pose subscriber dir src pose subscriber cpp o  error   make          auto land cmakefiles pose subscriber dir all  error   make       all  error    any suggestions  ,ros pose
8225,choice for camera sensor to be used with lidar,i am doing research on autonomous car and looking for a sensor to be used along with lidar laser scanner  ladybug could be a very good option but the cost   too expensive   could you please suggest me options for camera sensors with good fov and which will cost me around         thank you so much    chiang chen ,computer-vision
8226,how would i replicate a tank zero turn steering system in a small robotic vehicle ,i m working on a project that requires me to build a small vehicle  footprint of      x    inches  less than     pounds  that can traverse sand  for the steering system  i was thinking of replicating the way tanks and lawn mowers navigate  ability to do zero point turns   but i want to do this with four wheels instead of tracks like a tank  i need help with implementing this idea  my preliminary thoughts are to have two motors where each motor power the wheels on one side of the vehicle  i think this would require a gearing system  or to have a motor to power each individual wheel which i d rather avoid  ,mobile-robot motor wheeled-robot
8228,quad copter flight module can replace with smart phone ,i want to replace the flight module with smart phone because it has all sensors that are required  like gyroscope  magnetometer  etc  is that possible  i am using an google nexus   android  os model       i will control using another mobile  i am able write an app  with an arduino acting as a bridge between smartphone and copter  i am using flight controller openpilot cc d coptercontrol  ,arduino quadcopter
8229, dof or  dof robot arm with stepper motors tool chain for an hobbyist,in the past i built some simple robot arms at home  using rc servo motors or stepper motors  till  dof   i would like to build a new arm with  dof or  dof with the steppers  until now i used arduino and a     stepper drivers and gcode  for calculating inverse kinematics in real time for a  dof or  dof i think the arduino is not enough powerful  so i m searching for a new tool chain gcode interpreter   inverse kinematics calculation   stepper controller  i see linuxcnc   beaglebone black   cnc cape  not too expensive for an hobbyist  but this is the only possibility i found  there are other possibilities for an hobbyist to implement a  dof or  dof robot arm working with the stepper motors  ,stepper-motor arm
8231,my quadcopter settling time is very large,my quadcopter s settling time is very large  that is it sets its setpoint in very large amount of time  during which it has covered a large distance  but at settle point  when i gives it a jerk or push its returns to settle in normal duration  doesnt over shoots little   the problem is with the settling time that is when i move the stick front or back it takes huge amount of time  what could be wrong  i have tried giving more p value and i value to pid but then it overshoots and get unstable  this is my pid program  the pid values are given  i read   channels from remote using the command pulsein    which i guess is taking upto   ms per command   pidy is added and subtracted to esc speeds respectively  ,arduino quadcopter pid
8234,for a quadcopter  premade flight controller or custom made ,i m interested in building a quadcopter  the result i d like to obtain is an autonomous drone  i d be interested in a gps to allow it to remain stationary in the air  and also to fly through checkpoints  can this be done with a flight controller  or does it need to be programmed  i m not too sure about what flight controllers really are  could someone offer any materials to help me get towards this goal  thanks  jacob ,arduino quadcopter
8239,embedded frame grabber machine vision fusion,looking to find a solution to save stills from three cameras  communication protocol can be camera link or gige  but we are looking for a lightweight solution to save stills  don t require video  as the system will be tested for a multirotor application  frames will be saved every   seconds so we don t require a lot of bandwidth  we don t require to do anything with the frames other than store them  thanks ,sensor-fusion uav embedded-systems
8241,linear actuators in a cartesian robots,i would like to make a cartesian robot with maximum speed of up to  in x y plane  acceleration  and accuracy at least    mm  expected loads   kg on y axis   kg on x axis  expected reliability       work hours  from what i have seen in  d printers  belt drive seems not precise enough  too much backlash   while screw drive is rather too slow   what other types of linear actuators are available  what is used in commercial grade robots  i e   ,actuator industrial-robot cnc
8244,how to connect ethernet based hokuyo scanner ,this is a very basic beginner question  i know  but i am having trouble connecting to the hokuyo ust   lx sensor and haven t really found much in terms of helpful documentation online  i tried connecting the hokuyo ust   lx directly to the ethernet port of a lubuntu       machine  the default settings of the hokuyo ust   lx are apparently  ip addr               netmask                gateway              so  i tried going to the network manager and setting ipv  settings manually  to have the ip addr be              netmask of                and gateway to              i also have a route set up to the settings of the scanner  i then go into the terminal and run   and get this output   error                           setparam  failed to contact master at  localhost          retrying     how might i fix this  i figure it s just a simple misunderstanding on my end  but through all my searching i couldn t find anything to get me up and running    thank you for the help     edit  highvoltage pointed out to me that i wasn t running roscore which was indeed the case  i was actually running into problems before that when i still had roscore up  and when i tried it again  this was the output of the rosrun command   error                          error connecting to hokuyo  could not open network hokuyo                     could not open ethernet port   thanks again  ,sensors ros rangefinder linux
8245,aligning datasets with drift,i have a dataset that contains position information from tracking a robot in the environment  the position data comes both from a very accurate optical tracking system  vicon or similar  and an imu  i need to compare both position data  either integrating the imu or differentiating the optical tracking data   the main problem is that both systems have different reference frames  so in order to compare i first need to align both reference frames  i have found several solutions  the general problem of aligning two datasets seems to be called  the absolute orientation problem   my concern is that if i use any of these methods i will get the rotation and translation that aligns both datasets minimizing the error over the whole dataset  which means that it will also compensate up to some extent for the imu s drift  but i am especially interested in getting a feeling of how much the imu drifts  so that solution does not seem to be applicable  anyone has any pointer on how to solve the absolute orientation problem when you do not want to correct for the drift  thanks ,sensors localization imu calibration
8247,angular velocities and rotation matrices,let us assume i have an object o with axis       with different orientation from the global frame s with       i don t care about the position   now i know the   instantaneous angular velocities of the object o with respect to the same o frame  that is   how can i obtain this angular velocity with respect to the global frame  that is    thank you  ,mobile-robot imu gyroscope
8250,gyro measurement to absolute angles,let us assume we have a gyro that is perfectly aligned to a global frame      from what i know the gyro data give me the angular rate with respect to the gyro axis     so let s say i got   since i know that the   frames are perfectly aligned i perform the following operations        where  is the rotation angle around  and so on  my question is  what is this update like in the following steps  because this time the measurement that i get are no more directly related to the global frame  rotated with respect to the gyro frame   thank you  ,imu gyroscope frame
8255,accurate wheeled robot odometry,i m looking for a  good  algorithm model for wheeled odometry estimation  we have encoders on the two back wheels of the tricycle robot  and imu on the controller board  currently we use mems gyro for angular velocity estimation and encoders for linear velocity  then we integrate them to get the pose  but it s hard to calibrate gyro properly and it drifts  due to temperature or just imperfect initial calibration   how can we improve the pose estimation  should we consider model that incorporates both encoders and gyro for heading estimation  model slippage  sensor noise  is there some nice standard model  or should we just use more better gyro  not considering the visual odometry  ,kalman-filter wheeled-robot odometry
8261,robotic arm   fail   error display    festo   mitsubishi melfa rv  aj  controller cr      ,to avoid wasting your time on this question  you might only want to react on this if you have knowledge of industrial robotic arms specific  common troubleshooting is unlikely to fix this problem or could take too much time  we ve started a project with the mitsubishi melfa rv  aj robotic arm  everything went fine until the moment we replaced the batteries  the controller displays   fail  and does not respond to any buttons or commands sent through serial connection  we did replace the batteries of both the robot and the controller  as it took some time to get the batteries delivered  we ve left the robot  and controller  withouth power for the weekend   which might have caused this problem  is there anyone with knowledge of mitsubishi robotic arms around here  i m kinda hoping it would be a common problem mistake and anyone with experience on this subject would know about it  ,robotic-arm
8262,real time video processing on video feed from a drone s camera,i am working on a project where i want to run some computer vision algorithms  e g  face recognition  on the live video stream coming from a flying drone   there are many commercial drones out there that offer video streams  like    etc    but none of them seem to give access to the video feed for real time processing   another idea is to have the drone carry a smartphone  and do the processing on the phone through the phone s camera  or just use a digital camera and an arduino that are attached to the drone   although these ideas are feasible  i would rather access the video feed of the drone itself  so my question is that are there any drones out there that offer this feature  or can be hacked somehow to achieve this   ,computer-vision cameras
8271,dc motors for a rov ,i am planning to build a homemade rov  and i wanted to know a couple of things about the motors   first is  will it be ok  if i use a brushed dc motor   instead of a brushless motor  and is there any major disadvantages   second   what rpm dc motor should i aim for   high rpm or low rpm   will    rpm be enough   the specific motor that i am talking about is     will this be a good motor for the propellers of the rov   i am planning to have   motors   propellers  two for upward and downward thrusting   and   for forward and side thrusting  the propellers that i plan to use  are basic plastic   blade propellers   with diameter   between   mm and   mm   my main question is  what rpm and torque should i aim for when choosing the dc motor   ,motor
8272,ros moveit   virtual joints  planar joints  prismatic joints,i do have a robotic application  where a  dof robot arm is mounted on a omnidirectional mobile platform  my overall goal is to get moveit  to calculate a sequence of joint movements  such that the robot eef reaches a desired goal in cartesian space  in order to combine a robot platform with a world  the moveit  setup assistant lets you assign virtual joints between the  footprint  of the platform and the world it is placed in  i do have two strategies  either   select a planar joint as a virtual joint   what are the degrees of freedom or respectively the joint information that i can gather from this joint   or   select a fixed joint and add a  prismatic x    prismatic y    revolute z  chain to the robot model   are there any significant differences  advantages  disadvantages  to either of the approaches  ,mobile-robot robotic-arm ros motion-planning
8273,where should i put the angle sensor on my cart pole robot ,i m using an accelerometer and gyroscope to detect the angle and tilt rate on my two wheeled cart pole robot   is there an optimal height to place the sensors   should i place them closer to the bottom  near the wheels   the middle  near the center of mass   or the top   justification for the optimal choice would be appreciated  ,sensors balance
8276,should the therotical parameters match the physical setup constraints when modeling a robot ,i m working on modeling and simulation of robotic arm  after i obtained the mathematical model of the robot  i used that to implement some control techniques  to control the motion of the robot  the dimensions and masses of each links are taken from available kit  basically  it s ra   robot with servo at each joint  after the modeling  different parameters  can be plotted  like the joint angles speeds torques     etc  the point now is that  the value obtained for the joint toque is much more higher that the torque limit of the servo  does it mean my design modeling is not realizable  is it necessarily to get close  torque   value for servo s torque   any suggestion  ,control robotic-arm servomotor dynamics torque
8277,what is torque bandwidth in actuated joints and how does it affect the control systems ,the rest of my student team and i are in the process of redesigning an exoskeleton and building it based on an existing one  from the papers that we have been reading there are some references to low  high and zero impedance torque bandwith  what is that  does it have to do with the control system  it is measured in hz  here is a table from one of the papers   ,control design mechanism joint
8279,ways to estimate the drift rate of the gyrometer,i found not so much literature to the topic  this is why i ask here  does someone know some ways to estimate the drift rate of the gyrometer  i was thinking about basically two approaches   one would be to use a low pass filter with a low cut off frequency to estimate the drift of the angular velocity  second would be to use the accelerometer  calculate the attitude dcm and by this also the angular velocity  the difference between the acc angular velocity and gyrometer would be maybe also a drift rate  nevertheless  i am not so sure whether this is a good way to get reliable drift rates  d ,sensors gyroscope
8286,how to connect an arduino uno to an android phone via usb cable ,is it possible to set up communication between an arduino uno and an android phone using a wire that directly connects the android phone and the arduino  ,arduino usb
8288,sourcing motors by physical dimensions,i have a  inch square tube that i would like to place a motor into   the motor i have takes up approximately     of the available space  roughly     inch i d   i would like to find the largest motor that will fit in the space without having to cobble too much of a housing   where how can i find motors by physical dimensions  ,motor
8289,crock pot knob turner,i have a crock pot with an analog knob and would like to find a way to turn the knob by using and appliance timer  i have no idea where to begin  i need help  thanks ,control sensors stepper-motor
8292,are there any aerodynamics modeling simulation software that is capable to consume a solidworks model and to interface with matlab simulink ,currently i am developing a control system for an aircraft of a unique design  something in between a helicopter and a dirigible   at this moment i can model only the dynamics of this vehicle without any aerodynamic effects taken into account  for this i use the following work flow  mechanical model in solidworks    msc adams  dynamics       matlab simulink  control algorithms  thus  the dynamics of the vehicle is modeled in adams and all control algorithms are in matlab simulink  unfortunately  adams can not simulate any aerodynamic effects  as a result  i can not design a control system that is capable to fight even small wind disturbances  ,control simulator uav matlab simulation
8293,advanced line following robot of maze solving,i know how to make a line follower  but in this video what have they done exactly  they are giving the source and destination in the map but how the robot moves based on the instruction given in map  what is the procedure to do it  they have mapped the path  please do watch the video  ,wheeled-robot mapping line-following
8294,need a mobile robot simulator that provides easier odometry funtions,i want a mobile robot to go from a starting position to a goal position  but  i don t want to calculate the pose from encoders  instead i want to know if there exist such a simulator that provides pose function that makes the work easier  like go to x coordinate  y coordinate   that means  the robot will automatically calculate its current position and leads itself to the goal position   ,mobile-robot odometry simulation
8296,using gazebo installed on same machine in matlab,i am planning to use matlab and gazebo for one of my course projects  however all the tutorials i have seen till now use gazebo by using a virtual machine which has ros and gazebo installed  i have already installed ros and gazebo on this machine  os ubuntu   i also have matlab installed on it  is it possible to use the gazebo on this machine itself with the matlab toolbox  thanks  ,ros matlab gazebo
8302,what is the difference between path planning and motion planning ,what are the main differences between motion planning and path planning  imagine that the objective of the algorithm is to find a path between the humanoid soccer playing robot and the ball which should be as short as possible and yet satisfying the specified safety in the path in terms of the distance from the obstacles   which is the better terminology  motion planning or path planning  ,mobile-robot motion-planning humanoid
8310,what is the required theory behind building a robotic arm ,i am currently planning on building a robotic arm  the arm s specs are as follows       arms  with two servos each  to move the next arm  single servo clamp mounted on revolving turntable turntable rotated by stepper motor turntable mounted on baseplate by ball bearings to allow rotation baseplate mounted on caterpillar track chassis baseplate is smaller in length and width than caterpillar chassis  what are the required formulas in determining how much torque each servo must produce  keeping in mind that the arm must be able to lift weights of up to   kilogram  also  considering that the ball bearings will take the load of the arm  how strong does the stepper have to be  just formulas  no answers   as far as overall dimensions are concerned  the entire assembly will be roughly    mm x    mm x    mm  l x w x h   i have not finalized arm length  but the aforementioned dimensions give a general estimate as to the size   ,arduino robotic-arm stepper-motor rcservo torque
8313,is modelling a robot and deriving its equations of motions more applicable to a system that is inherently unstable ,as someone who is new and is still learning about robotics  i hope you can help me out  let s say i have two systems     a  inverted pendulum  unstable system   b  pole climbing robot  stable system   for system  a   i would say that generally  it is a more dynamic system that produces fast motion  so  in order to effectively control it  i would have to derive the equations of motions  eom  and only then i can supply the sufficient input to achieve the desired output  eventually  the program will implement the eom which enables the microcontroller to produce the right signal to get the desired output  however for system  b   i assume that it is a stable system  instead of deriving the eom  why cant i just rely on the sensor to determine whether the output produced is exactly what i want to achieve   for unstable system  controlling it is just difficult and moreover  it does not tolerate erratic behavior well  the system will get damaged  as a consequence   on the contrary  stable system is more tolerant towards unpredictable behavior since it is in fact stable  am i right to think about it from this perspective  what exactly is the need for deriving the eom of systems  a  and  b  above  what are the advantages   how does it affect the programming of such systems  edited  some examples of the climbing robot that i m talking about       ,mobile-robot control
8319,filtering angular velocity spikes of a cheap gyroscope,i would like to filter angular velocity data from a  cheap  gyroscope        these values are used as an input of a nonlinear controller in a quadcopter application  i am not interested in removing the bias from the readings  edit  i m using a  l g    d gyroscope connected via i c with an arduino uno  the following samples are acquired with the arduino  sent via serial and plotted using matlab  when the sensor is steady  the plot shows several undesired spikes   how can i filter these spikes   st approach  spikes are attenuated but still present    let s consider the following samples in which a couple of fast rotations are performed  let s assume that the frequency components of the  fast movement  are the ones i will deal with in the final application   below  the discrete fourier transform of the signal in a normalized frequency scale and the second order butterworth low pass filter   with this filter  the main components of the signal are preserved    although the undesired spikes are attenuated by a factor of three the plot shows a slight phase shift     and the spikes are still present  how can i improve this result  thanks  edit          i am using a breakout board from sparkfun  you can find the circuit with the arduino and the gyro in this post  can you roll with a l g    d gyroscope  arduino and matlab       i have added pullup resistors to the circuit  i would exclude this option because other sensors are connected via the i c interface and they are working correctly      i haven t any decoupling capacitors installed near the integrated circuit of the gyro  the breakout board i m using has them      uf   please check the left side of the schematic below  maybe i am wrong   motors have a separate circuit and i have soldered all the components on a protoboard   the gyro is in the quadcopter body but during the test the motors were turned off  that is interesting  the sampling frequency used in the test was    hz   increasing the update freq from     to     hz doubled the glitching   i found other comments on the web about the same breakout board and topic  open the comments at the bottom of the page and ctrl f  ,quadcopter gyroscope filter
8322,need an idea  automated sim card switcher,first off  sorry if my question is too naive or not related to the forum  this is the best matching one i ve found on stackexchange   i have some amount of sim cards  i can programmatically access a single sim card if it is inserted into a usb modem  i want to be able to access the specified card in the set  the best way to achieve this i can think of is to create a device that would somehow replace the current card in the modem with one in the set  i can not use several modems for this because i don t really know the amount of cards and i would like to automate this process anyway  i am more of a programmer than an engineer so everything that follows  including the entire concept of switching cards  looks pretty weird to me  there probably is a better solution  but this is the best i ve come up with  for now i consider building some sort of conveyor that would move cards and insert the ones i need with some sort of a feed device  this looks like an overkill to me that would be both expensive to build and uneffective to work with  i want an idea of a device that would replace sim cards into the modem  or maybe a better solution to the problem   any disassembly of a modem needed is possible  this is required to automate receiving sms from clients that have different contact phones  unfortunately  a simple redirection of sms is not an option  ,automatic automation
8327,transforming angular velocity ,i have the following system here    basically  i have a range finder which gives me  in this  d model  i also have the model rotate about the centre of mass  where i have angular values and velocities beta    and betadot     i can t see  for the life of me  how to figure the formula for the angular velocity in the range finder frame  how am i supposed to do this  i have all the values listed in those variables  the object there doesn t move when the vehicle system pitches  it s stationary  ,robotic-arm sensor-fusion
8329,filtering imu angle discontinuities,i try to measure euler angles from an imu  but some discontinuities happens during measurement  even in vibrationless environment  as shown in the images below   can someone explain which type of filter will be the best choice to filter this type discontinuities     ,sensors imu matlab noise filter
8331,designing a   bar linkage robot  plot clock,i am a beginner at robotics   i recently stumbled across this robotic clock on youtube  i am an electrical engineering student and am interested in submitting it as my minor project  i have studied the basics on forward and inverse kinematics  greubler s equation  four bar linkage but this robot seems to be a   bar linkage  i want to know how to implement it in a   bar linkage  how to use the inverse kinematics solutions described in combined synthesis of five bar linkages and non circular gears for precise path generation  to make the robot follow desired trajectory  i have been stuck at this for days    any sort of help would be appreciated  ,robotic-arm beginner first-robotics
8333,relation between pole placement and marginal stability ,i m given an assignment in which i have to design a full state feedback controller by pole placement  the state space system is fully controllable and i ve been using matlab simulink to determine the required feedback gain k using the place   command for several sets of poles  however once i use poles that are  too negative   for example p                             my controlled system starts showing bounded oscillatory behaviour   is it possible that too negative poles can cause marginal stability  and if so  why  i ve read that this is only possible when the real part of one or more poles equals    which certainly isn t the case here   ,control stability
8337,kuka fri program using java,i am trying to establish the fri connection for kuka lbr iiwa  i know how to configure the fri connection as there are example programs available in the sunrise workbench   a sample code is given below  my question is  how to pass  the joint torque values  or joint position or wrench  to the controller using  torqueoverlay  as mentioned in the code below  since i could not find any documentation on this  it was quite difficult to figure out  any sample code with explanation or any clues would be more than helpful     java code   ,robotic-arm programming-languages
8340,trying to calculate the thrust of my quadcopter motors,i am trying to calculate the thrust my   quadcopter motors will have  i am not sure how to do it  here are the parts i am using  s     mah     v lipo pack    x    prop    kv motor max output is   a esc    amp thank you ,quadcopter
8343,how much of a pause should there be between messages   irobot create   ,when i send several commands in a row some don t get executed  for example i have a script which starts the roomba driving in a circle and plays the john cena theme song through its speakers but sometimes it will only play the music and not drive  i have noticed that in all the guides there are pauses after every command  is there any documentation which describes when pauses are needed  ,irobot-create
8345,trying to figure out what parts to buy for my quadcopter,so i am building a quadcopter and i already have the frame which is about    inches      feet  and     grams  i want to run these multistar elite         kv multi rotor motor    kv rpm v      kv lipo cells      s   max current     w max amps     a no load current      a   v weight     g  i want use a multistar high capacity  s     mah multi rotor lipo pack  minimum capacity      mah configuration   s p       v    cell constant discharge    c peak discharge    sec     c pack weight     g  the props i am thinking of using are   x   props  so if anyone knows what is wrong with this setup  or if it will work  or maybe even have some tips and pointers for me since i am a beginner drone builder and i really don t want to spend the        it will take to build it and have it not work so any advice will be appreciated  total estimated weight         grams      pounds  also here is a chart for the motor that my be helpful  the chart is near the price under the files tab multistar elite         kv multi rotor motor thanks in advance ,battery multi-rotor
8348,changing stm   nucleo board s microcontroller,i have a stm  f   rb nucleo board which has a   pin microcontroller  for my application i chose the stm  f   rg which has a bigger ram size and flash size too  can i remove an f   r from a nucleo board put a f   r on top of it  i am testing my code with a f   c  but the flash and ram size is not meeting my requirement  i have a f   r nucleo board lying around so for a quick developmental test could i swap it for the    r   the r series is pin compatible  anyone has done microcontroller swapping before   ,microcontroller
8350,differences between scara arm design,i am currently interested in scara arm designs and i have few  beginner questions for which i didn t find answers yet      while comparing professional arms  made by epson  staubli     i noticed that the actuator used for the translation on the z axis is at the end of the arm  on  hobby  arms like the makerarm project on kickstarter they use a leadscrew with the actuator at the beginning of the arm  i thought it was smarter to put the actuator handling this dof at the begining of the arm  because of its weight  and not at the end  but i assume that these companies have more experience than the company behind the makerarm  so i m probably wrong  but i would like to understand why       also i would like to understand what kind of actuators are used in these arms  the flx arm  also a kickstarter project  seems to be using stepper motors but they also say they are using closed loop control  so they added an encoder on the stepper motors right  wouldn t it be better to not use stepper and  for instance  use dc brushless motors or servos instead      i also saw some of these arms using belts for the  nd z axis rotation  what is the advantage   it only allows to put the actuator at the begining of the arm   ,robotic-arm design actuator
8354,need help for a quadcopter pid,i m trying to make a quadcopter with arduino  i already have the angles  roll pitch and yaw  thanks to an imu  they are in degrees and filtered with a complementary filter  i want to apply a pid algorithm for each axis but i dont know if the inputs should be angles  degrees  or angular velocities in degrees per second so as to calculate the errors with respect referencies  which will be the difference  which will be the best way   finally  another question about a pid code  i have seen that many people don t include time in their codes  for example  their derivative term is kd  last error actual error  instead kd  last error actual error  looptime and something similar with the integrative term  which is the difference  thank you in advanced  ,quadcopter pid
8356,very low output voltage at the output of l   n ,i am using arduino and l   n motor driving ic to drive     v dc motors     rpm   also i am using     v lipo battery   cell       mah    c  i have connected two pwm pins of l   n to digital high from arduino battery positive terminal is connected to the   v input of ic battey negative terminal and arduino ground is connected to the ground input of ic also a  v input is given from arduino to ic and ground from arduino is connected to other gnd pin which is adjacent to int  pin motor  pins from l   n are connected with two motors  connected parallely on right side of bot  and motor  pins are connected with other two motors  connected parallely on left side of bot  appropriate inputs are given to int  int  int  int  to drive the bot in forward direction but the bot is moving too slowly the voltage measured across motor  pins is only  v i have connected the battery directly to the motors then it is running very fast how to run it fast please help       ,arduino motor
8357,how to drive robot without driving actuator ,i am participating in a robotics competition  i am supposed to design and build two robots  out of these  one cannot have a driving actuator  it can have a steering actuator though  fed by a line following circuit   the other is supposed to drive the non driving robot through an obstacle course  without touching it  this is kind of driving me crazy since at one point the separation between the two robots is    cm     inches   ways i ve considered   wind energy  wont work  need huge sails  magnetic repulsion of some sort  now repulsion i ve spent a lot of time studying   my solution was to use strong permanent magnets on the non driving robot  neodymium n    and electromagnets on the driving robot  but  after doing a huge load of calculations came to the conclusion that not enough force can be transmitted over the distance as magnetic fields fall off too quick  rulebook   i am really looking for even a pointer here  is there a trick somewhere that i am missing  ,line-following
8361, dof robot arm  velocity of end effector vs  joint velocities,i have a   dof arm whose velocities i m controlling as a function of force applied to the end effector  the software for the robot allows me to input either the desired end effector velocity or the desired joint angular velocities  which i know can be found using the inverse jacobian  are there any benefits of using one scheme over the other  would  for example  one help avoid singularities better  does one lead to more accurate control than the other does    ,robotic-arm jacobian force-sensor
8363,cannot command irobot create  ,this might be a dumb question  i have started to play with this robot with raspberry pi two days ago  i did some simple stuff  like  move around and sensor reading etc  but since yesterday night  it seems like i cannot send any command  the built in clean  dock functions are working perfectly but i cannot do anything using the same python code that i already used before  its behaving like nothing is going through the rx  can you suggest what might go wrong  thanks ,irobot-create
8365,using a device with os instead of microcontrollers,im working on a robot that needs image processing to analyze data recieves from cameras   as i searched for arm and avr libraries i found that there is no dip library for these micros and their limited ram is hard for image data process  i want to know is there any hardware that connects to a win or android or    devices and make it possible to that device connect to actuators and sensors  thank you or helping  ,microcontroller
8367,ardrone navdata reading error,i am trying to read navdata from ardrone using following callback function   but this is always returing   value  but when i echo navdata in linux terminal  these topics are publishing non zero value  where is the error  edit  after some debugging i found that this callback function is not being called at all  i wrote my subscriber node like this ros  subscriber sub   ardrone subscribe   ardrone navdata    callback   what is going wrong here  ,quadcopter
8368,solving for dh parameters,given three sets of joint angles in which the end effector is in the same position  is it possible to find the dh parameters  if the robot has   dof in shoulder    dof in elbow  and   dof in wrist  with dh parameters as upper arm length  elbow offset in   axis  lower arm length  can this be solved  if so how  i tried iterating through dh parameters to minimize position of end effector with forward kinematics  but this doesnt seem to work as dh parameters of   for everything makes   minimal distance  reason for this  given a physical robot  no dh parameters are known  and measuring by hand is not accurate  ,dh-parameters
8369,power on irobot create   via serial port,i have arduino talk with create   via serial interface  but before sending commands to the robot  i have to power it on by manually pushing the power button on the robot  how to make the robot turned on via that mini din   port  instead of pushing that power button   i notice when plugin irobot serial   usb cable into that port on the robot  the robot is immediately turned on  ready for received the first command  command       so apparently there is way to turn on the robot via that port  ,irobot-create
8371,switching scheme for vector controlled pmac drive,i have     pmac motors    ph      volt of     kw      kw an     kw  in motor control center  please suggest a time staggered switching scheme in order to avoid tripping due to voltage sag  swell   flicker etc ,power
8372,denavit hartenberg parameters,can anybody help figure out hd parameters for the case where two links with a revolute joint are in the same plane  thus that the variable angle is    but the twist is not    this is a simple drawing  i think that x axis that is perpendicular to both z axis  points away and goes through the intercection of z axis  the link length is    the twist is a and the offset is d  whould it be correct  thanks    ,dh-parameters
8375,can we detects animals through pir passive infrared sensors ,as i dont know that what kind of radiation animals emit  as humans emit ir radiations so pir sensors help to identify humans  pls suggest me if someone have knowledge about sensors which detects animals  ,arduino raspberry-pi first-robotics
8376,kk      gyro bubble is not at centre,i have a quadcopter controlled through kk      flight controller  i have been flying with it without problems  but now i am facing a problem  when i start and arm the kk       by giving throttle it starts turning towards some direction with acceleration  i double checked the motor pins locations and all other things  they are correct  when i took a look to the gyro bubble of kk      it wasnt at mid of the crosshair  i turned the quad off and then on  i check bubble again it was at centre  now again when i gave it throttle it started turning towards some direction  i checked the again  and it wasnt on centre this time too  so at the armed state the gyro bubble moves away from centre by giving throttle  due to which quad overcorrects itself  now i have understood that the gyro is off centre due to vibration  of the fc  what should i do to antivibrate it  what material should i keep in between so that vibrations are almost zero  ,quadcopter
8378,torque control in eye in hand visual servoing,in most papers about ibvs the camera velocity is computed and then used as a pseudo input for the manipulator   e g  this one  is there any work in which the dynamic lagrange model  of the manipulator is taken into consideration in order to compute the torque required to move the joints accordingly  ,dynamics torque visual-servoing
8382,how to make a stepper motor to rotate and come to a position of certain degress  say for    degrees  from any initial position ,i tried this coding and its working    but the problem is that if the above coding is placed inside a loop such as  if loop   its not working  can anyone help me in figuring out this problem  i am using accelstepper library for the above coding  void loop         int dummy        if dummy                   int y                int x    vertical  currentposition            int z    y x           int x    horizontal  currentposition            int z    y x            horizontal  moveto z            horizontal  run             vertical  moveto z            vertical  run             ,arduino stepper-motor
8387,optimal trajectory for manipulators using optimal control,i m trying to implement direct multiple shooting method to my problem   as i understand from the theory  i have to divide the variables as state variables and control variables  state variables are  q and v  control variable is  tau in each time interval i ll generate cubic splines which are q t  a   a   t a   t   a   t    could you help me how i will implement it  i don t understand what is the ode here and how i should construct the algorithm  are there any example about it  edit to make the equations clear i ll rewrite them here again  based on the link state variables  x  t     q  t         qn t   t and x  t     q   t         q n t   t   and derivatives of the state variables are equal to x  t    f x t   u t   where f is f x t   u t       q   t           q   t   t                    m x t       u t    n x t     i don t know how to insert cubic polynomials in that equation system and how to solve ode will it be like  t x  ode    f      t f    q   q f    ,manipulator
8389,  dof inverse kinematics implementation  what s wrong with my code ,i am currently trying to implement an inverse kinematics solver for baxter s arm using only   pitch dof  that is why the ygoal value is redundant  that is the axis of revolution   i for the most part copied the slide pseudocode at page    of     here is my logic in writing this  i first calculated the jacobian  x  matrix by taking the derivative of each equation seen in the forwardkinematics method  arriving at      cos theta        cos theta  theta                                                                                         sin theta      sin theta  theta                                       in order to arrive at numerical values  i inputted a delta theta change for theta    and   of     radians  i arrived at a jacobian of numbers                                                                                     i then input this matrix into a pseudoinverse solver  and came up with the values you see in the invjacob matrix in the code i posted  i then multiplied this by the difference between the goal and where the end effector is currently at  i then applied a tenth of this value into each of the joints  to make small steps toward the goal  however  this just goes into an infinite loop and my numbers are way off what they should be  where did i go wrong  is a complete rewrite of this implementation necessary  thank you for all your help  ,inverse-kinematics python joint jacobian
8391,what is the easiest and efficient way to detect human in close range distance and make the robot follow it ,i am having a thesis right now regarding a robot  my research requires the robot to be attached to linear guide rail  a robot has to detect human in a very close range  of about   meters distance   what easiest and efficient method or components shall i use  ,sensors wheeled-robot industrial-robot
8394,connecting mpu      gy      sensor module to arduino uno,i am using this sensor to make self balancing robot at first i have soldered the header only to vcc gnd scl sda   on the imu borad at the opposite side where there is no component mounted then connecting it to arduino uno r  vcc to vcc    v  v gnd to   of   gnd scl to scl and sda to sda first time at those next to aref  second time a  a     i uploaded the sketch  then when i opened the serial monitor i got  accelerometer test ff ooops  no adxl    detected     check your wiring   i thought may be i have soldered the header in wrong direction as in picture and videos at internet they are so  so i desolder with solder iron no other technique  the header but there were still some solder around the hole which i could not remove then while checking the continuity between pins with multimiter in resistance mode  i found the resistance to be   k scl sda     k scl gnd     k sda gnd  between vcc and   other pins multimieter shows   range     k   then i soldered it on opposit side this time where other components are mounted  the serial monitor still shows same output and so does the muiltimeter so where is the problem  is it with soldering  do i need to disolder the header again and clean left out solder with chip quik type desoldering technique   on the opposite side no component mounted  is there any hope that i won t need to buy it again  picture of opposite side where no component is mounted and this is after desoldering and resoldering ,imu accelerometer gyroscope
8399,updating firmware of kk ,i am facing problems in updating my kk  board  i have used usbasp header for connecting it to the pc  and kk firmware software  but it fails  it says not valid vid and pid values etc  please help me  if any idea on updating firmware other than this  i have used usbasp header connecting kk  board to pc  ,arduino
8400,using an rgb   depth camera to locate x y z coordinates of a ball,i ve recently been trying to use gazebo to do some modelling for a couple tasks  i have a robot that s effectively able to locate a ball and get x y coordinates in terms of pixels using a simple rgb camera from the kinect  i also have a point cloud generated from the same kinect  where i hope to find the depth perception of the ball using the x y coords sent from the circle recognition from my rgb camera  my plan earlier was to convert the x y coordinates from the rgb camera into meters using the dpi of the kinect  but i can t find any info on it  it s much  much harder to do object recognition using a point cloud  so i m hoping i can stick to using an rgb camera to do the recognition considering it s just a simple hough transform  does anybody have any pointers for me  ,localization computer-vision kinect cameras gazebo
8403,how to tilt a camera     using mirrors,how would you vertically tilt a camera     degrees using mirrors  i m trying to add a pan tilt mechanism to a raspberry pi s camera  the camera uses one of those flat cables with unstranded wires  and even with a strain gauge  i don t trust it to handle repeated bending  so i m trying to design a tilt mechanism that allows the camera to be rigidly mounted so no wires move  the tilting also has to happen very quickly  so i m trying to minimize the amount of mass i need to move  then i saw the oculus kit that actuates a mirror to effectively tilt a laptop s fixed webcam  i m trying to extend this idea  but i having trouble working out the mechanics that would allow the tilt to extend to     degrees  the layout in the oculus s mechanism only supports a tilt angle of about    degrees  and the mirrors are relatively large  is it possible to modify this to support     degrees  are there other ways to  bend  the view of a camera without having to move the actual camera  ,mechanism cameras
8406,samsung ip camera  wifi direct feature,can we use wifi direct feature of samsung ip cameras to connect them directly to laptop wifi adapter without the need of any additional router  i am working on an opencv project and i want to read stream from   cameras simultaneously  so i was thinking that i could connect   usb wifi adapter to my laptop and connect them directly with cameras  is this scenario possible  ,opencv
8407,one propeller drone how well it works hope,can a one propeller drone work efficiently for a good flight and stable camera footage in a drone flight ,quadcopter
8411,joint space singularities,i would like to clarify my self on singularity configurations  if i am moving the robot in joint space only one joint at a time  can i come to a singular configuration  if so how  thanks ,joint jacobian
8417,removing pcb from a dynamixel rx   f servo ,for a mod on the dynamixel rx   f i need to remove the enclosed pcb  i removed all screws but the pcb doesn t come out easily  without applying more force than i m comfortable with   it seems to be stuck on the three large solder points in the white area  has someone experience with this particular servo   it might be glued soldered to the case  but i m not quite certain  any help is appreciated   ,dynamixel
8418,how to compute the relative pose between two robots ,how can i compute the relative pose between two robots  i have these robots  matlab code    and the corresponding covariance matrix of the probability distribution of each one  the movement of each robot is asociate with a gaussian distribution  co    diag                   co    diag                      auxiliar functions to solve function to compose two poses   x   y   theta   function tac tcomp tab tbc   composition of transformations given by poses ang   tab    tbc      if ang   pi   ang     pi    ang   anglewrap ang   end  s   sin tab      c   cos tab      tac    tab        c  s  s c  tbc        function to get the inverse pose of a pose function tba tinv tab   tba   zeros size tab    for t     size tab        tba t t      tinv  tab t t      end  solution  to get the relative pose  we need to compute two things   the pose to be composed with poser  to get poser     it means that we need to get the  pose inc  that satisfy with this equality tcomp psoer    pose inc      poser   the next code compute that relative pose that allows to poser  reach poser    computing the relative pose between r  and r     pose to be composed with poser  to reach poser   pose inc   tcomp tinv poser   poser     the covariance matrix of the relative pose  the uncertainty of r  after reach the position poser      c   cos poser       s   sin poser            x     poser      y     poser           x     poser      y     poser             jacobians to compute the covariance of the relative pose     jacf       c  s   x   x    s  y   y    c                  s  c   x   c    c  y   y    s                               jacf      c   s                   s  c                                 computing the covariance of the relative pose     c p     jacf   co  jacf      jacf   co  jacf        roughly  jacf   is a jacobian that define how difference poser  is against pose inc jacf   is a jacobian that define how difference poser  is against pose inc c p   is the covariance matrix of r  after move to poser   ,sensors movement pose first-robotics
8419,running my   dof inverse kinematics code  works in matlab  not in python,i asked a question similar to this earlier  but i believe i have a new problem  i ve been working on figuring out the inverse kinematics given an x y z coordinate  i ve adopted the jacobian method  taking the derivative of the forward kinematics equations with respect to their angles and input it into the jacobian  i then take the inverse of it and multiply it by a step towards the goal distance  for more details  look at  page    onwards   for a better picture  below is something   below is the code for my matlab script  which runs flawlessly and gives a solution in under   seconds   below is my python code  which goes into an infinite loop and gives no results  i ve looked over the differences between it and the matlab code  and they look the exact same to me  i have no clue what is wrong  i would be forever grateful if somebody could take a look and point it out  def sendarm xgoal  ygoal  zgoal  right  lj       ycurrent   xcurrent   zcurrent         theta            theta            theta            xcurrent  zcurrent   forwardkinematics theta   theta   theta       xchange   xcurrent   xgoal     zchange   zcurrent   zgoal     while   xchange        or xchange          or  zchange         or zchange                   in          math cos theta    equations in    are in the pdf i linked to you  inv kinematics section          in          math cos theta  theta           in           math cos theta  theta  theta           in           math sin theta           in           math sin theta  theta           in            math sin theta  theta  theta           jacob   matrix   in  in  in  in  in  in    in  in  in  in  in  in               jacobian         invjacob   inv jacob   inverse of jacobian         xcurrent  zcurrent   forwardkinematics theta   theta   theta           xincrement    xgoal   xcurrent       dx increment         zincrement    zgoal   zcurrent       dz increment         incrematrix   matrix   xincrement    zincrement                 change   invjacob incrematrix  multiplying both matrixes         theta    theta    change item            theta    theta    change item            theta    theta    change item            xcurrent  zcurrent   forwardkinematics theta   theta   theta           xchange   xcurrent   xgoal         zchange   zcurrent   zgoal         print  xchange   f zchange   f     xchange  zchange      print  goals  f  f  f     theta   theta   theta       right set joint positions theta    first pitch joint     right set joint positions theta    second pitch     right set joint positions theta    third pitch joint   def forwardkinematics theta   theta   theta        xcurrent           math sin theta            math sin theta  theta            math sin theta  theta  theta       zcurrent           math cos theta            math cos theta  theta            math cos theta  theta  theta                   return xcurrent  zcurrent  ,kinematics inverse-kinematics matlab python jacobian
8420,why does it require more force to turn a servo if it is electronically connected to another servo ,i have two servo motors that i rigged up to use as a telescope remote focuser  the idea is to turn one servo by hand and use the power generated to turn the other  which is geared to a telescope focuser knob  i noticed that when the two servos are electrically connected  it is noticeably harder to turn a servo compared to turning it by itself  i tried changing the polarity of the connection hoping it would help  but it is still harder to turn the servo when they are connected  does anyone know why this is  ,servos servomotor
8421,i can t get motors to turn with raspberry pi,i want to turn some motors using my raspberry pi  i am able to turn an led on and off using the    v gpio pin  for the motors  i tried using a l   d chip as per the instructions on this link  what happened is that the very first time i set the circuit up for one motor  it worked perfectly  but then  i moved the pi a little and the motor has since refused to work  i even bought a new pi and still no luck with the circuit  i then bought a l   n board that fits smugly on top of the gpio pins of the pi and followed the instructions on the this video still no luck  the motor just won t run with either pi  i am using four aa batteries to power the motor and a connecting the pi to a power supply from the wall  what could possibly be the problem here  ,motor raspberry-pi
8425,relationship between earth frame attitude and acceleration for a quadcopter,for a quadcopter  what is the relationship between roll  pitch  and yaw in the earth frame and acceleration in the x  y  and z dimensions in the earth frame  to be more concrete  suppose roll    is a rotation about the earth frame x axis  pitch    is a rotation about the earth frame y axis  and yaw    is a rotation about the z axis  furthermore  suppose  gives the acceleration produced by all four rotors  i e  acceleration normal to the plane of the quadcopter  then what are  in a x   f a  theta  phi  psi  a y   g a  theta  phi  psi  a z   h a  theta  phi  psi  where     and  are accelerations in the     and  dimensions  i ve seen a number of papers articles giving the relationship between x y z accelerations and attitude  but it s never clear to me whether these attitude angles are rotations in the earth frame or the body frame  ,quadcopter dynamics
8426,denavit hartenberg parameters    dof articulated manipulator,i am trying to solve a forward kynematics problem for a  dof manipulator  i am working with the robotics toolbox for matlab created by peter corke and after calculte the dh parameters and introduce them into matlab to compute the fordward kynematics the plotted robot is not what it should be  i guess i made some mistakes calculating the dh parameters  attached is the file where you can see what are the dh frames calculated for each joint and the dh parameters for each frame  anyone could give me a clue whether this is the correct answer  here is the image with the frames calculated by me   and here the robot i get from matlab  using the robotics toolbox by p corke   ,robotic-arm inverse-kinematics forward-kinematics
8427,what charger to use with my zippy compact     mah  s   c lipo multirotor battery,hello i am trying to build a quadcopter for a school project and i need to finish quick before our mission trip because i was asked to finish it before then so that i could take it  but i am having a problem figuring out which charger would work with my zippy compact     mah  s   c lipo pack   here are the specs on the battery  capacity      mah voltage   s p     cell       v discharge    c constant     c burst weight     g  including wire  plug   case  dimensions     x  x  mm balance plug  jst xh discharge plug  hxt mm   also i will be running the tarot t   d brushless gimbal for gopro    axis  and if anyone can tell me a good battery to run it off of or maybe it would be better to run it off my main battery  thanks in advance ,quadcopter battery lithium-polymer
8428,moatech stepper motor salvage   unsure of pinout,i have salvaged a moatech bl  k m   stepper motor from an old printer and i d like to play around with it  but i m unsure of how to use the pinout listed on the board  pinout reads     v   v gnd gnd sgnd  v st sp rd clk gain  which is all well and good  but i am not sure what sgnd  st sp  rd  and gain should be used for  i understand clk  but also don t know what frequency this expects  moatech e mail bounced back  so i was hoping someone might have a coherent datasheet or know what these designations mean   ,stepper-motor
8432,how to use slam with simple sensors,what  d slam implementations  preferably included in ros  can be used with simple distance sensors like ir or ultrasonic rangefinders  i have a small mobile platform equipped with three forward facing ultrasonic sensors  positioned at    degrees  straight ahead  and     degrees   as well as a   dof accel gryo and wheel encoders  and i d like to use this to play around with a  toy  slam implementation  i don t want to waste money on a kinect  much less a commercial laser rangefinder  so methods that require high density laser measurements aren t applicable  ,slam ros
8438,solar panel set rotation  how to achieve both vertical and horizontal rotation , how can we achieve this kind of rotation to enable maximum trapping of solar rays during the day  ,mobile-robot
8443,irobot create    can i load the code in instead of connecting cable   new learner ,i am a new learner of irobot  i am trying to program it to control the movement of the create    after glancing through the existing project  i find most of them are based on sending commands to roomba through a cable   is there anyway to embed the code in and let the roomba behave accordingly  if there is not such method  which kind of api tool do you think is easiest for beginner   ,irobot-create
8444,is there a way to turn the sound off of a roomba ,i am working with an irobot create   and i work with others around me  whenever i turn the robot on  send it an oi reset command  etc   it makes its various beeps and noises  i would like to not have this happen since i find it a little annoying and i m sure those who have to work around me would like to have things quiet so they can concentrate on their work  is there a way to accomplish turning off the beeps  while still being able to easily re enable them   or am i out of luck  ,irobot-create roomba digital-audio
8448,quadrotor   control system  where to begin ,i am starting to assemble a quadrotor from scratch  currently  i have this   structure  an imu  accelerometer  gyro  compass     escs and dc motors    propellers  raspberry pi to control the system  and  lipo battery   i have calibrated the escs and the four motors are already working and ready  but now i am stuck  i guess the next step is to dive deeply in the control system  but i am not sure where to begin  i read some articles about the control using pids  but i don t know how many should i use  or whether i need to model the quadrotor first to compute kinematic and dynamic of the quadrotor inside the rpi  sorry if the question is too basic  more details the structure is from a kit  well  all i have now is the escs calibrated  although i do not have documentation of them to adjust the cut off voltage for the lipo battery  i have been made tests with some python code i found to have pwm outputs for the motors and to control i c bus to communicate with imu   one of my problems now is that i need rpio library for pwm and the  to work with the i c libraries from the mit to control my imu but as far as i know rpio works with python  and quick wire works with python  so i don t know how to manage this  so actually  i have no code yet to control the four motors in parallel  only have testing code to test them separately and also with the imu  about the imu  i am still learning how to work with it and how to use the mit library  the unit includes those sensors   adxl    hmc    l fds itg      you can see a picture of the quadrotor below   so as i said before  i would like to know how to handle the control system and how it is implemented inside the raspberry pi  and then start to work with the python code to assemble the motors  the imu and the control  ,control pid raspberry-pi quadcopter beginner
8450,torque   current control for bldc motors,i am working on a robotic application  and i want to control the torque  or current  of brushless dc motors  there are many bldc speed controllers but i could not find anything related to torque or current   instead of continuously spinning  the motor is actuating a robotic joint  which means i need to control the torque at steady state  or low speed  finite rotation   i am looking for a low cost  low weight solution  similar to what texas instruments drv    c dual  h bridge motor drivers does for brushed dc motors  ,brushless-motor
8451,what are hardware components to build a modular robot which consists of several  x x cm modules ,i am computer science student and i have no knowledge on robotics   in my project  i am trying to find controllers for modular robots to make them do specific tasks using evolutionary techniques  for the moment i am doing this in a simulator  but if i want to make physical robots i have to know a priori the components to add to the robot  where do i place them  especially if modules of robot are small  cubes of      cm     so my questions are   what are must have components to make physical robot    arduino  batteries  sensors       for a small robot how many batteries do i need   if modules have to communicate with wifi  do i have to put a wifi card on each module  i want to add an imu  is its position important  i mean do i have to put it in the middle of the robot    thank you very much  ,arduino mechanism
8452,what is the easiest yet precise method one can make a track and a train,i would like to put a train on a track and control its movement with high precision left and right using a wireless controller  what is the best way to do it  ,arduino
8455,small ir distance sensor that works on black surfaces,can anyone recommend an ir distance sensor that works on black surfaces  i m looking for something to use as a  cliff  sensor  to help a small mobile robot avoid falling down stairs or off a table  and i thought the sharp gp y d   z f would work  however  after testing it  i found any matte black surface does not register with the sensor  meaning the sensor would falsely report a dark carpet as a dropoff  sharp has some other models that might better handle this  but they re all much larger and more expensive  what type of sensor is good at detecting ledges and other dropoffs  but is small and inexpensive and works with a wide range of surfaces  ,sensors
8457,create   cad files,i found cad files for the create on the ros turlebot download page   zip   and shells on the gazebo sim page   any ideas where the files for the create   could be found  ,design irobot-create
8461,electronic circuit for heating nylon fishing line muscle,i m trying to make artificial muscles using nylon fishing lines  see  and   so far  i ve produced a nicely coiled piece of nylon fishing line  but i m a little confused about how to heat it electrically  i ve seen most people say they wrap the muscle in copper wire and the like  pass current through the wire  and the muscle acuates on the dissipated heat given the wire resistance  i have two questions regarding the heating     isn t copper wire resistance extremely low  and thus generates very little heat  what metal should i use      what circuit should i build to heat the wire  and to control the heating   most examples just  attach a battery  to the wire  but afaik that is simply short circuiting the battery  and heating the wire very inneficiently  and also may damage the battery and it could even be dangerous   so what s a safe and efficient way to produce the heat necessary to make the nylon muscle react   i ve read     centigrads  could that be correct   for example with an arduino  or a simple circuit in a breadboard  thanks a lot  ,arduino electronics actuator
8462,automatic sliding window shutter,i want to build an automatic sliding window shutter and need help with part selection and dimensioning  some assumptions    window width     m sliding shutter weight    kg max speed      m s max acceleration       m s   pulley diameter     m   leaving out friction i need a motor with about      nm of torque and a rated speed of    rpm  what i would like to use   motor controller with soft start and jam protection  dc motor   v  pulleys and timing belts   would you suggest other components or a different setup  how do i connect motor and pulleys  clamping set    do i need additional bearings because of the radial load    m motor  p pulley  b bearing    shaft  if so i have to extend the motor shaft  what would i use for that  clamp collars  couplings    what width do i need for the belts  which belt profile  t  at  hdt  should i use  update the construction i am aiming for resembles the one which can be seen on page    pdf numbering  here  ,motor design microcontroller automation
8463,angular velocity to translational velocity,i have a  d point in space with it s xyz coordinates about some frame a  i need to calculate the new xyz coordinates  given the angular velocities of each axis at that instant of time about frame a i was referring to my notes  but i m a little confused  this is what my notes say   as you can see  i can calculate the angular velocity vector w given my angular velocities  but i m not sure how this translates to how to calculate my new xyz position  how can i calculate the rpy values this equation seems to need from my xyz  and how can i calculate my new position from there ,mobile-robot
8466,sizing high current power supplies for large robots,i m a researcher in a lab that s starting work on some larger humanoid quadruped robots as well as a quadcopter  currently  we have several power supplies that have a max rating of   v   a and our modified quadcopter easily maxes out the current limit with only half of its propellers running  it seems like most power supplies are meant for small electronics work and have fairly low current limits  i think that i want to look for power supplies that are able to provide between      v and higher than   a for an extended period of time       is this unreasonable or just expensive       do most labs just connect psus in series to get higher voltages  thanks for the input  ,quadcopter power humanoid
8470,xaxxon oculus prime platform  using a different sbc than the one sold by manufacturer,i am using the kit version oculus prime mobile platform sold by xaxxon for a project and was planning to use and odroid xu  running ros  but  the problem i faced was that the odroid xu  has a   bit processor whereas the server application and ros packages written for oculus prime run only on   bit  here are the links for the documentation and server application  could anyone tell me if   there is a    bit variant or any other way to run the server application and ros packages on the odroid  will any single board computer with a    bit architecture be able to run the required packages or is there any special configuration in the motherboard that they sell   is this the case with all such platforms in general  which single board computers would be ideal for this situation so that i can purchase them   ,ros ugv platform
8471,dynamic simulation of compliant elements in quadruped robot,i have a preliminary design for a legged robot that uses compliant elements in the legs and in parallel with the motors for energy recovery during impact as well as a pair of flywheels on the front and back that will oscillate back and forth to generate angular momentum  i d like to create a dynamic simulation of this robot in order to be able to test a few control strategies before i build a real model  what simulation package should i be using and why   i have heard good things about msc adams  namely that it is slow to learn  but has a lot of capability  including integration with matlab and simulink  i have also heard about the simmechanics toolbox in matlab  which would be nice to use since i already am decent with cad and know the matlab language  i am not yet familiar with simulink  but have used labview before  ,mobile-robot design dynamics matlab simulation
8474,kinematic decoupling,is kinematic decoupling of a  dof revolute serial manipulator also valid  the three last joints is a spherical joint  most literatures only talks about decoupling of  dof manipulators  thanks in advance  oswald ,kinematics
8475,how can i reduce a motor s maximum current draw ,i have a motor with a stall current of up to   a  i also have a motor controller which has a peak current rating of   a  is there any way i could reduce the stall current or otherwise protect the motor controller  i realize the  right  solution is to just buy a better motor controller  but we re a bit low on funds right now  i thought of putting a resistor in series with the motor and came up with a value of    m   which would reduce the maximum current draw to   a  given the   v   a    m  maximum impedance of the motor   is there any downside to doing this  would i be harming the performance of the motor beyond reducing the stall torque  ,motor microcontroller current
8480,what s the difference between feedback and feedforward control ,i m reading from astrom   murray        s feedback systems  an introduction for scientists and engineers about the difference between feedback and feedforward   the book states   feedback is reactive  there must be an error before corrective actions are taken   however  in some circumstances  it is possible to measure a disturbance before the disturbance has influenced the system   the effect of the disturbance is thus reduced by measuring it and generating a control signal that counteracts it   this way of controlling a system is called feedforward   the passage makes it seem that feedback is reactive  while feedforward is not   i argue that because feedforward control still uses sensor values to produce a control signal  it is still reactive to the conditions that the system finds itself in   so  how can feedforward control possibly be any different from feedback if both are forms of reactive control   what really separates the two from each other  a illustrative example of the difference between the two would be very helpful  ,control
8483,powering   servomotors requiring  v and  a each,the title pretty much says it all   i m on a team that is currently building a robotic arm for the capstone project of my engineering degree  our design is similar to the dobot    degrees of freedom   we purchased our   servomotors  and each one requires  a at  v    from my preliminary research  i haven t been able to find a power source that could satisfy this   we d rather not purchase six individual ac dc power source for each servo  and we ve heard that these can introduce problems  as they aren t necessarily voltage regulated   another suggestion we ve received is to buy a computer power source  and modify it to output our the voltage and amperage we need  this raises some concerns  since our professor running the course might find this dangerous  we d like some input into how we can power our servos effectively  without going overboard on costs  we are students  after all   thanks  ,power servos servomotor arm
8486,how to build a fast quadcopter,im currently in a  risky  proyect that involves me building the fastest quad i can afford  im trying to get something close to this extremely fast warpquad after reading a lot about quadcopters  as i know i can buy all this and it should fit together and fly without any problem   my questions are  first if im wrong or im missing something as i had only read about it  thinking this is a common build for racer quad   then  will this overheat  bad consecuences  if i let it drain the full battery at      throttle  will this fly at least   minutes under the previous conditions  should i get a higher c rating battery  as i can t find better motors of that size  is the only way to improve its speed by putting a  s battery  and what would happen if i do it  should i put the  inch props or  inch  i know  inch should get faster rpm changes but will it be noticeable at this sizes  and in general any tips to make it faster will be welcome  thanks   ,quadcopter
8487,is there a way to disconnect and reconnect from a create   that was streaming sensor readings without having to unplug replug my usb serial cable ,i am working with a create   and i am executing a simple sequence like  in pseudocode    the outcome when i run the above program repeatedly is that it works the first time  i see sensor data  that seems to not change or be reactive  printing to the screen  but on future runs no serial can be read and the program crashes  because i am throwing an exception because i want to get this problem ironed out before getting to far along with other things   if i unplug and replug my usb cable from my macbook  then the program will work for another run  and then fall back into the faulty behavior  i do not experience this issue with other things like driving the robot  i am able to run programs of similar simplicity repeatedly  if i mix driving and sensor streaming  the driving works from program run to program run  but the data streaming crashes the program on the subsequent runs  i have noticed that if i want to query a single sensor  i need to pause the stream to get the query response to come through on the serial port  and then resume it  that is why i am so inclined to pause restart the stream  am i doing something wrong  like pausing the stream too often  are there other things i need to take care of when starting stopping the stream  any help would be appreciated  edit  i should note that i am using python and pyserial  i should also note  for future readers  that the irobot pushes its streamed data to the laptop every   ms where it sits in a buffer  and the data sits there until a call to serial read   or to serial flushinput    this is why it seemed that my sensor values weren t updating when i read polled every half second  because i was reading old values while the current ones were still buried at the back of the buffer  i worked around this issue by flushing the buffer and reading the next data to come in  edit    sometimes the above workaround fails  so if i detect the failure  i pause the stream  re initialize the stream  and read the fresh data coming in  this seems to work pretty well  it also seems to have solved the issue that i originally asked the question about  i still don t know exactly why it works  so i will still accept  jonathan  s answer since i think it is good practice and has not introduced new issues  but has at least added the benefit of the robot letting me know that it has started exited by sounding tones  ,mobile-robot irobot-create
8491,relative orientation of two robots,given two robot arms with tcp  tool center point  coordinates in the world frame is   and  the base of the robots is at     the coordinates are expressed as successive transformations  x translation  y translation  z translation  x rotation  y rotation  z rotation  none of the joint axes are capable or continuous rotations   how many degrees does the tcp of robot   have to rotate to have the same orientation as the tcp of robot one  is the calculation   wrong  if yes  please specify why  updated  is the relative orientation of the two robots                                         but the euclidean distance cannot be applied to calculate angular distance  in other words   while programming the robot  and tool frame is selected for motion  to match the orientation of the other one  i would have to issue a move rel   command  but the executed motion would have magnitude of   while programming the robot  and world frame is selected for motion  to match the orientation of the other one  i would have to issue a move rel   command  and the executed motion would have magnitude of    ,robotic-arm kinematics geometry
8499,mapping between camera pose and image features in visual servoing,i have a robotic arm and a camera in eye in hand configuration  i know that there is a relationship between the body velocity  of the camera and the velocities  in the image feature space that is  where  is the interaction matrix  i was wondering if one can find a mapping  a so called diffeomorphism  that connects the image features  vector  with the camera pose   all i was able to find is that it is possible to do that in a structured environment which i don t fully understand what it is  ,mapping visual-servoing
8500,forward kinematic and inverse kinematic    when to use what ,i am not quite sure if i quite understand the difference between these two concepts  and why there is a difference between these two concept   yesterday i was trying to compute the jacobian needed for an inverse kinematics  but the usual input i provided my transformation in the forward kinematics being the points p and xyz could not be applied  the transformation matrix was given a state vector q  at which the the tool position could be retrieved     i am not sure if understand the concept quite well  and can t seem to the google the topics  as they usually  include terminologies which makes the concepts too simple  angle calc and so on     i know it might be pretty much to ask  but what form of input is needed to compute the jacobian    and what and why is there a difference between forward and inverse kinematics     ,inverse-kinematics forward-kinematics jacobian
8501,lifting robotic leg with only one servo,note before i start  i have not actually put anything together yet  i m still just planning  so any changes that require a shape change or anything like that are accepted  i m working on making a walking robot with my arduino and  d printing all the pieces i need  it will have four legs  but since it needs to be mobile  i didn t want the power supply to be huge  i ve decided it would be best if i can get each leg to only require   servo  at  v each  i know how to get the leg to move back and forth  but i want to be able to lift it in between  before it brings the leg forward  it needs to lift up the foot  the only thing i can think of is the rotation maybe locking some sort of gear  when a motor begins rotating clockwise  how can i have it power a short motion to move an object toward itself  and when it begins moving counterclockwise to power the same object a short distance away from itself  the servos i am using have      of rotation  so they don t go all the way around in a loop  also  don t know if it will be important or not  but because of the peculiar construction of the foot  it would be best if it was lifted straight up  rather than up at an angle  but it isn t      necessary   are there any robots that already do this  if so  i m unaware of them  thanks for your time  ,mechanism motion-planning servomotor legged gearing
8510,what are the approaches for indoor robot positioning ,i understand that most of the self driving cars solutions are based on lidar and video slam  but what about robots reserved for indoor usage  like robot vacuums and industrial agvs  i see that lidar is used for irobot and their latest version uses vslam  agvs also seem to use lidar  ,slam lidar
8511,what engineering problems needs to be solved to build a potato peeling robot ,ok  let s say we have a tech request for a robotic system for peeling potatoes  and a design is as follows   one  arm  for picking up a potato and holding it  rotating when needed  another  arm  for holding a knife like something which will peel the skin from the potato  arm picks up a potato from first container  holds it over trash bin while peeling  then puts peeled potato in second container  for simplicity a human rinses peeled potatoes  no need to build automatic system for it  in first iteration even      spherical peeled potatoes are ok  but ideally would be good to peel as little as possible  to minimize the wastes   question  i know that we re very  very far away from building such a system  nevertheless  what are the purely technical difficulties which needs to be solved for such a robot to be built   edit let s assume we stick to this design and not invent something radically different  like solving the problem with chemistry by dissolving the skin with something  i know that the problem of peeling the potatoes is currently being solved by other means   mainly by applying friction and a lot of water  this question is not about it  i am asking specifically about the problems to be solved with the two arms setup using the humanlike approach to peeling  ,robotic-arm
8512,how to connect absolute encoder on the rotating shaft  please see the three options ,  hi  here i have added   options for connecting encoder on shaft  motor  gearhead and shaft is connected using coupling  but where will be best place for encoder  to avoid backlash from coupling and gearhead   whether through hollow encoder is available   see option     i dont know which one will be best for this kind of system   which one is widely using arrangements  options   is encoder will be placed before the motor  ,motor
8516,getting pitch  yaw and roll from rotation matrix in dh parameter,i ve calculated a dh parameter matrix  and i know the top  x  matrix is the rotation matrix  the dh parameter matrix i m using is as below  from  above is what i m using  from what i understand i m just rotating around the z axis and then the x axis  but most explanations from extracting euler angles from rotation matrixes only deal with all   rotations  does anyone know the equations  i d be very thankful for any help  ,kinematics forward-kinematics dh-parameters
8519,fanuc robot  heat  control,my work has an older fanuc robot   arc mate     ibe rj ib  fanuc awe  teach pendant with  powerwave    m  and the old operator programmer has left  i have taken over his job and cant find out how to turn down the voltage and wire feed speed because it occasionally burns through parts  i tried manually putting in voltage and wire feed speed but it seems it will only accept the previous weld schedules     and if i mess with them that will affect other programs using those  i just need someone to please point me in the right direction   p s  typed on phone   sorry if sloppy  ,industrial-robot
8522,recommendation for  d mechanism modeling and simulation software,i m working on a robotic hand and i would like to simulate different joints and tendon insertion points before starting to actually build it  i ve been googling and found things like solidworks and autodesk  that seem very costly for a hobbyst like me but also i don t quite fully understand their capabilities  just cad   d modelling but not simulation  simulation but not interactive    i ve also found things like freecad which seem to me somehow abandoned or just for cad and not for simulation  another requirement would be interactivity of the simulation  not just rendering  i don t have a problem with commercial software  but i m looking for a reasonable cost for a hobbyst  not an engineering company  is there a software out there that meets all this requirements  or should i use several programs each for a specific purpose  thanks  ,design mechanism software simulator 3d-model
8525,quadrocopter problem with stability,i m building quadcopter from scratch  software is implemented on stm  f  microcontroller  frequency of main control loop equals    hz  i ve though everything is almost finished but when i ve mounted everything and started calibration of pids i faced a problem  it was impossible to adjust pid parameters properly  so i started test with lower power  not enough to fly  and i ve managed quite fast adjust pid for roll but when i ve increased power problems with control came back  after that i ve done more measurements    i didn t make test with blades but probably this is even worse and that is why i cannot calibrate it   if problem is due to vibration how can i fix it  if something else is cause of that symptom  what is it  can i solve this through better controls and data fusion algorithms  now i use complementary filter for acc and gyro sensors data fusion in roll and pitch   ,control imu accelerometer gyroscope
8526,which usb interface for android device i can use for motor driver,i am new to robotics  i will be controlling dc motors from android device through usb for this i have selected l   n motor controller after watching youtube videos   and got some dc motors i have no idea how do i connect this to android device via usb cable help appreciated ref    ps  all i know is programming android ,motor usb
8527,which brushless dc and propeller to choose ,i have a small bot around    kg with wheels  which is to be pushed without contact by another bot  i plan to do this using a bru and a propeller  i am having problems selecting the right combination  please help me with these questions    should the bldc be high kv or low kv will i need high rpm or low rpm  what is the  ideal propeller to use with the motor so that i can create enough thrust to get the  small  bot in motion and keep it in motion  what are the other criteria i should keep in mind while selecting   ,brushless-motor
8538,setting up a gimbal with the dji wookong m but using a separate transmitter and receiver,i just bought the wookng m for my multi copter and i was wondering if it is possible to have a two man system where one controls the main craft with one transmitter and the other controls the camera and gimbal with another transmitter  i know you can set up a gimbal with the wookong m but i wasn t if you could use a separate transmitter to control it or even control it at all  i am also waiting for my   axis gopro gimbal to arrive but can i even control the pan or do i have to control the gimbal completely separate and not use the wookong m for the gimbal and camera  i am a beginner and this is my  st time working with the wookong m so please keep the answers understandable  thanks in advance ,quadcopter
8539,how can i increase the resolution of a pwm signal ,say i have a motor and i want it to spin at exactly           revolutions per minute   say i have a very precise sensor to detect the rpm of the motor to a resolution of       th of a revolution per minute     can i produce a pwm signal which can match the speed to that degree of  precision    what variables in the signal parameters would i have to adjust to get the precision if possible    would i have to use additional circuitry between the motor and the driver    would i have to design the signal circuitry around the specific specifications of the motor  should i just use a stepper motor   this is assuming i am using a microcontroller to measure the motor s speed and adjust the signal in real time to maintain a certain speed  ,motor microcontroller stepper-motor pwm stepper-driver
8544,pole balancing   inverted pendulum  is there a need for active control ,not sure if i am posting this question in the correct community  as it relates primarily to reinforcement learning  apologies early on if this is not so  in reinforcement learning many algorithms exist for  solving  the cart pole problem  that of balancing a mass on the edge of a stick  connected to a cart on a hinge  which has   dof  there is td learning  q learning and many other on and off policy methods  there is also the more recent  model based policy search method pilco  what i am really wondering  i suppose is more of a physics question  is there a need for active control  why is it not possible to find the one point for the cart  which prevents the mass to move  even incrementally  left or right as it sits atop the pole  why does it always  fall   ,control
8546,modelling point clouds for collision detection in gazebo,i am currently applying path planning to my robotic arm  in gazebo  and have chosen to use an rrt  in order to detect points of collision  i was thinking of getting a point cloud from a kinect subscriber and feeding it to something like an octomap to have a collision map i could import into gazebo  however  there is no gazebo plugin to import octomap files and i do not have enough experience to write my own  the next idea would be to instead feed this point cloud to a mesh generator  like meshlab  and turn that into a urdf  but before starting i d rather get the input of somebody far more experienced  is this the right way to go  keep in mind the environment is static  and the only things moving are the arms  thank you  below is just a picture of an octomap  ,robotic-arm localization slam kinect gazebo
8549,dh parameters and kinematic decoupling,is it possible to decouple a  dof manipulator   this question i asked earlier and i believe i got the right answers but i never show the drawings of the manipulator and now i m hesitating during setup of the dh parameters for forward kinematics  see drawing depicted here    ,kinematics forward-kinematics dh-parameters
8555,which trajectory planning algorithm for minimizing jerk,in order to perform a cyclic task  i need a trajectory planning algorithm  this trajectory should minimize jerk and jounce  when i search for trajectory planning algorithms  i get many different options  but i haven t found one which satisfies my requirements in terms of which values i can specify  an extra complicating factor is that the algorithm should be used online in a system without too much computing power  so mpc algorithms are not possible    the trajectory i am planning is  d  but this can be stripped down to   trajectories of   dimention each  there are no obstacles in the field  just bounds on the field itself  minimum and maximum values for x and y  values that i should be able to specify   total time needed  it should reach its destination at this specific time   starting and end position starting and end velocity starting and end acceleration maximum values for the position   ideally  i would also be able to specify the bounds for the velocity  acceleration  jerk and jounce  but i am comfortable with just generating the trajectory  and then checking if those values are exceeded  which algorithm can do that  so far i have used fifth order polynomials  and checking for limits on velocity  acceleration  jerk and jounce afterwards  but i cannot set the maximum values for the position  and that is a problem    thank you in advance  ,control algorithm
8556,length and width of a line following robot,i m building a line following robot  i have made different chassis designs  the main prototype i m using is a rectangle base  at one side motors are placed  on the other side of the rectangle caster wheel is placed in the middle  look at the following image   by varying the values of   i have seen that the stability of the robot is varying rapidly   i m driving the robot using pid  i have seen that for some chassis designs it is very hard sometimes impossible  to calculate correct constant values  and for some chassis it is very easy  by the word stability i meant this  i have a feeling that the robot dimensions  distance values and that stability has a relationship   is there an equation or something that can be used to estimate the value of the distance when the width of the robot is known    other than that is there a relationship between robot weight and diameter of the wheel or robot dimensions and the diameter    thanks for the attention   ,arduino motor pid line-following
8559,is it possible to design robot software or ai to function in different devices ,so i m really interested in robotics   i m not really a robot expert as i have no experience on creating one  i just like them   anyway  i am always wondering if its possible to build a robot that can transfer itself to different devices and still function  i mean  if you want that robot to transfer itself the data that making it function or whatever you call it  to your laptop so you can still use it while you are away or anything   does creating one require advanced computing and knowledge  is it kind of creating a artificial intelligence   when it think of this i would always thought of j a r v i s since he can go to stark suit and communicate with him   translated into robotics terminology by a roboticist  is it possible to create software for controlling robot hardware that can transfer itself to different devices and still function  could it transfer itself to your laptop and collaborate with you using information it gathered while it was in it s robot body     does creating software like this require advanced knowledge and computing  is software like this considered to be artificial intelligence   i am serious about this question sorry to bother or if anyone will be annoyed    ,mobile-robot
8561,is venetian mirror possible in autodesk inventor ,i see there are things like glass and mirror in autodesk inventor professional      but is there a possibility to have venetian mirror  so that from one side it would look like a mirror and from the other side it would look like a transparent glass  ,design mechanism 3d-printing 3d-model visualization
8562,humanoid balancing,i m currently working on humanoid robot  i ve solved the forward   inverse kinematic relations of the robot  and they turn out to be fine  now i want to move onto walking  i ve seen tons of algorithms   research papers but none of them make the idea clear  i understand the concept of zmp   what the method tries to do  but i simply can t get my head around all the details that are required to implement it in a real robot  do i have to plan my gait   generate the trajectories beforehand  solve the joint angles  store them somewhere   feed it to the motors in real time  or do i generate everything at run time a bad idea imo   is there a step by step procedure that i can follow to get the job done  or do i have to crawl all my way through those research papers  which never make sense at least for me   ,mobile-robot stability humanoid
8565,velocity of link  i    with respect to frame  i   ,i read several textbooks but could not find a good explanation  can anybody tell me why velocity of link  i    with respect to frame  i    is not zero  my argument is  since the velocity of the link  i    is the velocity of origin of the frame  i    it should be zero with respect to itself   from  introduction to robotics mechanics and control  ,kinematics forward-kinematics
8570,calculate robot heading to follow wall and avoid obstacles,i have a task that involves implementing robot behaviour that will follow wall and avoid obstacles along it s path  the robot must stay at desired distance from the wall but also stick to it so it should not loose sight of it  robot is sensing it s surrounding with ultrasonic sensor that is oscillating from left to right and filling an array of small length     values  with detected distances  every    degrees   from this reading i would like to calculate heading vector that will result in robot path similar to one shown in bottom picture  black walls   red obstacles   blue robot   green desired path   ,wheeled-robot navigation
8575,pid tuning for   dof robotic arm,i m currently developing a   dof robotic arm  the arm is vibrating when it stop moving and i want to reduce it  another thing is that arm is so heavy  because there is a projector inside it  lol  and i have to use spring between joints  so  can anyone tell me    how to select springs because my supervisor told me that proper selection of springs can reduce vibration     how do i tune the pid parameters  all the joints are dynamixel servos and their pid parameters are tunable  i read article about tuning for a single servo  how do i tune these parameters for the whole arm  ,control pid robotic-arm
8579,change pwm values according to encoder output,i have a motor with an encoder  when i set the speed of the motor it should change its speed so that encoder readings per second should fit an equation  where  is speed value that is given to the motor and y is the encoder readings per second that should get with motor  encoder reading is counted in every  ms and if it is not equal to the value of the encoder output should get from motor  it is calculated using the equation   the pwm input to the motor should vary in order to get desired encoder output  i want to control this value using a pid controller but i m confused in writing equations  any help would be appreciated   ,motor pid pwm
8580,arduino power adapters,i m shopping for my first arduino with a specific goal in mind  i need to attach   standard servo motors  an arducam mini  mp camera  and several leds  i m trying to figure out power requirements  i assume that usb power won t be sufficient  i m looking at   v ac to dc outlet adapters and i noticed that amps vary from     ma to  a  i don t want to use batteries  what would you recommend as minimum amperage for this setup  is there a maximum amperage for arduino boards  i don t want to plug it in and burn it out  if i plug in both the usb cable and a power adapter at the same time  is power drawn from both cables  thanks  ,arduino power
8585,ros and kinect data without callbacks,i d like to get rgb and depth data from a kinect  and i found a little tutorial here    it s fine  but what i d like is to be able to get the data on demand  and not as whenever the callback is triggered  assuming i won t try to get the data faster than it can be available  i d appreciate any help   do go easy on the ros jargon  i m still learning   thanks  ,ros kinect
8586,how can i measure the actual speed and distance traveled of the robot with an external setup ,good day to all  first of all  i d like to clarify that the intention of this question is not to solve the localization problem that is so popular in robotics  however  the purpose is to gather feedbacks on how we can actually measure the speed of the robot with external setup  the purpose is to be able to compare the speed of the robot detected by the encoder and the actual speed  detected by the external setup  i am trying to measure the distance traveled and the speed of the robot  but the problem is it occasionally experiences slippage  therefore encoder is not accurate for this kind of application   i could mark the distance and measure the time for the robot to reach the specified point  but then i would have to work with a stopwatch and then transfer all these data to excel to be analyzed   are there other ways to do it  it would be great if the external setup will allow data to be automatically sent directly to a software like matlab  my concern is more on the hardware side  any external setup or sensors or devices that can help to achieve this  thanks  ,mobile-robot control wheeled-robot
8590,how can i measure the height of an object with a single sharp sensor  gp y a  yk f  ,i have one sharp sensor and i have to use it to measure the height of a block   cm      cm   how can i accomplish this   actually it is to be connected to a robot which will move near the box and determine its height  about gp y a  yk f   the robot is like this    if possible please suggest a solution that doesn t require moving the sensor  but any method will do fine  ,mobile-robot first-robotics
8592,manipulator end effector orientation with quaternions,i have the following problem  given   points on a surface  i have to adjust a manipulator end effector  i e  pen  on a baxter robot  normal to that surface  from the three points i easily get the coordinate frame  as well as the normal vector  my question is now  how can i use those to tell the manipulator its supposed orientation  the baxter inverse kinematics solver takes a  tuple of cartesian coordinates for the desired position  as well as a  quaternion for the desired orientation  what do i set the orientation to  my feeling would be to just use the normal vector  and a   or do i have to do some calculation  ,inverse-kinematics orientation
8595,in order to integrate mcl and occupancy grid to implement grid based fastslam  do you have to record all data ,it s unclear as to how one goes about integrating occupancy grid mapping and monte carlo localization to implement slam  assuming mapping is one process  localization is another process  and some motion generating process called exploration exist  is it necessary to record all data as sequenced or with time stamps for coherence   there s motion    map    estimated state    measurement   so    each estimated state    is a function of the current motion    current measurement    and previous map    each confidence weight    of estimated state is a function of current measurement     current estimate state    and previous map    then each current map   is a function of current measurement    current estimated state     and previous map     so the question is  is there a proper way of integrating mapping and localization processes  is it something you record with timestamp or sequences  are you suppose to record all data  like fullslam  and maintain full history   how can we verify they are sequenced at the same time to be referred to as current  i e  measurement  and previous  measurement   ,slam occupancygrid
8596,what can this picture data tell ,i ve implemented a model of a ball on plate plant and am controlling it over a network  below is the open loop output when excited by successive sinusoidal inputs with increasing frequencies  i know that the plant is open loop unstable  and it is cool that this figure so nicely captures the instability   what i d like to know is if there is other information that i can glean about the plant from the relationship between the input and the output state   the state is clipped at     units    ,control balance distributed-systems
8598,comparison of lifting systems,what kind of systems can be used to make a torso lifting system like the one used by this robot  the black part      rack and pinion lead screw scissor lift can a triple tree help     what are the pro and cons of each system   how do they ensure stability   and finally  is there a way to draw current when lowering instead of drawing current when lifting   ,mechanism
8600,ros   kinect depth data duplication,i am trying to get depth data from a kinect in a ros project  it currently looks like this   to arrive at this  i ve done   i also launch openni launch from the openni launch package  which publishes the depth data  i also get this weird warning from the node  can be seen in the image       complexwarning  casting complex values to real discards the imaginary part  but as i understand it the data type is an array of    bit floats  yet some of the values appear as nan  i would like a depth image that directly corresponds to a rgb image array of the same size  i will be doing some tracking in the rgb space  and using the tracked coordinates  x y  from that to index into the depth array  thanks   edit  turns out   camera depth image is published as an array of uint s  but the actual data is   bit floats  which is not listed anywhere  had to hunt it down in other people s code   thus an array of    x    uint s  interpreted as   bit floats  in effectively  quartered  in the number of data points  which could explain how the image is   times smaller  and hence accessing datapoints out of bounds   nan    but not why there are two of them  ,ros kinect
8601,choosing a proper sampling time for a pid controller,i have a robotic system i m controlling with arduino  is there an heuristic way to determine a proper sampling time for my pid controller  considering i have some other things to compute on my sketch that require time  but of course a good sampling time is crucial  basically i have a distance sensor that needs to detect at a constant rate an object that is moving  sometimes slow  sometimes fast  i don t have a good model of my system so i can t actually tell the physical frequency of the system  ,pid
8605,mechanical robustness shock resistance lipo batteries,how mechanically robust are lipo batteries  how much force or acceleration can they maximally withstand before failure  what is their  mechanical  shock resistance  for some electrical components used in robots  such as imu s  it can be found in datasheets that they can suffer mechanical failure if accelerated or loaded beyond given values  for imu s  this is typically somewhere between  and   where    i m wondering if similar values are known for lipo batteries  since they are known to be vulnerable components  but  is there any quantification known for their claimed vulnerability  ,battery
8607,open source implementations for gps imu sensor fusion ,are there any open source implementations of gps imu sensor fusion  loosely coupled  i e  using gps module output and   degree of freedom imu sensors      kalman filtering based or otherwise  i did find some open source implementations of imu sensor fusion that merge accel gyro magneto to provide the raw pitch yaw  but haven t found anything that includes gps data to provide filtered location and speed info  ,kalman-filter imu sensor-fusion gps
8611,iphone controlled rc car,i have an r c car and there is a program in my computer in which i can code the car to perform movements i would like to have an application with a visual design where it shows the cars path  is there available software code for this  saves me lots of time  ,software research
8612,combustion engine controlled with a remote,how can one control a combustion engine using a remote control  or how would you make a car controlled using a remote  ,robotic-arm first-robotics
8617,what is  in the inverted pendulum problem ,i am preparing for an exam in neural networks  as an example for self organizing maps they showed the inverted pendulum problem where you want to keep the pole vertical   now the part which i don t understand   f  theta     alpha  sin  theta     beta  frac  mathrm d   theta   mathrm d  t    let       solution with som   three dimensional surface in  adapt two dimensional som to surface method of control       for a given  find neuron  for wich   is then     i guess we use the som to learn the function   however  i would like to understand where  comes from   what it means in this model  ,control stability machine-learning
8618,does c have advantages over c   in robotics ,i want to build robots  and right now i aim to work with arduino boards i know that they are compatible with c and c    so was wondering which language is better for robotics in general  i know how to write in java  and the fact that c   is object oriented makes it look like a better choice for me does c have any advantages over c    ,arduino c++ c
8621,forward kinematic computing the transformation matrix,i am the moment trying to compute the transformation matrix for robot arm  that is made of   joints  serial robot arm   with which i am having some issues  l      l    l       and q           based on this information i have to compute the forward kinematic  and calculate the position of each joint   problem here is though  how do i compute the angle around x y z   for the transformation matrix   using sin cos tan is of course possible  but what do their angle corresponds  which axis do they correspond to   i tried using  steveo answer to compute the  using the method he provided in his answer  but i somehow mess up something  as the value doesn t resemble the answer given in the example      ,kinematics forward-kinematics orientation
8631,imu sensor and compensation,hi i m using  minimu      dof imu  gyro  accelerometer and compass  sensor and it gives pitch roll and yaw values with a slope on desktop  no touch  no vibration  steady   y axis is angle in degree and x axis is time in second  x axis length is    seconds  how can fix this  pitch  roll  yaw  note   minimu code ,sensors imu sensor-fusion
8636,sum error in pid controller,i m trying to implement a pid controller by myself and i ve a question about the sum error in i control  here is a short code based on the pid theory   now  i start my commands  phase    if at t    i set target      and the controller begins to drive motor to go to the target      phase    and then  at t n  i set target      and the controller begins to drive motor to go to the target     my question is  in the beginning of phase    the error      the sum error    and after the phase    the sum error is not zero anymore  it s positive  and in the beginning of phase    the error      it is also the same with above   but the sum error is positive  so  the iterm at t n is much greater than iterm at t    it means  the curves between phase   and phase   are different    but to end user  the command    and the command   is almost the same  and it should drive the same effort  should i set the sum error to zero or bound it  can anyone tell me how to handle the sum error in typical  any comment will be much appreciated   kevin kuei ,pid
8642,discontinuity in device orientation,why is there a discontinuity in the quaternion representation of my device orientation  i m using a sentral pni rm     st lsm    to track orientation  i performed the following test   place the device in the center of a horizontal rotating plate   lazy susan    pause for a few seconds  rotate the plate      clockwise  pause for a few seconds  rotate the plate      clockwise again   i got this output  which appears discontinuous at sample              sample       has    but sample       has  qx qy qz qw                                        plugging in the formulas on page    of this document  this corresponds to a change in orientation from  heading  pitch  roll                     to  heading  pitch  roll                     the graph of  heading  pitch  roll  is also not continuous mod      does this output make sense  i did not expect a discontinuity in the first plot  since the unit quaternions are a covering space of so     is there a hardware problem  or am i interpreting the data incorrectly  edit  the sensor code is in central c and main c  it is read with this python script  ,sensors calibration orientation
8644,is robotbasic outdated ,i found this website  and it talks about a language used for programming things related to robotics  and i want to make sure whether or not it s worth investing any time or energy into compared to other languages before i just wipe it from my browser bookmarks for good  nowadays  are there better languages and methods for going about the same things that it talks about   i mean  the site looks pretty old  like something from the late   s or pre       plus i never heard of it anywhere except for this site  so i wonder if it s just not relevant any more if it ever was  ,control software
8654,finding cubic polynomial equation for   joints,my professor gave us an assignment in which we have to find the cubic equation for a   dof manipulator  the end effector is resting at a            and moves and stops at b        in    seconds  how would i go about this  would i use the jacobian matrix or would i use path planning and the coefficient matrix to solve my problem  i m assuming coefficient matrix but i am not given the original position in angle form  i was only taught how to use path planing when the original angles are given  ,motion-planning inverse-kinematics motion jacobian
8657,p gain tuning for quadcopter  is my perception for a p gain too high correct  ,good day  i am currently working on a project using complementary filter for sensor fusion and pid algorithm for motor control  i viewed a lot of videos in youtube as well as consulted various blogs and papers with what to expect with setting the p gain to high or too low  p gain too low  easy over correction and easy to turn by hand  p gain too high  oscillates rapidly  i have a sample video of what i think a high p gain    in my case  looks like  do this look like the p gain is too high     from the video  i noticed that the quad sometimes corrects its orientation immediately after turning few degrees      deg   however  it does not do so in a consitent manner  it also overcorrects  the reason behind my doubt is because the quadcopter doesn t react immediately to changes  i checked the complementary filter  it updates  fast  the filtered angle reading from sudden angular acceleration from the gyro as well as updates the long term filtered angle changes from the accelerometer  albeit slowly   if i am right  is the the p gain is responsible for compensating the  delay   the formula i used in the complementary filter is the following   here is a video for a p gain of     your help would be very appreciated    ,quadcopter pid sensor-fusion tuning filter
8661,calculating required torques for a given trajectory using lagrange euler,i have a  dof robot with   revolute joints  as shown in the diagram below  i m trying to calculate  using matlab  the torque required to move it but my answers don t match up with what i m expecting   denavit hartenberg parameters    begin array  c cccc  joint   a    alpha   d    theta     hline          pi          theta                       theta       end array   i m trying to calculate the torques required to produce a given acceleration  using the euler lagrange techniques as described on pages     in this paper  particularly   t i inertial     sum  j    nd  ij  ddot q i where  d  ij     sum  p max i j   n trace u  pj j pu  pi  t   and   j i    begin bmatrix     i  xx  i  yy  i  zz    over      i  xy    i  xz    m i bar x i    i  xy      i  xx  i  yy  i  zz    over      i  yz    m i bar y i    i  xz    i  yz      i  xx  i  yy  i  zz    over      m i bar z i     m i bar x i   m i bar y i   m i bar z i   m i  end bmatrix   as i was having trouble i ve tried to create the simplest example that i m still getting wrong  for this i m attempting to calculate the inertial torque required to accelerate  at a constant     as  is constant at    i believe this should remove any gyroscopic coriolis forces  i ve made link   weightless so its pseudo inertia matrix is    i ve calculated my pseudo inertia matrix for link     i  xx     mr    over               i  yy    i  zz     ml    over            j     begin bmatrix                                                                                        end bmatrix   my expected torque for joint      t     i ddot  omega    t      ml    over     times  ddot  omega    t        times  over   times     t       over  nm  the torque calculated by my code for joint      t      over  nm  so this is my problem  my code  doesn t match up with my simple mechanics   the key functions called are shown below  function inertial torque n   calc inertial torque n  t  j  qdd      inertial torque n          for j               mnj              joint accel   qdd j           for i                   uij   calcuij t  i  j               ji   j     i               uin   calcuij t  i  n               mnj   mnj   trace uin ji transpose uij            end         inertial torque n   inertial torque n   mnj   joint accel      end end  function u calcuij t i j        t     j    derivative t     j         u   eye            for x     i         u   u t     x       end end  function t   derivative t      dt by dtheta                                                                                                                   t   dt by dtheta t  end  i realise this is a fairly simple robot  and a complicated process   but i m hoping to scale it up to more dof once i m happy it works   ,dynamics matlab torque
8663,how to program an nxt brick to always hit a ball ,i am using a mindstorm robot with an nxt brick  using the graphical interface to create the program  part of the course my robot will take includes a black line on a white background  at the end of the line there is a gap  and after the gap there is a semi circular line  there is a ball that the robot has to hit soon after the robot crosses the gap   the robot has a small code to follow the black line for a certain amount of time  enough time so that it stops just before the gap  the the robot just runs forward for   second across the gap  then the robot swings an arm to hit the ball  and after that i have the code for line following again  however  once it crosses the gap  the robot stops in a different place every time  so the arm usually misses the ball  is it possible to program the robot to hit the ball every time almost every time in the gui     among other things i have tried using the ultrasonic sensor to detect the ball  but the sensor does not pick it up  ,nxt mindstorms
8665,color sensor alternatives,i am making a white line follower  i am using an ir sensor module based on tcrt      i am directly taking the  bit adc reading from arduino uno and printing the values on serial monitor  i observe that the values for white are around        which is ok  the problem arises when i try detecting an orange     c  surface  the sensor gives me values very close to that of white which is around         i can use a color sensor but they are bulky and i am not sure how i can get readings faster with them since they take a finite time for sampling  r   g  and  b  pulses  can someone please tell me an alternate approach to detecting the colours or any other possible solution to my problem  edit  i would like to add that the line i wish to follow is  cm in width  hence i plan to use three sensors  two just outside the line on either sides and one exactly at the centre  the sampling frequency of arduino uno is around    khz  sampling ir is not an issue because it is quick but using a color sensor takes a lot of time  ,sensors line-following
8667,visual servoing   tracking a point,i am trying resolve some issues i am having with some inverse kinematics   the robot arm i am using has a camera at the end of it  at which an object is being tracked  i can from the the camera frame retrieve a position  relative to that that frame but how do i convert that position in that frame  to an robot state  that set all the joint in a manner that  the camera keep the object at the center of the frame        my approach     from my image analysis i retrieve a position of where the object i am tracking is positioned     x y    coordinate  i know at all the time the position  a  of the end tool by the t base tool   matrix  and from the image analysis i know the position  b  of the object relative to the camera frame for which i compute the difference as such c   b   a   i then compute the image jacobian  given the c  the distance to the object and the focal length of the camera   so    thats where i am at the moment   i am not sure whether the position change retrieved from the cam frame will be seen as position of the tool point  at which  the equation will become un undetermined as the length of the state vector would become   instead of      the equation that i have must be  j  image  q dq   dp  j image q   x    being the image jacobian of the robot at current state q  dq  x    wanted change in q state  dp  x    computed positional change     solution would be found using linear least square    but what i don t get is why the robot itself is not appearing the equation  which let me doubt my approach    ,inverse-kinematics visual-servoing
8670,robotic manipulator,i have started working on robotic manipulators and got into a project which deals with control of robotic manipulator using artificial neural networks  solution of inverse kinematics and trajectory generation  to be precise    can someone please suggest me where to start as i have no prior knowledge about robotic manipulator and ann and how to code them  ,arduino robotic-arm inverse-kinematics machine-learning
8671,is robocup still vivant and significant robotic issue ,a couple years ago robocup competitions seems to be quite vivant issue  now when i m looking for some info about it  it seems to be some kind of insignificant but this may be only my first impression  i was looking for  d simulator league and it seems that it does not even exist anymore   so is robocup still alive and significant robotic issue  ,soccer
8673,is there a  net library for conveyor belt automation ,i m a software developer and i work for a company that i think could use some automation in its warehouse  i thought it would be fun to put together a prototype of a conveyor system that automates a manual sorting process that we do on our warehouses  i m primarily a  net developer so i m wondering if there is an  net sdk for conveyor automation   any other information on where to start would be helpful but is not my main question here   ,automation
8680,calculating position based on accelerometer data,please help me with the following task  i have mpu      from which i get acceleration gyro and magnetometer data  what i m currently interested in is to get the orientation and position of the robot  i can get the position using quaternions  its quite stable  rarely changes when staying still  but the problem is in converting accelerometer data to calculate the displacement  as i know its required to to integrate twice the accel  data to get position  using quaternion i can rotate the vector of acceleration and then sum it s axises to get velocity then do the same again to get position  but it doesn t work that way  first of all moving the sensor to some position and then moving it back doesn t give me the same position as before  the problem is that after i put the sensor back and it stays without any movement the velocity doesn t change to zero though the acceleration data coming from sensors are zeros  here is an example  initially its like this   the gravity                      raw accel                accel after scaling to   g                       the result after rotating accel vector using quaternion                       after moving the sensor and putting it back it s acceleration becomes as                                                                                          and so on  if i m integrating it then i get slowly increasing position of z  but the worst problem is that the velocity doesn t come back to zero for example if i move sensor once and put it back the velocity will be at         for vx and      for vy after several such movements it becomes        for vx      for vy        for vz and after another such movement  vx       vy      vz      the x and y doesnt change if sensor is not moving but z is changing slowly  though the quaternion is not changing at all  what should be the correct way to do that task  here is the part of code for integrations   currently set speed to   just to test how it works  edit    here is the code to retrieve quaternion and accel data  rotate and compensate gravity and get final accel data             display initial world frame acceleration  adjusted to remove gravity            and rotated based on known orientation from quaternion         mpu dmpgetquaternion  q  fifobuffer           mpu dmpgetaccel  aareal  fifobuffer           mpu dmpgetgravity  gravity   q              serial print  gravity t            serial print gravity x           serial print   t            serial print gravity y           serial print   t            serial print gravity z           serial print   t                serial print  accell t            serial print aareal x           serial print   t            serial print aareal y           serial print   t            serial print aareal z           serial print   t              float val      f          float ax   val    float aareal x          f          float ay   val    float aareal y          f          float az   val    float aareal z          f            theworldf x   ax                      theworldf y   ay          theworldf z   az             serial print  scaled accel t            serial print ax           serial print   t            serial print ay           serial print   t            serial print az           serial print   t              theworldf x    gravity x          theworldf y    gravity y          theworldf z    gravity z           theworldf rotate  q             gravity rotate  q             serial print  gravity compensated accel t            serial print theworldf x           serial print   t            serial print theworldf y           serial print   t            serial print theworldf z           serial print   t            serial print deltatime            serial println      edit     dmpgetquaternion  dmpgetaccel functions are just reading from the fifo buffer of mpu   dmpgetgravity is  uint  t mpu      dmpgetgravity vectorfloat  v  quaternion  q        v    x        q    x q    z   q    w q    y       v    y        q    w q    x   q    y q    z       v    z   q    w q    w   q    x q    x   q    y q    y   q    z q    z      return       edit    the library for using mpu        edit    another example  gravity vector                       raw accel data                       accel data scaled     g range                        gravity compensation and rotation of accel data                          ,accelerometer algorithm
8684,is there a way to use a stress ball like device as acceleration control interface,i am thinking of a project proposal for my robotics course and we are required to make one that has a potential application on physical therapy or medical fields  one thing that came across my mind is a motorized wheelchair that moves when a stress ball control is squeezed by the user  as a robotics novice  i wonder if i could integrate a sensor circuit with a rubber ball so that when it is pressed  perhaps by a stroke patient  it triggers some driver circuit  is this possible  if so  how  my experience with robotics is limited to arduino  servo motors and basic sensors  ,wheeled-robot
8686,increase current draw from serial port of icreate  ,this is from the icreate   s document   pins   and    vpwr  are connected to the roomba battery through a     ma ptc resettable fuse  the continuous draw from these two pins together should not exceed     ma  do not draw more than     ma peak from these pins  or the fuse will reset   my project just need to draw a bit more than that number  so is there anyway to disable   short circuit   that fuse or replace that fuse with a bigger one  where does that fuse reside on the bot s circuit board  if the above   is not possible  because the fuse is embedded inside some chip or too difficult to access for example   is it safe to run a small wire from the battery pole to the pin to by pass that fuse   i know i can run a wire directly from battery pole to my circuit or draw power from the motor wires  but i love running through the serial port with keep things simple   ,power irobot-create serial
8689,how do i if know my quad is powerful enough to take off vertically smoothly and how do i calculate max thrust g  for given current a  and voltage v  ,if i build my quadcopter with the following components  will it take off vertically smoothly  frame  f    glass fiber and polyamide nylon     g  landing gear  high landing gear for f       g  battery      mah   c    c burst   s  p     g  motor  xxd a         kv brushless outrunner motor   x  g  esc    a    a burst  brushless with bec    a  v   x  g  prop       propeller set  assume that the total weight of the quad is     kg and i would like to have payload upto    g  making the quad weigh     kg  from all that i ve learnt  the thrust weight ratio should never fall below        and a     is recommended to have better control  which if does creates problems in lifting my quad vertically smoothly  i m neither planning to have very high maneuverability nor cruise the sky pushing my quad s limits  i just want it to fly   here s the motors pull g  amps a  voltage v  power w  specificthrust g w  information for a         kv with    x     props   since my battery s discharge rate is limited to   c  if i m not wrong  it can give out only   a  since its     mah  for the entire circuit with four motors  each of which can take   a max  which from the above table would produce     g thrust  which is     g from all four motors   does this mean i can get       thrust weight at      throttle  can my quad still take off vertically smoothly   i m also confused about the efficacy of my motor  meaning if i buy a bigger motor  can get more than    g thrust at   a     v with same bigger props  if not  is this the most efficient combination of motor and prop    if yes  what is the maximum thrust  practical pulling force in g  not in n  i can get outta   a     v  which equation tells defines that exact relation  provided i fly my quad at usual conditions      hpa   degc exttemp         relhumidity max  malti    ps  i tried ecalc  prop power thrust and efficiency calculations  and a few other online stuff  update  will replacing the     mah   c   c battery with the     mah   c   c  s p keeping everything same solve some problems and increase the flight time  provided i keep everything else the same  ,quadcopter brushless-motor battery lithium-polymer
8692,what is the max thrust a   w brushless motor can produce  can it produce    g ,i am a newbie  i got a   w motor here    they claim to have    g thrust however compaired to other motors like on hobbyking  this motor seems to have too good   power input   thrust  ratio  could it be true  besides esc of   amp          seems sufficient why did they recommend   amp  also what is the max thrust i can get from a motor w r t  power consumed in decent price  ,quadcopter brushless-motor
8693,how to perform odometry on an arduino for a differential wheeled robot ,i am using a differential wheel robot for my project  i need to know the current coordinates of the robot with respect to it s initial position taken as the origin  i m doing the computation on an arduino uno and the only sensory input that i get is from the two encoders  i have the function updateodomenty   called in the loop   and this is it s corresponding code   this is the code that me and my team mates made after reading this paper  i am wondering if this is the best possible way to solve this problem with an arduino  if not  how is odometry done in differential wheeled systems  ,arduino kinematics odometry differential-drive
8698,what exactly are ppm controlled escs  are most escs available to build quadcopters ppm controlled ,first  i don t see any manufacturer or online store telling whether an esc is ppm controlled or not  second  i have also been googling and asking comments in all about escs youtube videos for long  but i couldn t find anything useful   why do i need ppm controlled escs   i m doing a project based on androcopter and its clearly mentioned that it specifically requires the use of ppm controlled escs   can i use any escs available in the market for this project   it s also mentioned in the github repo that ppm controlled escs are the most common ones  however from some who explained escs in youtube video has commented back for my doubt telling that most common escs are pwm controlled which is contradicting the previous statement  ps  i need to use arduino mega to control the four escs  and arduino mega is programmed to send out ppm signals which is exactly why i need ppm controlled escs  correct me if i made any mistakes  ,arduino quadcopter esc
8700,inverse kinematics osciliations  ,i am the moment having some issues with an jacobian going towards a singularity  i think as some of its values becomes close to zero  and my robot oscillates  and therefore thought that some form of optimization of the linear least square solution is needed   i have heard about the interior point method  but i am not sure on how i can apply it here   my equation is as this    j q dq   du  how would i have to implement the optimization  and would be needed  ,inverse-kinematics c++
8702,malfuction in motors using l   n,i have purchased the undermentioned robot chassis with dc motors supported with plastic gears from a local store  there is a  a battery holder and when i connect robot to that and put it on the ground both the motors working fine and smooth  but when i connect the l   n motor controller which was made by myself and tested with proteus  only one motor is working  when i switch the wires of both motors  still the motor which worked before is working and the other motor never runs unless i manually give a little rotation to the wheel  i use a pic  f     to control the motor controller and tried usb power and a  v regulator created by myself and the result is the same in both occasions  what could be the issue here  if i tried oiling the malfunctioning motor will it work  i heard one of my friends having the same issue  one motor is not working  but both motors work with just two pen torch batteries and can t think of a valid reason that the motor is faulty  may be my motor controller  but when i swap the wires from faulty to the working one  the working one still works as i ve mentioned above    ,mobile-robot
8703,pixhawk or naza m v  for aerial imaging of small study area with hexacopter,i have a project that is going to involve capturing     images of a   m x   m agricultural study area for image processing  i am wondering whether to use a naza v  or pixhawk controller to outfit my ship  on a dji f    flamewheel airframe   my understanding is that naza is limited as far as the amount of waypoints i can have during a particular mission  can i break my imaging mission up into   or    sub missions  i also understand that pixhawk is in many ways superior but getting it up and running can be more finicky   i am on a limited time frame for this project  ,gps uav radio-control
8704,using another device instead of rc transmitter,i want to make pc controlled quadrotor  all the tutorials projects made with rc receiver  i want to use arduino or xbee instead of rc receiver for pc control of quadrotor  how can i do this   note  i have arduino  beaglebone  xbee  hc     kk  and multiwii parts   ,pid quadcopter
8705,problem with hc sr   sensor,i have three hc sr   sensors connected to a pic  f     with the schematic provided below  before building the pcb i ve tried testing all three sensors with a bread board and they worked fine  but now i have my pcb and when i connect them to that and tried testing  they work only for a few seconds and then stop working  i set timers and a set of leds to lit if an item is in between   cm from each sensor  as i ve tried from the bread board  when i cross my arm withing that range  the appropriate bulbs are lit and when i take my arm off the other bulbs are lit  but using the pcb  when i upload the code through a pickit  they work fine for a few seconds and then they freeze  if i reset the mclr pin it works again for another few seconds and freeze again  and sometimes randomly if i touch the receiving part of the sensor it works but that happens randomly  not always working  what could be the issue   is my oscillator burnt while i was soldering it  once i connected two     uf polar capacitors and found out that for one second  it takes one minute or more to blink a bulb    ,mobile-robot
8709,birrt  getting path from an array of   dof angle configurations,i ve kind of finished implementing a birrt for a   dof arm  using a kd tree from numpy spatial in order to get nearest queries  a picture is below   i m currently having trouble with the fact that it is impossible to retrieve a path from the start node to a particular node using a kd tree  and while i do have an array of of all the nodes  and there are edges that can be calculated between subsets of the array  but the edges are not in any useful order  can anyone give me some tips on how i d retrieve a path from the starting node in the first array  and the ending node in the second array  are there any useful data structures that would let me do this  below is my code  ,inverse-kinematics motion-planning planning rrt
8710,ros on raspberry pi model    ubuntuarm vs rosberrypi,before i ask my question  i d better confirm that i ve read the most prominent post about running ros on raspberry pi devices  that post contains some valuable information  but it s a bit dated  and ros support for arm devices is much better these days  in fact  ros     is evidently going to have excellent support for running on embedded devices like the raspberry pi  i just got a pi model   for my birthday  and i m really eager to get ros running on it so i can build a robot i ve been working on  which is based on the wild thumper  wd platform  from my perspective  here are a few pros   cons regarding ubuntuarm and rosberrypi  ubuntuarm pros   ubuntu is the official ros distro and is the most well supported ros os  the best documentation on the ros wiki for running on arm devices is written for ubuntuarm  cons   raspbian  on which rosberrypi is based  is the official distro for rasbperry pi and thus has the best support for the board    rosberrypi pros   raspbian  on which rosberrypi is based  is the official distro for rasbperry pi and thus has the best support for the board  cons  ros is not well supported on os s other than ubuntu to use the rosberrypi distro  you must build ros from source   my question is  can anyone provide any further insight into this dilemma  if you ve been running ros on your raspberry pi    model   only please  the model b  has completely different issues  like not being well supported by ubuntu   what s your experience been   which distro would did you choose  and why  ,ros raspberry-pi arm
8711,how to convert rotation matrix in to equivalent quaternion using eigen library ,eigen library     which is used extensively in ros and pcl  thank you  ,ros
8717,  degrees of freedom analytical solution, i have got a robot that exactly looks like as shown in the figure above  i have worked out the inverse kinematics analytical solution without the base rotation  considering   dof alone  but i am not able to find the analytical solution including the base   dof   how do i find the anlytical solution for this robot     ,robotic-arm
8719,mean shape for initializing the training of a face shape regression tree,i am studying an article about estimating facial points using forests of regressions  random forests   in order to train the trees of the forest  the training algorithm is initialized by a mean shape  i don t understand what a mean shape is  i looked it over the internet and came across it in articles that talk about face detection and facial shape estimation  but there was no clear explanation of it  can you please tell me what exactly is a mean shape  ,computer-vision artificial-intelligence
8720,which algorithms are used in autonomous robot,i am working on proposal of autonomous fire fight robots but i m little bit confused about its sensor and algorithms  my friend suggested there are some path finding  algorithms like bfs  dfs  a   and dijkstra s algorithm which are used in robots  but i didn t believe it   i want to ask  are these algorithms used in real world robots or some other genetic algorithms  how does a robot discover path to detect  and differentiate  a human from fire   i only want some explanation that gives knowledge  ,algorithm machine-learning
8722,microcontroller flashing itself,can a micro controller flash itself  what i mean to say is  i have an stm  f   rg with  mb flash size   i have a uart communication modem connected to it  can i send a firmware   hex or  bin  to the microcontroller via the radio verify checksums  on sucess the microcontroller saves the file into a sd card   via spi   and then restarts itself and start flashing itself reading from the file   in the sd card    can something like this be done or an external mcu is required to carry out the flashing  the purpose is the microcontroller and radio will be sitting at a remote location and i need a way to change the microcontroller s firmware by sending it a firmware update file remotely   ,microcontroller
8726,how to have a  auto go home  feature  like the dji phantom    on a project built quadcopter ,what should a quadcopter have  or have access to  in order to make this  return home  feature work  is gps enough  what is the approach needed to make this happen  i used a arduino mega      with imu to stable my quadcopter  ,arduino quadcopter sensors localization gps
8728,dc motor shaft and gear installation,i m hoping to use a dc motor to drive a cog bar horizontally along a track  afaik  i d need to install a  plastic  cog on the motor shaft  which itself grips on the  plastic  cog bar  does anyone know how to prevent the cog from shifting on the shaft  the shaft is   mm long and i d like to make sure the cog cog sits at  mm  where the cog bar is  any help will be appreciated  thanks ,motor
8731,sending commands from ubuntu,i have a irobot create model      and i need to send commands to the open interface through ubuntu  i m using gtkterm at       baud but when i press play button  it only drives around itself  i have tried to send commands as raw data and as hexadecimal data but it doesn t work  what am i doing wrong  ,irobot-create roomba linux
8732,weird magnetometer values,i bought a   axis magnetometer  similar to this one   and plugged into an arduino in order to read the heading value  i mounted it on my robot and i drove with the robot for around    meters  turned     degrees and drove back to my starting position  i plotted the heading value and it shows inconsistent values  the     degrees turn started at sec     the rest is driving in one direction using a joystick and following a wall as reference so small deviations are expected but not that big as in the image   when the robot is turning in place  there is no such problem and the heading variation follows the rotation of the robot  the robot  turtlebot  is a little bit shaky such that the magnetometer doesn t always have the x and y axes parallel to the floor but i don t think few degrees of offset can cause such a huge difference  i calculate the heading as follows   heading   atan  y field intensity  x field intensity   why does this happen  could it be form some metals or electric wires under the floor  can you suggest a more robust method sensor for estimating the heading in indoor environments  edit  i drove the same path again and the pattern similarity is making it even weirder  ,mobile-robot navigation magnetometer
8742,could a motor shaft be swapped for a threaded shaft ,i m looking at the n   dc motor which is fairly popular  does anyone know if the shaft could be swapped out for a threaded shaft  ,motor
8748,phantom omni type robot inverse kinematics solution,guys my robot looks like this  thanks to  croco i came to know that it looks much similar to phantom omni  since it looks similar to the phantom omni i am trying to get the inverse kinematics geometric solution for it  using this inverse kinematics solution i can build my fpga design  there is a very good research paper on this  but i do not understand in page      how they find the l  and l   shown in the image below   if i find this for my robot then my project is almost done  how do i find l  and l  for my robot   should i just bring my end effector to the         position as shown in fig   amd then measure the l  and l   would this work    would be great if you guys could help  cheers   ,inverse-kinematics geometry
8749,bulding a robot arm for neural networks understanding,i am thinking about building a small robotic arm with   small servo motors and an arduino uno to apply basic neural networks concepts  is it  a good idea to use a hand made robotic arm to learn more the power of neural networks  thank your for your time and merry christmas ,control
8751,how do i go about implementing a kalman filter for a pose estimation algorithm ,i am currently in the process of writing a pose estimation algorithm using image data  i receive images at    fps  and for every image  my program computes the x y z and roll  pitch  yaw of the camera with respect to a certain origin  this is by no means very accurate  there are obvious problems such as too much exposure in the image  not enough feature points in the image  etc   and the positions go haywire every once in a while  so i want to write a kalman filter that can take care of this part    i have read through the basics of kf  ekf etc  and then i was reading through an opencv tutorial that has an implementation of a kalman filter inside an algorithm for the pose estimation of an object  while this matches my use case very well  i don t understand why they are using a linear kalman filter while explicitly specifying parameters like  dt dt  in the state transition matrix  for reference  the state transition matrix they are considering is   i m a little confused  so my main question can be broken down into three parts   would a linear kalman filter suffice for a  dof pose estimation filtering  or should i go for an ekf  how do i come up with the  model  of the system  the camera is not really obeying any trajectory  the whole point of the pose estimation is to track the position and rotation even through noisy movements  i don t understand how they came up with that matrix  can the kalman filter understand that  for instance  if the pose estimation says my camera has moved half a meter between one frame and other  that s plain wrong  because at     th of a second  there s no way that could happen   thank you  ,kalman-filter pose
8752,automatic activation of a spray can,i would like to wirelessly control the button on a spray can such that on pressing it the spray comes  for example  a deodorant bottle  what is the best way to do this   what thing can i mount on the bottle to do this  ,robotic-arm
8757,fastslam     implementation ,i have studied claus brenner s lectures on how to implement the fastslam     algorithm  where each particle maintains the robot pose  and maintains ekf s of the landmarks  however  i d like to implement fastslam      which i understand uses particle filters completely  is this the same as fs      but instead of each particle maintaining an ekf of the landmark  each particle maintains yet another array of particle filters for landmarks  ,slam
8758, d robot motion,good day  i have a robot with an imu that tells yaw rate  and magnetic heading  it also tells xvelocity and yvelocity at that instance of the vehicle  on the vehicle frame   so irrespective of heading  if the robot moved forward  yvelocity would change for example  assuming my robot starts at position       and heading based on the magnetic heading  i need to calculate the next position of the robot based on some world frame  how can i do this  ,mobile-robot
8761,completely autonomous traversal of a planar graph,i have to program an autonomous robot to traverse through a grid given in the following figure  but the main problem is that the nodes to visit is not known beforehand  it will be received by the bot in real time  e g   after reaching the node     the bot now has to go to node    the shortest path            can be calculated by dijkstra algo but i don t know how to make the robot traverse that path  any idea    edit  sorry for not making the question clear enough  i am facing the problem in determining the current position and the direction the robot is facing so i can t define the set of commands  turn left right forward  to traverse to the next desired node  i am thinking about an extra array for previously visited nodes and the current node and an extra variable for facing direction  but for that i will have to define command sets for each node from each and every node  any better idea   ,mobile-robot automatic dynamic-programming
8763,irobot create   to vacuum ,i just got a create   for christmas  and while i m planning to create with it  obviously   i d like to use it around the house as a vacuum if at all possible  i ve heard that you can buy parts for the roomba and throw them on to this chassis  but i wanted to confirm refute that before i bought anything  is that possible or am i crazy  ,irobot-create
8765,apps for pepper robot,i recently googled about pepper robot and i wonder how one could write apps for it and get money for them  as far as i know they have app store  but does it sell apps or give them for free   all info i googled myself is rather incomplete and old   probably outdated  also i believe that apps for such  or similar  robots is the potential multibillion dollar market  what do you think about that  ,mobile-robot
8768,moving a small plate back and forth,i m hoping to move a plate   mm x   mm  back and forth using a dc motor  here s my idea so far   the motor drives a threaded shaft which is attached on one side of the plate  to help alignment  a rod is added to the other side of the plate  red   my guess is that if it s just a rod in a through hole  it could potentially jam  afaik  usually  in bigger setups  a linear bearing would come in handy  however  given that the plate is just  mm thick  are there better ways to help alignment  could making the edge around the through hole like the inside of a donut help  something like  is it easy to make  in fact  is my concern actually valid  thanks edit the centre area of the plate needs to be kept clear  this is intended to be part of a     mm thick  pole climber  where several guide rollers are fitted on the left side of the plate and a motor driven roller is on the left of the part  not depicted   so the idea is the press the guide roller against the pole until the two rollers have a good grip on the pole  the whole car is fairly light  so the force expected is around   n  here s a more complete depiction   the rollers are spring loaded  but they need to be released and retracted   and adjusted for different pole widths  ,motor linear-bearing tracks
8775,attaching a m  screw shaft to a cog wheel,does anyone know of a good  low profile  way to attach the threaded  chamfered  end of a m  screw shaft to a   mm    t  m  plastic cog wheel  would it be a good idea to widen the shaft hole and just let the threads grip the hole  edit the torque will be around  kg cm and the plastic i m looking at is pom  ,mechanism torque gearing
8779,panasonic msmo  f g  stepper motor hook up ,i have a panasonic msmo  f g servo motor that i m using as a stepper motor  the motor has   wires coming out of a port farther to the front  and    wires coming out of a port towards the rear of the unit  presumed to be the encoder   i am trying to drive the motor with an arduino motor shield   my question is this  how do i hook it up  i have read that a stepper with   leads is a bipolar stepper  and that you group same coil wires together  i found that   wires on my stepper were on the same coil and the fourth seems to have no effect on the stepper  my checking process was using an ohm meter to see what was connected to what  as well as connecting wires and feeling the resistance  ,arduino stepper-motor
8785,roomba schedule opcode       byte  ,just a short question  the irobot create   open interface spec says  serial sequence         days   sun hour   sun minute   mon hour  etc  can somebody explain to me  what  days  stands for  ,irobot-create
8786,are there any lithium ion battery monitors designed for hobbyists  quadcopters  ,i have a friend who is getting into quadcopters and being the good techie buddy  i m trying to find the right technology for battery monitoring so his expensive machine does not fall out of the sky unexpectedly   so far the only technology for hobbyists that i am seeing is voltage monitors  which aren t really useful for this battery chemistry  with the flat voltage curve liion has i d expect a voltage monitor to falsely report a low battery when you draw extra current and indeed i m seeing exactly this when my buddy does fast maneuvers mid flight  in my day job we use charge counting battery monitors  bms  for this battery chemistry  usually custom designed for the battery pack  just like for laptop batteries  etc   sometimes built into the battery pack  or sold by cell suppliers  have i missed a product for electric aircraft  are hobbyists in the battery dark ages  ,battery lithium-polymer
8787,best power solution for my robot,i ve built quadruped robot which is using    servos  towerpro sg   servo  and raspberry pi  model b     right now i m  feeding  it with  v    a charger   how can i make it un tethered  what should i look out for when selecting batteries  also  i think that i need to separate powering of rpi and servos because power is  jumping  when it moves and that isn t good for rpi    a little video   testing walking algorithm ,mobile-robot raspberry-pi power battery walking-robot
8797,suitable gear construction for a robotic extender   plastic ,i have a rather simple setup for my robotic extender  the dc motor turns a shaft with a worm on it  the worm connects to a small worm gear  green  which itself has a small gear  red  on the same shaft connecting to a large gear  blue    the dc motor s gearbox gives around       rpm and has a stall torque of around  kg cm  the small gear should be around   mm tall and the large gear should be around   mm tall  if the load  on the large gear  has a maximum torque of  kg cm and a typical torque of  kg cm  could the two gears be made from plastic and be of module  metric form for pitch  as  chuck pointed out       is a higher module needed  how about the worm  could it be made of plastic  nylon    any help will be appreciated  edit fixed typos and updated diagram  ,motor torque gearing
8804,see cc d actual configuration,just received my first hobby grade quadcopter  its the eachine racer     and comes preassembled with transmitter and receiver also included  it comes with some kind of cc d flight board  most people say its not the original one  but can be configured with the same software  it is actually flying very well right out of the box so im not sure if i want to touch the fc config  im mostly interested in learning to fly in manual acro mode  the transmitter seems to have a switch with   flight modes  first   looks like low high rates in self level mode  im expect the third to be the acro mode  but im not sure right now  i couldnt test it because of the weather  it could be a third higher rate   so  is there any way i can look at the actual fc config without changing anything  witch software do i need  and are the flight modes actually set on the fc or transmitter so i could be able to see and edit them  thanks in advance  ,quadcopter
8807,pom gears and metal fittings,i m looking at this setup    where the pom bevel gears are fitted with some kind of metal  bronze   tube inside which fits over the shaft  what benefits does this method provide  is it to allow the shaft to free spin  the metal fitting wouldn t be able to grip on the shaft   right  is it supposed to be a canonical approach to fitting a pom gear for  relatively  high load applications  ,motor mechanism gearing
8810,gazebo or simmechanics,i m now considering to choose gazebo or simmechanics for simulating my quadruped robot  i set some standards for the simulation   support real time application with ros simulate contact impact well with ground   deformable if possible  good rendering quality   i have learned gazebo for months  and see it has some limits to meet my requirements  especially the contact and friction problems   i didn t use simmechanics  but when i m very impressed on it when i see this video  anyone who has experiences on quadruped simulation can share me some advice  thank you so much  ,simulator gazebo
8811,will a     mah   c     v  s lipo battery work with,i am building a quadcopter and i was wondering if a     mah   c     v  s lipo battery will work with a   amp esc s  mt         kv motors  and gemfan      carbon fiber props  the over all payload will be about     pounds  ,quadcopter
8816,create    wheel interface board replacement, scroll to page    i m trying to interface the roomba s preloaded navigation system with a pair of motors not attached to the roomba itself  however  to do this i need an interface board of the same dimensions as the one pictured in the above document  it has               contact centers  which don t seem to be commercially available  can anyone provide any help locating pcbs of this size  ,irobot-create electronics navigation roomba
8818,accurate technique to locate position ,what is the most accurate way to locate the position and orientaion of the body during some motion  rotation and translation   i need to track the body very precisely  the required accuracy is         microns  and with rather high frequency   at least  khz  the body has one rotation axis  this axis can translate along the path  normally the track has ellipse like shape  but translation path can change  that s why i need to track the body  the limit of motion is    cm on any direction  maximum velocity is   m s   requirments about sensors  it s possible to place any sensor on the surface  but it s impossible to change the construction  so it s impossible to use encoders at the rotation axis to measure the angle   i tried to do it with mems  dof sensors  but because of the noise it s very difficult to understand when there is a motion and when it s a noise  another idea is to use magnet and magnetomemter  but how is it possible to measure the resolution in this way   ,kinematics navigation tracks orientation
8820,arduino project  turning with a fixed front wheel axis,i am working on an arduino robot project  this project requires a base with   wheels where the back wheels are attached to two dc motors that can be controlled independently of each other  i am thinking that the robot will turn by giving power to just one of the motors but i am having trouble with how the front axis should look like  would it be possible to have a solid front axis with   wheels and still possible for the robot to turn or would the friction be too great  ,arduino wheeled-robot brushless-motor
8822,orienting rectangular plastic bricks,as part of a sorting machine  i need to orient a pile of plastic brick shaped objects  which are all identical in size   about  cm x  cm x    cm  so that they always end up with the white side facing up   these will then be fed into a bowl feeder type of machine for further re orienting   how can i accomplish this  preferably without optical sensors  i was thinking about cutting into the bricks and putting magnets inside  but is there a more elegant solution  ,mechanism orientation
8823,does the mah of a battery mean longer power or more power ,if a lipo battery has more mah will it be slower to run out of energy or will it have larger power output  thanks in advance ,power battery
8831,are joint state vectors limited ,are joint state vectors   which define the position and orientation of a set of joints  limited somehow   i know they are used for the rotation part of the transformation matrix    therefore i would think they were limited within   and   ,joint
8833,erratic motor behavior  is it due to the faulty remote control or grounding or something else ,i am using arduino mega to run   motors via   motor controllers  i am using a ps  controller as the remote control  when the joystick is at rest  the motor should stop  the problem is the motor still moves randomly when the joystick is at rest  sometimes  the joystick can only produce forward motion on the motor but not backward  is this the grounding issue or the ps  remote control issue ir others   does the gnd from the arduino board have to be connected to the gnd from the external battery   how can i troubleshoot this   thanks  ,mobile-robot control power
8835,q state vector used to define the transformation matrix  how ,how can it be used to determine the transformation matrix  an example could be at computing the inverse kinematics for small displacements  j q q   u u is a vector defining the difference between current and desired position  the desires position can always be computed  but if keep solving this in such manner that every time you solve j q  delta q    delta u you do this   q   q   q compute  compute the difference between  and   if change is less than       finish and output q  if not resolve    how would you compute the transformation matrix based on q state vector   ,inverse-kinematics jacobian
8840,rc car circuit  what does it do ,i have just disassembled a rc car  a bbr      scale ferrari enzo from        attached to the stepper motor that controls the steering of the car was a small circuit board with a cog wheel attached to it  i am trying to figure out what this circuit does  my idea is that it is responsible of keeping track of the wheels position but i am not certain  here is a picture of it    as you can see there are   wires coming out of it and i know that the green one is gnd  does anyone have an idea of what its function might be  ,stepper-motor radio-control circuit
8842,path following with precise positioning system  rtk ,is there any general problem in using precise positioning  centimeter accurate gnss rtk system meant  for autonomous car guidance given i have a predefined path the car should follow  i mean  autonomous cars were the topic    at ces      yet no such simple system seems to have been introduced to date    of course the  path planning  is only a part of the  autonomous package  and other problems need to be solved  collision prevention etc   but i really wonder whether something simple like rtk guidance could be used  an rtk system relies on very little amount of live correction data  about   kb s  and mobile networks are really ubiquitous today so i can not really see a technical problem in such solution given there are enough rtk base stations around  edit  this question is only about using precise positioning to follow a predefined track in obstacle free environment  i am not asking about other systems that need to be implemented in an autonomous car like collision prevention etc   such systems may employ lidar or a stereo camera   surely a collision prevention is a must for an autonomous system but i consider a theoretical case only  an updated question may be  is precise satellite positioning accurate enough to guide navigate a full scale passenger car in an obstacle free outdoor environment in the speed of about     km h given i have a precise enough path prerecorded that is to follow  some answers below already say yes  this is a solved problem  it would be nice to have the answers elaborated in more detail regarding the existing solutions  accuracy  possible problems etc    one of the solutions may probably be the open source apm autopilot which work for rovers too  example by emlid  but that does not seem to use rtk so the accuracy may be rather low  ,navigation gps precise-positioning
8844,dc motor to open a door,i want to open a door using a dc motor  i ve estimated that the required power in the worst case would be around      w  considering a      efficiency   the whole is controlled by a particle photon  i was thinking to use a l   n to control the output of current to the motor  however  when i looked for powerful enough motors  they would all consume too much current when stalling     a part of the l   n datasheet   do you have ideas of how to overcome this  maybe there s another dual bridge that can handle more current  maybe there exists a dc motor that is ok for a l   n  or maybe i need to have simultaneous dc motors  edit  this part should be a question by itself  i ll keep it here so that future visitors know what the sub question was about  but please ignore it from now on if answering   as a sub question  would it be better to use a brushed or a brushless dc motor   ,motor h-bridge
8845,exchange air and maintain thermal insulation,my application is composting with worms outdoors inside an a styrofoam cooler   i use a heat lamp and a thermo electric cooler to maintain the temperature in the bin when the temperature outside is out of bounds for healthy worms   when the temperature outside is in bounds  i d like to exchange the air in the bin with fresh air from outside  but i don t want to permanently compromise the insulating properties of my bin with lots of air holes   so i m looking for actuator solutions that would allow me to open close a window of sorts   i m considering a solenoid air valve but i don t necessarily need want an air compressor   a simple fan is sufficient to circulate the air  any suggestions  ,actuator valve
8849,tracking objects from camera  pid controlling  parrot ar drone  ,i am working on a project where i should perform object tracking using the camera of parrot ar drone      so the main idea is  a drone should be able to identify a specified colour and then follow it by keeping some distance  i am using the cvdrone api to establish communication with the drone  this api provides function   which moves the ar drone in  d space and where   vx  x velocity  m s  vy  y velocity  m s  vz  z velocity  m s  vr  rotational speed  rad s   i have written an application which does simple image processing on the images obtained from the camera of the drone using opencv and finds needed contours of the object to be tracked  see the example below   now the part i am struggling is finding the technique using which i should find the velocities to be sent to the move d function  i have read that common way of doing controlling is by using pid controlling  however  i have read about that and could not get how it could be related to this problem  to summarise  my question is how to move a robot towards an object detected in its camera  how to find coordinates of certain objects from the camera   ,control pid quadcopter tuning opencv
8852,quadcopter charging,our thesis is about multicopter using two batteries wherein the first battery is used and when the power goes out  a switch is placed use to charge the first battery while the second battery is powering the multicopter  the process repeats again and again until all the power of the battery is drained  is the process possible to achieved  edit    just to clear everything up again  the thesis is about a quadcopter that uses two batteries as its power source  these two batteries are attached to a  switching circuit system  that will allow one battery to be drained then the quadcopter will be transferred to the other battery  the solar panels serve as the  charger  of whatever battery is in its standby mode  the discharged battery   so while one battery is being used by the quadcopter  one will be connected to a solar panel which will be charging that battery  once the other battery is drained  the quadcopter will switch to the charged battery  this will continue to go on until both batteries are drained  is this achievable  ,battery multi-rotor
8855,how can i detect ground collision  for an hexapod robot ,i m planning to build a small  probably around    centimeters in diameter  at rest  hexapod robot  but  currently  it would only be able to walk on even ground  to improve this  i would have to  somehow  detect when each leg collides with the ground   ideally  i would be able to know how much weight each leg is supporting  so that i could both balance the weight and adapt to moving  up or down  terrain  so  if you put a finger below one leg and lifted it  the leg would go up   however  if that s not possible  a simple binary signal would do  is there a simple and compact method to do this   ,sensors hexapod
8857,imu position without gps or camera,i have a imu that has   axis accelerator    axis magnetometer    axis gyroscope and row  yaw  pitch value  i want to get the location of the imu coordinate the beginning point is          but i know just using double integration will has dead reckoning problem  and i found a lot of paper just talking about combining imu with gps or camera by using kalman filter  is it possible that i just use a imu to get a slightly precise position data  because in the future work i will use multiple imus bounded on human arms to increase the accuracy   ,imu gps
8860,angle random walk vs  rate noise density  mpu     ,i ve made a datalog from a mpu      imu  gyroscope and accelerometer  at    hz sample rate  now i want to calculate the characteristics from the gyro to evaluate the sensor   for the gyro i ve found following values in the datasheet  total rms noise          s low frequency rms noise           s  rate noise spectral density           s sqrt hz  now i want to ask how i can calculate these values from my dataset  at the moment i ve the following values from the dataset  standard deviation            s variance          angular random walk  arw            sqrt s   from allan deviation plot  bias instability            s is the arw equal to the rate noise spectral density mentioned in the datasheet  and also is the rms noise from the datasheet equal to the standard deviation   edit  i found following website   there is the statement       because the noise is approximately gaussian  the standard deviation of the histogram is the rms noise  so i guess the standard deviation is the rms noise from the datasheet  but how about the arw  ,sensors imu gyroscope sensor-fusion statistics
8863,cracked gps chip antenna,my quadcopter has an onboard gps unit  and in a crash today i happen to come down on top of it  i split apart the broken case and noticed that the chip antenna has cracked  i am unfamiliar with how this type of antenna functions  will this be an issue   this is a closed source drone so i have little insight as to the number of gps locks acquired  and the signal strengths  would a broken antenna cause any type of signal degradation  or will i not even be able to acquire a lock  ,gps
8866,tf frame origin is offset from the actual base link,i have built my differential drive mobile robot in solidworks and converted that to urdf file using soliworks urdf converter  i successfully launched and robot and simulated with tele operation node  since i am intended to use navigation stack in i viewed the transform of the robot in rviz which resulted as below   as you can see the base plate is the one which supports the wheels and castors but the tf of base plate is shown away from the actual link and even odom is away from the model  where have i gone wrong and how to fix this  refer the urdf of model below   ,mobile-robot ros navigation odometry gazebo
8874,how can this mobile robot rotate so perfectly ,please have a look at this youtube video  when this mobile robot operates  the rack  which is said to weight up to     kg  can have its center of mass  com  distributed at any location  for example  this com can be located   or    cm off from the center of the robot  because of this  when the robot revolves  the center of rotation will not be at the center of the robot anymore  however as you see in the video  it can still rotate many circles perfectly around its up right axis  so what do you think about this  is this possible by mechanical design only  or did they use some kind of advanced feedback control system to counter the effect of the off center com  ,mobile-robot control mechanism
8877,need the uav to perform a circle turn,i ve got a project that will require my drone to perform a circle turn while the drone is always facing the tangent of the turning curve  similiar to a car that is performing a frictionless banked turn   just wondering which method should i use to achieve it  the throttle control can be ignored since i already have a pid on height control  any suggestions would be appreciated   ,quadcopter pid multi-rotor
8879,can i use dc brushed motors for building a drone ,i want to make a drone  but my budget is very low  brushless motors are very expensive  i want use the brushed cheap ones  can i us them   ,quadcopter motor brushless-motor
8882,canny s roadmap algorithm,where can i find a general implementation of canny s roadmap algorithm or silhouette method  for robot motion planning  ,motion-planning
8883,how to find center of a disk using robotic arm,hello i am new to the field of robotics but have some knowledge of raspberry pi  arduino  python  i want to make robotic arm which can be used to find the centre of any disk  there may be disk of different diameter coming one after another on conveyor  i need to make hole at the center of disk using robotic arm  how can i do this   what techniques and sensors i should use to implement the mechanical and electronic part   i don t want to use camera and opencv   thanks in advance   ,robotic-arm mechanism electronics movement
8887,how does the kirobo robot make up sentences   know how to respond to humans ,basically  how does the kirobo  which went on the iss and spoke some sentences  think  does it talk to itself  does it learn  become more intelligent with time  to have better conversations with  experience   ,mobile-robot humanoid
8888,cc d openpilot   communication port,i am building a quadrotor with a cc d  openpilot  and a rpi   my first idea is trying to communicate the cc d with the rpi using the main port of the first one but i can t find any information about how to communicate the board with any device  or other information about the commands or serial configuration   anybody knows whether this is possible and where to find that info   ,raspberry-pi quadcopter
8891,figure out pid values from drone specs,i have all the specs from a quadcopter  everthing  would it be possible to figure out the pid from those specs  ,quadcopter pid
8893,gazebo  moving joint with model plugin,this is my first week with gazebo   the tutorials are clear  except for my dearth of c   knowledge  but now that i m working to move out on my own things are getting cloudy   i made a model comprising two boxes and a revolute joint   the file one r test world loads this model   a plugin is  loaded      in model sdf and that plugin  modelcontrol  comes from model push cc in the  model plugins  tutorial     which uses setlinearvel to move a box   i can get this same behavior out of model control cc if i just copy the tutorial code  and change the plugin name as appropriate   but that s not what i want   i m seeking to eventually simulate joint control of robotic manipulators and what s not working in this basic simulation is my attempt to move the model joint via the modelcontrol plugin   it moves in the gui if i set the velocity  or torque  that way   the model control cc code is pasted below in hopes that you can identify a problem  model control cc  edit  if i change this  jointr    setparam  vel           to this  jointr    setvelocity         then the joint moves  yes  very  very quickly    what s wrong with setparam vs setvelocity  ,simulator joint gazebo
8894,how a  d printer moves the header vertically in a makerbot printer,i would like to know how the header in this makerbot printer moves in the vertical up  down direction   is there a detailed explanation of it including the parts involved   ,mechanism 3d-printing
8895,quadcopter pid control  is it possible to stabilize a quadcopter considering only angle measurements ,good day  i am a student currently working on an autonomous quadcopter project  specifically the stabilization part as of now  i am using a tuned propeller system and i also already considered the balancing of the quadcopter during component placements  i had been tuning the pid s of my quadcopter for the past       weeks now and the best i ve achieved is a constant angle oscillation of the quadcopter by      degrees with   degrees as the setpoint desired angle  i also tried a conservative   degrees setpoint with the same results on the pitch axis  as of now my pid code takes in the difference of the angle measurement from the complementary filter  and the desired angle   i have read somewhere that it is impossible to stabilize the quadcopter utilizing only angle measurements  adding that the angular rate must be also taken into consideration  but i have read a lot of works using only a single pid loop with angle differences  pitch yaw and roll  as the input   in contrast to what was stated above  i have read a comment from this article    by edouard leurent that a single pid control loop only angle errors and a cascaded pid loop  angle and rate  that utilizes both angle errors and angular velocity errors are equivalent mathematically  if i were to continue using only the single pid loop  angle  method  i would only have to tune   parameters  kp  ki   kd   but if i were to change my code to utilize the cascaded loop  angle and angular velocity    would i have to tune two sets of the   parameters  kp  ki   kd for angle and kp  ki   kd for the angular velocity   would the cascaded pid control loop give better performance than the single pid control loop  in the cascaded loop  is the set point for the angular velocity for stabilized flight also   in deg sec  what if the quadcopter is not yet at its desired angle   thank you    ,control quadcopter pid raspberry-pi stability
8900,slam   why is marginalization the same as schur s complement ,consider the system    tag   h delta x  g   where  and  are the hessian and gradient of some cost function  of the form   the function  is an error function   is an observation  measurement  and   maps the estimated parameters to a measurement prediction   this minimization is encountered in each iteration of many slam algorithms  e g one could think of  as a bundle adjustment hessian  suppose   and let  be some variables that we seek to marginalize  many authors claim that this marginalization is equivalent to solving a smaller liner system  where  and  are computed by applying schur s complement to      i e  if h   begin pmatrix  h        h        h        h       end pmatrix   then  m h      h     h          h        and   b g   h     h          g    i fail to understand why that is equivalent to marginalization    i understand the concept of marginalization for a gaussian  and i know that schur s complement appears in the marginalization if we use the canonical representation  using an information matrix   but i don t see the link with the linear system   edit  i understand how schur s complement appears in the process of marginalizing or conditioning  with  gaussian variables  as in the link supplied by josh vander hook  i had come to the same conclusions  but using the canonical notation  if we express the gaussian  in canonical form  then  is gaussian and its information matrix is the schur complement of the information matrix of   etc  now the problem is that i don t understand how schur s complement appears in marginalization in bundle adjustment  for reference  in these recent papers  c klam  page   if you want to look  and in this  part titled marginalization   in these papers  a single bundle adjustment  ba  iteration is performed in a manner similar to what i initially described in the question  i feel like there is a simple connection between marginalizing a gaussian and the marginalization in ba that i am missing  for example  one could say that optimizing   one iteration  is equivalent to drawing a random variable following a denstiy e    frac       x  mu  t sigma      x  mu    where  is the inverse of the hessian  of   and  is the true value for   or an approximation of that value   and that marginalizing this density is equivalent to using schur s compelement in the bundle  i am really confused      ,slam computer-vision
8902,real time gy    imu sensor interfacing with simulink,how do i read real time values from the gy    imu sensor at simulink connected via arduino  also  i intend to interact with the virtual reality environment at simulink using this gy    imu sensor  is this possible  how do i make matlab read real time values from this gy    imu sensor connected to arduino via i c communication   please help  ,imu matlab
8906,how do i create a portable solar panel lipo charger ,we re working on a quadcopter that will carry a solar panel on top that will continually charging the lipo battery of the quad  what s the smallest and easiest way to recreate a charger that will allow safe charging for the lipo battery  ,quadcopter battery
8907,inverse kinematics of dlr hit ii hand,i am trying to find the inverse kinematics formulation of dlr hit ii hand  till now i had success in finding an analytical method described in the thesis of mavrogiannis  christoforos i  named grasp synthesis algorithms for multifingered robot hands  given in appendix b   my question is regarding the a    where the author calculates q  but has mentioned previously in the text that q  is equal to q    note  q here denotes joint angles ,inverse-kinematics
8909,typical problem in simple line follower using   sensors,i am working on building a line follower robot using atmega     and i want its movement to be more precise  i am facing a very typical problem  it consists of three    ir sensors  the thickness of the line to be followed is    cm and the gap between the sensors is more than that  around    cm   so if the black line comes between the center and any of the side sensors  all the three sensors are on white and it stops  and i need the robot to stop over white  due to my application   so please can anyone suggest me a good algorithm to tackle this situation  i think pid control can be of good use  as i searched on google  but i don t understand how to implement it with three sensors  please help ,microcontroller line-following avr
8910,how to interpret the result of image rectification ,i ve been trying to understand image rectification  most of the time the result of image rectification is illustrated by the original image  i e the image before rectification  and the rectified image  like this  the original image   the rectified image   to me the original image makes more sense  and is more  rectified  than the second one  i mean  why does the result of rectification looks like that  and how are we supposed to interpret it  what information does it contain   an idea has just dawned on me   could it be that this bizarre shape of the rectified image is dependent on the method used for rectification  because  here polar rectification was used  around the epipole   ,mobile-robot stereo-vision 3d-reconstruction
8911,how to find kinematics of differential drive caster robot ,i m working on a little project where i have to do some simulations on a small robot  i my case i m using a differential drive robot as one of the wheels of a bigger robot platform  which has two differential drive casters   and i really do not understand how to find its kinematics in order to describe it in a model for finding the speed v tot of the platform   this is my robot and i know the following parameters  d is the distance between a joint where my robot is costrained blue point is the joint where the robot is linked to the robot platform l is distance between the wheels r the radius of the wheel the robot can spin around the blue point and with and theta angle  as i know all this dimensions  i would like to apply two velocities v left and v right in order to move the robot  let s assume that v left     v right how do i find analitically the icr  istantaneous center of rotation  in this costrained robot  i mean that i cannot understand how to introduce d in the formula  ,mobile-robot kinematics wheeled-robot differential-drive two-wheeled
8916,quadcopter program execution time optimization using raspberry pi by increasing i c baudrate, is it possible to speed up execution time of a c   program in raspberry pi solely by increasing the i c baudrate and increasing the sampling frequency of the sensors    i have the issue of sudden jerkiness of my quadcopter and found the culprit which is the frequency at which my loop excecutes which is only about   hz  the minimum requirement for a quadcopter is        hz  it is similar to the issue he faces here raspberry pi quadcopter thrashes at high speeds he said that he was able to increase his sampling rate from   hz to    hz by increasing the i c baudrate  i am confused on how that is done  in the wiring pi library  it says that we can set the baudrate using this command   what i am curious about is how to set this baudrate to achieve my desired sampling rate  i plan on optimizing it further to achieve at least a    hz sampling rate as of now  the execution time of each loop in my quadcopter program is at     ms or   hz  it takes     ms to     ms to obtain data from the complementary filter  i have already adjusted the registers of my sensors to output readings at    hz  gyroscope l gd  h  and    hz  accelerometer lsm     and    hz  magnetometer lsm      ,quadcopter pid raspberry-pi sensor-fusion c++
8917,how to actuate pneumatic muscle by the signals received by emg sensors interfaced with raspberry pi ,my aim is to actuate a pneumatic muscle based on signals received by emg sensors placed on the biceps  is there any matlab code which can process the received emg signals and convert them into any form which can be useful for muscle actuation  the linked video gives better insight to my question  exoskeleton arm pneumatic muscle ,raspberry-pi matlab
8918,canny s silhouette method,how to construct silhouette curves  roadmap  in canny s silhouette method  when  d model of the environment  obstacles and robot  is given    i want to specifically implement cannys roadmap method  which works for any n dimensional configuration space  ,motion-planning
8930,modified dh parameters ,is the notation of the geometry of robots from khalil and kleinfinger be considered as one of the probably  many  modified dh parameters  ,dh-parameters
8931,how to combine odometry information with time shifted information from imu,i m working with a differential drive robot that has odometry measurements from wheel shaft encoders and heading information from an imu  i m using bno    in imu mode to get euler angles  primarily the heading angle   i d like to use the imu header angle to augment the odometry which is prone to slipping and other errors  but the imu lags the odometry by up to    ms  how can i combine these measurements to get the best estimate of the robot pose  thanks for any word on this  ,mobile-robot imu odometry
8934,autonomous robots hardware structure planning,i ask this question to clear my concept about hardware structure of humanoid autonomous fire robot  here is scenario a fire robot detect humans from fire  there are some vision cameras some temperature and smoke sensors which help to perform this task  now a days in market there are many processors like  and snapdragon which process tasks in any device and control the system i don t think autonomous fire robot use some kind of processors  does autonomous robots like fire robot use processors or micro controllers  does it require os or rams environment  like any computer system which use these kind of things  ,embedded-systems humanoid
8935,gazebo laser plug in fails to publish scan results,i have added hokuyo laser plug in to mu urdf file  i successfully launched the robot in gazebo and done required changes to visualize it in rviz  i didn t get any error but the laser scan results are not published  fine my results below  terminal while launching gazebo model in world  result for   i have also verified the tf of the model in rqt and its fine aslo find my urdf file below  can someone help me to fix this  link   joint   link name  hokuyo link        collision         origin xyz         rpy                  geometry           box size                         geometry        collision       visual         origin xyz         rpy                  geometry           box size                         geometry        visual       inertial         mass value   e              origin xyz         rpy                  inertia ixx   e    ixy     ixz     iyy   e    iyz     izz   e             inertial      link      joint name  hokuyo joint  type  fixed        axis xyz                 origin xyz                rpy                parent link  base plate         child link  hokuyo link        joint   controller   gazebo reference  hokuyo link            sensor type  gpu ray  name  hokuyo              pose              pose             visualize false  visualize             update rate     update rate             ray               scan                 horizontal                   samples      samples                   resolution    resolution                   min angle            min angle                   max angle           max angle                  horizontal                scan               range                 min       min                 max       max                 resolution       resolution                range              ray             plugin name  gpu laser  filename  libgazebo ros gpu laser so                topicname  scan  topicname               framename hokuyo link  framename              plugin            sensor          gazebo   ,mobile-robot ros navigation simulation gazebo
8938,irobot create   ir bump light sensor specifications,can someone tell me where can i find some specifications about the irobot create   ir bump light sensors  we have an sdf model of the create   that uses the hoyuko laser range finder sensor and we have to simulate the behavior of the ir sensors starting from the laser scan data   hence we would like to have some additional information on the ir sensors which we can t find anywhere on the web   such as their exact position in the robot chassis  their maximum range  the shape of the obstacle detection field and so on  ,sensors irobot-create
8940,robotic manipulator jacobian by product of exponentials,i ve taken a class and started a thesis on robotics and my reference for calculating the jacobian by product of exponentials seems incorrect  see   specifically the resulting jacobian matrix for the scara manipulator on page     would have us believe that the end effector translational velocity depends on joints   and   rather than   and    could someone please explain me why  ,jacobian manipulator product-of-exponentials
8941,localization with only imu,what will be the best approach to get the most localization accuracy out of only an accelerometer and gyroscope  ,localization imu accelerometer gyroscope algorithm
8946,modified dh parameters,is the notation of the geometry of robots from khalil and kleinfinger be considered as one of the probably  many   modified dh parameters  ,dh-parameters
8949,mbed dc motor speed control using optocoupler encoder,i have been playing with mbed since few week ago and would like to create a test program for dcmotor speed control  im using a   v dc motor with encoder attach   then test  at first i test with supplying a  v and    v from mbed to the motor  the thing work fine giving a    and   rpm respectively  later i try using   v it give   rpm   then i try a   v input  now the speed wont come out  and also the counter that count each on off tick not counting up  any possible reason  my though that maybe when it move so fast that the isr routine couldn t catch up to the speed     ,control motor
8950,wheel encoder triggers interrupt too many times,i am building a simple robot with two driving wheel  i want to control the wheel rotation using a wheel encoder like this one  here is a code i have on arduino to try to understand the problem i m facing   what i notice is  the interrupt is triggered multiple times when the sensor beam is cut once  but when i digitalread the pin  then there is only one change    i also noticed that the interrupt is also triggered when going from high to low  here is an example of the ouput i have                                                   change from low to high                the interrupt must have incremented only once      instead                                          change from high to low  the interrupt shouldn t be triggered            still    we have    increments                                                   same here                   increments                          same here                  increments              the only way i can explain that is that during a change of state  the signal received from the sensor is not really square  but somehow noisy  like in this image    therefore we would have  indeed  many rising on one change      however reading the output of the sensor on an analog pin shows a direct variation from     high  to    low   does anyone have another explanation  or a solution to this problem    edit thanks to  tobiask i know that this is called a bouncing effect  by doing further research i came across this solution    ctrl f for rafbuff   i m trying it and i ll let you know  ,arduino wheel two-wheeled interrupts
8951,establishing data transfer between two raspberry pi s using gpio,good day i am currently implementing an autonomous quadcopter with stereo vision using raspberry pi  one  let s call this pi    is responsible for stereo vision the other is responsible for motor control and trajectory planning  pi     i was looking for a way to transfer a     element float vector via gpio from pi   to pi    pi   stereovision program runs at  hz while pi   motor control runs at    hz    is there any protocol fast enough to deliver this amount of information to the second raspberry pi via gpio    i am currently looking at spi but i saw that the raspberry pi cannot be turned to a slave making it not an option  i also looked at uart however it is too slow for my needs  all the i c ports on the pi are currently being used by the stereo vision cameras and the imu s  if the gpio option is not feasible  i am also open for other suggestions such as using other hardware  middle man  or wireless options     ,quadcopter raspberry-pi communication
8954,software to control an arduino setup with a timing belt and stepper motors,i would like to know what software is available to control a timing belt with stepper motors for arduino board much like how its done in  d printing  but in this case i wont be making a  d printer just one simple setup  ,arduino robotic-arm stepper-driver
8960,what to do when position control with trajectories is interrupted ,what are strategies used when trajectories  which are applied to a robotic joint  are interrupted  say a robotic arm hits an obstacle  the controller just keeps applying the trajectory  then at the end  the error gets so large  the torque can get quite strong and damage the robot or snap  ,control robotic-arm joint
8962,using the brush assembly and aerovac bin space ,a lot of the create   s interior space is taken up by the brush assembly and the aerovac bin   i d like to take these out and put in my own stuff  but i m concerned that the roomba might get confused by the fact that i ve unplugged these items   is there anything special i need to do  aside from adding an appropriate amount of weight in that area  ,irobot-create
8965,cc d   replacing rc emitter with an rpi,i am trying to control a quadcopter using te openpilot cc d board and a raspberrypi  the main idea was first replace the signals from the rc emitter to the cc d rc receiver for an rpi connected directly to the rc receiver inputs of the cc d  as far as i know the rc signals to the cc d are pwm so the rpi should be able to control the channels using rpio library to create the pwm by software   but after make some tests i haven t find any way to move the motors  i am using the ground control system  openpilot software  to configure the cc d  i am not sure whether i need to send the pwm signals in any order or something like that  i am also not sure how the flight mode switch works  i suposse it works the same way as the other channels  using pwm  anyone have made anything similar to this   ,raspberry-pi quadcopter uav
8968,do these motors really have enough torque to lift     pounds,i was looking at these dc motors and i converted the torque to force at a meter distance and i got that two of them should be able to lift over     pounds  is this right   there has to be some catch i am not seeing ,motor torque
8970,is alljoyn a good ros alternative regarding message passing cross multiple devices ,i ve used ros for a while  my environment is raspberry pi   ubuntu   opencv   ros   c c    i also use several ros packages  tf   usb camera  slam related  and laser scanner capture   also  in my projects  nodes are in multiple devices  and i m using multiple master package for one project  i did review some tutorials about alljoyn  but no handon experience so far  the questions are   regarding to message  especially  ros image  passing cross devices  is alljoyn a good ros alternative   devices are connected by wifi or bluetooth   for alljoyn  does it still need single master  like roscore in ros  to coordinate the nodes  or similar     thanks  ,ros alljoyn
8973,how to estimate the position of multiple static ground targets captured from a down facing camera ,an aerial vehicle captures images of the ground using its down facing camera  from the images  multiple targets are converted from their pixel position to the camera reference frame using the pinhole camera model  since the targets are static and there is information of the vehicle attitude and orientation  each sample is then converted to the world referencial frame  note that all targets are on a flat  level plane  the vehicle keeps  scanning  for the targets and converting them to the world referencial frame  due to the quality of the camera and detection algorithm  as well as errors on the altitude information  the position of the  scanned  targets is not constant  not accurate   a good representation might be a gaussian distribution around the target true position  however it will also be influenced by the movement of the aerial vehicle  what s the best approach to estimate the position of the targets from multiple readings  this basically resumes to a problem of noise removal  as well as outlier removal  and estimation  so i would like to know what algorithms and strategies could solve the problem  in the end i expect to implement and test a collection of different approachs to understand their performance on this specific problem  furthermore  this system is implemented using ros  so if you know of packages that already do what i m searching for i would be glad to hear  you can also cite papers on the topic that you think might be of my interest  ,localization ros computer-vision algorithm uav
8975,how does one implement a third order complementary filter for estimating altitude using data from an accelerometer and a barometer ,i am working with the cjmcu build of cleanflight on a small drone  as of now  the algorithm for altitude hold uses a first order complementary filter to combine data from the barometer and the accelerometer  after integrating the accelerations twice   however  i have noticed a considerable lag in the altitude readings and this seems to be hampering the control algorithm s performance  the filter in question has been implemented in  however  i m unable to understand how this works  pardon me for any errors i may have committed  ,quadcopter sensors sensor-fusion
8976,irobot create   stuck in clean mode ,i m using the delphi example to command my create    i just adapted the demo code to unicode  delphixe   i use the original irobot usb to serial cable   my create   seemed to be responding fine to all the commands send via serial yesterday and correctly received all sensor data back this morning  until i recharged the battery  now when i send      soft reset  the robot attempts every time to start a clean cycle  it also attempts to start the clean cycle when i press the clean button  it tells me to move the roomba to a new location  which is normal in cleaning mode because my wheels are not touching my desk  communication via serial seem to be fine because i still get the soft reset response texts in the log memo of my app when i use the   buttons method to soft reset my create    so there is still communication both ways  i must say i had the same yesterday after charging but after a while unexpectedly  don t know why  the robot responded again fine to my commands  it really seems to me the create   is stuck in the cleaning mode  or am i missing something  btw  i also tried to fix the problem by removing the battery  ,irobot-create
8981,how do i get the create   to communicate with a laptop via the serial to usb cable ,my computer will not recognize the serial to usb cable   i have tried it on a mac and an hp    is there a driver that i need to install   if it is supposed to install automatically  it is not  ,irobot-create serial usb
8987,error while building map in ros slam gmapping,i have recorded the rosbag data by simulating the robot in gazebo  i played back the logged bag file and tried to build the map using slam gmapping node and i ended up in error below      warn                          laser has to be mounted planar    z coordinate has to be   or     but gave            after few iterations  i was able to build the map by modifying laser scanner joint origin in my urdf file  from   to origin xyz            rpy                     but my robot model become weird as below  laser scanner is away from the robot    how to get around the issue without relocating the laser scanner  find my urdf file here  ,slam ros navigation mapping simulation
8988,building a quadcopter  what motors  props and what are the calculations ,before i start  i am a    year old  i would like to apologise because i am a beginner to all this and i wouldn t really understand any professional talk  i am only doing this for a hobby  i am building a quadcopter   flight controller  kk       esc  q brain   amp frame  kk       fpv     frame addon  kk fpv     long frame upgrade kit tx   rx  hobbyking  ch tx rx  mode    battery  turnigy nano tech      mah  s  i am not sure about what motor and propellers i should use  all i know is  for the frame the motor mounts are    mm to   mm with m  screws i am not sure what      and      means  here are my questions   what calculations should i do to find out how much thrust the quad needs to produce   any other useful calculations using the calculations what would be the best and cheapest motors i could have and finally  what propeller would be best suited for the motor   p s  i am looking for a durable and really cheap motors also  i live in london  so shipping might be a problem if there is an immense bill  thanks a lot for your time  sid ,quadcopter motor
8990,standard equation for steering differential drive robot,i am writing a code in arduino ide for nodemcu board to control a differential drive   wheeled robot  i am able to steer only one direction for some reason and the steering response time is a little awkward  is there perhaps a better strategy for the code that i am using    i am using an app called blynk that has a virtual joystick that controls that feeds the data through virtual pins  v  param   and   are x and y  x would be left to right on the joystick and y would be forward and back   information about the app is available here    i have it working for the most part  but there is some latency since it is through a cloud service  the main problem i am stuck on is steering while driving forward and backward    any help would be appreciated  thanks   ,differential-drive
8992,in the slam for dummies  why are there extra variables in the jacobian matricies ,i am reading slam for dummies  which you can find on google  or at this link  slam for dummies   a tutorial approach to simultaneous localization and mapping  they do some differentiation of matrices on page    and i am getting different answers for the resulting jacobian matrices   the paper derived    left    begin array  c   sqrt   lambda x   x        lambda y   y       v r     tan      left  frac  lambda y   y   lambda y   x  right     theta   v  theta  end array    right   and got   left    begin array  ccc   frac x    lambda y  r     frac y    lambda y  r         frac  lambda y   y  r       frac  lambda y   x  r          end array    right   i don t get where the  came from  i got completely different answers  does anybody know what the  stands for  if not  is there a different way to represent the jacobian of this matrix  ,slam
8994,how to implement transmission in tracked chassis with one motor ,i see that in small robots tracked chassis is implemented with   motors  each powering one side of the vehicle  like this    image stolen from here  but in real scale tanks i assume there is only one motor so there must be some way of applying power to both sides independently  ,tracks gearing chassis
8998,quadcopter pid controller  derivative on measurement   removing the derivative kick,good day  i am currently implementing a single loop pid controller using angle setpoints as inputs  i was trying out a different approach for the d part of the pid controller   what bought this about is that when i was able to reach a    hz         ms  loop rate  when adding a d gain  the quadcopter seems to dampen the movements in a non continous manner  this was not the case when my algorithm was running at around   hz  at an angle set point of   degrees  i would try to push it to one side by   degrees then the quad would try to stay rock solid by resisting the movements but lets go after while enabling me to get it of by   degrees  the dampening effect weakens over time  then tries to dampen the motion again  this is my implementation of the traditional pid   derivative on error    what i tried to do now is to implement a derivative on measurement method from this article to remove derivative output spikes  however the derivative part seems to increase the corrective force than dampen it   derivative on measurement     calculate orientation error  current   target  float pitcherror   pitchanglecf   pitchtarget  pitcherrorsum     pitcherror deltatime    float pitcherrordiff   pitchanglecf   pitchprevanglecf           pitchprevanglecf   pitchanglecf   float rollerror   rollanglecf   rolltarget  rollerrorsum     rollerror deltatime    float rollerrordiff   rollanglecf   rollprevanglecf           rollprevanglecf   rollanglecf   float yawerror   yawanglecf   yawtarget  yawerrorsum     yawerror deltatime    float yawerrordiff   yawanglecf   yawprevanglecf           yawprevanglecf   yawanglecf      pid controller list          the d terms are now negative float pitchpid   pitchkp pitcherror   pitchki pitcherrorsum   pitchkd pitcherrordiff deltatime   float rollpid   rollkp rollerror   rollki rollerrorsum   rollkd rollerrordiff deltatime   float yawpid   yawkp yawerror   yawki yawerrorsum   yawkd yawerrordiff deltatime       motor control   mixing       motor front left     float motorpwm      pitchpid   rollpid   yawpid   basethrottle   basecompensation   my question now is   is there something wrong with my implementation of the second method    source   the way i ve obtained the change in time or dt is by taking the timestamp from the start of the loop then taking the next time stamp at the end of the loop  their difference is obtained to obtain the dt  gettickcount   is an opencv function     initialize i c         open files for data logging     while         deltatimeinit  float gettickcount            get imu data           filter using complementary filter           compute errors for pid           update pwm s           terminate program after    seconds     if    float gettickcount   starttime     float gettickfrequency                       float stoptime   float gettickcount   starttime    float gettickfrequency         gpiopwm                 gpiopwm                 gpiopwm                 gpiopwm                 gpioterminate             int i        for  i     i   arrpitchcf size    i             file     arrpitchcf at i     endl             for  i     i   arryawcf size    i             file     arryawcf at i     endl             for  i     i   arrrollcf size    i             file      arrrollcf at i     endl             for  i     i   arrpitchaccel size    i             file     arrpitchaccel at i     endl             for  i     i   arryawaccel size    i             file     arryawaccel at i     endl             for  i     i   arrrollaccel size    i             file     arrrollaccel at i     endl             for  i     i   arrpitchgyro size    i             file     arrpitchgyro at i     endl             for  i     i   arryawgyro size    i             file     arryawgyro at i     endl             for  i     i   arrrollgyro size    i             file     arrrollgyro at i     endl             for  i     i   arrpwm  size    i             file      arrpwm  at i     endl             for  i     i   arrpwm  size    i             file      arrpwm  at i     endl             for  i     i   arrpwm  size    i             file      arrpwm  at i     endl             for  i     i   arrpwm  size    i             file      arrpwm  at i     endl             for  i     i   arrperr size    i             file      arrperr at i     endl             for  i     i   arrderr size    i             file      arrderr at i     endl                  file  close            file  close            file  close            file  close            file  close            file  close            file  close            file  close            file   close            file   close            file   close            file   close            file   close            file   close            file   close            cout      time elapsed        stoptime    endl          break             while    float gettickcount   deltatimeinit     float gettickfrequency                                             cout      dt end        deltatime     endl         deltatime    float gettickcount   deltatimeinit     float gettickfrequency                 cout      dt end        deltatime     endl     here s my data     ,control quadcopter pid raspberry-pi stability
9001,robot never goes straight,i am using   identical dc motors and a castor wheel  the motors are connected to l   d motor driver and are controlled by rpi   the robot is not going straight  it veers off to the right  i am running both the motors at      pwm  what i tried to correct the error   i adjusted the pwm of the wheel going faster to      but the robot just turns to the other side   i adjusted the weight on the robot and the problem still persists   i once tried to run the motor without any load  is that the cause of this  as i was later told that  running a dc motor without any load damages them  if that is not the cause  then please tell me how to solve this problem without using any sensors for controlling it   ,control motor wheeled-robot raspberry-pi
9007,is   motors needed for a arm that can move anyway not just circular ,if i m limited to   motors  for four legs  how could the robot rotate if they all only go up down directions  i d have to use   motors on a leg  correct  ,stepper-motor
9009,how to connect phone to robot while charging phone from external battery ,i am controlling a robot via usb from an android phone running the robot s code  this phone has a poor battery and i need to extend its life with a usb charger  can t change phones   how can i charge an android phone via usb  while maintaining a usb connection to the robot  i can solder wires together if needed  or can buy adapters as needed   ,mobile-robot usb
9010,is the distortion introduced by a lens protector significant in practice ,i have a computer vision application i made to localize a robot in a room  the software has been in use for a while and is working fine  when i calibrated the camera and got the intrinsics and lens distortion coefficients there was a lens protector on the lens  mounted on the robot s lid  if i take off the robot s lid  and thus the lens protector  the localization solution becomes erratic and inaccurate  so i think the lens protector might be changing the distortion properties significantly  today the lens protector became detached and it was replaced shortly after  so now the calibration may no longer be valid and the localization solution is much more noisy  can a lens protector can greatly effect the distortion properties of the image  or can someone offer another explanation  i intend to recalibrate and super glue the lens protector down to the robot s lid  but i am curious if this is my problem  and if anyone else has encountered this with lens protectors  ,computer-vision cameras calibration
9013,how many dofs required to define a  d pose,i understand that to be able to define point in  d space  you need three degrees of freedom  dofs   to additionally define an orientation in  d space  you need   dofs  this is intuitive to me when each of these dofs defines the position or orientation along one axis or an orthogonal x y z system  however  consider a robot arm such as this    this too has   dofs  but rather than each dof defining a position or orientation in an x y z system  it defines an angular rotation of one joint along the arm  if all the joints were arranged along a single axis  for example  then these   dofs would in fact only define one angular rotation  so  it is not true that each dof independently defines a single position or orientation  however  in the case of this robot arm  it can reach most positions and orientations  i m assuming this is because the geometry of the links between the joints make each dof define an independent position or orientation  but that is a very vague concept to me and not as intuitive as simply having one dof per position or orientation  can somebody offer some help in understanding these concepts  ,kinematics
9020,how does one calculate distance and angle using a target with known measurements ,the target is in the shape of a u where the horizontal segment is    inches  and the two vertical segments are    inches  we are using a camera to image the target  and then using vision processing to isolate the target from the rest of the image  we know the vertical field of view  and the horizontal field of view of the camera  the resolution of the camera is    x    pixels  the vertical distance between the camera on the robot and the target is constant but as of yet unknown because the robot hasn t been constructed yet  it is known  however  that the target will always have a higher elevation than the camera  how can we use this data to calculate in real time the robot s distance to the target  and the angle to the target  ,computer-vision real-time
9022,the logic of implementing an auto level function in a pid flight controller,so i have multi rotor with a basic pid controller  that keeps its axis stable through the gyroscope  however  the multi rotor  does not keep its height or position  so i would like to use an accelerometer for keeping its rough position  auto level   i want to use both the gyro and accelerometer  but how would the accelerometer values be used  is it implemented through the pid the same ways the gyro values are  degrees per second  which is the rate i used to calculate pid   and then adjusting the esc through that   i am confused at that part  the basic logic for using the accelerometer values   ,quadcopter pid imu accelerometer
9023,is there a way to measure   axis orientation without a magnetometer ,i have bought an stm inemo evaluation board in order to monitor the inclination of a separate magnetic sensor array as it moves in a linear scan outside of a  non magnetic  stainless steel pipe  i want to measure the inclination of the sensor along the scan and ensure that it does not change  the problem i have found is that the measured magnetic field from the integrated magnetometer varies greatly with position along the pipe  and in turn  causes a large  position dependent error in one axis of the inclination reported by the inemo imu  in fig    below i show the set up of the test  i measured the inclination from the imu while moving it along the length of the pipe and back again  the board did not change inclination throughout the measurement  in fig   i show the magnetometer and inclination measurements recorded by the  inemo application  showing the large error in one of the inclinations  my question is whether you know if there is any way of correcting for the magnetic field variation so that i can still accurately determine the inclination in all three directions  my data suggests to me that the magnetic field variation measured from the magnetometer is much greater than the geomagnetic field  so the inclination measurement will always be inaccurate  a follow up question i then have is  is there a way to measure   axis orientation without using a magnetometer    ,imu gyroscope magnetometer orientation
9025,cost of material to  d print,can someone please share the typical cost of material to  d print an object like a raspberry pi case   thank you  ,3d-printing
9027,do walking robots use accelerometers ,my understanding of walking robots  e g    is that they use a gyroscope to determine the current orientation of the robot  or each joint of the robot  this is because if you just put encoders on each joint  the cumulative error over the entire robot will be too large to maintain stability  therefore  a gyroscope measures the  real  orientation  and this is used for feedback when the robot is walking  however  i m also aware that some walking robots use accelerometers to maintain stability  what would be the benefit of using an accelerometer in this case  would it be used instead of a gyroscope  or together with a gyroscope  my guess is that gyroscopes do not measure acceleration directly  unless you were to numerically calculate this based on lots of orientation readings   but accelerometers do measure it directly  and more reliably than this numerical method   know the acceleration as well as the position then enables to robot to more accurately predict its future position  and hence the feedback loop is more robust  is this correct  or am i missing the point  ,control sensors accelerometer dynamics walking-robot
9033,how modular arm joints work,hello i m trying to figure out how modular arm joints are designed and what kind of bearings shafts are used for a modular type robotic arm  take  ur arm  for example  i believe those  t shaped pipes  include both a drive and bearing system  and as you can see from second image  it can be detached easily  so i think it s not just a simple  motor shaft connecting to the member that we want to rotate  mechanism  i m wondering which type of mechanism and bearing system is inside of those t shaped pipes  how can i transfer rotational motion to a member without using shafts     ,mechanism joint arm
9034,what does    degrees of freedom  mean ,i am looking at this page that describes various characteristics of gyroscopes and accelerometers  close to the end  where they speak about imus   the names of the items have something like this     degrees of freedom   degrees of freedom  can anyone explain what does this mean  ,accelerometer gyroscope
9038,how to load a puma robot in the existing environment in openrave    ,i have a pr  robot in an environment  which can be seen on the gui of openrave   now  how can i load a puma robot arm in the same environment  ,robotic-arm motion-planning
9039,how can i switch between autonomous mode and usercontrol ,i want to switch from usercontrol to autonomous  when i have the program running for     seconds  how come it wont automatically switch in autonomous mode  thanks   ,wheeled-robot robotc vex
9040,metal shaft design for a  mm plastic bevel gear,i have a small pom bevel gear with these dimensions   it has a  mm hole for the shaft and a m  hole for the set screw  suppose this bevel gear is meshed with a   t bevel gear and give a max  output torque of    kg cm  how should the design of the  mm shaft be  should the diameter be precisely  mm  should it be flattened into a  d  shape  so that the set screw can hold the shaft   i m planning to use a metal shaft  any help will be appreciated  thanks ,mechanism torque gearing
9043,joystick rate limit filter for frc java programming,i am a programmer for my school s frc robotics team and have received the request from our hardware driving department to limit the speed at which the robot s motors can accelerate given a joystick input telling it to increase the speed of the motor  for example  when the robot first starts up and the driver decides to move the joystick from the center to the fully up position    to full motor power   we don t want it to literally go from   to full motor power in an instant   it obviously creates some rather jerky  unstable behavior  how might i receive the target joystick position from the joystick  save it  and build up to it over time  and if any other inputs are sent in this process   like telling it to turn around   stop the current process and enact the new one   i am using java with wpilib s      robotics library  here s the api   and here s the tutorials   i am using the  iterativerobot  template class  and teleop is being run in the method teleopperiodic    which is continuously called every few milliseconds in the program  it s where i m receiving joystick input and calling the method robotdrive tankdrive   with the inputs   i realize this is more of a programming question than a robotics question  but i figured it would be better to put it here than in stack overflow  etc  if someone could give me some simple pseudocode or just a conceptual idea of how this might be done  not necessarily as it pertains directly to the library or the language i m using   that would be great  ,software first-robotics
9044,create   cable with     series roomba,for the last few months i have been playing with ros on an nvidia jetson tk  development board  up until this point  it has mostly been playing with the gpio header  an arduino uno  a couple physical contact sensors  and a few custom motor and servo boards that i slapped together  but lately i ve been eyeing an old     series roomba that has been gathering dust  was replaced by an     series   does anyone know if the communication cable for create   will work with a     series roomba  i know there are diy designs out there  but i have always been a fan of using off the shelf components if they exist   you rarely save more money than your time is worth if it is something like a cable or similar component  so if the create   cable will work  i ll use that  if not  i ll see what i can do to make my own  ,ros irobot-create roomba
9048,l   d won t turn motor backwards,my small robot has two motors controlled by an l   d and that is controlled via a raspberry pi  they will both go forwards but only one will go backwards   i ve tried different motors and tried different sockets in the breadboard  no luck  either the l   d s chip is broken  but then it wouldn t go forwards  or i ve wired it wrong   i followed the tutorial  controlling dc motors using python with a raspberry pi  exactly  here is a run down of what works  let the   motors be a and b  when i use a python script  see end of post  both motors go  forwards   when i change the values in the python script  so the pin set to high and the pin set to low are swapped  motor a will go  backwards   this is expected  however  motor b will not move at all   if i then swap both motors  wiring then the original python script will make both go backwards but swapping the pins in the code will make motor a go forwards but motor b won t move  so basically  motor a will go forwards or backwards depending on the python code but motor b can only be changed by physically changing the wires  this is  import rpi gpio as gpio from time import sleep  gpio setmode gpio board   motor a      motor b      motor e       motor a      motor b      motor e       gpio setup motor a  gpio out  gpio setup motor b  gpio out  gpio setup motor e  gpio out   gpio setup motor a  gpio out  gpio setup motor b  gpio out  gpio setup motor e  gpio out   print  on   gpio output motor a  gpio high  gpio output motor b  gpio low  gpio output motor e  gpio high   gpio output motor a  gpio high  gpio output motor b  gpio low  gpio output motor e  gpio high   and this is backwards py import rpi gpio as gpio from time import sleep  gpio setmode gpio board   motor a      motor b      motor e       motor a      motor b      motor e       gpio setup motor a  gpio out  gpio setup motor b  gpio out  gpio setup motor e  gpio out   gpio setup motor a  gpio out  gpio setup motor b  gpio out  gpio setup motor e  gpio out   print  on   gpio output motor a  gpio high  gpio output motor b  gpio low  gpio output motor e  gpio high   gpio output motor a  gpio high  gpio output motor b  gpio low  gpio output motor e  gpio high   if you see this diff   you can see the difference     below are some pictures  you can use the colour of the cables to link them between pictures  enter image description here   ,wheeled-robot raspberry-pi
9052,alternative to beaglebone black for node js based remote control project ,i am working on a remote control project that involves using node js and socket io to transmit joystick data from a webpage to my beaglebone black  however  i am somewhat disappointed with the beaglebone   it seems like what should be such simple tasks such as connecting to wi fi can be quite tricky    my question is  are there alternative boards i should be looking at  boards that also have node js libraries with pwm support  could stream video from a webcam  but are easier to set up and have a larger developer community  ,control microcontroller pwm beagle-bone
9054,mass matrix in lagrange equation,i want to find the equations of motion of rrrr robot i have studied about it a bit but i am having some confusion  here in one of the lectures i found online it describes as inertia matrix of a link as ii which is computed by tilde of i also described in picture below     so tilde of i is computed wrt to fixed frame attached to the centre of mass  however in another example below from another source there is no rotation matrix multiplication with ic  and ic  as shown above am i missing something    what is the significance of multiplying rotation matrix with ic  or tilde of i  i am using former approach and getting fairly large mass matrix  is it normal to have such long terms inside mass matrix   still need to know though which method is correct       the equation i used for mass matrix is ,robotic-arm dynamics
9057,is this supposed to be a bearing ,i m looking at the assembly of a tail rotor that should look like this  original image i wonder if the  tail output shaft stopper   circled in red  is meant to be a bearing or just a piece of metal stopper   my reading is that  since it s held by   set screws  the whole part should rotate with the rod  while rotating  it d rub against the bevel gear on the tail drive though  am i missing something  ,mechanism torque gearing
9063,irobot create   roomba     screw size thread ,i ve looked everywhere i can think of to find this information  but haven t come across anything  does anyone know what kind of screws i can use to replace the ones on top of my roomba       i realize that the create   is technically a     series  but i would expect they were the same  i d like to replace the screws on my roomba with standoffs so i can stick a mounting plate on top of it   additional sensors  cpu  etc   ,irobot-create roomba
9069,analogue video to digital,i have fpv camera which outputs analog video  rca  pal   i want to capture video and do image processing  therefore i need some way to convert the analog video to digital  can some one recommend me how to do it  is there advice or a shield which can assist  please note   i want to convert the frames with minimum latency  because it is a real time flying drone  i don t need to convert the image to some compressed format  which encoding  decoding may take time   if i can get the rgb matrix straight  it is preferred  i thought about digital output camera  but i need one which weighs few grams and i haven t found yet   ,quadcopter cameras
9073,determine robot s position in a nearby room,scenario i have   roaming robots  each in different rooms of a house  and both robots are connected to the house wifi  each robot only has access to the equipment on itself  question how can the robots be aware of each other s exact position using only their own equipment and the house wifi  edit  additional info right now the robots only have   rgbdslam via kinect no initial knowledge of the house or their location  no docks  no mappings markings  nada   can communicate via wifi and that part is open ended  i m hoping to be able to stitch the scanned rooms together before the robots even meet  compass   altimeter   gps will get me close but the goal is to be within an inch of accuracy which makes this tough  there is freedom to add whatever parts to the robots themselves   laptop but the home needs to stay dynamic  robots will be in a different home every time   ,mobile-robot localization precise-positioning
9074,software real time of ros system,as far as i know  a hardware real time robot control system requires a specific computing unit to solve the kinematics and dynamics of a robot such as interval zero rtx  which assigns cpu cores exclusively for the calculation  or a dsp board  which does exactly the same calculation  this configuration makes sure that each calculation is strictly within  maybe    ms   my understanding is that ros  which runs under ubuntu  doesn t have a exclusive  computing unit for that  kinematics and dynamics run under different threads of the same cpu which operates the ubuntu system  path plan  and everything else   my question is that how does ros achieve software real time  does it slow down the sampling time to maybe    ms and makes sure each calculation can be done in time  or the sampling time changes at each cycle maybe from  ms    ms  to   ms each time in order to be as fast as possible and ros somehow compensates for it at each cycle  ,microcontroller ros real-time
9077,pid tuning for an unbalanced quadcopter  when do i know if the i gain i ve set is too high ,good day  i am working on an autonomous flight controller for a quadcopter   x  configuration  using only angles as inputs for the setpoints used in a single loop pid controller running at    hz  pid implementation is here  quadcopter pid controller  derivative on measurement   removing the derivative kick   for now i am trying to get the quadcopter to stabilize at a setpoint of   degrees  the best i was able to come up with currently is     degrees which is bad for position hold  i first tried using only a pd controller but since the quadcopter is inherently front heavy due to the stereo cameras  no amount of d or p gain is enough to stabilize the system  an example is the image below which i added a very small i gain   as you can see from the image above  at the second plot   the oscillations occur at a level below zero degrees due to the quadcopter being front heavy  this means that the quad oscillates from the level postion of   degrees to and from a negative angle towards the front  to compensate for this behaviour  i discovered that i can set the dc level at which this oscillations occur using the i gain to reach the setpoint  an image is shown below with  i think  an adequate i gain applied   i have adjusted the pid gains to reduce the jitters caused by too much p gain and d gain  these are my current settings  which are two tests with the corresponding footage below    test     test     i can t seem to tune the quadcopter to reach the setpoint with at least     degrees of error  i noticed that further increasing the i gain no longer increases the dc offset    when do i know if the i gain i ve set is too high  how does it reflect on the plot   edit  the perr in the graphs are just the difference of the setpoint and the cf  complementary filter  angle  the derr plotted is not yet divided by the deltatime because the execution time is small         s which will make the other errors p and i hard to see  the ierr plotted is the error integrated with time  all the errors plotted  perr  ierr  derr  are not yet multiplied by the kp  ki  and kd constants the  rd plot for each of the images is the response of the quadcopter  the values on the y axis correspond to the value placed as the input into the gpiopwm   function of the pigpio library  i had mapped using a scope the values such that     to     pigpio integer input corresponds to      to     ms time high of the pwm at    hz to the esc s edit  here is my current code implementation with the setpoint of   degrees   ,pid raspberry-pi quadcopter tuning
9082,optimal location of the center of mass for an inverted pendulum,i m building an inverted pendulum to be controlled by dc motors  but i ve run across a conundrum   personal life experience tells me that it s better to have a lower center of mass to maintain balance   on the other hand  the greater the moment of inertia  e g  the higher the center of mass   the easier it is to maintain balance as well  these two views both seem plausible  and yet also seem contradictory    for an inverted pendulum  is there an optimal balance between the two perspectives   or is one absolutely right while the other absolutely wrong   if one is wrong  then where is the error in my thinking  ,dynamics balance
9090,xbee xtend recovery troubleshoot,i have a broke my xbee xtend    mhz module  while it was doing firmware writing job i suddenly restarted the windows  i ve tried recovery procedure of xctu new version and it does not work  therefore i m still working with old version  here is the error i m facing   ,radio-control
9096,is there an alternative to manifolds when using quaternions for orientation representation in pose graph slam ,i want to implement my own pose graph slam following      since my vehicle is moving in  d space i represent my pose using a  d translation vector and a quaternion for orientation      tells me that it s necessary to adapt their algorithm   by using manifolds to project the poses into euclidean space  i also studied the approach of      in section  iv b  nonlinear systems  they write that their approach remains valid for nonlinear systems  i conclude that for their case it s not obligatory to make use of a manifold  but i don t understand how they avoid it  so my questions are   is it correct that there is an alternative to manifolds  if yes  how does this alternative look like        grisetti  g   kummerle  r   stachniss  c     burgard  w          a tutorial on graph based slam  intelligent transportation systems magazine  ieee                   kaess  m   ranganathan  a     dellaert  f          isam  incremental smoothing and mapping  robotics  ieee transactions on                    ,slam pose
9097,a simple function plotter project,to plot any curve or a function on a paper we need points of that curve  so to draw a curve  i will store a set of points in the processor and use motors  markers and other mechanism to draw straight lines attaching these points and these points are so close to each other that the resultant will look an actual curve  so i am going to draw the curve with a marker or a pen   yes to do this project i need motors which would change the position of a marker but which one   with my knowledge stepper motor and servo motors are appropriate but not sure whether they are appropriate since i have never used them  so will they work  the dimension of paper on which i will be working on is   x   cms  i have two ideas for this machine  a  a rectangular one as shown  i would make my marker holder movable with help of rack and pinion mechanism but i am not sure that this would be precise and i may have to alter to some other mechanism and if you know such then that can really help me  b  a cylindrical one  here i would roll a paper on this cylinder and this paper will get unrolled as the cylinder rotates and even the marker holder is movable but only in x direction and the rolling of paper is nothing but change of y position   which one of the above two methods is good  i know about microcontrollers and i want to control the motors using them so i decided to go with atmega    microcontroller  but here i might need microstepping of signals how would i be able to do that with microcontrollers   if you know the answer to atleast one of the questions then those answers are always welcomed   if you need any clarifications about these then please leave a comment  thankyou for your time  your sincerely  jasser edit   to draw lines of particular slope i would have to know the slope between two points and the depending on the slope i would rotate motors with particular speed so that marker will move in a straight fashion with that slope  ,microcontroller stepper-motor servomotor
9099,reference request  path accuracy algorithm in the joint angle space,i am currently reviewing a path accuracy algorithm  the measured data are points in the   dimensional joint space  the robot under test  is a   axes robot  but this is not of importance for the question   as far as i know path accuracy is measured and assessed in configuration    d  space  therefore i am wondering if a path accuracy definition in joint angle space has any practical value  sure  if one looks at the joint angle space as a   dimensional vector space in the example  with euclidean distance measure  one can do formally the math  but this seems very odd to me  for instance  an angle discrepancy between measured and expected for the lowest axis is of much more significance than a discrepancy for the axis near the actuator end effector  so here is my question  can anyone point me to references where path accuracy in joint space and or algorithms for its calculation is discussed      i am not quite sure what tags to use  sorry if i misused some   ,algorithm industrial-robot joint
9100,finding center of mass for humanoid robot,i ve been working on humanoid robot  and i face the problem of finding the center of mass of the robot which will help in balancing the biped  although com has a very simple definition  i m unable to find a simple solution to my problem  my view  i have already solved the forward and inverse kinematics of the robot with torso as the base frame  so  if i can find the position and orientation  of each joint in the base frame  i can average all of them to get the com  is this approach reasonable  will it produce the correct com  can anyone offer any series of steps that i can follow to find the com of the biped  any help would be appreciated   cheers   ,mobile-robot inverse-kinematics humanoid balance
9103,connecting a cc d board with raspberry pi to get telemetry data,i want to get telemetry data in my raspberry pi that will be connected to a cc d board either via usb cable or serial communication  how can i get the data  i plan to have wifi communication between the pi and my laptop  also oplink modems will be used both in the pi and the cc d for the telemetry  does anyone have a python example that may help to build an interface or output in the linux shell to get raw telemetry data in rpi   ,serial communication
9105,lag in altitude measurements using a barometer and an acclerometer,i am fusing data from the barometer and accelerometer using a complementary filter  however  there is a considerable lag in the readings which is affecting the alt hold performance   accelerometer   mpu       baro   ms        here s the code    you will find the filter being implemented in the function calculateestimatedaltitude   does anyone have any suggestions to improve the measurements   ,quadcopter sensors sensor-fusion
9106,sensors for identifying stacked books,i am working on a robotics application that involves moving objects  e g  books  between several  around     stacks  to measure the performance  i d like to be able to measure which book is located on each of the stacks  the order is not important i just want to know if a book is on one of the stacks   the stacks are separated by at least one meter and the height of the stacks is less than   cm      books    if have thought of putting an rfid card in every book and fixing rfid readers above  or below  the stack positions  several readers could be attached via spi or i c to some arduinos or rpis   what to you think about this approach  is there a simpler way  could someone maybe recommend a sensor that could solve this problem      update  i can modify the books  e g  add a qr marker  to some extent  but can t guarantee that the orientation on the stack is fixed   ,untagged
9111,how to make a raspberry pi ,i m currently a robotics hobbyist and am full fledged in arduino and i have used the raspberry pi to make some robots and pcs  currently  i am thinking of making my own raspberry pi  from scratch  on a breadboard or a pcb or something  i surfed the web quite a bit and i did not get the answer i was hoping for  by making a pi  i mean like instead of buying an arduino  i can make one myself by buying the atmega     crystal oscillators  etc  i am asking for this because my school requires me to do a project in which i make a computer or a gaming console or something like that and i would hate to look at the disappointed face of the tester all because i just bought a pi   an connected some devices to it  thanks in advance  ,arduino raspberry-pi
9114,simple equation to calculate needed motor torque,suppose i have a dc motor with an arm connected to it  arm length     cm  arm weight       motor speed   rpm  if i connect a  kg weight to the very end of that arm  how much torque is needed for the motor to do a complete      spin  provided the motor is placed horizontally and the arm is vertical  is there an simple equation where i can input any weight and get the required torque  provided all other factors remain the same   ,motor torque
9115,sphero s logic  how does it work,i m willing to make my first robot  and i d like to make one similar to the sphero  i know i have to add   motors in it  and make it work as a hamster ball  but i don t understand how i can make it rotate on the x axis aswell and not only on the y axis  if we assume that the y one is in front of the robot and the x one on its sides  any ideas  ,design two-wheeled
9119,weird behaviour with a create  connected via xbee,this is not really a problem but something strange is going on  when create  is connected to a pc via the usb original connector lead  when you start up the computer the create  is activated by the baud rate change  brc  pulling to ground  if i understand correctly  normal behaviour  my create  is connected to a xbee via a buck converter  i added a switch so the buck converter and the xbee should not drain the battery continuously so as mentioned in the specs  i followed the bluetooth pdf for the connections  its working well for sending commands but i still just have a few problems with streaming the return data but that will be resolved  but now  with the xbee switched off my create  still activates when i start up my pc  how is that possible  how can the brc be pulled to ground  there can be no communication between the pc xb and the create  xb since the create  xb is switched off  only the pc xb is switched on when starting the computer  its not a problem  its just that i am puzzled  can anyone explain why this is happening  ,irobot-create
9124,choosing stepper motor for hand,i m developing a robotic hand  and decided to place motors inside joints  as in picture  and i m stuck with finding a stepper motor that can fit there  approximate size of motor body is radius     mm  length      mm   any suggestions   ,stepper-motor
9129,how to compute the error function in graph slam for  d poses ,given a pose  with translation vector  and rotation quaternion  and a transform between poses  and  as  i want to compute the error function   which has to be minimized like this to yield the optimal poses   x     argmin x  sum  ij  e  ij  t  sigma       ij  e  ij  a naive approach would look like this   e  ij    z  ij    f x i x j   where  is the current measurement of the transform between  and  and  calculates an estimate for the same transform  thus   simply computes the difference of translations and difference of turning angles   e  ij     begin pmatrix  t  ij    t j   t i     q  ij   q j q i             end pmatrix   is there anything wrong with this naive approach  am i missing something  ,slam errors
9130,choosing the state vector for an ekf,could someone help me understand the logic behind choosing a particular state space vector for an ekf  context  say there is a   wheeled robot that operates only in  d  it is equipped with an inertial unit  a g m  and wheel encoders  i understand that these alone might not satisfy accuracy constraints  but consider this as a hypothetical case   now  some literature has the state as  q  x  y  vx  vy   while a few others as  q  q dot  x  y  vx  vy    my question is  what is the advantage with having certain  rate terms  as opposed to only the normal parameters  also  what about including bias terms in there  how do i go about selecting an appropriate state space vector for any use case  in general   is there a set of intuitive mathematical steps to consider follow  thanks  ,wheeled-robot kalman-filter ekf pose
9132,find orientation through transformation matrix,i have a robot with   rotational joints that i am trying to simulate in a program i am creating  so i have   frames  one base frame  and each joint has a frame  i have   transformation functions to go from frame   or   or   to frame    by using the transformation matrix  i want to know how much each frame has been rotated  by the x y and z axis  compared with the base frame  any suggestions  the reason i want this is because i have made some simple  d shapes that represent each joint  by using the dh parameters i made my transformation matrices  when ever i change my    it does not mater how the   changes  it just does   i want the whole structure to update  i take the translation from the last column  now i want to get the rotations  ,robotic-arm dh-parameters
9135,freewheel diode   capacitor with this board ,with dc motors  it is common to put a freewheel diode and or a capacitor in order to protect the equipment as the motor can induce current into the system  i plan to use this board to control a   v dc motor with a arduino like microcontroler  in an example in their documentation  they don t put such protection  so i wanted to know if it s unsafe  or is it that the board already protects the system  the example in question   ,arduino motor protection
9139,can i control irobot create   with ni myrio and labview codes ,i need to know if the irobot create   can be controlled with a ni myrio that has been programmed through labview   the goal is to program an autonomous robot for real time tracking using a kinect sensor   ,mobile-robot irobot-create labview
9143,how is homotopy used in planning algorithms ,what is an intuitive understanding for homotopy   at what stage is homotopy  i understand it as stretching or bending of path  in a planning algorithm   is homotopy involved  for example  while implementing an algorithm like rrt  ,motion-planning rrt
9144,making a car go straight,i m trying to work a car that s being controlled by an arduino  i m using the following chassis  new  wd car chassis dc gear motor  wheels easy assembly and expansion and an l   n motor driver  the problem is that it s hard to make the car go straight  giving the same pwm value to the motors still makes them spin in different speeds  trying to calibrate the value is hard and every time i recharge my batteries the value changes  what are my options on making the car go straight when i want  well  sometimes i ll want to turn it around of course   i ve thought about using an encoder but i wish to avoid that since it will complicate the whole project  is there any other viable option  and even when using an encoder  does it means i will need to keep track all the time and always adjust the motors value continuously  is there some built in library for that  ,arduino wheeled-robot calibration two-wheeled
9145,list of books similar to thrun s probabilistic robotics for robot mechanics and manipulation,what  put together here a list of books  like the one for c c   on stackoverflow  that are spiritually similar to sebastian thrun s probabilistic robotics for robotic manipulation and mechanics  why  thrun s book is a wonderful resource for implementable algorithms while also dealing with the mathematics theory behind them  in somewhat similar vein for robotic mechanics there is  a mathematical introduction to robotic manipulation   s sastry  z li and r murray  which has a lot of mathematical theoretical content  what is missing however in this book are the algorithms concerned with how should would one go about implementing the theoretical stuff  requirements  ideally list books dealing with diverse areas of robotics  the books have to present algorithms like what thrun does in his book  algorithms presented have to be language agnostic and as much as possible not be based on packages like matlab in which case they should be categorized appropriately   ,kinematics inverse-kinematics algorithm dynamics books
9152,inverse kinematics after calibration,i am working on a  dof robot arm project and i have one big question  when i first derived the inverse kinematics  ik  algorithm after decoupling  spherical wrist   i could easily get the equations based on nominal dh values  where alpha are either   or    degrees and there are many zeros in  and   however  after kinematics calibration  the identified dh parameters are no longer ideal ones with a certain small  but non zero  bias added to the nominal values   so my question is  can the ik algorithm still be used with the actual dh parameters  if yes  definitely there will be end effector errors in actual operation  if not  how should i change the ik algorithm   p s  i am working on a modular robot arm which means the dh bias could be bigger than those of traditional robot arms   ,inverse-kinematics calibration
9155,how to import catia assembly to matlab  simmechanics,in catia  stl format is available only for part file not for assembly file  please help how to import asembly in simmechanics  catproduct to  stl or is there any other way to do  ,matlab
9157,regarding finding out sensor,i am looking for a sensor which is able to read the displayed data from a lcd display    digits   the output of this sensor must be fetched to a  microcontroller  can anyone suggest me such sensor please soon  ,sensors hall-sensor
9159,multi rate sensor fusion using ekf,context  i have an imu a g m    wheel odometry measurement data that i m trying to fuse in order to localize a  d  ackermann drive  robot  the state vector   i m using the odometry data to propagate the state through time  no control input   the update step includes the measurement vector z    x odo y odo yaw imu   i have two questions    does it make sense to use the odometry data v linear  omega  in both the prediction as well as update steps    how do i account for the frequency difference between the odometry data   hz  and the imu data   hz   do i run the filter at the lower frequency  do i dynamically change the matrix sizes or is there any other way  thanks  ,localization wheeled-robot imu ekf odometry
9161,robot autonomous variable terrain with yaw sensor,i am programming a robot to drive over variable terrain obstacles autonomously  the variable terrain could potentially knock the robot off of its initial heading  but i would like to design an autonomous sequence to correct for any change in direction  i am using a very accurate sensor with compass and yaw  what is the best way to have it correct for any changes and maintain its heading  side to side motion does not have to stay perfect  but the heading needs to stay the same we are currently correcting it by overpowering one side of the wheels  depending on direction of correction needed  until the heading is correct again  but this seems to be a slightly antiquated method  so i m looking for a cleaner and more smooth method  ,compass automation
9163,making a vex central controller,is there any way to make the central controller for all vex parts without using the vex cortex  or anything by vex    i am wondering whether you can make your own custom controller for vex parts  ,vex
9167,check collision between robot and environment in openrave,i have a robot arm in an environment  how can i check for collision between this robot arm and the environment  ,robotic-arm motion-planning python
9168,memory as a benchmarking criteria for motion planning algorithm,are there still applications where memory is still a criteria with respect to motion planning algorithms  are memory efficient motion planning algorithms still relevant  ,mobile-robot quadcopter motion-planning
9169,pid control  integral error does not converge to zero,good day  i had been recently reading up more on pid controllers and stumbled upon something called integral wind up  i am currently working on an autonomous quadcopter concentrating at the moment on pid tuning  i noticed that even with the setpoint of zero degrees reached in this video  the quadcopter would still occasionally overshoot a bit    here is the corresponding data testing the roll axis   i noticed that the i error does not converge to zero and continues to increase    is this the integral wind up  what is the most effective way to resolve this   i have seen many implementations mainly focusing on limiting the output of the system by means of saturation  however i do not see this bringing the integral error eventually back to zero once the system is stable  here is my current code implementation with the setpoint of   degrees   ,control quadcopter pid stability tuning
9171,plotting location using wheel encoder data,context  i am working with the sfu mountain dataset    the ugv image   via the sfu mountain dataset website   i have used the following state update equations  husky a      differential drive  state update   from prob  robotics  thrun et  al    after plotting the x and y positions based on just the wheel encoder data  v fwd and w    the dataset provides these directly  instead on the vr and vl   the curve seems to be quite weird and unexpected  wheel odometry data    blue   wheel odom     red   gps  actual path   question  is the above curve expected  considering the inaccuracy of wheel odometry  or is there something i m missing  if the wheel encoder data is that bad  will an ekf  odom   imu  even work  ps  i m not worried about the ekf  update step  just as yet  what concerns me more is the horrible wheel odometry data  ,localization wheeled-robot ekf odometry differential-drive
9174,what kind of sensor i can use to identify which fruit it is  like mango or apple  ,what kind of sensor i can use to identify which fruit it is  like mango or apple   moreover  is there any sensor to identify different varieties of apples or mangoes   ,sensors
9175,what is the best way to attach a  d printed part to a servo for robotics use ,i am trying to make custom parts that fit directly onto a servo  doing this has proved more difficult than i ve expected so far  i was hoping to avoid incorporating the provided servo horns into the  d printed part  so i ve been trying this method out  below are images of my current test   a  d printed attachment to the servo  with an indentation for an m  nut  the servo accepts an m  bolt  for attachment to the servo  the plastic ring doesn t have the spline  i can t print that level of detail i think  but is tight around it  the top piece attaches to a      nut for use with the      threaded rod i had laying around    so far  i m having difficulty of this setup working with any level for torque and not just spinning in place  so    is this the correct approach  am i going to have to design a piece with the servo horn inside of it to get the servo to connect  are there better approaches i haven t considered  ,servos 3d-printing
9180,how does information gain based exploration differ from frontier based ,i ve recently come across the concept of using information gain  or mutual information criteria  as a metric for minimizing entropy on a map to aid in robotic exploration  i have somewhat of a basic question about it   a lot of papers that talk about minimizing entropy consider an example case of something like a laser scanner and try to compute the  next best pose  so that the maximum entropy reduction is achieved  usually this is mentioned like  information gain based approaches help finding the best spot to move the robot such that the most entropy is minimized using raycasting techniques  as opposed to frontier based exploration which is greedy  etc  but i don t understand what the underlying reason is for information gain entropy based exploration being better   let s say a robot in a room with three walls and open space in front  because of range limitations  it can only see two walls  so in frontier based exploration  the robot has two choices  move towards the third wall and realize it s an obstacle  or move towards the open space and keep going  how does an information gain based method magically pick the open space frontier over the wall frontier  when we have no idea what s beyond our frontiers  how can raycasting even help  ,mapping exploration information-gain
9183,ekf slam  prediction of new landmarks ,prediction of new landmarks are commonly expressed as   however this is only true for point landmarks  what if i am extracting line feature  ,slam ekf
9185,which ultrasonic sensor can be used for detecting hydraulic flow ,i am looking to make a non contact hydraulic flow meter  i was wondering  which ultrasonic sensor to use  i don t have any specific ideas on how to go forward  are there any articles or documented builds out there about this subject  ,ultrasonic-sensors
9186,using genetic algorithm for tuning controllers,i ve read some papers for controlling nonlinear systems  e g  nonlinear pendulum   there are several approaches for targeting nonlinear systems  the most common ones are feedback linearizaing  backstepping  and sliding mode controllers   in my case  i ve done the theoretical and practical parts of controlling nonlinear model of a simple pendulum plus other manipulators problems in c    for the pendulum  i ve utilized a backstepping controller for solving the tracking task for the angular displacement and velocity  the results are    ddot  theta     k m   dot  theta     g l   sin theta  u   where  and     the results are good  however  tuning the controller is time consuming  the majority of papers use genetic algorithms for tuning their controllers such as pd  pid  and backstepping controllers  i m clueless in this field and i hope someone sheds some light on this concept  preferable if there is a matlab sample for at least controlling a simple pendulum  so far i ve designed a simple gui in c   qt in order to tune the controller manually  in the below picture  the response of the controller for step function     ,control
9187,ultrasonic flow sensor,the goal is to have a non invasive flow meter that i can clamp over hydraulic lines  as a student of hydraulics  i ended up looking and poking around for a good way to make an ultrasonic flow sensor with arduino and possibly the hc sr    not married to either idea   so  i admit  i know nothing  but is it possible to do this  is there an easier way  ,ultrasonic-sensors
9194,what determines the speed of quadrotor,how to design a quadrotor which travels at particular maximum speed  and how to determine the power required for a quadrotor to hover  ,mobile-robot quadcopter power
9195,how to align solidworks global origin with assembly origin while exporting in solidworks to urdf,i have created a robot model in solidworks and exported in solidworks to urdf plug in  when exporting the co ordinates of the model is misaligned which is causing problem while using in ros   as you could see in picture the z axis is horizontal in assembly whereas vertical in solidworks  how to align these co ordinates  the generated co ordinate system must be similar to solidworks  co ordinates ps  i have mated the assembly origin and base link origin ,mobile-robot ros navigation odometry gazebo
9200,a vector field histogram implementation in python    ,i am trying to implement the vector field histogram as described by borenstein  koren       in python     using the scipy stack  i have already been able to calculate the polar histogram  as described in the paper  as well as the smoothing function to eliminate noise  this variable is stored in a numpy array  named   however  the function computetheta  pasted below  which computes the steering direction  is only able to compute the proper direction if the valleys  i e  consecutive sectors in the polar histogram whose obstacle density is below a certain threshold  do not contain the section where a full circle is completed  i e  the sector corresponding to       to make things clearer  consider these two examples    if the histogram contains a peak in the angles between  say       and      with the rest of the histogram being a valley  then the steering direction will be computed correctly  if  however  the peak is contained between  say      and      then the valley will start at      go all the way past      and end in      and the steering direction will be computed incorrectly  since this single valley will be considered two valleys  one between    and      and another between     and       def computetheta self  goal   thrs      s max         we start by calculating the sector corresponding to the direction of the target  target sector   int       np pi  np arctan  goal      self vcp     goal      self vcp      if target sector          target sector        target sector        next  we assume there is no best sector  best sector      dist best and target   abs target sector   best sector    then   we find the sector within a valley that is closest to the target sector  for k in range self hist shape          if self hist k    thrs and abs target sector   k    dist best and target          best sector   k         dist best and target   abs target sector   k    if the sector is still     we return it as an error  print  target sector  best sector  if best sector            return      if not  we can proceed    elif best sector                by deciding whether the valley to which the best sector belongs is a  wide  or a  narrow  one       assume it s wide      type of valley    wide        if we find a sector that contradicts our assumption  we change our minds      for sector in range best sector  best sector   s max               if sector   self hist shape                 if self hist sector    thrs                  type of valley    narrow         if it is indeed a wide valley  we return the angle corresponding to the sector  k n   s max         if type of valley     wide            theta      best sector   s max            return theta       otherwise  we find the far border of the valley and return the angle corresponding to the mean value between the best sector and the far border      elif type of valley     narrow           for sector in range best sector  best sector   s max               if self hist sector    thrs                  far border   sector          theta      best sector   far border            return theta   how can i address this issue  is there a way to treat the histogram as circular  is there maybe a better way to write this function  thank you for your time  ,motion-planning python planning
9203,helicopter stabilization algorithm,i ve hacked a rc helicopter  and i am able to control it by running a program on my computer  i am interested in writing algorithms that will stabilize the helicopter  for instance  the helicopter is hovering  and then if it is shoved off balance it can return to its previous position in a stable state  any help on an algorithm would be awesome  ,algorithm stability
9206,irobot create  making noise and flashing red light while charging,my irobot create is playing a tune about every    seconds and continuously flashing a red light when i attempt to charge it  what is the issue  ,irobot-create
9210,what is the difference between planning for kinematic car  dynamic car  blimp and quadrotor,i am working with a sampling based planning library  when i looked into the implementation  i found for kinematic car a se  state space x  y  yaw   for dynamic car a se  compound state space  space allowing composition of state spaces   for blimp and quadrotor a se  compound state space was used  i could understand the design of se  and se  state spaces but the compound state spaces of dynamic car  blimp and quadrotor i could not comprehend or differentiate  what is the difference in terms of state space for motion planning for kinematic car  dynamic car  blimp and quadrotor  ,mobile-robot quadcopter motion-planning
9214,wireless mini camera,i am looking for a mini  wireless  chargeable  camera that can stream video in real time to my computer  i will put the mini camera on my helicopter and send the live video feed to my pic and make certain calculations to make the helicopter navigate in a certain way  any help would be great  ,cameras
9218,programming   digit seven segment display using interrupts only,i have to program an autonomous bot  using an atmega       it has a   digit seven segment display attached to it  i have to make the bot traverse through arena while continuously displaying the time in seconds on the seven segment display  i can t use the code to display on seven segment display in my  function  any help   ,interrupts
9225,how to communication with old robotic arms from nakkanippon electric ,i have a few robotic manipulators from nakkanippon electric and i m trying to communicate with them using rs    without success  the robot model are microrobots      or       i m sending commands via com port  but i can t received anything from the box  i m using a usb to db  converter  ftdi  with a db  db   cable  on the net  the only reference i have for the robot is from an old post from year      that was from user  peterkneale  if it can help  here is the link to the scanned pdf manual  you can see the commands on page       of the pdf  page       in document    any advice would be grateful ,robotic-arm
9226,wind flow diagram of a quadcopter,i m trying to determine the wind flow diagram around a quad copter when it is in action  i looked up on internet but couldn t find any reliable source  by wind flow diagram what i mean is when my quad copter is in mid air hovering at some fixed position  how the air is moving around it  all the directions are needed to be kept in mind  from top to bottom   vertical direction  and also the horizontal direction  thank you  ,quadcopter dynamics
9227,solar cells charging a li po battery,is there a way to charge a li po battery using solar panels to increase the flight time of a quadcopter during its flight  ,quadcopter power
9228,evaluating the similarity of two   degree of freedom arms,i am working on the baxter robot where i have a first arm configuration and a bunch of other arm configurations  where i want to find the closest arm configuration to the first among the many other arm configurations  the trick here is that the end effector location orientation is the exact same for all the arm configurations  they are just different ik solutions  can anyone point me towards the right direction towards this  thank you  ,robotic-arm inverse-kinematics
9232,how to interrupt on a data ready trigger when communications to the sensor are interrupt driven ,background  i m using the l gd  h mems gyroscope with an arduino through a library  pololu l g  that in turn relies on interrupt driven i c  wire h   i d like to be able to handle each new reading from the sensor to update the calculated angle in the background using the data ready line  drdy   currently  i poll the status register s zyxda bit  which is what the drdy line outputs  as needed  general question  with some digital output sensors  i c  spi  etc    their datasheets and application notes describe using a separate  out of band  hardware line to interrupt the microcontroller and have it handle new sets of data  but on many microcontrollers  retrieving data  let alone clearing the flag raising the interrupt line  requires using the normally interrupt driven i c subsystem of a microcontroller  how can new sensor data be retrieved from the isr for the interrupt line when also using the i c subsystem in an interrupt driven manner  possible workarounds   use nested interrupts  as  hauptmech mentioned   re enable i c interrupt inside of isr  isn t this approach discouraged  use non interrupt driven i c  polling   supposedly a dangerous approach inside of isrs  the sensor library used depends on the interrupt driven wire library   edit  professors  suggestion  use a timer to interrupt set to the sample rate of the sensor  which is settable and constant  although we measure it to be e g       hz rather than      hz per the datasheet   handling the i c transaction still requires re enabling interrupts  i e  nested interrupts or performing i c reads from the main program    edit   here s a comment i found elsewhere on a similar issue that led me to believe that the hang encountered was from i c reads failing inside an interrupt handler      during the isr  interrupt service routine  i was trying to read the   device to determine which bit changed  bad idea  this chip uses the   i c communications which require interrupts  but interrupts are turned   off during an isr and everything goes kinda south   ,arduino microcontroller gyroscope i2c interrupts
9233,uncented kalman filter for dummies,i need some help here because i can t figure how the unscented kalman filter works  i ve searched for examples but all of them are too hard to understand  please someone can explain how it works step by step with a trivial example like position estimation  sensor fusion or something else  ,kalman-filter
9234,syncing camera with other signals,i am not sure if this is the best place to ask this question  but hopefully someone here can give me some advice  i have a device hooked up to a data acquisition system that can provide sync out signal and record sync in signals  i need to synchronize my recordings with this device to a video feed  i am having trouble finding a camera that can provide a sync signal or any other good way to accomplish this  thanks for your help  ,sensors cameras
9236,controlling hubsan x  with crazyflie usb dongle,i have the crazyflie usb dongle and it works with the python crazyflie software  and the usb dongle can control the crazyflie drones as well as other drones that operate on     ghz  how can i get the dongle and software to work with the hubsan x   any help would be great  the link for the usb dongle and software    ,python
9239,cartesian space velocity profile to minimize jerk,i am working with a   dof manipulator  currently i have implemented a simple velocity controler along a fixed direction on xyz space  i control the xyz space velocity  xdot  by using a predefined velocity profile against time   joint values are updated based on the defined velocity profile  assume i want to move robot along a direction parallel to z axis  i define a trapezoidal velocity profile  z dot  over time as following   in the robot controller program  i convert this  z dot  to velocity at a time in joint space by multiplying by inverse of jacobian  in this way i can move robot as needed  my question is how we can define the above velocity profile over time  so that the total jerk in joints over time is minimized   your help is really appreciated  ,control robotic-arm manipulator
9240,simulation software for kuka lbr iiwa robot ,i have been working with kuka lbr iiwa   r    robot  with the kuka s ide  which is the  sunrise workbench   since it does not have any virtual platform to verify the code  simulate   it s been quite difficult  as i need to test each code by deploying to the robot  can anyone suggest if there is any simulation software available where i can test the code written using the robotics api in sunrise workbench  i came across v rep simulation software  but  not sure if i can use my code in the workbench platform  appreciate if anyone can shed some light on it  thanks in advance  ,robotic-arm simulation
9241,use matlab compiler sdk generated package in kuka sunrise workbench,the matlab compiler sdk allows to create a wrapper for a matlab function which can be accessed by java software  based on my understanding  kuka s sunrise workbench ide uses most of the standard java functions   i was trying to read the package generated using the matlab compiler sdk  the new version of matlab builder ja  into the workbench platform  i could successfully read the package into eclipse ide  but not into workbench  the reason for using the compiler sdk is that  i have some functions is matlab  and i want to use the same in the workbench programming  does anyone have experience with the same  appreciate any help  ,matlab robotc
9243,how is it possible to decouple mimo transfer function of robot to multi siso system,here there is a mimo transfer function with size of        inputs and   outputs    is it possible to decouple the interaction between the loops and how can we get multi siso system from g   ,control
9244,ros tutorials no longer working,has anyone ever run into a case where a fresh install of ros cannot run its tutorial packages  i am running ros indigo on an nvidia jetson tk   using the nvidia supplied ubuntu image  i just did a fresh install  ubuntu and ros  just to keep things clean for this project  i am building a kind of  demo bot  for some students i will be teaching  it will use both the demo files and some of my own code  now  after setting things up  i try to run the talker tutorial just to check to make sure that everything is running  and rospack is pretty sure that the tutorials don t exist  for example  inputting this into the terminal  outputs  rospack  error  package  rospy tutorials  not found  this is the case for every tutorial file  python and c    now  i am sure the tutorials are installed  i am looking right at them in the file system  installed from the latest versions on github  so i think it is something on ros  side of things  has anyone ever bumped into something similar before  where a ros package that supposedly was installed correctly isn t found by ros itself  i would rather not have to reinstall again if i can avoid it  edit    after playing with it some more  i discovered that multiple packages were not running  all of them   some turtlebot code  and some of my own packages   returned the same error as above  so i suspect something got messed up during the install of ros  roswtf was able to run  but it did not detect any problems  however  going forward  edit    i double checked the bashrc file  one export was missing  for ros directory i was trying to work within  adding it did not solve the problem   i am still looking for a solution  that hopefully does not involve reflashing the tk   edit    alright  so i ve been poking at this for a few days now and pretty much gave up trying to get ros to work correctly  and decided a re flash was necessary  but i think i found something when i booted up my host machine  in my downloads folder  i have the v    and the v    jetpack  i know i used the v    for this latest install  and it has been the only time i have used it  it provides some useful updates for opencv and bug fixes  among other things   i m going to re flash using the v    jetpack this time  see if things behave better with ros under that version  its a long shot  but it is all i have to work with at the moment  and it shouldn t lose any ros capabilities  aside from some of the stuff i wanted to do with opencv   i ll update everyone if that seems to work  edit    ok  everything seems to be working now  the problem does seem to be an issue with jetpack v     i suspect that some change  somewhere between v    and v     made to accommodate the new tx  board   messes with running ros indigo on a tk   i m going to be a more detailed explanation in an answer to this question  ,ros
9246,simulation of robots,i am designing a new mechanism similar to robot arm  it would be a   or   axis with arms but not the same with traditional articulated arms  as a result  new dh matrix and inverse kinematics involve  i would like to consult the robot professionals in this forum that do you suggest any simulation tool of this mechanism  i plan to start with start and end points  then i will do a trapezoid velocity plan and take sample points with sampling time along the path  after that  i would like to transfer these sampling points to motor joints by dh matrix and inverse kinematics  finally i would do some basic  d animation to visualize the movement temporally  i do not plan to simulate controller behavior because in my application motor drivers deal with it  i only need to focus on sending reasonable commands to motor drivers   in my opinion  matlab  octave  vc    and some third party tools are candidates  starting from ground zero would be a time consuming work  i would appreciate if any experts can share a tool or open source code from his or her experience  i did some search on matlab robotics toolbox but i am not sure if it fits my need because it is expensive and optimized for ros  in octave there are also some robotics toolbox but i am not sure about what it can do and what it cannot   ,robotic-arm matlab simulation c
9250,quadcopter pid  controller is saturating,good day  i am currently creating an autonomous quadcopter using a cascading pid controller specifically a p pid controller using angle as setpoints for the outer loop and angular velocities for the inner loop  i have just finished tuning the roll pid last week with only     degrees of error however it is very stable and is able to withstand disturbances by hand  i was able to tune it quickly on two nights however the pitch axis is a different story  introduction to the problem  the pitch is asymmetrical in weight  front heavy due to the stereo vision cameras placed in front   i have tried to move the battery backwards to compensate however due to the constraints of the dji f    frame it is still front heavy  in a pid controller for an asymmetrical quadcopter  the i gain is responsible for compensating as it is the one able to  remember  the accumulating error  problem at hand i saw that while tuning the pitch gains  i could not tune it further due to irregular oscillations which made it hard for me to pinpoint whether this is due to too high p  i or d gain  the quadcopter pitch pid settings are currently at prate        irate      drate          pstab   giving an error from the angle setpoint of   degrees of     degrees  here is the data with the corresponding video  rate kp           ki         kd            stab kp   video   plot   analysis of results it can be seen that the controller is saturating  the motor controller is currently set to limit the pwm pulse used to control the esc throttle to only     ms or     in the code  the maximum is     ms or      with the minimum set at     or     ms  enough for the quad to lift itselft up and feel weightless   i did this to make room for tuning the altitude height pid controller while maintaining the throttle ratio of the   motors from their pid controllers     is there something wrong on my implementation of limiting the maximum throttle   here is the implementation   possible solution i have two possible solutions in mind  i could redesign the camera mount to be lighter by       grams  to be less front heavy i could increase the maximum throttle but possibly leaving less room for the altitude throttle control    does anyone know the optimum solution for this problem   additional information the quadcopter weighs about     kg and the motor esc set from dji  e     is rated up to    kgs with the recommended thrust per motor at    g     kg   though a real world test here showed that it is capable at    g per motor with a setup weighing at     g take off weight  how i tune the roll pid gains i had set first the rate pid gains  at a setpoint of zero dps  set all gains to zero  increase p gain until response of the system to disturbances is in steady oscillation  increase d gain to remove the oscillations  increase i gain to correct long term errors or to bring oscillations to a setpoint  dc gain   repeat until desired system response is achieved  when i was using the single loop pid controller  i checked the data plots during testing and make adjustments such as increasing kd to minimize oscillations and increasing ki to bring the oscillations to a setpoint  i do a similar process with the cascaded pid controller  the reason why the rate pid are small because rate kp set at     with the other gains at zero already started to oscillate wildy  a characteristic of a too high p gain    i had set the rate pid s such that it would maintain the angle i physically placed it to  setpoint at   degrees per second   i then used only p gain at the outer loop stabilize pid to translate the angle setpoint to velocity setpoint to be used to control the rate pid controller  here is the roll axis at    degrees set point  rate kp         ki          kd          and stabilize kp      it is very stable however the reaction time rise time is too slow as evident in the video  ,quadcopter pid stability
9254,pure arduino quadcopter,i recently bought a set of escs  brushless outrunner motors and propellers  i m trying to perform a calibration on the esc  but i can t find how i can do that without using components other than the arduino uno itself  the setup i ve managed to make is the one shown in the picture  the escs are a mystery  as there is no manual to be found  if it helps  the buy link is this    there might also be a problem with the battery  lipo    v      mah    can andybody figure out what i m doing wrong  the sample arduino code i found was this   ,arduino quadcopter esc
9256,  way check valve,i am working on a micro dispensing system  using syringe pump  the design involves a syringe on top to be moved by stepper motor  there would be one liquid reservoir form which the syringe would pull liquid from  and push it to eject liquid from other end   when we pull the syringe  the liquid is sucked into the syringe  while the other opening is shut  when the syringe is pushed  the liquid is ejected from the other end  the quantity of liquid to be dispensed would be very small     mg  so i am using small syringe of   or   ml    as per my measurement  after every     dispensing operations    ml syringe would be empty and we would need to pull liquid from the reservoir into the syringe  and do the dispensing again   my question is  i am unsure about the check valve here  is there a  single  check valve available which would allow this kind of flow to happen   ,motor design
9260,how difficult it is to build simple robots  for example line follower  using raspberry pi and ros ,i want to build a low cost robot  running ros for educational purposes  it can be a simple line follower using raspberry pi and an ir sensor  is it overambitious as a beginner project  how difficult is it to make ros run on custom hardware  p s  i am newbie in both robotics and programming and i am more interested in building actual robots than running simulations  also  i cant afford to buy ros compatible robots  ,ros raspberry-pi electronics
9262,topics of object perception for pr ,i started to use ros hydro  robot operating system  on ubuntu  using the simulator  gazebo  and roscpp library  in order to program some robots   in case of pick up and place known objects by robots  what are the topics of object perception for pr  in ros   ,ros gazebo
9263,are operational space and joint space dependent on each other ,some questions about this  my friends and i argued with this problem  are operational space and joint space dependent on each other  i know that   end effector s pos   and   joint var   can be expressed by an equation with non linear function    but i don t think that it tells us operational space and joint space are dependent   ,kinematics
9265,waiting for the r gripper sensor controller gripper action action server to come up,i started to use ros hydro  robot operating system  and roscpp  i tested some examples to move the gripper of pr  in gazebo  especially the code in       with catkin package  i launch   roslaunch pr  gazebo pr  empty world launch  and when i run the node of code with   rosrun pack name node name  i get    waiting for the r gripper sensor controller gripper action action server to come up     waiting for the r gripper sensor controller gripper action action server to come up     i want to know the cause of those lines in order to see the results  what should i do   it is notable that when i launch   roslaunch pr  gripper sensor action pr  gripper sensor actions launch       in the previous link  i get     pr  gripper sensor actions launch  is neither a launch file in package  pr  gripper sensor action  nor is  pr  gripper sensor action  a launch file name ,ros gazebo
9267, d localization with   lasers,i have to know where a multi rotor is  in a rectangular room  via   lasers    on each axis  the problem is like this   inputs    room   square       meters by    meters   positions of the lasers   fixed on the frame   orientations of the lasers   fixed on the frame the   measurements of the lasers the quaternion from the imu of my flight controller  pixhawk   the origin is centered on the gravity center of the multi rotor and defined as if the walls are perpendicular to each axes  the normal of the wall in x is             output    position in  d  x y z  angular position  quaternion   since i got the angular position of the multi rotor  i rotated the laser positions and orientations via the quaternion  then extrapolate via the   measurements and i got the   walls   orientations of the walls are trivial  then only one point is enough to determine its position  badly  i noticed that the yaw  rotation about z  measurement from the pixhawk is unreliable  then i should measure the yaw from the lasers  but i do not success to do it  event if the  d problem is easy  i am lost in  d  does someone know if it  algorithm to know xyz position and quaternion from   measurments  exists somewhere   or what is the right way to go on this problem    the question   how could i get the yaw from   measurements from   lasers which i know the original position  orientation and the pitch and roll   note   green pointers are the origin position  red pointers are the  final  position  but could be rotated around the red circle  due to yaw    ,algorithm geometry
9269,suggestions on object types  features  to track from ardrone   camera, update   i have aded    bounty for this question on the stackoverflow  i am trying to implement object tracking from the camera just one camera  no z info   camera has          resolution  but i usually rescale it to         for faster processing  this tracking is done from the robots camera and i want a system which would be as robust as possible   i will list what i did so far and what were the results   i tried to do colour tracking  i would convert image to hsv colour space  do thresholding  some morphological transformations and then find the object with the biggest area  this approach made a fair tracking of the object  unless there are no other object with the same colour  as i was looking for the max and if there are any other objects bigger than the one i need  robot would go towards the bigger one then  i decided to track circled objects of the specific colour  however  it was difficult to find under different angles then  i decided to track square objects of specific colour  i used this     and then i checked this condition  if  approx size           approx size          and afterwards i checked for  solidity        and aspect ratio between      and       but still result is not as robust as i would expect  especially the size  if there are several squares it would not find the needed one   so  now i need some suggestions on what other features of the object could i use to improve tracking and how  as i mentioned above several times  one of the main problems is size  and i know the size of the object  however  i am not sure how i can make use of it  because i do not know the distance of the object from the camera and that is why i am not sure how to represent its size in pixel representation so that i can eliminate any other blobs that do not fall into that range  update in the third step  i described how i am going to detect squares with specific colour  below are the examples of what i am getting   i used this hsv range for the red colour   scalar               scalar                 params to opencv s inrange function hmin        hmax        smin        smax        vmin      vmax           would like to see your suggestions on tweaking this values as well   so  in this picture you can see the processing  gaussian blurring        morphological closing two times        and the image with the label  result  shows the tracked object  please look at the green square    on the second frame  you can see that it cannot detect the  red square   the only main difference between these two pics is that i bended down the lid of the laptop  please look closer if you cannot notice   i suppose this happens because of the illumination  and this causes the thresholding to give not desired results    the only way  i can think of is doing two separate processing on the image  first  to do thresholding based on the colour as i was doing above  then if i find the object to move to the next frame  if not to use this opencv s find squares method  however  this method will involve doing too much of processing of the image   ,quadcopter cameras opencv
9274,action cost to get smooth path,what action cost should be used to get a smooth path  like we use distance traversed to get the shortest path  will the cost to get a smooth path will be something related to rate of change of slope of the path  ,motion-planning
9276,papers on algorithms in robotics,i m a cs student and i need to give a    minute lecture about     papers describing     algorithms for any of the main problems in robotics  navigation  coverage  patrolling  etc    i have no background in robotics specifically  but i did take classes such as algorithms and ai  including some basic ai algorithms such as a   ids  ucs  and subjects such as decision trees  game theory  etc    the difference between simply describing one of the above is that i need the paper to refer to actual physical robots and their algorithms  with real problems in the physical world  as opposed to ai  agents  with more theoretical algorithms  i am required to lecture on     academic papers  published from      onward  with a  respectable  amount of citations  any suggestions of such papers would be greatly appreciated  ,navigation algorithm theory coverage
9277,how to guide a camera through a circular tube ,let s say i have a   dof flying camera and i want to make it move through a circular tube autonomously and let s suppose that the camera and the system that makes it fly are considered to be just a point in space  which feature of the image i get from the camera can i use to move the camera appropriately  that is to get in one end of the tube and get out from the other   for example  i thought i could use edge detection  as the camera moves forward through the tube  due to the fact that its far plane is not infinitely away  there is a dark circle forming where the camera sees nothing surrounded by the walls of the tube  i think that  preserving  this circle might be the way to go  for example if it becomes an ellipse i have to move the camera accordingly for it to become a circle again   but what are the features that will help me  preserve  the circle  i would like to use image based visual servoing to do that  however  what troubles me is the following  in most visual servoing applications i have seen  the control objective is to make some features  look  in a certain way from the camera point of view  for example  we have the projections of   points and we want the camera to move accordingly so that the projections  coordinates have some specific values  but the features are actually the same   in my case i thought that for example i could say that i want the projections of the    edge points  of the circle ellipse to take specific values so that they define a circle centered at the fov of the camera  but if the camera moves to achive this setup of features  then the   new  edge points  will correspond to the projections of   different real points of the pipe and the theory collapses  am i right to think that  any way to get past it  any oher ideas or relevant literature  ,localization cameras motion-planning visual-servoing exploration
9280,inverse kinematics with singularity in matlab,i want to find the general coordinates q  alpha beta gamma     revolute joints  that minimizes the norm   rgoal   r     with rgoal not included in the manipulator workspace   the problem is already solved for coordinates rgoal inside the manipulator workspace  but i really dont know how to do that for singularities   a stopping criteria i can use is  norm rgoal r bf inb q old    q old    q old       norm rgoal r bf inb q    q    q       but that does not really give me the correct answer  how can this be solved in general for a rgoal outside of the workspace  ,inverse-kinematics
9282,mobile phone power packs,for my robotics project i would like to utilise readily available mobile phone  power banks  to simplify the power system for my robot  however  such power banks output  v  great for the logic systems but not for the motors   i was wondering if i could wire the outputs of two power banks in series and get   v or is this a very bad idea  should i wire them in parallel and use a boost converter  is a custom solution using  ordinary  li po batteries and associated charging circuit the best answer  additional information   this will be a two wheeled robot   v logic   v motor driver power banks   v    amp     mah  ,mobile-robot power battery
9290,micro powder dosing,i am in process of designing a micro powder doser for metallic powder into plastic capsules  the capsule volume would be bigger than what we require  so traditional capsule filling wont work   the quantity i need to dose is     mg    what in your opinion would be the best approach for this   as per my research  i have found out that there can be   approaches  auger based solution  where an auger is used to control the powder drop gravitationally      volumetric as powder quantities would be small  a metal rods with groove of proper volume can be designed to dispense powder  for keep powder flowing we can use a vibration motor to pour powder in the groove  a stepper motor can rotate the rod for dispensing the powder  i have made the rod bigger to show the concept  and then how it would be mounted in a cap so when we rotate it that much volume of powder is dropped from the cap     weight based measurement  dropping powder on to a weighing balance  and control it via feedback    i think it would be a difficult thing to do  plus time consuming  provided we d have to fill thousands of capsules   prio     is accuracy  with an error margin of           secondly cost    i d like it not to be too costly                  the metal powder is not magnetic    is very fine    and doesn t clump    i have read articles and it appears by continues tapping the powder flow can be improved a lot  ,arduino motor
9294,choosing a battery  is a harbor freight solar battery ok for a r c lawnmower ,i have built an r c lawnmower   i call it the honey badger  because it tears stuff up  that s a good thing    well  i used used batteries to get the project going and now it s long past time to get the honey badger going again  the honey badger is built on an electric wheelchair frame  and originally used wheelchair deepcycle batteries   u  if i recall   there are   of them wired in   banks in series and parallel to give   v for the   v motors  going down to the used wheelchair parts place is about an hour drive and requires a weekend visit and will get me used batteries of unknown condition    contrast that with harbor freight  which is    minutes away and has solar batteries the same physical dimensions and comparable     electrical characteristics   i think with coupons  tax  and after playing the game  i can get a battery for      for   with shipping  batteries plus will sell me some deepcycle auto batteries of greater ah capacity for                is there a difference in technology between a  solar battery  and a  wheelchair battery    is that difference substantial   given that i m pretty rough with this thing  is any particular technology any better suited to these tasks   is there a benefit or drawback to using an automotive battery  i have the charger from the original wheelchair and if i recall  it s good for the capacity and has room to spare   i think it can put out   amps   ,battery
9296,why does my roboclaw seem to be ignoring the pid gain settings ,i m seeing a behavior in my roboclaw  x  that i can t explain   i ve been trying to manually tune the velocity pid settings  i don t have a windows box so i can t use ionmc s tuning tool  by using command    to set the velocity pid gains  then command    to verify that they re set correctly  then    to spin the wheel at half of its maximum speed   the problem is that no combination of pid gains seems to make any difference at all   i ve set it to       and the motor still spins at roughly the set point  i must be doing something wrong  but i m pouring over the datasheet and i just don t see what it is   by all rights the motor shouldn t spin when i use         any ideas  ,control pid
9297,finding rotation quaternion,i am trying to use a quaternions for robotics and there is one thing i don t understand about it  most likely because i don t understand how to define position with quaternions and how to define rotation with quaternions if there is any difference   please watch my  understanding steps  and correct if i am wrong somewhere  lets assume i we have   vehicle positions described by   rotation quaternions   q     w     x  i   y  j  z  k    cos  pi       sin  pi   i  this quaternion is normalized and represents rotation over the  axis for  angle as i understand it   q     w     x  i   y  j   z  k    cos  pi       sin  pi   k  and this one represents rotation for the same angle  over the  axis   which would be the same rotation as if we made  first and  second   q      frac          frac i       frac j       frac k     question    given  and  how can i find   question    how to find a rotation angle over some other vector  given rotation quaternion  for example i want to find on what angle does  turned over  quaternion  ,kinematics
9298,finding high torque servo for robotic arm,i am new working with robotic arms but i am having trouble finding the correct servo for the base of the arm   it is a   link robot   each link weighs     kg and is    cm long  i have a gripper of    centimeters  the servo in the gripper can hold a max of  kg  the whole robotic arm  including the maximum load it will carry and the servos and other accessories  is     kg  the maximum load it needs to carry is   kg at the end of the arm at    cm   what servo could i use to move the rotary base and what servo could i use to lift the arm in the base  the last one is to move the link so it would be preferable to have a   axis servo  the only specification i need right now is what servo to use my energy supply are two    volts dc batteries connected in series with   ah  i need the servo to be dc  the other things can be worked around the servo that can best do the work  ,robotic-arm servomotor
9301,direct vs semi direct methods for visual inertial odometry,i was reading these papers on visual inertial odometry from iros     semi direct ekf based monocular visual inertial odometry robust visual inertial odometry using a direct ekf based approach  i would appreciate if someone could explain how semi direct and direct methods vary exactly  as far as i understand  direct methods use pixel intensities in their framework  however  both these papers listed above use photometric intensities pixel intensity values and yet one is semi direct and the other s direct   ,ekf
9302,output angle of dc motor   with current input,what is your preferred time domain method to simulate ideal position of a motor given an electrical current input  assume that the goal is to plot the position output of a motor  based only on a constant electrical current input  for example  x amps are given to the motor  plot the output angle y as a function of time  using only time based tools  not laplace or matlab outputs             two methods             here are two methods  which yield different results for some reason  any ideas why they are not identical  input is a constant current   method    find updated velocity given an acceleration acc k     i k  kt   b vel k       j vel k    vel k      acc k  dt pos k      pos k    vel k  dt        acc k  dt   so  as desired  this is just a function of  i   this version has a less stable  oscillating output  regardless of which order vel and acc are computed in  method    find velocity using difference between positions  this could obviously be a noisy result  in practice would need to be filtered  acc k     i k  kt   b vel k     j vel k     pos k    pos k       dt pos k      pos k    vel k  dt        acc k  dt   as before  this position equation is then ultimately just a function of i  however  this version has a smoother output                        appendix    for method      assume an ideal current driven dc motor laplace model  angvelocity current   kt  js b   kt is motor constant  j is rotor inertia  and b is damping  then acc j   b vel   current kt  so acc k       current k  kt   b vel k     j  as a reminder  vel k  was found using the previous acceleration via v k    v k      acc k    dt as noted above in method     ,motor kinematics servomotor simulation
9303,ultrasonic sensor s lag    hz  effect on pid contol loop rate     hz ,good day  i would like to ask how is it possible to use an ultrasonic sensor for altitude hold in a quadcopter if the sampling rate of the ultrasonic sensor  hc sr    is only   hz before incurring any errors through polling when i had tested it  i have seen this sensor being implemented on other projects however i could not find any papers that explain the use of this sensor in better detail  i have seen possible solutions on the raspberry pi one using interrupts and the other using linux s multithreading  if my understanding is right  to use interrupts  i need a some sort of data ready signal from the ultrasonic sensor  however this is not available in this particular sensor  is it possible to use the echo pin as the positive edge trigger for the interrupt service routine  read sonar calculate distance function   but would this not introduce inconsistent loop execution times which is bad for a consistent pid loop  another approach is to use multithreading using the wiring pi library which enables me to run a function  let s say a function that triggers the sonar and calculates the distance along side the pid control loop  how would this affect the pid control loop rate   which is the best way to implement sonar sensor based altitude hold   ,quadcopter pid stability real-time sonar
9305,create   light red green,i am working on a project with the create    just recently i have run into a problem with the battery state  the create   has been charging all night so its clean light shows green  however  when i unplug it and press the clean button  it shows red and will not consistently run commands from my arduino that i have hooked up to it   what could be the problem  ,arduino irobot-create battery
9312,kuka delimiter  net,i have a chance to develop a user interface program that lets the user control a kuka robot from a computer  i know how to program stuff with the kuka utilities  like orangeedit  but i don t know how to do what i want to do  i don t even know what s the  best  language to talk to the robot  my idea is to control the robot with the arrow buttons  like up down controls the z axis and left right controls the x y axes  can someone help me here  i know there s a lot of libraries to control the robot even with an xbox controller  but if i limit the robot to   axes i might be able to control with simple buttons   edit  now imagine that i have a routine that consists on going from p  to p  then to p   i know i can  touch up  the points to refresh its coordinates using the console  but can i do it in a  net application  like modifying the src srcdat files  ,robotic-arm kuka
9313,how to detect wall corners  fans  lights in an indoor using cv ,im currently working on an autonomous indoor quad rotor  for this purpose i m using opencv to enable computer vision in my drone  i need to be able to detect wall corners  fans  both stationary and rotating   lights and lamps  wall paintings and any other object associated with the walls and ceiling of an indoor environment  until now i have come up with two ideas to achieve this      establish ml  machine learning   use feature descriptors like sift  surf to collect a set of feature descriptors from a training set and try detect the objects of interest  the main issue with this is the access to sift and surf algorithms as they are not available in opencv        implement slam algorithm and map the environment and then use the information returned to identify the wall corners  of course this way i will be not able to detect fans and lights   so the question is  is there are any other methods i could use other than ones listed above in order to achieve my goal  am i missing something on image segmentation  clustering or image transforms  hough line circle  which could be utilised in my situation   thanks ,computer-vision machine-learning opencv
9318,understanding drift in simultaneous localization and mapping  slam ,i am trying to understand the effect of drift in simultaneous localization and mapping  slam   my understanding is that drift occurs because the robot tracks its position relative to a set of landmarks it is storing  but each landmark has a small error in its location  therefore  an accumulation of these small errors over a long trajectory causes a large error by the end of the trajectory  however  what i am confused about is what would happen when the robot tracks its way back to its starting positions  suppose the robot starts in position a  and then starts to move along a path  mapping the environment as it does so  until it reaches position b  now  the robot will have some error in its stored position of b  due to the drift during tracking  but then suppose the robot makes its way back to a  by tracking relative to all the landmarks it created during the first path  when it reaches a  will it be back at the true position of a  i e  where it started the first path  or will it have drifted away from a  my intuition is that it will end up at the true position of a  because even though the landmarks have errors in them  as long as the error is not too large then the robot will eventually get back to the position where it stored the landmarks for a  and once it is there  those landmarks are definitely correct  without error  because they were initialized before any drift errors had started to accumulate  any help  thanks  ,mobile-robot localization slam navigation mapping
9320,why is quadrotor motion planning hard ,with introduction of incremental sampling algorithms  like prm and rrt planning in higher dimensional spaces in reasonable computation time has become possible though it is pspace hard  but why is a quadrotor motion planning problem still difficult even with simplified quadrotor model   i was solving a dynamic car problem with ompl  which produced solution within   s but i set a planning time of    s for quadrotor  but it still does not find a solution  ,mobile-robot quadcopter motion-planning planning rrt
9321,having a hard time understanding this equation in monocular ekf slam,reading this paper on visual odometry  where they have used a bearing vector to parameterize the features  i am having a hard time understanding what the state propagation equation for the bearing vector term means    the vector n is not mentioned in the equations  so its not very clear what it does  would really appreciate if someone would help me understand it    ,localization slam navigation ekf mapping
9323,lateral load on a servo motor,looking at pictures of existing designs for quadropod robots  the servos in the legs seem to usually be mounted inside the chassis  with a second attachment at back of the servo as well  such as this   rather than putting what looks like an asymmetrical load  like the knees here   is this for aesthetics or are there real structural reasons to minimize the lateral load on the axle on a robot of this size  ,joint
9324,quadcopter pid tuning for altitude hold position hold along z axis,good day  i have just finished tuning the pitch and roll pid s  i did this by setting the throttle such that the quad is weightless  i did the tuning of each axes separately  i would just like to ask what is the best way to tune the pid for maintaining an altitude setpoint   is it best to turn off the pitch and roll pid controllers while tuning the altitude pid or is it best to have them already active while tuning the latter controller   i am going to use a cascaded pid controller using the velocity along the z axis calculated from the accelerometer output for the inner pid loop     hz  and the altitude measurement of the hc sro  ultrasonic sensor    hz  for the outer pid loop  ,quadcopter pid stability real-time sonar
9327,vision based position estimation for a quadrotor,as a subtask inside a main project i need to compute the position  x y z  of a quadrotor using an homography   to do this i will use a camera  attached to the quadrotor  pointing down to an artificial landmark on the floor  basically i need to compute the extrinsic parameters of the camera to know the pose with respect to the landmark  i know the projective points of the landmark in the camera  and the intrinsic matrix of the camera but i also need the real landmark position  x  y  z   i suppose that z coordinate is equal to   because the landmark is plane  but i am not sure how to compute the real  x y  coordinates  any idea how to do that  i am also interested in put the  x y z  position of the quadrotor into a control path  anybody knows where i can find info about the most common controllers for do this kind of task  ,control computer-vision quadcopter uav visual-servoing
9334,controlling syma x c from a laptop,out of curiosity  it is possible to control my x c from a computer  i think that i can buy a transmitter to attach to my laptop  do you think that the communications between my transmitter and the drone be over some proprietary protocol  or would they adhere to some standard  if you have any links advice that could point me in the right direction  that would be appreciated  ,quadcopter
9336,jacobian for inverse kinematics with quaternion of end effector,quaternion has four parameters  calculating jacobian for inverse kinematics    positions and four quaternion parameters make jacobian  instead of   how to reduce jacobian to  when using quaternion  ,robotic-arm inverse-kinematics jacobian
9337,suitable d star variant is for non holonomic motion planning of mobile robots,i am working on a non holonomic motion planning problem of a mobile robot in a completely unknown environment  after going through some research papers  i found that d star algorithm is widely used in such conditions  but there are many d star variants like focused d   d  lite  field d  etc    so which of these variants is suitable in this case  also please suggest any other better approach for this problem  ,mobile-robot motion-planning algorithm
9341,computer stereo vision simulator,in my research project i deal with a mobile robot that perceives through stereo vision  as the stereo input data i currently use several datasets taken from a passenger vehicle that contain real world photos  the datasets are good to get started but have a limited content so i would need to model my own traffic situations to further work on the stereo vision system  i am thinking about using some kind of synthetic graphics simulation as the input for the stereo system  what are my options  i can imagine a  d graphics rendering engine whose output would be fed as the input for the stereo vision could probably be used  i found there are general robotic simulators available like gazebo but since i am all new to robotic simulation i do not really know where to begin  edit  i forgot to write that all my code is a pure c    i use opencv and libelas for stereo vision and point cloud library  pcl  for visualization  all glued together into a single c   project and compiles into single binary  ,mobile-robot simulator stereo-vision
9342,zigbee like network for fpv,zigbee is not designed for video transmission  i need a mesh network which contains multiple nodes like zigbee for networking robots fpv  is there any solution   ,communication
9344,which geo projection to use for odometry,i would like to make a little survey regarding the  geo spatial projection that you use when elaborating your gps and movement data for the spatial awareness of your robots   moving all gps coordinates to a planar projection seems to be the more reasonable choice since not only distances  for which several formulas and approximations exist   but bearings must be computed  generally  although scales are pretty small here  avoiding equirectangular approximation seems a good idea in order to keep a more consistent system  avoiding working in the  d world  haversine and other great circle stuff  is probably a good idea too to keep computations low cost  moving the world to a  d projection is hence what seems to be the best solution  despite reprojection of all input gps coordinates is needed   i would like to get opinions and ideas on the subject      if ever anyone is interested in doing it u u   ,odometry geometry
9346,pick and place robot,i have to simulate a pick and place robot    dof   i tried with matlab  it should pick and place different objects according to their geometry   where can i find similar m codes and algorithms  ,robotic-arm matlab
9349,applying mocap data to real life robot,i have a kinect sensor  and ipi software i use to create motion capture data to use in film editing  i am looking at creating a small  raspberry pi driven bipedal robot just for fun  and i was wondering if it was possible to use the mocap to control the robot  it will only be       cm tall  with six servos  hips  knees  ankles   is it possible to apply the movement from these six joints on the human body to my robot  like having a string directly from my left knee joint to its left knee servo  it could either be in real time  like following my actions  or using pre recorded data   note  if needed  i can plug it directly to my apple windows computer  if the pi could not support this  also  it will have no upper torso at the moment   ,mobile-robot motion-planning servos
9351,which kind of valve is used for dispensing food grains ,i am doing a project on an automated grain dispenser system using a plc control  i need a valve for dispensing grain from hopper to packet  i should be able to control the flow of the grain   so what kind of valve should i use for flow control of the grain  there are different types of grains like rice  wheat  etc   and the valve should be controlled by the plc  opening and closing of valve   ,automation
9353,why does the esc stop ,i ve built a quadcopter with four brushless motors and escs    a   i m using an arduino to control them  i haven t written any complex code  just enough to get them running  everything is fine until i send a number over     to the serial  then  for some reason  all the motors stop spinning  i m using three freshly bought and charged lipo cells  v       v   here is the link for the site that i bought them from  i cannot seem to find any other resource about them     x a         kv outrunner motor    x hp   a esc    x      prop  b  quad rotor   when i tried turning on only one motor  i could write up to about      microseconds  while both with   and with   motor  the minimum that it works is       can somebody explain why this happens and i how i can fix it   here is my code    ,arduino quadcopter brushless-motor esc
9355,dynamic model of a robot lifted by a balloon  multibody system ,i m having a hard time trying to understand how to obtain the dynamic model for a system similar to the image    the balloon is a simple helium balloon  however the box is actually an aerial differential drive platform  using rotors   now there s basically a model for the balloon and another for the actuated box  however i m lost to how to combine both   the connection between both is not rigid since it is a string  how should i do it  is there any documentation you could point me to  in order to help me develop the dynamics model for this system   since i m so lost  any help will be useful  thanks in advance     ,mobile-robot kinematics dynamics
9365,difference between an underactuated system  and a nonholonomic system,what s the difference between an underactuated system  and a nonholonomic system  i have read that  the car is a good example of a nonholonomic vehicle  it has only two controls  but its configuration space has dimension      but i thought that an underactuated system was one where the number of actuators is less than the number of degrees of freedom  so are they the same  ,kinematics
9367,relationship between motor torque and acceleration,i am working on designing and building a small        lbs     wheeled  differential drive arduino controlled autonomous robot  i have most of the electronics figured out  but i am having trouble understanding how much torque the motors will actually need to move the robot  i am trying to use the calculations shown here and the related calculator tool to determine what speed and torque i will need  i will be using wheels   mm in diameter and one of pololu s high power micro metal gearmotors  i performed the calculations for a robot weight of   lbs to be safe and found that the      hp micro metal gearmotors      rpm     oz in  should theoretically work fine  moving the robot at      ft s with an acceleration of around    ft s   up a   degree incline   however  i have not found an explanation for several things that i think would be very important to know when choosing drive motors  when the robot is not moving and the motors are turned on at full power  they should need to deliver their full stall torque  based on the calculations  it seems that any amount of torque can get the robot moving  but the more torque  the faster the robot s acceleration  is this true  also  if the power source cannot supply the full stall current of the motors  will the robot not be able to start moving  in my case  i am powering the robot through a    v   s      mah nimh battery pack that can provide around    a continuously  and when it does that the voltage drops to less than  v  will this be able to power my motors  once the robot reaches full speed and is no longer accelerating  theoretically the motors will not be providing any torque  but i do not think this is the case  is it  and if so  how will i know how much torque they will be providing  will the motors i chose have enough torque to move my robot  ,mobile-robot motor
9370,thermal imaging camera activation upon detection,so i am planning on building a robot that turns on when it detects some kind of heat source  i am currently looking at thermal imaging cameras  but am not sure as to how to go about writing code to send a ping or some sort of message when the camera detects a heat source  does anyone know of any way to do this  thanks  ,wheeled-robot
9371,reliably establishing communication and oi mode with create  ,i ve started tinkering with a create    but i m having issues reliably getting it to accept my commands   i can occasionally get it right  but sometimes  it just seems to ignore me   i m guessing my cleanup code isn t getting the state fully reset or something   is there a good pattern to follow for fail safe initialization code  here s what i m doing right now   pulse brc low for   second wait   second send   x   bytes  to make sure if it s waiting for the rest of a command  this completes it   seemed to help a bit when i added this  send    reset  wait    seconds send      start  wait   seconds send         ask for the current oi state  wait   second send      safe mode   sometimes i m then able to issue      drive  commands and have it work   most times it doesn t   the times when it doesn t  i m seeing a lot of data coming from the create   that i m not expecting  that looks something like this  hex bytes    there s more  but my logging cut it off   i get the same pattern a couple of times  and it seems to be at least partially repeating   i thought maybe it s the      bytes i sent followed by    f  aff        cc  a    but i still don t know how to interpret that  sometimes it will make some noise for the reset command  but usually ignores the start safe mode commands completely  i can tell because the green light stays on   ,irobot-create
9372,real time object classification for an indoor autonomous quad rotor,i am designing an indoor autonomous drone  i am currently writing an object classification program in opencv for this purpose  my objects of interests for classification are  ceiling fans  ac units  wall and ceiling lamps  and  wall corners  i am using bow clustering algorithm along with svm classifier to achieve this  i m still in the process of developing the code  and i might try other algorithms when testing   the primary task of the drone is to successfully scan  what i mean by scanning is moving or hovering over the entire ceiling space  a ceiling space of a given closed region while successfully avoiding any obstacles  like ceiling fans  ac units  ceiling and wall lamps   the drone s navigation  or the scanning process over the ceiling space  should be in an organised pattern  preferably moving in tight zig zag paths over the entire ceiling space  having said that  in order to achieve this goal  i m trying to implement the following to achieve this   on take off  fly around the given closed ceiling space and use slam to localise and map its environment  while running slam  run the object classier algorithm to classify the objects of interests and track them in real time  once obtained a detail map of the environment and classified all objects of interest in the local environment  integrate both data together to form an unified map  meaning on the slam output  label the classified objects obtained from the classifier algorithm  now we a have fun comprehensive map of the environment with labeled objects of interest and real time tracking of them  localization   now pick random corner on the map and plan a navigation pattern in order to scan the entire ceiling space    so the question now here is  is using object classification in real time will yield successful results in multiple environments  the quad should be able to achieve the above mentioned tasks in any given environment    i m using a lot of train image sets to train my classifier and bow dictionary but i still feel this won t be a robust method since in real time it will be harder to isolate an object of interest  or  in order to overcome this  should i use real situation like train images  currently my train images only contain isolated objects of interests   or in my is using computer vision is redundant  is my goal completely achievable only using slam  if  yes  how can i classify the objects of interest  i don t want my drone to fly into a running ceiling fan mistaking it for a wall corner or edge   furthermore  is there any kind of other methods or sensors  of any type  to detect objects in motion   using optical flow computer vision method here is useless because it s not robust enough in real time   any help and advice is much appreciated  ,mobile-robot quadcopter slam opencv
9373,drawbacks of goal bias in rrt,i am working on rrt planner to remove the goal bias in it and introduce a new method to direct the planner towards the goal  i find this method good for lower dimension  when the dimension increases  especially for a dynamic car  though the new method works better  i observe that the new method along with goal bias works even better   so  what are the possible advantages of removing goal bias will i be loosing by adding it along with the new method   ,mobile-robot motion-planning algorithm rrt
9374,measure weight of an object using a servo,assuming a quality industrial servo  would it possible to calculate the weight resistance of a load  maybe by comparing current draw in a holding position  or by the time it takes to lift lower an object  could it accurately measure grams  kilograms  what kind of tolerance could be achieved  i m trying to eliminate the need for a dedicated weight measurement sensor  ,sensors robotic-arm servomotor
9377,real time simulation model of sensors with matlab,i am trying to make a real time simulink model of leddar sensor  ledddar sensor evaluation kit  in matlab using usb port  but i can t use  data acquisition toolbox  and  instrument control toolbox  because the leddar vendor isn t listed in these toolboxes  i would really appreciate if someone could help me with this because i am new to real time simulink    ,sensors matlab simulator real-time
9380,slam map quardrant,transformation of frame from global to local is crucial for measurement update but how do we keep track of the direction   eg  robot location        and         requires different sign  is there a way to not have to set a if else case and have a general expression   ,slam
9381,pid tuning for quadcopter,i have been stabilizing my quadcopter  i tuned my angle pidies and my quadcopter tries to stabilize itself  but there is some overshooting  which is  i think  due to gyro rates  i have read that we have to use two pidies on an axis  i m having problems to attach these two pidies   can anyone help me in cascading angle pid and rate pid  will i have to tune rate pid after tuning angle pid  ,quadcopter pid
9382,any books or web resources for robotics mechanical design ,i plan to build a mechanism with multiple axis  which is similar to a robot  to start  i need to define some specifications such as repeatable precision  speed  acceleration  and payload  then the motor and structure is selected and designed based on these parameters  after that  i need to choose methods to manufacture these components  i would like to consult experienced experts in this forum that is there any suggested books  textbooks  or website resources i can learn these knowledge   ,mechanism manufacturing books
9383,how to make a robot arm follow a shape path,first of all hope this is not a stupid question but i couldn t find any ware a solution  i have constructed a   dof robot arm  i want it to follow a trajectory on a  d plane  xy   tha shapes i want to follow are lines  cycles and splines  i now the math behind these   shaped  how they are defined   i have the kinematics  the inverse kinematics the jacobian and the whole control system  with the pid controller   the system receives as inputs  xd position   xd  velocity  and xd   acceleration  over time  i found the following image that shows  more or less  my system   so here is were i am stuck  how do i translate the shape to the position  velocity and acceleration that each joint needs to make so the end effector moves in the cartesian space according to that shape  ,pid robotic-arm line-following
9384,pid tuning with methods like ga and pso,i have recently started reading about pid tuning methods and algorithms  and i encountered the particle swarm optimization algorithm and genetic algorithm  the problem is  that i don t understand how each particle chromosome determines his fitness  on real physical system  each particle chromosome checks his fitness on the system  wouldn t it take a really long time  i think that i am missing something here    can those algorithms be implemented on an actual physical system  if so  then how  ,pid algorithm
9386,angle to a circle tangent line,i want to simulate the detection of a moving object by a unicycle type robot  the robot is modelled with position  x y  and direction theta as the three states  the obstacle is represented as a circle of radius r    in my code   i want to find the angles alpha   and alpha  from the robot s local coordinate frame to the circle  as shown here   so what i am doing is trying to find the angle from the robot to the line joining the robot and the circle s centre  this angle is called aux t in my code   then find the angle between the tangent and the same line  called phi c   finally i would find the angles i want by adding and subtracting phi c from aux t  the diagram i am thinking of is shown   the problem is that i am getting trouble with my code when i try to find the alpha angles  it starts calculating the angles correctly  though in negative values  not sure if this is causing my trouble  but as both the car and the circle get closer  phi c becomes larger than aux t and one of the alphas suddenly change its sign  for example i am getting this   begin array  c c c c    text aux t     text phi c     text alpha       text alpha        hline  text           text           text           text            text           text           text           text            text           text           text           text            text           text           text           text           end array  so basically  the alpha   gets wrong form here  i know i am doing something wrong but i m not sure what  i don t know how to limit the angles from   to pi  is there a better way to find the alpha angles  ,mobile-robot kinematics matlab geometry
9388,building a robotic clamp,if i had a single stepper motor how could i use it to create a robotic clamp that could simply grab hold of something like a plank of wood and release it  are there any standard parts that i could use for this  i m having trouble finding out what the names of the parts would be  ,robotic-arm
9391,slam odometer requirement,how accurate must my odometer reading be for slam   i am writing this extra section because it says my question body does not meet the quality standard   ,slam
9395,kuka robot   update coordinates,i need to develop something in order to update some coordinates in a kuka kr c  robot predefined program  after some research i ve found some ways to do it  but all of them non free  i had several options  like developing a hmi in the console with   buttons  to touch up the   coordinates that i have to update for example  sending a xml file would work too but i need a rsi connection  and i can t do it without proper software  i guess   do you know about something like this  or a c   library that allows me to have access the   dat files or to create a new one with the same  body  but with different coordinates  summing up  imagine that i have a conveyor that carries boxes and i need to develop a pick and place program  so far so good  but every     boxes  the size changes  and i can t predict it   so the operator goes and updates the coordinates  but i want to make sure that he won t change anything else in the program  any ideas  ,robotic-arm industrial-robot kuka
9397,if i must fly my drone in bad weather  how can i maintain control of it in strong winds ,if i need to fly a drone in strong winds  how can i stabilize it  should i use accelerometers and gyroscopes to keep it steady  or should i just use some flight technique under such circumstances  ,quadcopter navigation accelerometer
9400,choosing motor type for high reliability for many cycles,i am designing a multi modal stent testing machine which will bend  twist  and compress stents  very thin  light  and fragile cylindrical meshes for in arteries  in a tube  the machine will operate at maximum     hz for months at a time       million cycles   as the machine will be in a lab with people  the noise should be minimal  i am choosing actuators for my design but was overwhelmed by the range of products available  for rotating the stents around their axis  i will need a rotary actuator with the following specs   torque  negligible max angle     deg angular velocity needed  max    deg s hollow shafts are a plus  for compressing the stents  i will need a linear actuator with the following specs   force  low    n  max stroke    mm but if possible   mm for allowing different stent lengths  stroke velocity needed  max    mm s  price of these motors is not the driving factor  i looked into stepper motors  servo motors  and piezoelectric motors  there seems to be s huge selection that fits my requirements  if all motor types have a reliability that suits my needs  which characteristics advantages disadvantages should i consider that determine the selection of suitable actuators  i do know what the difference is between the motor types  but there is a lot of overlap  concrete suggestions are welcome  ,actuator reliability
9403,slam starting point   quardrant issue,i have a question that is puzzling me  i have a simple rectangle enclosure and i have extracted the lidar and odometer data from a test run  if i put my starting position at          it gives bad map  however if i shift it away from       to something like            the map seems fine  how can this be    ,slam
9405,vex cortex motor speeds up under load,i am trying to get my robot to drive straight and am having trouble   i find that when running the motors with no load they run fine   if i put a load on one motor it accelerates   the other performs as expected  it tries to maintain speed   i am running     motors with encoders and pid selected   i am running robot c  see the following video   program is as follows   thank you  mark ,pid robotc vex
9409,why would a drone need a magnetometer  are an accelerometer and a gyroscope not sufficient ,why would a drone need a magnetometer  what would the drone do with this information  i think it would be to tell direction  but why would it need this if it has an accelerometer and a gyroscope  ,mobile-robot magnetometer
9413,rrt algorithm in c  ,i want to implement rrt for motion planning of a robotic arm  i searched a lot on the internet to get some sample code of rrt for motion planning  but i didn t get any  can someone please suggest a good source where i can find rrt implemented in c   for any type of motion planning  ,robotic-arm motion-planning algorithm
9417,how to decide the battery power for my robot,i need my motor to be powered with   v   a for   hour continuously  how can i decide the ah rate of the battery  please suggest some lithium ion battery for the specification ,mobile-robot motor power battery lithium-polymer
9420,why do i need i gain in my outer loop ,i m implementing a set of loops to control pitch and roll angular positions  in an inner loop  motor speeds are adjusted to achieve desired angular rates of rotation  the  inner loop setpoints    an outer loop decides these desired angular rates  the  inner loop setpoints   based on the aircraft s angular positions   outer loop  frequency       hz outer pv   input angular position  in degrees  outer sp   desired angular position   input angular position  in degrees    inner loop  frequency       hz inner pv   input angular rotation  in degrees per second  inner sp   constant    outer mv  in degrees per second  pwm   inner mv   constant   as percentile    i understand what i gain does and why this is important  but i m not able to see any practical reason for also having i gain specified in the outer loop  surely the inner loop would compensate for any accumulated error  leaving no error to compensate for in the outer loop  or is my thinking flawed  any example gain values to elaborate would be greatly appreciated  ,quadcopter pid
9429,drone flight formation,how does one today program a fleet of drones autonomously fly together in a formation with visual feedback from onboard camera  ,quadcopter uav
9434,pose graph slam  how to create edges if only imu odometry is given ,i want to estimate the poses of a vehicle at certain key frames  the only sensor information i can use is from an imu which yields translational acceleration and orientation measurments  i obtain a  d pose  i e   d position vector   unit quaternion orientation  if i integrate the translational acceleration twice and propagate the orientation measurements  if i want to add a new edge to the graph i need a constraint for that edge  in general  for pose graphs this constraint represents a relational transformation  between the vertex positions  and  that are connected by the edge   comparing my case to the literature the following questions arised   how do i calculate a prediction  which i can compare to a measurement  when computing the edge error  initially  i understood that graph slam models the vertex poses as gaussian distributed variables and thus a prediction is simply calculated by    how do i calculate the information  preferred  or covariance matrix   how and when do i update the information matrices  during optimization  or only at edge creation  at loop closure  i read about the chi square distribution and how it relates to the mahalanobis distance  but how is it involved in the above steps   studying current implementations  e g  mrpt graph slam or g o  i didn t really discover how predictions  or any probability density function  is involved  in contrast  i was even more confused when reading the mrpt graph slam example where one can choose between raw poses and poses which are treated as means of a probability distribution   ,slam imu data-association
9435,object following robot,can you please help me out  i need my car prototype to follow the object ahead of it  i m using two ultrasonic sensors hc sr   to sense the distance of the obstacle  i want these sensors to determine the direction of the servo motor mg    using python  how do i calibrate this servo to get an appropriate output   if anybody could help me out with a code in python on it  i d be grateful  ,software
9436,what is the common process to place a robotic arm gripper,i implemented a simulation for a robotic arm that has to grab things  this arm has a  dof structure and a simple gripper on the top  i made a simple ccd ik algorithm to control the arm  i can use it in two ways   compute the position of the last joint of the arm before the hand part  which means   end effector   then use an analytical method to place the hand in a good orientation  compute directly the arm  and the hand position by giving the ccd ik algorithm   end effectors that are the   finger of the hand   what is the most used method for a grabbing arm robot   i m not willing to find a solution  just to know what people usually do   ,robotic-arm inverse-kinematics
9437,can we simulate a actuator with a very strong torque with a pid controller,i use gazebo to simulate a robot arm  to control its joints  i use pid controllers  as you might know  pid are sometimes pretty hard to tune and this is the case for a robotic arm  to avoid any tuning  and because i don t need the pid values to be realistic  i set to zero the derivative and integral parameters  increase a lot the proportional gain and add a lot of damping in my joints  by doing this  i can get a well working arm but only if i disable the gravity   my question is the following  do you have an idea how i could simulate a very strong actuator with not necessarily realistic parameters  edit    setting the integral and derivative gain is stupid  the integral gain helps in correcting the effect of the gravity  the derivative gain counters the loss of stability and speed due to the integral gain   this question somehow leads to another  do you know what tuning do the robotic arm manufacturer  big arms for car industry for example   i guess that this arm use actuators with a very strong torque and a low maximum speed which reduces the need of tuning    edit    more info on my setup  i use gazebo    with ode  the robot description is in sdf  i control the robot with a model plugin  as a pid controler i use the pid class from the common library of gazebo and get directly the jointcontroler associated to the model   let say that i would like actuators very robust without any tuning needed  this way i could have a simulation with dynamics  by opposition to the setposition method   do you think it is possible       ,pid power servomotor joint gazebo
9441,create  commands with an app called serial,there is an app called serial  available in the app store   i ve downloaded it on my mac and am experimenting with it  any ideas on how to send create  oi commands using  serial   so far it seems a handy app  i ve bypassed all the need for other drivers  anyone else use serial something of the like    when the serial terminal is open and the number   is pressed on my mac it seems to activate cleaning mode  thats all the communication i m getting after hours of playing around in python and mac terminal    ,mobile-robot irobot-create serial
9443,openrave chechcollison command in c  ,what is the equivalent code of  env checkcollision robot   in c    even though it is said that conversion of commands from python to c   is easy and intuitive  where can i find a proper documentation for this conversion  ,motion-planning algorithm
9445,name of large robotic arms  two finger  with wrist  arm  hands and spinning shoulder axis,i ve been looking for large robotic arms  with two fingers  and the arm so they are able to pick up and drop things in a space around the arm  and even spin around the  wrist    i m not sure what the terminology is for such an arm  i ve seen this  owi     robotic arm edge  and it looks close  is there something larger that can be hooked up to a raspberry pi instead of the remote controller  is there a particular term for this in a generic context  or is there a way to build such an arm using off the shelf parts  ,robotic-arm raspberry-pi
9447,programming a rover,i am part of my college team which is planning to enter a mars rover challenge  in the point of view of a programmer  where should i start  i know c is the main language nasa used for their rover and i have a basic understanding of it  plus  how much should i look into the rtos part for making a rover  any books links to this topic would be greatly appreciated   ,programming-languages c
9454,what is the correct name for  servo brackets  ,i refer to these types of brackets as servo brackets  or robot brackets   i know that the two specific brackets  shown above  are known as a short u  some vendors refer to them as  c   en lieu of  u   and a multi function bracket  respectively  and that there are other types available  namely   long u bracket oblique u bracket i bracket l bracket etc   however  i am sure that there is a correct name for these types of bracket  or this range of bracket  if you will   rather than just servo brackets   either a generic name or a brand name  i have seen the term once before  on a random web page  but the name escapes me  they are either named after their creator  or  if i recall correctly  the institution where they were developed  does anyone have a definitive answer  preferably with a citation or web reference  or a little historical background  ,mechanism
9456,how can we use the accelerometer for altitude estimation ,i am currently implementing an autonomous quadcopter which i recently got flying and which was stable  but is unable to correct itself in the presence of significant external disturbances  i assume this is because of insufficiently tuned pid gains which have to be further tweaked inflight  current progress   i ruled out a barometer since the scope of my research is only indoor flight and the barometer has a deviation of     meters according to my colleague  i am currently using an ultrasonic sensor  hc sr    for the altitude estimation which has a resolution of    cm   however i found that the ultrasonic sensor s refresh rate of   hz is too slow to get a fast enough response for altitude correction  i tried to use the accelerations on the z axis from the accelerometer to get height data by integrating the acceleration to get velocity to be used for the rate pid in a cascaded pid controller scheme  the current implementation for the altitude pid controller is a single loop pid controller using a p controller with the position input from the ultrasonic sensor  i had taken into account the negative acceleration measurements due to gravity but no matter how much i compute the offset  there is still the existence of a negative acceleration  eg            i computed the gravitational offset by setting the quadcopter to be still on a flat surface then collecting        samples from the accelerometer z axis to be averaged to get the  offset  which is stored as a constant variable  this variable is then subtracted from the accelerometer z axis output to remove the offset and get it to  zero  if it is not accelerating  as said in the question  there is still the existence of a negative acceleration  eg            my quad then proceeds to just constantly climb in altitude  with only the ultrasonic sensor p controller  my quad oscillates by    cm    how can this consistent negative acceleration reading be effectively dealt with   possible solution  i am planning to do a cascading pid contoller for the altitude hold with the innerloop  pid controller  using the accelerometer and the outer loop  p controller  using the sonar sensor  my adviser said that even a single loop p controller is enough to make the quadcopter hold its altitude even with a slow sensor  is this enough  i noticed that with only the p gain  the quadcopter would overshoot its altitude    leaky integrator  i found this article explaining how he dealt with the negative accelerations using a leaky integrator however i have a bit of trouble understanding why would it work since i think the negative error would just turn to a positive error not solving the problem  i m not quite sure   single loop pd controller with the ultrasonic sensor only  is this feasible using feedback from a slow sensor   sources   lsm   dlhc datasheet   leaky integrator   ardupilot pid loop    ,quadcopter control pid raspberry-pi sensor-fusion
9459,building a stationary robot which can talk,i am a computer science major and i only have basic ideas on robotics  i am planning to build a stationary cubical ai   the main purpose of this bot will be that  it will have a sensor to check if the door has been opened and immediately asks a question  who has opened the door   i also want it to recognize the correct words to interact the word  i am not talking about voice recognition but word recognition so that who ever speaks the correct words words in bot s memory  can interact with it  depending on who opens the door prolly my family  i want it to speak out different things  i want it to respond to simple questions like   what is the date and time       a random qoute or a fact or a joke    is this too hard to achieve  could anyone give me a basic idea on how to approach this project   ,sensors communication first-robotics speech-processing
9463,quadrocopter pid,i am building a quadcopter for my school project  i am trying to program my own flight controller using pid algorithm  i ll try to make my question simple using as an example below only two motors  let s say i am trying to stabilize my two motor system using gyro from the diagram below to one above                                                                                                  using the formula output    gyro        pgain do i need to increase the output only on the motor   or would i have to do both  increase the output on the  nd motor while decreasing the output on the first motor  thank you ,quadcopter pid ardupilot logic-control
9472,does a controlling system need to be more complex than the system being controlled ,is there any theoretical principle  or postulate  that states that the controlling system has to be more complex than the system being controlled  in any formal sense of the notion  complex   ,control theory
9476,remaking an rc transmitter for controlling aircraft,i am thinking about working on alternative drone controllers  i am looking into making it more easy to use and a natural feel  debating between sensor bracelets  rings  etc    the main issue i have is  i ve been looking over all the standard rc transmitters that are used to control rc aircraft  but i am not sure what technology is inside of them  what kind of ics they use for the actual rc signals   i want more information on how to make an rc transmitter myself  mainly the protocol that s used to send messages  and what circuitry is needed to actually transmit that  what kind of components do i need and how should i implement the software  i was aiming at doing this as a side project  hobby   but now i have the chance to use it as a uni project as well  so i d like to give it a shot now  but i lack the proper information before getting started   i d rather not take apart my current rc controller and use an oscilloscope to decode the protocol   any answers  short or long  and reading material is appreciated  other questions  can the protocol be implemented in software on an embedded system  raspberry pi  arduino  intel galileo  etc    i am asking this because the frequency for these are     ghz  this is part of a bigger project  drone related currently  and i could use alternative methods of sending the information  through other wireless means  as the first prototype  suggestions are welcomed  need  aircraft rc transmitter protocol info  rc transmitter components   schematics  anything else that might help with the transmission side ,microcontroller radio-control
9482,fastening sheet steel on nylon,i m trying to attach a small piece of sheet steel    mm x   mm x  mm  to a small piece of nylon    mm x   mm x  mm   does anyone know how they could be fastened using small screws    any thought appreciated  ,mechanism
9488,fixed wing uav  do inherently unstable systems desire to be stable for all cases when a closed loop control is implemented on them ,as we all know fixed wing vehicles are designed to have inherent instability which is what enables all fixed wing vehicles to fly  however does this apply to all cases   do inherently unstable systems desire to be stable for all cases when a closed loop control is implemented on them   ,control pid microcontroller uav stability
9491,can you interface to a braava jet ,is there any open interface access to the new braava jet just to drive it around  ,irobot-create
9495,what irobot products support the open interface besides the irobot create ,i have read that certain irobot products support or can be hacked to support something close to the open interace  there is even a book about hacking roomba  what robots have this capability  ,irobot-create
9500,apm mission planner        install firmware failure mac os x      ,i installed multiple versions of                          on windows    ubuntu        and osx        i could connect to my ardupilot but could not install firmware  here s the error i would get  started downloading  finished downloading  var folders r  s j c  s wvcx wy    rnwh    gp t apm planner uq     opening firmware file    unable to open file   var folders r  s j c  s wvcx wy    rnwh    gp t apm planner uq      ,ardupilot
9502,use data from gyroscope to calculate orientation,from a gyroscope i m getting angular velocities  droll  dpitch and dyaw  as rad s  sampled at intervals dt     ms  how do i calculate the short term global orientation  drift ignored  of the gyroscope  pseudo code would be helpful  ,gyroscope
9505,euler lagrange systems  autonomous or nonautonomous ,i was reading an article on euler lagrange systems  it is stated there that since m q  and c q q   depend on q  it is not autonomous  as a result  we cannot use lasalle s theorem  i have uploaded that page of the article and highlighted the sentence   ren pdf  then  i read spong s book on robotics  and he had used lasalle s theorem  i am confused   spong pdf  i did some research  and found out that non autonomous means it should not explicitly depend on the independent variable  isn t independent variable time in these systems  so  shouldn t they be considered autonomous  ,control dynamics robotc
9508,considerations to design actuators  and loop feedback systems  for a robotic arm,let s say i have an industrial sized  dof robotic arm  i want to control each one of the six joints despite the non linearity produced by the chain structure  the gravity and the weight of the loads it could lift   i don t focus here on the speed nor the power limitations  i just want the arm to respond well  moreover  i would like to avoid the use of any prior knowledge such as inertial computation  then i had these considerations  considering that i can play with both the actuator design  and the loop feedback control system   limit the maximum speed of each actuator to smooth their error variation  increase the damping of the actuators to avoid high frequency instability       find a good control system  such as a pid  to make sure the targets are reached without oscillations    do you have any other considerations in mind  do you know what process es  industrial designers follow  edit  as it is said in the comments  my question concern the design of an adaptive controller for a robot arm  which is  how to design a joint control system  actuator   loop control  that don t need inertia and masses to be computed  the controller could adapt to its own structure  or to the loads it lifts    i ll be very much interested if you know some paper about adaptive control in the field of robotic arms      ,control pid robotic-arm design actuator
9512,dc motor control,my project requires a dc motor for mobility  very similar to an rc car  if precision isn t critical  can i use a solid state relay instead of a motor driver  if the vehicle moves an extra inch on the ground  i don t really care  ,motor driver
9518,choose and connect a camera to a robot,there are tons of cameras in devices around us these days  there are used photo cameras  smartphones  tablets at my home gathering dust  i wonder  what the easiest way could be to get a camera module from some device  connect it to my robot project with a soldering iron and make it work from the software point of view  i am planning to use something like arduino  an stm   platform  or probably intel edison  may be some camera modules are easier to solder and program for a custom  project  or shouldn t i look this way and better find a camera module that is specially designed for custom projects  ,cameras
9521,difference between g value and rhs value in lifelong planning a ,what is the difference between g value and rhs value of lifelong planning a  algorithm   according to this link  d  lite  g s  directly correspond to the g values of an a  search  i e  g s    g s     c s  s   and rhs s  is given as   rhs s     begin cases     s   s  start       min  s  in pred s   g s     c s   s      text otherwise   end cases   where  pred s  denotes the set of predecessors of node  s    thus  unless node  s  has more than one predecessor  its g value and rhs value will remain same   so  my question is  in which case will the rhs value and g value of a node be different  ,mobile-robot robotic-arm wheeled-robot motion-planning algorithm
9523,neural nework code or library for msp   g     microcontroller,i am new here and i am new to neural network also   p i have gone through the concepts of neural networks but i want to implement it in my project including microcontroller msp   g     on launchpad series  i am using some sensors and i want to use some neural network code to manipulate the data from sensors to get some threshold  i went through this post and tried to implement the codes from the link given but it is giving some error on less ram  i guess it is due to my mcu    so  i wanted some help regarding the neural network code or library for energia which i should use  thanks in advance  ,microcontroller electronics machine-learning embedded-systems
9532,quadcopter propeller physics,in propellers as the airspeed increases thrust decreases  is the air speed component taken as a vector quantity perpendicular to the propeller  if thats true the its quiet easy to visualize in case of airplanes but for quadcopters will it be   copter airspeed   sin copter tilt     ,quadcopter
9535,anthropomorphic arm,i developed an anthropomorphic arm  structure in aluminium  with   dof    plus spherical wrist  for direct kinematic   i chose magnetic rotary encoders to measure angles but i am not satisfied  due to them causing noise on angle measurements   what do you advise me    to add another sensor and perform a sensor fusion   to replace magnetic encoders with optical ones   or    what else   ,arm manipulator
9536,meaning of  sign  in writhe matrix,following is the equation of writhe matrix from the article topology based representation page no       what is the meaning of  sign  in the second part of this equation  i am not sure if this is some typo in that article as the other article of hierarchical motion planning page no      compleletely neglects the term  sign        ,mobile-robot control robotic-arm wheeled-robot motion-planning
9538,meaning of symbol   curly n  in the equation of linear gaussian system dynamics,in the article of topological based representation page no       the equation of the linear gaussian system dynamics is given as   in above equation what is the meaning of  curly n    ,mobile-robot control robotic-arm wheeled-robot motion-planning
9542,meaning of the equation of graphical model,the paper topology based representations for motion planning and generalisation in dynamic environments with interactions by ivan et al   says on page    that the approximate inference control  aico  framework translates the robot dynamics to the graphical model by the following equation   what does p x  t u  t  mean  i feel that p means  prior of  some uncertain quantity  but i m not sure about this   ,mobile-robot control robotic-arm motion-planning
9544,enable bluetooth communication with irobot create  ,i just got a new irobot create    i used to use an element direct bam  bluetooth adapter module  for irobot create previously  how can i communicate with a create   using bluetooth  what accessories do i need  ,irobot-create
9545,autonomous indoor positioning system robot based on cv approach,i have some questions regarding an ips autonomous robot system  configuration    mounting a camera to the ceiling of a room assume the room is a cube of  mx mx m  lxwxh  assume the camera is microsoft lifecam studio  cmos sensor technology  sensor resolution       x           diagonal field of view  auto focus from    m to     m  up to    frames per second  frequency response      hz      khz  a rover  objectives   by putting the rover in an unknown location  x y  in the room  the system should localize the rover s position after the rover s coordinates will be known  navigation will be the next step we want the rover to navigate from the known coordinates  x  y    let s say point a  to another point b on the map  x  y   control signals will be sent to the rover s servos to complete the navigation task  methodology   camera will capture the environment in real time environment will be represented as cells  occupancy grid mapping  assume each cell represents   cm in the environment rover will be localized by the system point a determine the navigation to point b determine the path of the rover in the grid map  ex  go x cells horizontal then y cells vertical  control signal will be sent to rover s servos  questions   can i use this camera for this task or i need another type of cameras   what are the factors affecting the system accuracy    ex  sensor resolution   fov   fps   frequency response   distance of the camera in the ceiling  what s is the most important factor to consider to increase the accuracy   i would appreciate any opinions regarding the project  king regards  thank you ,mobile-robot localization slam computer-vision mapping
9547,reverse engineering commercial drone control algorithms,i m wondering if there is a way to figure out the actual controllers used in the commercial drones such as ar drone and phantom  according to ar drone sdk  users are not allowed to access the actual hardware of the platform yet they are only capable of sending and receiving commands from to the drone    edit  i m hoping to to check the actual controller utilized in the software  when i fly ar drone  it seems the platform can t stabilize itself when i perform aggressive maneuvers  therefore  i can guess that they use linearized model which is applicable for using simple controllers such as pd or pid ,quadcopter control
9552,how is topology based representation invariant to certain change in environment,the article of topology based representation  page no      line    says that  topology based representation is invariant to certain changes in the environment  that means the trajectory generated in topology based space will remain valid even if there are certain changes in the environment  but how is this possible  is there any simple example to understand this concept  ,mobile-robot control robotic-arm motion-planning
9553,counting number of people entering a room,we are making a project in which we want to count the no  of people entering and leaving a room with one single entrance  we are using ir sensors and detectors for this  along with an aurdino  we have a problem in this system   i e when two or more persons are entering or leaving the room at a time we are getting a wrong count  thanks in advance for your valuable time and solution     if there is any other better way please state that  ,arduino sensors microcontroller
9554,quadcopter pid algorithm,i m trying to implement a pid control on my quadcopter using the tiva c series microcontroller but i have trouble making the pid stabilize the system   while i was testing the pid  i noticed slow or weak response from pid controller  the quad shows no response at small angles   in other words  it seems that the quad s angle range has to be relatively large  above    degrees  for it to show a any response  even then  the response always over shoots no matter what i  d gains i choose for my system  at low p  i can prevent overshoot but then it becomes too weak     i am not sure if the pid algorithm is the problem or if its some kinda bad hardware configuration  low imu sample rate or maybe bad pwm configurations   but i have strong doubts about my pid code as i noticed changing some of the gains did not improve the system response    i will appreciate if someone can point out whether i m doing anything wrong in the pid snippet for the pitch component i posted  i also have a roll pid but it is similar to the code i posted so i will leave that one out     void pitchpid adjustment float pitchpidcontrol  unsigned char pitch attitude        if  pitchpidcontrol  maximum dutycycle set dutycycle             pitchpidcontrol maximum dutycycle set dutycycle          switch  pitch attitude       change rotor      case  p     positive status     pwm    cmpa r     pitchpidcontrol     red   motor      pwm    cmpa r     pitchpidcontrol     yellow   motor      break      change rotor       case  n     negative status     pwm    cmpa r    pitchpidcontrol    orange   motor      pwm    cmpa r    pitchpidcontrol    green   motor      break       also  can someone please tell me how this motor mixing works    front  throttle   pitchpid  back  throttle   pitchpid  left  throttle   rollpid  right  throttle   rollpid  vs what i did in the function  void pitchpid adjustment float pitchpidcontrol  unsigned char pitch attitude   ,quadcopter control pid imu pwm
9555,what is the millisecond rate that robot create can respond to two different drive commands ,i want to issue two slightly different drive commands what is the smallest loop rate that the robot create accepts new commands  i know from reading the documentation that it appears the sensors are read every   ms   not sure what the command rate is  ,irobot-create
9565,best sensor to determine  up  versus  down ,i want to start designing an arduino project and have telemetry readings that indicate tilt or angle of placement   would an accelerometer be the best for determining tilt  are there good tutorials   ,mobile-robot arduino
9568,what is a cim motor ,i m trying to make decisions for motors on a robot build  i keep running across cim motors  what is a cim motor  where does the designation cim come from  what does cim mean  ,motor
9569,robotic arm analysis in matlab simulink,i am going through a paper  kinematic modelling and simulation of a   r robot using solidworks and verification by matlab simulink  which is about a   link revolute joint robotic arm  according to the paper  the trajectory analysis of the robot was done via simulations in matlab simulink   it shows the following picture  trajectory generation of   r robot with matlab simulink   and then  simulink   simulation block to calculate the trajectory   i think this is done in simmechanics  but i am not sure  experienced users  can you please tell me what am i looking at and how can i reproduce this  ,robotic-arm matlab simulation
9571,simulating dynamixel motors in gazebo,i m trying to simulate a humanoid robot using gazebo with plugins  since our actual model uses dynamixel motors  i d like to know how exactly they work to make the simulation as realistic as possible  gazebo offers two options to control joints  one is a pid controller  provided by the  class  the other way is to directly set a torque to the joint   the pid method too is ultimately implemented using torques   currently  i m trying the pid based implementation  i ve used a p only controller with damping on all joints  i ve had to guess both values   however  there is a large amount of noise  and the difference between actual and desired position is at times as much as       degrees  especially when the foot of the robot hits the ground   does the actual motor use a pid controller as well  i can t seem to find the details here  dynamixel ex     user s guide  but this link  dynamixel ex      robot actuator mentions  compliance pid   yes   if the motor does use a pid controller  then what are the parameters  and how does it allow us to set moving speed then  if the motor doesn t use a pid controller  then what is the pattern of torque provided  in the manual  first link   i found this  from the current position     to                       movement  is    made  with appropriate  torque  to  reach  the  set  speed  from         to                      torque is continuously reduced to the punch    value  from       through                      no torque is generated   this is rather vague though  and no further details are provided  also  i m aware that extremely high damping and extremely high p values might do the trick  but i want to simulate what actually happens on the motors  and that is probably not the way to go   i d appreciate it if anyone has any idea of what dynamixel servos do  or examples of simulated dynamixel motors anywhere else  ,pid simulation gazebo humanoid dynamixel
9572,transfer function of a quadrotor position controller,i m trying to find the transfer function of a quadrotor with two controller loops  following next structure   i know how to calculate the attitude stability controller  which relate rotor speed and desired angles  however  i have no clear at all how to implement the translational controller transfer function  whose output is the desired angle that the rotors must achieve considering the position i want to translate  considering that two controllers are pd  how can you calculate the translational controller transfer function and include it in the system  time domain equations in the outer loop are next  where u terms relate to the thrust axis components  thanks  ,quadcopter control
9578,create  serial  canonical versus number of bytes interface,there is a message system which does not appear to be document in the oi spec  this appears to be a a canonical terminal type serial interface in which messages come back such as firmware version and stuff  i am not sure how to determine what the end of this type of message is  it is a fixed number of end lines  or bytes  one message seems to indicate str    which would be a     byte string  the open interface spec seems to indicate a non canonical interface spec in which you read a fixed number of bytes with no processing of end lines  is this correct  ,irobot-create roomba
9580,ultrasonic sensor range and shape,i have been looking for a cheap ultrasonic sensor that is not blind under       cm but the only sensors i could find use the following shape  which is not suitable for my project  because of the robot design that only has   hole  and not         is there any chance to find a sensor with that other shape with a range starting around  cm    actually i am wondering if that  nd shape makes this constraint mandatory or if i just did not found the appropriate product  ,ultrasonic-sensors
9583,servo motors for large scale rc car,i want to convert an electric atv  quad  for kids  like the highper atv  e  to radio control for a robotics project  these small atvs are about a meter long and weigh about    kg  i need to choose servo motors for steering and braking  what grade servos do i need and how much torque do they need to have  can i use the strongest rc servo i may find  like this    kg cm one or maybe even more  with metal gears of course  or do i need an  industrial grade  servo  i plan to use one servo for steering and one for braking  for braking the atv has mechanical disc brakes   two discs in the front and one common disc in the rear  there are two brake levers   front rear   i plan to use only one servo and use it either for front or for rear  the plan is to mount the brake wire to the servo which would  simulate  the lever movement  i guess i could also make a  weak  servo stronger by adding a proper gear  but i am not really into mechanical engineering much and would prefer an off the shelf component   ,servomotor rcservo steering brake
9590,downgrade ros from jade to indigo,is it possible to downgrade from ros jade to indigo  for those who are not yet familiar with robot operating system  ros   here  ros ,ros
9592,meaning of s last in d star lite algorithm,in the d lite algorithm  described in line    of figure    on page    in d  lite  the  starts with defining   but value of  is never updated in the entire algorithm   so what is the purpose of defining this term and what does it mean   ,mobile-robot control robotic-arm motion-planning algorithm
9593,mechanical odometer with digital output,i would like to mechanically measure the distance a kids electric atv traveled  the atv will not be used with kids but as a mobile robot instead  it has a common rear axle for both rear wheels which i think could be a good place to put an odometer on  since the chance both wheels will slip should be minimal   regarding suspension it has a single shock for rear axle  my plan is to put a bigger gear on the axle itself and then add a smaller gear to it on which some kind of sensor would measure number of its rotations  one rotation of the axle may be something like    rotations of the small gear  what kind of sensor can i use for sensing rotation  another way of making an odometer may be some kind of optical solution  disc with holes and an optical sensor  but this seems to be rather complicated and also the the direction of travel could not be easily estimated  unless the motor is running in some direction   i just found a term called wheel speed sensor which looks interesting and seems to employ primarily non contact sensing  which is definitely better than mechanical gears   rather then optical solution i like the hall effect sensor solution which may be simple and mechanically robust  but still  my question is open on how to implement this    i would like to use the odometer for both speed estimation and distance estimation  i need to read the sensor from c c   on a linux box  edit  the thing i am looking for is probably correctly called a rotary encoder or a wheel encoder  the atv may look like one of these    ,mobile-robot sensors odometry encoding rotation
9597,hand eye calibration ,i am having an issue with some hand eye calibration   so i am using a simple robot which at its tool point has an stereo camera mounted on it   i want to perform some visual serving tracking based stereo images extracted from the camera in the  hand   the camera provides me x y z coordinates of the object i want to track   i can at all time extract an homogenous transformation matrix from base to tool  not cam  as    firstly    i guess i would need perform some form of robot to  vice versa  camera calibration  my idea was that would consist of something like this  t base world    t base tool   t tool cam   t cam world    where the t tool cam would entail the calibration    since the camera is at the tool point  would that entail the t tool cam should entail information on how much the camera is displaced from the tool point  and how it is rotated according to the tool point  or is not like that  secondly    how do i based purely x y z coordinate make an homogeneous transformation matrix  which includes an rotation matrix   thirdly   having a desired transformation matrix which in theory this      t base world    t base tool   t tool cam   t cam world    would provide me  would an inverse kinematics solution provide me with one or multiple solution     in theory should this only provide me one  or what  ,robotic-arm inverse-kinematics rotation
9600,how can i determine the pose of the origin after some transformations ,find the origin and coordinate directions of a frame resulting from a rotation of  about the z axis  followed by a displacement of   hence find the position  in the original frame  of the vector   defined in the resulting frame  ,kinematics inverse-kinematics
9602,computeshortestpath   in dstar lite algorithm,in optimized d lite algorithm as shown in the figure below  page    of the paper d lite   when the procedure computeshortestpath   is called for the first time in line     u list of inconsistent vertices  contains only goal vertex     thus in the procedure computeshotestpath   line           and as    because    condition  is satisfied and  is again inserted in u with same value of   thus  it seems that line        will run forever  and the algorithm will not be able to find the shortest path from goal to start  i know that this algorithm has been widely used and i am failing to understand it  but where am i going wrong    ,mobile-robot control robotic-arm motion-planning algorithm
9604,quadcopter heading calculation,i m working on an autonomous quad copter  i have two gps co ordinates  source and destination co ordinates   i need to move my quad from the source to the destination  for this i need to calculate the heading and set the yaw value of my quad  how can i calculate the heading and make sure the quad is headed in the right direction as the target co ordinates  if i use magnetometer the declination angle will vary from place to place and so i will have to keep changing the declination angle  if i m calculating based on just the gps co ordinates  it s not accurate   what is the best way to do this   how do i calculate the above   ,quadcopter gps magnetometer
9608,quaternion kalman filter algorithm,i have been stuck on this for weeks  i really hope that someone can help me with this thank you in advance  i am trying to write an imu attitude estimation algorithm using quaternion kalman filter  so based on this research paper    i have developed the following pseudo code algorithm  predict stage  qk   k   ak   qk   where ak contains the gyro measurement    pk   k   ak   pk  ak transpose     q  where q is assumed to be zero  after prediction  we can use this formula to get the supposed gravity measurement of accelerometer yg in body frame   yg   r   g      r is the rotation matrix generated from quaternion qk   k and g                 this equation then translates to the following equation which allows me to get measurement model matrix h  h   qk   k        where h stores value related to  yg g   update stage  k   p   h    h   p   h transpose   r          r should be adaptively adjusted but right now initialized as identity matrix qk   k      i kh qk   k  qk   k      qk   k     qk   k       normalize quaternion pk   k      i   kh pk   k  the following is the main part of my code  the complete c   code is at here  if you want to test   the problem that i face is that my code does not work the prediction stage works fine but the updated quaternion state is only correct for the first few iterations and it starts to drift away from the correct value  i have checked my code against the research paper multiple times and ensured that it is in accordance with the algorithm proposed by the research paper  in my test  i am rotating around x axis by    degree per iterations  the number below the started is the angle of rotation  state and updated state is the predicted and updated quaternion respectivly while true value  meas  result are acceleration due to gravity in body frame as the test result indicates  everything is way off after rotating     degrees  the following is my test result      started    state                  true value                 meas                          updated state                           e            e     result                                started     state                           e            e     true value                             meas                              updated state                                       result                               started     state                                         true value                              meas                             updated state                                         result                                  started     state                                         true value                            meas                            updated state                                        result                               started     state                                        true value                         meas                           updated state                                       result                             started     state                                             true value                           meas                            updated state                                         result                             started    state                                        true value                         meas                         updated state                                      result                          can someone help me confirm that my understanding about the theory of this quaternion kalman filter and my pseudo code is correct  also  if anyone has implemented attitude estimation using maybe a different version of quaternion kalman filter  i would greatly appreciate if you can provide a pseudo code and a little explanation  thank you guys very much  ,quadcopter kalman-filter
9609,most accurate rotation representation for small angles,assume that i have a rigid body for which i know that it can rotate with respect to a global reference frame  which is considered fixed and already given  for only a few degrees of angle  so i can describe its rotation by using the small angle approximation  for this system  i would like to know if there is a rotation representation that offers more accuracy when compared with other representation methods  the main representation methods that i considered are the euler angles and the pitch yaw roll transformation  to my perception  i think that pitch yaw roll representation is expected to be more accurate  since all the angles are expressed with respect to the initial coordinate frame  on the other hand  euler angles are defined on different frames  so i am not sure if the resulting angles will be really small  to sum up  i know that the body can rotate for only a few degrees and i would like to know which coordinate representation is much probable to deliver the smallest angles  such that the small angle approximation is more valid  it could also be the case that there is not a general answer  so it depends on the specific configuration  but still i haven t found anything about this topic on the related literature  example  no small angle approx used   assume i have a coordinate frame which describes a point in space by the following vector   given another coordinate frame which is rotated with respect to the previous one  the description of the same point is given by        using euler angles  i can find that the rotation matrix  is characterized by the angles  rads  which correspond to the angle of rotation around z axis  the rotation around the resulting y axis and the rotation around the resulting z axis  respectively  these are basic stuff  it is explained in many books    so i have that   now i want to find the corresponding rotation matrix if i use the pitch yaw roll representation  here i have to solve an optimization problem and the solution that i get  maximum error between p  and the estimated p  is   delivers me the following angles   which correspond to the rotation around the x y and z axis of the initial coordinate frame   ,inverse-kinematics geometry rotation
9615,orientation error with free rotations,i am working on inverse kinematics for a  dof arm   the tool is symmetric about its z axis so we don t card about those rotations in the solution but we do care about the direction of the z axis   in other words instead of the goal states orientation being  we only care about   how would i calculate the orientation error  or adjust normal inverse kinematics  to account for this   setting  and  to zero or any value forces a particular orientation which may not be reachable   for full  dof situations i have previously used the following equation for orientation error   e o    frac        n e q   times n d   s e q   times s d   a e q   times a d   is it sufficient to remove  and  from this equation giving e o    frac        a e q   times a d  if not how else could i handle this situation    ,robotic-arm inverse-kinematics
9616,motor upgrade to higher torque ,i have assembled a  wd car using kits i bought on ebay  i have   motors similar to this one    the description says    operating voltage   v   vdc     recommended operating voltage of about   to  v  maximum torque     gf cm min   v  no load speed         v time  the load current    ma     ma max    v  this motor with emc  anti interference ability     the microcontroller without interference  size   x   x   cm approx    i am not too fond of the max speed i can reach  but i would be able to provide more power  because i have a   v  a battery onboard  so far i have used  v  because that seemed to be the safer voltage choice  has anybody tried successfully higher voltages  without wearing down the motor in few hours  i ve read this can happen   alternatively  can someone recommend replacement motors that would tolerate reliably a higher power envelope  i would like to preserve the gearbox and replace only the motor  if possible  i think i could fit a motor     mm longer  replacing the transparent strap which bonds it to the gearbox   if that makes any difference  btw  i m making the assumption  higher voltage    higher torque    higher speed but i m not sure it s overall correct  i expect that it would at least produce higher acceleration during the transients  ,brushless-motor
9619,extracting as many possible end configurations as possible,i am trying to implement a path planner to generate a path that moves the robot from q start to q goal     q goal is extracted from a stereo camera mounted on the tool  from which i extract x y z coordinates of the desired position  the rotation can be arbitrary   the robot i am using is an industrial ur  robot arm  the software i use is capable of performing jacobian based inverse kinematics given a transformation matrix with rotation and translation   my inverse kinematics provide me with only one solution  which is ok  but doesn t provide me flexibility for path planning    how do i using inverse kinematics determine all possible q configurations that fulfills my criteria of having the desired x y z coordinates   ,robotic-arm inverse-kinematics
9620,mobile robot path following using model predictive control  mpc ,i am trying to implement a path following algorithm based on mpc  model predictive control   found in this paper   path following mobile robot in the presence of velocity constraints  principle  using the robot model and the path  the algorithm predict the behavior of the robot over n future steps to compute a sequence of commands  to allow the robot to follow the path without overshooting the trajectory  allowing to slow down before a sharp turn  etc   linear velocity  angular velocity the robot  i have a non holonomic robot like this one  image extracted from the paper above     here is my problem  before implementing on the mobile robot  i am trying to compute the needed matrices  using matlab  to test the efficiency of this algorithm  at the end of the matrices computation some of them have dimension mismatch what i did  for those interested  this calculation is from                         p    of the paper         model          with               sampling period     linear velocity     sampling index  i e       the state vector  position and angle difference to the reference path    the reference vector  with  is the reference angle of the path at step k      criterion the predictive receding horizon controller is based on a minimization of the criterion            subject to the inequality constraint         where  is the predicted output   is a weight matric   is a scalar weight  and  is prediction horizon      predictor an n step predictor  is easily found from iterating       stacking the predictions  in the vector  yields            with           and          where index  should be substituted with either  or       controller using the n step predictor      simplifies the criterion      to            where  is a diagonal matrix of appropriate dimension with instances of q in the diagonal  the unconstrained controller is found by minimizing      with respect to              with        i am trying to compute  but the dimension of  and  does not match for matrix multiplication  parameters are           with   i get    a    x   matrix  n   elements of size  x   transposed   a    x    matrix  a    x    matrix  a    x    matrix  a    x   matrix  a    x    matrix     so lz computation gives  according to the matrix sizes   a    x   matrix  as  is   x   matrix  doing  from      is fine    and lr computation gives  according to the matrix sizes   a    x    matrix  as  is    x   matrix  doing  from      is not possible  i have a    x    matrix multiplicated by a    x   matrix  i m sure i m missing something big here but unable to see what exactly  any help appreciated  thanks ,mobile-robot navigation
9621,electric vs  internal combustion engine for propulsion,what are the main differences between electric motor and internal combustion engine for an atv sized mobile robot platform in terms of functionality  implementation difficulty   rc  conversion   electronic  operation   durability and maintenance when used as an autonomous platform  a full sized atv utv like polaris ranger  ev  is in question  are the advantages disadvantages basically the same as the differences between electric and nitro rc cars or does the bigger scale adds something important to the game  i can think of the main differences like bigger range and faster  refueling  with ic and less maintenance with electric but i am interested in a detailed comparison  the transmission for the ic engine is considered to be automatic  edit  the fuel injection for ic is considered to be electronic  efi  but i do not know whether that also means the  electronic  throttle  no mechanical wire as with carburetor    whatever the throttle may be i see the lag between its  actuation  and the engine running into higher rpm and giving more power speed as the main disadvantage for ic control   however  it may probably be quite easy dealt with in software  by adding some timeout when checking desired rpm   ,mobile-robot electronics engine electric propulsion
9622,inverse kinematics for   jointed robots,i am a  uncertain about how to compute the right homogeneous transformation matrix to compute an inverse kinematic q configuration   looking at robot like this  where at the end of this robot i have a camera mounted on to it   the purpose of my application is to make the robot follow an object  so basically tracking it   the camera provide me with an x y z coordinate  which the position i want place my robot arm   first question   how do i set up the desired homogenous transformation matrix  the way i see it  i have   transformation matrices being  and t world tool which become t world base    t tool base   t world tool  my question is that how do i compute my desired transformation matrix   i think i know how i should setup the transformation matrix for the camera which would be like this t world tool         x                      y                      z                         second question is regarding the rotation matrix  how do prescribe such that rotation in arbitrary as long the endpoint has the desired position in the world frame   but what should t tool base entail  should it entail the transformation of its current state or the desired transformation  and if so how do i extract the desired t tool base transformation     ,robotic-arm kinematics inverse-kinematics
9625,bayesian filter for   d grid localizaton,i have some data obtained from an experiment in terms of movements and observations with odometry and sensor data  my task is to find the probability mass on each of the grid cells after each set of motion and observation  i m a bit lost in figuring out how to compute probability mass for each of the grid cell  my odometry information is in terms of rotation  translation and rotation and my sensor information is in terms of range and bearing angle   how do i calculate the probability of robot present in each of the grid cell  i have the formula for belief after motion as summation p x u  x  xbel x    how do i compute the motion model with noise  ,localization filter
9629,quadcopter refuses to fly when the yaw pid component is added,good day  i would like to ask why is it that when i add the yaw control to my pid controller for each motor  the quadcopter refuses to take off or maintain its altitude  i am curently using a cascaded pid controller for attitude hold using an accelerometer  a magnetometer and a gyroscope  and a   hz ultrasonic sensor for altitude hold  since the scope is indoor i have done away with the barometer due to its     m error   resulting response without yaw control  the plot below shows the response of the quadrotor   with yaw control  the plot below shows the response of the quadrotor   debugging i found out that each of the outputs from each pid s give a too high of a value such that when summed together goes way over the pwm limit of     or full throttle   without yawpid contribution the limiter kicks in without damaging the desired response of the system thus is still able to fly albeit with oscillatory motion along the z axis or height    with yawpid contribution the added yaw components increases the sum of the pid s way above the limit thus the limiter compesates the excess too much resulting in an over all lower pwm output for all motors thus the quad never leaves the ground       motor front left     float motorpwm     pitchpid   rollpid   yawpid   basethrottle   basecompensation    motor front right     float motorpwm     pitchpid   rollpid   yawpid   basethrottle   basecompensation     motor back left     float motorpwm     pitchpid   rollpid   yawpid   basethrottle   basecompensation     motor back right     float motorpwm     pitchpid   rollpid   yawpid   basethrottle   basecompensation   background the pid parameters for the pitch  yaw and roll were tuned individually meaning  the base throttle was set to a minimum value required for the quadcopter to be able to lift itself  the pid parameters for the altitude sensor is tuned with the other controllers active  pitch and roll   possible problem  limiter algorithm  a possible problem is that the algorithm i used to limit the maximum and the minimum throttle value may have caused the problem  the following code is used to maintain the ratio of the motor values instead of limiting them  the code is used as a two stage limiter  in the  st stage  if one motorpwm is less than the set basethrottle  the algorithm increases each motor pwm value until none of them are below that  in the  nd stage  if one motorpwm is more than the set maxthrottle  the algorithm decreases each motor pwm value until none of them are above that    this was obtained from pixhawk  however the difference is that they employ only upper bound compensation limiting  while mine also performs lower bound compensation limiting which may cause more saturation once it reaches the second stage   from   gains are set too high   it is also possible that i ve set my p gains too high thus exceeding the max rpm limit of the motors causing the limiter algorithm to overcompensate  current pid settings  the minimum motor value for the quad to lift itself is     while the maximum limit is     from the pwm time high of     ms   pitch  cascaded p pid controller  rate p        rate i        rate d          stabilize p     roll  cascaded p pid controller  rate p        rate i        rate d          stabilize p     yaw  cascaded p pid controller  rate p        rate i        rate d          stabilize p     hover  single loop pd controller  p       d       possible solution i think i have set the pid parameters particularly the p or d gain too high that the computed sum of the outputs of the controller is beyond the limit  maybe retuning them would help   i would just like to ask if anyone has encountered this problem or if you have any suggestions  thank you      edit i have added the plots of the response when the control loop is fast     hz  and slow     hz      hz  does not fly       hz  flies     ,quadcopter control pid raspberry-pi stability
9636,regarding kalman filter and estimating heading with magnetic compass,i have trouble estimating the heading when close to the  pivot  point of the compass  and could use some input on how to solve it  i have set up my angles to be from       degrees during the testing but will be using radians   pi  pi  from now on  the setup is a differential robot with imu  wheel encoders and a magnetic compass   a complementary filter is used for fusing gyroz and odo measurements to estimate the heading  and then correct it with a kalman filter using the magnetic compass  my problem occurs when the robot heading is close to  pi pi   the estimated heading is useless even though the robot is not even moving  i am thinking this must be a very common problem and probably has a better solution than what i came up with  which was either re initializing the integrator when crossing zero  adding     degrees each time the error is larger  or just ignoring the compass if the error is too large    it s my first kalman filter so i may have made a poor implementation if this is not a common issue    edit  trudesagen s solution solved my problem  ,mobile-robot kalman-filter compass
9637,how do we write a stop to a continuous servo ,i m using processing to send strings to arduino  using functions like   on the processing side and in the arduino side i m using calls like    case  z       z write v       v          break    case  l       z write           v          break     yet i can t get the servo to stop at all  how do i make it shut off  if it was a regular servo i wouldn t even ask because that s easy but i write   or    or low and nothing  it just keeps spinning in one direction but when it meets one of the conditions in my statements it switches polarity direction and that s good   i want that but i made this function to make it stop and it is not doing so  does anyone have any ideas   i am using a parallax continuous rotation servo  ,arduino
9640,steadier wheels   pin them or lock springs,when running on a hard surface  the create will shake sometimes during turns or acceleration  has anyone ever removed the springs or pinned the wheels in place so they can t move up and down  ,irobot-create roomba
9642,what s the difference between a holonomic and a nonholonomic system ,i was wondering if a  d point mass  a mass which can only move on a line  accelerated by an external time varying force  see wikipedia   double integrator  is a holonomic or a nonholonomic system  why  i think that it is nonholonomic since it cannot move in any direction in its configuration space  which is  d  just the  axis   e g  if the point mass is moving at x    with a velocity of     m s in positive  direction it cannot immediately go to x     due to its inertia  however  i have the feeling that my thoughts are wrong    the background is the following  i am trying to understand what holonomic and nonholonomic systems are  what i found so far  mathematically   holonomic system are systems for which all constraints are integrable into positional constraints  nonholonomic systems are systems which have constraints that are nonintegrable into positional constraints    intuitively   holonomic system where a robot can move in any direction in the configuration space   nonholonomic systems are systems where the velocities  magnitude and or direction  and other derivatives of the position are constraint    ,dynamics movement
9646,forward kinematics with dh parameters,i just started learning robotics at school and i have some problems to solve forward kinematics with dh parameters  i don t really understand how i can get them from the image  i would appreciate if somebody could help me with it     ,forward-kinematics dh-parameters
9647,what rating li po battery should i get for this configuration ,i will have this configuration    a     brushless motor     kv     each ecs     a electronic speed control  esc      each  propeller        propeller cw   ccw pair    inch       pitch arduino mega        board raspberry pi    open pilot cc d flight controller   i want to know what rating li po battery should i get for this configuration  the reason behind my asking here is because a simple google search is not able to satisfy me with an explanation    also  my weight will be     kg for the quadcopter  so i need a stable current discharge  this is my first quadcopter  i am a computer science guy  so i have little knowledge of electronics  i m learning  but need help    ,quadcopter arduino raspberry-pi battery
9652,smart home model with raspberry pi,i m still new to rpi and i am currently trying to do a smart home model   i planned to use rpi only to control   servos  which will be controlling the open close of the doors by setting the angle  and   leds   will i need to use an external circuit to supply the power for the servos or is it fine to just connect them to the rpi  ,raspberry-pi rcservo
9654,how to know the payload of the chassis from its motors ,i m doing a mobile robot project with robotic arms  i wanted to buy a chassis for my robot that can carry enough weight  but many websites don t give definitive answers about maximum payload  is there is a way to figure this out just by knowing details about the motors  ,mobile-robot
9657,dynamic model of a manipulator,i m stuck on equation      of page     in  this equation     seems impossible to process because it requires adding a  x  to a  x  matrix  going by rowsxcolumns notation  matrices m and a are  x  and  is a  x   so how does this addition statement fit the rules of matrix addition   this must be my mistake  i just don t see how  ,dynamics matlab
9659,how to find maximum force of a robot joint,i want to know if there is any equation that calculates the maximum force of a robot joint  the force that we should not exceed  for example in human leg  if we apply a big external force to the knee  it will break  now how can i find the necessary force that will just make the leg move without breaking the knee  i have a programme that generates robot morphologies randomly with different sizes  so i have to know the force to not exceed for each joint  i think this depend on weight  mass  inertia of each robot part  i can not do this by trial and error because i have hundreds different morphologies  this video shows the behaviour of robot if i apply a big force  it is in gazebo robotic simulator  thanks in advance  ,simulation joint force
9662,implementing an analytic version of an inverse kinematic,people have recommended me implement an analytic version of inverse jacobian solver  such that i won t be forced only the least square solution  but would have an local area of solution near to the one i desire   i can t seem to implement it correctly  i mean how much does it differ from the least square inverse kinematics which i have implemented here   i want a vector of solution   how do i get that  the q is related to this how do i construct i a transformation matrix given only x y z of tool position  the robot being used is a ur      ,robotic-arm inverse-kinematics industrial-robot c++
9668,directly observing lidar laser rays,i am working with sick lidars and have to mount unmount them quite often on my robot  the mounting process is very tedious especially when it comes to making sure that the lidars are horizontal  i thought about using ir goggles  like the night vision ones  and some fog machine  like the one in nightclubs  in order to see the surface covered by the lidar s rotating laser ray  as a result i would expect to see something like this but planar   before thinking about trying to get my hands on such hardware i wanted to ask  do sick laser have enough intensity to be observed by such goggles  does anybody tried such an approach  ,laser lidar
9669,what type of actuator should i use ,i need to find out if there is a way to get at least    hz of linear motion with at least   mm of stroke that i intend to make linear persistence of vision device not rotating one it must be small and light as possible    maybe    mm long and       mm diameter or around these   less than     grams  the load will be around    grams   there are voice coils that is very expensive  can i use solenoids for instance or what do you recommend   thanks  ,actuator motion
9673,is there a  follow me  roomba create that works like a beambot ,the diagram below shows an old beambot strategy    is there code or an example using this method  i would rather avoid opencv  ultrasonic  gps etc  i just want the roomba wheels to react as i go straight  turn left or right  finally  i could add a front wheel on a servo and try having the roomba turn with me   also has anybody added big  all terrain wheels to a roomba to replace the originals  ,control irobot-create roomba
9675,suitable uc for atonomous robot,i am going to build an autonomous robot with kalman filter for localization integrated from lidar  encoder  imu and gps  i will also add obstacle avoidance while moving to the required position  is the atmega     bit suitable for that  or arduino mega  or do i have to use avr    arm  or pic   and which is better  ,mobile-robot arduino localization microcontroller
9677,kuka kr  l   robot simulation base and wrist rotation inconsistent with original robot,the issue is regarding simulation of kuka robot kr  l    in matlab using robotics toolkit by peter corke  i wish to simulate  the kinematic before passing a command to real robot for motion  i have attached the dh parameters  apart from this i have also tried many other combination of orientations but to no useful effect   the problems is that the robot base rotates counter clockwise by default for positive increases in   while the original robot moves in the opposite direction  similarly for the wrist roll  i e  joint    the direction of simulation is reversed  in order to confirm that it s not my mistake only  i searched for similar ready made simulation software  although it did not include the same kuka robot  a similar variant  kuka kr   sixx r     was available  hence  kuka kr   sixx r    had one set of motions for base and wrist in rokisim v    for positive increases in joint angle and reverse motion in roboanalyzerv      note  only the rotation of j   base  and j   wrist roll  are reversed and i want to recreate the results of rokisim v    in matlab where rotations are similar to the real world robot spec provided by kuka  ,matlab industrial-robot simulation kuka
9680,getting  rospack package not found error  in ros,i created a package in catkin workspace and put a publisher py node inside the src directory of package which worked fine  then i added another node subscriber py node and used catkin make to build  now when i try to run any of the nodes or find package i am getting above error  am i missing any step   thanks  ,ros
9682,what frames are supported by the dynamixel xl     ollo ,i was recently looking into purchasing either a dynamixel ax   a or xl      the xl seems to use ollo frames  which only seem to be available in a toy like set   i was wondering if there are any other frames available or if i should just get an ax     ,servos walking-robot dynamixel
9683,choosing the right mecanum wheel,i am part of my college robotics team which is preparing for robocon       we have used mecanum wheels in last robocon competition  but we have faced huge slip and vibration  i have looked for all kinematic and dynamic formulas and all stuff about mecanum wheels  but still can t get to a conclusion for my problem  video of the problem the robot is around    kg and the mecanum wheel diameter is about    cm with    rollers  single type   please help me why it happened like that   also suggest me what to do now   should i design a new mecanum wheel or bring it from market   if i should design  what parameters should i consider  and please help me how to design in cad software like solidworks  and then  shall i give it to  d printing  if i should buy directly from market  where should i buy  ,design wheel
9684,cannot disable sleep in passive mode for irobot create  ,i tried to disable sleep by pulsing the brc pin low for one second every minute as suggested in the oi  but my create   still goes to sleep after   minutes  my firmware is r  robot tags release            clean the create   is connected to an arduino  and the brc is driven by one of the arduino pins   i verified on a dmm that the voltage is indeed toggling   i am able to both send and receive serial data between the arduino and create   pseudo code   initialize roomba   connect serial at        baud   toggle brc  high for     ms  low for     ms  then high again   leave it high  ask roomba to stream sensor data in passive mode   wait   second after brc toggle to give some extra time to wake up   then send opcode    reset   wait for reset message to complete by looking for the last few characters  then wait another second for good measure   next  send opcode      start into passive mode   wait     ms to let opcode stick  then ask for stream of data  opcode     followed by number of packet ids and the packet ids themselves   main loop  echo data from create  to the serial usb output of the arduino so that i can view the create  data   the data sent by the create  look valid  good checksum  and are sent in the expected time interval of     ms   the main loop also toggles the brc low for   second every minute   for the full gory details  the complete arduino sketch is shown below  ,irobot-create
9686,performing inverse kinematics based on a displacement of the end effector ,i think i have an simple problem  but can t my head around how i should resolve it    my setup looks like this     the grey box on end effector is supposed to be an camera  which measures a dx dy dz between the object and the camera  these are used to  position the camera such that dz between the object and the camera is equal to      and dx   dy       i know that i using inverse kinematics can determine the q which positions it according the given rotation and position  but what if i only provide it a position only  how do extract all q that make dx   dy      and dz        while keeping the object in sight at all time  an example could be if an object was placed just above the base  see second image   it should then find all possible configurations which in this case would consist of the arm rotating around the object  while the camera keeps the object in sight    update i just realized a possible solution would be to create a sphere with the object in centrum  an radius of dz  and then use this sphere to extract all pairs of rotations and position    but how would one come by with such an solution  ,robotic-arm inverse-kinematics stereo-vision
9691,generate transformation matrices for rotating around a object ,how do i compute all transformation matrices which places a robot endeffector at the shell of this sphere  with the end effector pointing toward the object in the center    i know at all time how far the object is relative to the endeffector  and radius of the sphere is the desired distance i want between the object and endeffector    i want by using inverse kinematics pan around this object in a sphere shaped trajectory   each transformation matrix should contain different positions on the sphere and the rotation should be oriented such that the arm looks at the object   the position should be relative easy to compute  as i already know the distance to to object  and radius of the sphere   but the rotation matrix for each position is still a mystery for me    ,robotic-arm rotation
9696,vector field histogram  is it possible to generate an occupancy grid without position feedback ,i am currently working on an autonomous quadcopter project using stereo vision for obstacle detection  i am planning to use vfh  for  d trajectory planning  meaning movements of the quadcopter are only available on the x and y axes and no movement is permitted along the z axis or altitude  i currently have no methods implemented on position tracking  accelerometers have been known to generate a lot of errors from integration  i tried to look for optical flow sensors for low computation needed however have found no luck as most of them are out of stock  probably due to company change  agilent avago to pixart     from what i understand  when the after the certainty occupancy grid is constructed and reduced to a polar coordinate system  the robot s heading is aligned to the computed unblocked sector   is it possible to generate the occupancy grid without position feedback   i am planning to run the quadcopter at a slow constant velocity due to the data throughput of the raspberry pi stereo vision system of  hz  i plan to use the obtained angle direction from the vfh algorithm and align the quadcopter s heading  the motor control scheme to be used for the quadcopter is mostly yaw and pitch based  yaw for heading control and pitch for forward control  two raspberry pi b  s are used  one for motor control which is currently running the pid control loop at    hz  another for stereo vision which is currently running at  hz  ,quadcopter motion-planning stereo-vision vector-field-histogram vfh
9697,how to determine the angles between a uav and a sphere,i have an uav modeled in three dimensions with let s say position coordinates  that is moving in a direction  and a moving obstacle modeled as a sphere with known centre coordinates  and radius    if i have a plane   in the direction of movement of the uav that intersects the sphere  i want to be able to calculate the angles with respect to the vehicle s movement formed by the tangents to the sphere in the plane   in the figure  i would like to know how to calculate the angles  and    if it helps  what i am looking is an extension in three dimensions for this   which is a vehicle in two dimensions  it is obviously an easier problem which requires only the centre of the circle  however i am not really sure how to make it work in  d  as supposedly the plane can intersect the sphere at any two points  not necessarily the centre   thanks in advance for your help  ,localization kinematics geometry
9700,implementation of inverse kinematics solution in c  ,i am having some issue with implementing a least square solution of the inverse kinematics problem   the q configuration i get are rather large  or makes no sense  so i was hoping someone here could help me find my error in my program    what am i trying to do  i am trying to orbit a robot endeffector  around an object in the center  the trajectory of the endeffector is an sphere where the endeffector should always point in to the object   the sphere function should compute all transformation matrices which move the robot arm to the different position on the sphere with a given rotation  and the inverse kinematics should compute all the different q states  given an x y z which is the actual displacement to the object itself  i am not quite sure where my error could be at  but i think it might either be at transform function where i generate my desired transformation matrix  or in invkin where i create du  i think i might have made an mistake in creating du      du     du    the libraries i ve been using is eigen  robwork  basically all rw    if anyone want to look syntax through   update based on  ghanimmukhtar i began checking for singularities for the jacobian   which seems in general supringsly low  i computed it for a list of random q configurations which resulted into this    determinant             determinant             determinant            determinant             determinant            determinant             determinant           determinant            determinant             determinant             determinant            determinant           determinant             determinant              determinant            determinant           determinant            determinant            determinant             determinant            determinant             determinant            determinant              determinant             determinant              determinant            determinant              determinant             determinant             determinant            determinant             determinant             determinant             determinant              determinant            determinant              determinant            determinant            determinant             determinant              determinant             determinant             determinant            determinant             determinant            determinant             determinant             determinant            determinant             determinant             determinant              determinant             determinant            determinant            determinant            determinant               determinant           determinant           determinant             determinant             determinant             determinant             determinant           determinant              determinant             determinant             determinant              determinant             determinant              determinant           determinant            determinant            determinant            determinant            determinant            determinant             determinant            determinant              determinant             determinant            determinant              determinant             determinant              determinant             determinant             determinant            determinant           determinant              determinant            determinant            determinant             determinant             determinant             determinant            determinant              determinant            determinant          determinant              determinant            determinant            determinant            determinant               determinant              determinant            determinant            determinant             determinant            determinant             determinant             determinant           determinant            determinant              determinant             determinant             determinant              determinant              determinant             determinant            determinant              determinant             determinant            determinant              determinant              determinant              determinant            determinant             determinant               determinant             determinant             determinant             determinant            determinant             determinant              determinant            determinant             determinant            determinant              determinant             determinant            determinant             determinant              determinant             determinant              determinant              determinant              determinant            determinant            determinant             determinant              determinant              determinant            determinant            determinant            determinant             determinant             determinant             determinant             determinant            determinant            determinant           determinant           determinant             determinant             determinant             determinant             determinant             determinant             determinant            determinant             determinant             determinant             determinant            determinant              determinant             determinant              determinant           determinant             determinant             determinant             determinant             determinant            determinant            determinant            determinant           determinant            determinant             determinant             determinant           determinant            determinant             determinant             determinant             determinant            determinant             determinant              determinant              determinant            determinant            determinant            determinant             determinant             determinant            determinant            determinant            determinant             determinant            determinant             determinant              determinant             determinant             determinant            determinant             determinant            determinant             determinant            determinant          determinant         e    determinant            determinant            determinant         e    determinant              determinant             determinant             determinant              determinant            determinant            determinant             determinant             determinant             determinant            determinant             determinant             determinant              determinant             determinant            determinant            determinant            determinant           determinant             determinant             determinant            determinant            determinant           determinant          determinant            determinant             determinant            determinant            determinant            determinant            determinant             determinant              determinant             determinant            determinant             determinant            determinant            determinant              determinant           determinant             determinant            determinant            determinant             determinant             determinant             determinant            determinant             determinant             determinant             determinant              determinant             determinant             determinant            determinant            determinant             determinant             determinant             determinant            determinant            determinant            determinant             determinant             determinant             determinant            determinant             determinant              determinant             determinant              determinant             determinant            determinant              determinant            determinant              determinant             determinant            determinant             determinant             determinant            determinant             determinant             determinant             determinant             determinant             determinant            determinant             determinant            determinant             determinant            determinant             determinant            determinant            determinant            determinant              determinant             determinant              determinant             determinant            determinant             determinant              determinant            determinant             determinant             determinant            determinant             determinant            determinant            determinant             determinant              determinant            determinant             determinant             determinant            determinant             determinant            determinant             determinant             determinant             determinant             determinant             determinant            determinant            determinant             determinant             determinant             determinant             determinant           determinant          e    determinant             determinant            determinant            determinant            determinant               determinant             determinant              determinant            determinant              determinant             determinant             determinant            determinant              determinant             determinant              determinant               determinant            determinant             determinant             determinant            determinant             determinant            determinant             determinant          determinant            determinant              determinant             determinant             determinant              determinant            determinant             determinant            determinant            determinant              determinant            determinant            determinant            determinant            determinant            determinant             determinant             determinant             determinant             determinant            determinant             determinant            determinant            determinant             determinant             determinant            determinant             determinant            determinant             determinant            determinant             determinant              determinant             determinant            determinant              determinant             determinant            determinant             determinant             determinant          determinant             determinant              determinant             determinant             determinant              determinant              determinant             determinant            determinant             determinant             determinant            determinant             determinant            determinant              determinant             determinant             determinant            determinant            determinant            determinant             determinant             determinant             determinant             determinant             determinant           determinant             determinant            determinant             determinant            determinant             determinant             determinant               determinant             determinant             determinant            determinant             determinant             determinant             determinant             determinant             determinant             determinant            determinant             determinant             determinant             determinant              determinant             determinant             determinant            determinant            determinant             determinant              determinant             determinant             determinant            determinant              determinant             determinant            determinant            determinant             determinant           determinant              determinant           determinant             determinant            determinant             determinant            determinant            determinant            determinant             determinant             determinant             determinant            determinant             determinant             determinant              determinant            determinant             determinant            determinant             determinant            determinant            determinant             determinant             determinant             determinant            determinant             determinant            determinant              determinant            determinant             determinant             determinant            determinant             dx dy dz is a is the distance between tcp and an object i want to keep in sight  the sphere is like a safety zone  but is mainly used to compute the orientation of the tool   ,inverse-kinematics c++
9701,designing ackerman s steering principle for an autonomous robot,i am working on a high speed autonomous robot  about     m s   which does obstacle detection as well as senses traffic lights  i have used raspberry pi   and arduino uno     for the steering mechanism  i wanted to implement an ackerman s steering  i ve read about the principle and have understood its basics  now to actually make the design  i am currently using switchboards  sold here in india  they are surprisingly strong  lightweight  waterproof they are switchboards  and cheap  now i got   big axle and the small axle cut out already  along with the two l shaped pieces that join the   axles together    i m just now confused as to how to connect the wheels to the axle and how to make them rotate along side it  the site won t let me upload any pics right now  i ll try again asap  i have the switchboard  an electric drill and will to do anything to make this happen    p    i don t have access to a  d printer  any help would be greatly appreciated      p s  and if you have any suggestions of your own  which might be better for my robot  feel free to share them  i m just looking for a good steering method for my robot  ,arduino raspberry-pi navigation steering
9702,how can i improve zed camera precision ,i m using stereolabs zed camera for my computer vision project  i did a small research about several sensors on the market and ultimately we decided to go with the zed camera   however i m finding that the precision of the camera isn t that great  and the point cloud takes too much storage space  anyone found the same problems  and if so  how did you managed them  thank you  ,computer-vision stereo-vision
9704,motor inertia tensor ,in modeling dynamics of a robot  in which servo motor is adjusted inside the link  there is a need to find inertia tensor of the motor itself right   so if it is needed how can i get the inertia tensor of motor since i couldn t find its solid works model having internal components i mean gears and other stuff with related specified materials   ,servomotor dynamics
9709,is my servo fried ,i got a new servo a few days back  rc servo  futaba fp s      i first tested it out with the sweep sketch on arduino  powering it with the arduino  v and gnd pins only  it was working  just fine  today i was trying to use it in my robot and i tried powering it with   lipo batteries  samsung icr          mah  from an old laptop battery  connected in series  giving     v  as soon as i connected my servo  it started rotating randomly  i had not connected it to my arduino yet  i quickly took it out  next  i used a l     to get     v regulated supply out of my batteries that i used earlier  when i connected my batteries to the servo  and the servo to the arduino  uploaded the sketch  the servo started behaving rather strangely  it first did a complete turn and then stopped  only a humming sound came from the servo  strange thing is  whenever i connect one of my multimeter leads to the power cables  the servo immediately turned in the opposite direction only as long as only lead was in contact with either the positive or negative wire  otherwise  the servo just gives a humming sound  have i fried my servo  or is it some other issue  update   i stripped down the servo and checked the motor  it is working fine  seems like this is a gear problem  ,arduino battery rcservo
9711,testbed for testing navigation algorithms,i m looking for a testbed  simulator or web based interface that lets me to have control on a robot  for testing different routing and navigation algorithms  is there such a system on the web  ,navigation routing
9716,quality check robot,how to develop a robot based system to continuously monitor and check products for defeat which are moving on a conveyer belt using sensors and kick out the defect product from the queue  ,microcontroller
9720,  wheeled vehicle model,i want the dynamic model for   wheeled robot  i expected to find it easily like the   wheeled bicycle model  but i couldn t  here is my effort only for rotation not for feedback   from that i can calculate steering angle  but it was very messy to manage them all  i need the model for controlling  ,wheeled-robot dynamics motion robotc
9724,how to apply a bang bang signal of amplitude   n and   s width as an input force to reproduce certain results in matlab ,i working on dynamic modeling and simulation of a mechanical system  overhead crane   after i obtained the equation of motion  in the form   m q  ddot q  c q  dot q   dot q  g q  q  all the matrices are know inertia    coriolis centrifugal matrix   and gravity  as functions of the generalized coordinates   and their derivatives   i want to solve for   using matlab ode  in m file   i got the response for some initial conditions and zero input  but  i want to find the response  for the aforementioned control signal  a bang bang signal of amplitude   n and   s width   i m trying to regenerate some results from the literature  and what the authors of that work said  regrading the input signal is the following   a bang bang signal of amplitude   n and   s width is used as an input force  applied at the cart of the gantry crane  a bang bang force has a positive  acceleration  and negative  deceleration  period allowing the cart to  initially  accelerate and then decelerate and eventually stop at a target location   i didn t grasp what do they mean by bang bang signal  i know in matlab we could have step input  impulse     etc  but bang bang signal  i m not familiar with  according to this site and this bang bang is a controller rather  could anyone suggest to me how to figure out this issue and implement this input signal  preferably in m file  the code i m using is given bellows  two parts   and  clear all  close all  clc   t      tf        x                                        initional conditions      spectifications mp                       variable mass for the payload figure plotstyle     b    k   r    for i       mp   mp i   mc         mr                    each mass in kg l        j                       m  kg m   respe  spec    mp mc mr l j       call the the function  t x    ode     t x alfagera t x spec   t          tf  x     legendinfo i      mp   num str mp i    kg      fx   diff x        diff t   fy   diff x         diff t   tt    t end   length fx      t end     this time vector    to plot the cart positions in x and y direcitons subplot        plot t x      plotstyle i   axis                 grid xlabel  time  s     ylabel  cart position in x direction  m     hold on legend legendinfo  location   northeast    subplot        plot t x      plotstyle i   axis                grid xlabel  time  s     ylabel  cart position in y direction  m     hold on legend legendinfo  location   northeast    end    to plot the input torque   bagn bang signal   just one sample figure plot tt fy  grid set gca  xtick          xlabel  time  s     ylabel  input signal  f y  n      furthermore  the results i m getting and what i supposed to get are shown    major difficulties  initial conditions are not clearly stated in the paper  the input force direction  is only in y  which it should be   or it has different direction  i appreciate any help   the paper i m trying to recreate is    r  m  t  raja ismail  m  a  ahmad  m  s  ramli  and f  r  m  rashidi   nonlinear dynamic modelling and analysis of a   d overhead gantry crane system with system parameters variation    international journal of simulation systems  science   technology  vol      no               ,control robotic-arm dynamics matlab input
9727,how can my robot find its position in any given map without gps  including when the initial point is not given ,consider this map  the contest arena shown in figure   consists of two sub arenas  both the sides are identical to each other and their scientists and safe zone locations are similar  each sub arena has   different colored rooms and a fourth shared room  each robot will be placed at identical start locations  respective to their arena  these locations will be random and anywhere on the map  each room  other than the shared room  will have two entry and exit gates  both of these gates will be open at all times  the robot can enter and exit from any gate it chooses  ,localization
9728,how to check for a sharp angle with a line follower ,i have the mbot robot and i want to program it to follow the line  so far it can pass any kind of line that is       i want it to be able to pass     ish angles as well  like this one   the problem is that my mbot robot has only   line following sensors  they are   mm apart and the line is   cm wide  so i can t use just the sensors   most of the times it just goes to the line and when it s supposed to turn it just misses the line  goes on the white  and goes back to get back on track  once it s back on the black line it once again tries to go forward but goes on the white instead of taking a turn  this happens endlessly  sometimes it passes the angle by going back and forth and accidentally turning  but that s not even a workaround  let alone a solution  here s a test course of the first round of the competition   my robot can pass this without a problem  but it gets stuck on this  poorly edited  sorry  course   it can t pass the    block if the robot enters it from a    or    block  so basically it gets stuck if it s coming from an angle and hits a    degree turn   the sensor value could be read as either         or   depending on what the robot currently sees       on the line      on the right of the line      on the left of the line      not on the line  pseudo code of my current program   so how would i go about taking such sharp turns  ,arduino motor line-following
9729,diffrence between degrees of freedom  dof  and degrees of motion  dom ,could anyone expain me shortly what is a diffrence between degrees of freedom  dof  and degrees of motion  dom   i know that dof is the number of independent movements a manipulation arm can make and robot system can have max   independent dof and unlimited number of dom but i do not distinguish them from each other  ,manipulator theory
9738,how can a quadcopter be made to hover perfectly still ,i need to get my drone flying still enough that i can rest a glass of water on it  i ve tried a few kk boards and apm          software   i ve balanced props  set pid settings  auto trim   autotune and the drone still tends to inconsistently drift a little one way or another  what is a plausible way to completely isolate drift  ,quadcopter
9739,quadcopter flight controller why does using gyroscope data give better results ,i have succeeded in making my first quadcopter from scratch with a readymade frame  i designed the flight controller myself with help from ymfc  d youtube series of videos   but in the process  i discovered that using the euler angles or the  ypr  values from the mpu     as the feeback to the pid loop makes it super difficult to tune the quadcopter and even then it doesn t fly great   whereas although not intuitive to me  using the gyroscope values with a complementary filter instantly made the quad respond much better and the tuning also was not too difficult  let me clearly define the response in both cases  using ypr values    always keeps overshooting or  underreaching   very small range of values that can let the quad fly stable  drastic reactions to extreme values of p  kp values using gyro values    reaction is much more stable  tuning the pid was also simple   even under high values of p kp  the quad might crash due to oscillations but not flip or react extremely below is a portion of the pid loop   ,quadcopter pid gyroscope
9741,principle of virtual force   general help in understanding   explanation,i m an electronics student taking a module in robotics   from the example   i understand line   as the jacobian is found from the time derivative of the kinematics equation and such relates joint angles to velocity  i do not understand why the transpose has been taken on line   and how line   is produced  ,kinematics jacobian
9751,measuring vehicle s forward and lateral acceleration using a smartphone,i want to measure the acceleration  forward and lateral separately  using an android smartphone device in order to be able to analyse the driving behavior   my approach would be as follows     aligning coordinate systems calibration  no motion   first motion   while the car is stationary  i would calculate the magnitude of gravity using  and rotate it straight to the z axis  pointing downwards assuming a flat surface   that way  the pitch and roll angles should be near zero and equal to the angles of the car relativ to the world  after this  i would start moving straight forward with the car to get a first motion indication using sensor type accelerometer and rotate this magnitude straight to the x axis  pointing forward   this way  the yaw angle should be equal to the vehicle s heading relativ to the world  update orientation  while driving   to be able to keep the coordinate systems aligned while driving i am going to use sensor type gravity to maintain the roll and pitch of the system via   where a x y z is the acceleration of gravity   usually  the yaw angle would be maintained via sensor rotation vector or sensor magnetic field  however  the reason behind not using them is because i am going to use the application also in electrical vehicles  the high amounts of volts and ampere produced by the engine would presumably make the accuracy of those sensor values suffer  hence  the best alternative that i know  although not optimal  is using the gps course to maintain the yaw angle     getting measurements by applying all aforementioned rotations it should be possible to maintain an alignment between the smartphone s and vehicle s coordinate systems and  hence  giving me the pure forward and lateral acceleration values on the x axis and y axis  questions   is this approach applicable or did i miss something crucial  is there an easier alternative approach to this   ,sensors accelerometer gps
9752,e  unable to locate package ros jade desktop full,i want to install ros on my xubuntu        xenial xerus  i have followed the ros s site instruction    and did the following  first  setup my sources list   second  set up keys  sudo apt key adv   keyserver hkp   ha pool sks keyservers net      recv key  xb  fa    then  make sure my package is up to date   sudo apt get update last  try to install ros jade  sudo apt get install ros jade desktop full and get this error  e  unable to locate package ros jade desktop full where did i go wrong  and how can i get ros  any version is ok  running on my xubuntu        ,ros
9754,are all flight controllers and remote controls using the same protocol ,i m about to start a project  where i m sniffing data between remote controls and flight controllers on rc copters and doing stuff with that information   do all  or most  flight controllers use the same protocol to communicate with the remote controls  or does it vary based on which one you buy   i would be testing on drones  dji phantom and the like     so  my real question is  if i want to write something to read the data  will i need to buy a different flight controller for each protocol used  or do they all use the same protocol  and i can just buy one flight controller  and the info i can get out will be the same for all types of flight controllers  also  are the protocols only spoken by the ground remote control and the flight controller   does the receiver care what protocol is being used  or is it just a middle man  ,quadcopter radio-control research
9755,dead reckoning  obtaining position estimation from accelerometer acceleration integration,good day  i have been reading papers about position integration from accelerometer readings  i have consulted this paper from freescale on how that is achievable and this article regarding leaky integrators to help in preventing accumulation of errors from integration  i was testing this algorithm by moving the imu by approximately     meter  the algorithm does get it right at the instant it arrives at approx     meter however when left still at that position  the integrated position goes to zero  it turns out the velocity readings become negative at a certain period after reaching     meters   does anyone have any suggestions in dealing with this error   plots  red is the position  blue is the velocity   the imu accelerometer  was moved alternating positions   meters and     meters with a stop of approximately     seconds in between before moving to the next position  actual data   desired data output  green   desired position integration    code   ,quadcopter sensors localization integration dead-reckoning
9756,step size in numerical differentiation,i get position information and a corresponding timestamp from a motion tracking system  for a rigid body  at     hz  the position is in sub millimeter precision  but i m not too sure about the time stamp  i can get it as floating point number in seconds from the motion tracking software  to get the velocity  i use the difference between two samples divided by the  of the two samples    the result looks fine  but a bit noisy at times  a realized that i get much smoother results when i choose the differentiation step  larger  e g      on the other hand  peaks in the velocity signal begin to fade if i choose  too large  unfortunately  i didn t figure out why i get a smoother signal with a bigger step   does someone have a hint  is there a general rule which differentiation step size is optimal with respect to smoothness vs   accuracy   this is a sample plot of one velocity component  blue  step size    red  step size       ,motion pose
9770,mobile robot algorithm implementation error,i am working in reproducing a robotics paper  first simulating it in matlab in order to implement it to a real robot afterwards  the robot s model is   dot x  v t cos theta   dot y  v t sin theta  dot  theta  u the idea is to apply an algorithm to avoid obstacles and reach a determines target  this algorithm uses a cone vision to measure the obstacle s properties  the information required to apply this system is     the minimum distance   between the robot and the obstacle  this obstacle is modelled as a circle of know radius       the obstacle s speed     the angles  and   that form the robot s cone vision  and    the heading   from the robot to the target first a safe distance    between the robot and the obstacle is defined  the robot has to reach the target without being closer than         to the obstacle  an extended angle   is defined  where   then the following auxiliary angles are calculated      then the following vectors are defined      here   is the maximum robot s speed and   a constant that fulfills    this vectors represent the boundaries of the cone vision of the vehicle given the vectors   and    the angle   is the angle between   and   measured in counterclockwise direction  with    then the function  is  the evasion maneuver starts at time   for that the robot find the index h   where  and  is the robot s velocity vector  then  from the two vectors   we choose that one that forms the smallest angle with the robot s velocity vector  once h is determinded  the control law is applied     this is a sliding mode type control law  that steers the robot s velocity   towards a switching surface equal to the vector   ideally the robot avoids the obstacle by surrounding it a  while the robot is not avoiding an obstacle it follows a control law        hence the rules to switch between the two laws are  r   switching from     to     occurs whenthe distance to the obstacle is equal to a constant c  which means when  and this distance is becoming smaller in time  i e   r   switching from     to     occurs when  and the vehicle is pointing towards the obstacle  i e   where  ideally the result should be similar to this but i m getting this instead while i understand the theory there s obviously a flaw in my implementation that i haven t been able to solve  in my opinion the robot manages to avoid the obstacle but at certain point  in the red circle   the robot turns to the wrong side  making impossible the condition  to be achieved  i feel that i am not measuring properly the angle alpha between the  and    because while debugging i can see that at certain point it stops switching between negative and positive values and become only positive  leading the robot s to the wrong side  it also seems to be related with my problem here  angle to a circle tangent line  ,mobile-robot kinematics matlab geometry
9772,is this a singularity or incorrect implementation of inverse kinematics ,i at moment trying to compute the q configuration that moves my robot from it current state described by this transformation matrix  with rotation  and position as this                                  to this rotatation                                                                                 and this position                         due to the drastic change in the z direction  i thought i could split the path between start and end into small chunks by creating data inbetween by interpolating  and compute the inverse kinematics for each of these small position   problem is that the output i am getting is pretty large   which making me suspect that some of the output might be wrong  the simulation i am using constrains the rotation to     degrees   i think something goes wrong    the only reason i could think would do this  would be if the jacobian i am was using had singularities    which why i assumed that i was running into singualarity issue    setq                                                                          setq                                                                          setq                                                                          setq                                                                          setq                                                                         setq                                                                         setq                                                                         setq                                                                           setq                                                                            setq                                                                            setq                                                                            setq                                                                            setq                                                                            setq                                                                             setq                                                                             setq                                                                             setq                                                                             setq                                                                             setq                                                                             setq                                                                             setq                                                                             setq                                                                             setq                                                                            setq                                                                            setq                                                                            setq                                                                             setq                                                                             setq                                                                             setq                                                                              setq is just a function for my simulation  the numbers are the actual q values starting from         i am using a   jointed robot  ur    update i am using a sphere to compute my desired transformation matrix   the idea is that i want my arm be on this sphere  point inward to the center   std  vector transform d    pathplanning  sphere double dx  double dy  double dz        double r           radius of the sphere    set to     cm  todo  has to be checked if that also is accurate      cout     create a sphere     endl       double current x   this  device  basetframe this  toolframe this  state  p           double current y   this  device  basetframe this  toolframe this  state  p           double current z   this  device  basetframe this  toolframe this  state  p                formula for sphere  x x     y y     z z    r         x  x   x     rcos theta sin phi         y  y   y     rsin theta sin phi         z  z   z     rcos phi         angle range       theta     m pi        phi    m pi      double obj x   current x   dx      double obj y   current y   dy      double obj z   current z   dz       std  vector transform d    out       int count            for double azimuthal      azimuthal    m pi   azimuthal                        for double polar         polar    m pi        polar                                double sphere x   obj x   r cos azimuthal  sin polar               double sphere y   obj y   r sin azimuthal  sin polar               double sphere z   obj z     r cos polar                  string text   to string sphere x            to string sphere y           to string sphere z                 positions    text    endl               transform d   transformation matrix   transform obj x obj y obj z sphere x sphere y sphere z                if      transformation matrix p        current x          transformation matrix p        current y          transformation matrix p        current z                                 cout     interpolate       endl                   std  vector transform d    transformation i   invkin largedisplacement transformation matrix                   out insert out end   transformation i begin   transformation i end                     cout    out size      endl                  cout     only returning one interpolation onto the sphere      endl                   return transformation i                            else                               cout     ok     endl                  out push back transformation matrix                                if count          todo  why       is this occuring                                  cout     theta       theta      phi       phi    endl                    cout    sphere x             sphere y           sphere z    endl                  count                                else                               count                                       return out     this function provides me with the point on the sphere  which is use to create my rotation matrix using transform  transform d   pathplanning  transform double obj x  double obj y  double obj z  double sphere x  double sphere y  double sphere z           z axis should be oriented towards the object         rot consist of   direction vector  x y z  which describes how the axis should be oriented in the world space         looking at the simulation the z axis is the camera out  x  and y describes the orientation of the camera         the vector are only for direction purposes  so they have to be normalized            todo  case              why is it happening at what can be done to undo it      cout     inside transform     endl      cout    obj x           sphere x              obj y             sphere y            obj z             sphere z     endl      vector d   dir z  obj x   sphere x    obj y   sphere y    obj z   sphere z          vector d   dir z  sphere x obj x    sphere y   obj y    sphere z obj z        dir z   normalize dir z       vector d   downplane                    vector d   dir x   cross downplane dir z       dir x   normalize dir x       vector d   dir y   cross dir z dir x       dir y   normalize dir y       rotation d   rot out  dir x dir y dir z        x y z       vector d   pos out sphere x sphere y sphere z        transform d   out pos out rot out       cout     desired       out    endl       return out     the transform basically computes the rotation matrix  the math is based on the on this post by  ben  which is an answer to a similar problem i am having         update error with the rotation matrix was due to the polar coordinate being      sin          i made this plot displaying the determinant of the jacobian  while i compute the inverse kinematics for the large displacement  for each inverse kinematics iteration  i set the robot to the new q i and use that as current and continue computing until i reach the end configuration    it seems that alot of them goes toward a singularity or in general a pretty low number   update again i think the singularities might be the culprit here    determinant            q                                                          determinant             q                                                         determinant             q                                                         determinant             q                                                         determinant               q                                                          determinant             q                                                            determinant              q                                                         determinant            q                                                            determinant             q                                                        determinant             q                                                          everytime i compute a new q i set the robot in that state  and perform inverse kinematics from that state   q is the joint angles for the   joints   update interpolation is done by lineary dividing the path from start to end into a specified amount of of data points     this plot shows  each tranformation matrices generated from the interpolation and with their the position part plotted  the red dots is the path  every     th position   the blue ball is the object in want to track  and green dots represents the sphere   as i am only doing this for the first point on the sphere  it only hits one point on the sphere  which is the top point  which the plot also shows   rotation doesn t show that much change  which also makes sense based difference between the current and desired rotations   update my invkin implementation for largedisplacements  std  vector q  pathplanning  invkin largedisplacement std  vector transform d    t tool base desired i          device  ptr device backup   this  device     read in device parameter      workcell  ptr workcell backup   this  workcell    read in workcell parameter      state state backup   this  state       std  vector q  output        for unsigned int i      i t tool base desired i size       i                  transform d   t tool base current i   device backup  basetframe this  toolframe state backup     read in current transformation matrix           eigen  matrixxd jq device backup  basejframe this  toolframe state backup  e   cols    this  device get    basejframe this  toolframe state backup  e   rows               jq    this  device get    basejframe this  toolframe state backup  e       get the jacobian for current configuration             least square solver   dq    j q  t  j q  j q  t    du      dq   a du          eigen  matrixxd a                    a   jq transpose    jq jq transpose    inverse             a    jq jq transpose    inverse   jq transpose              vector d   dif p   t tool base desired i i  p   t tool base current i p       difference in position           eigen  matrix d dif   t tool base desired i i  r   e    t tool base current i r   e      differene in rotation          rotation d   dif r dif     making a rotation matrix the the difference of rotation          rpy   dif rot dif r        rpy of the rotation matrix             eigen  vectorxd du       creating du          du      dif p              du      dif p              du      dif p               du      dif rot              du      dif rot              du      dif rot               eigen  vectorxd q              q   a du     computing dq           q q current           q current   this  device  getq this  state            q dq q             q q new   q current  dq     computing the new q angles          output push back q new   store it in the output vector          device backup  setq q new state backup     set the robot to the calculated state               return output     i am pretty sure that my interpolation works  as the plot shows   my inverse kinematics on the other hand not so sure   update  chuck mentions in his answer that it would be a good idea to check the core functionality  which might shed some light on what could be going wrong   i tried it with an inv kin function i know would work  which didn t return any result  which make me doubt whether my transformation function i create is accurate  the robot simulation is the one shown above    the  transform function shown above  is the function which i use to compute my desired  and provide my inverse kinematics    is something incorrectly setup   update  chuck came up with an different approach to my problem  which only has   dof  being the position   i choose change track  and peform a simple inverse kinematics given a distance dx dy dz   which for some reason isn t working quite good for me  even for small differences     here is my code      std  vector q pathplanning  invkin double dx  double dy   double dz         kinematics  state state    this  state      transform d   t tool base current    this  device get    basetframe this  toolframe state        cout    current      t tool base current p   e     endl       vector d   p desired          t tool base current p   e      t tool base current p   e      t tool base current p   e            cout    desired      p desired    endl       transform d   t tool base desired p desired t tool base current r         eigen  matrixxd jq this  device get    basejframe this  toolframe state  e   cols    this  device get    basejframe this  toolframe state  e   rows         jq    this  device get    basejframe this  toolframe state  e            least square solver   dq    j q  t  j q  j q  t    du      dq   a du     eigen  matrixxd a               a   jq transpose    jq jq transpose    inverse        a    jq jq transpose    inverse   jq transpose         vector d   dif p   t tool base desired p   t tool base current p        cout    difference      dif p    endl       eigen  vectorxd du         du      dif p         du      dif p         du      dif p          du             du             du              eigen  vectorxd q         q   a du       q q current      q current   this  device  getq this  state       q dq q       q q new   q current  dq      std  vector rw  math  q  output      if  collision q new                 output push back q new             else               cout    endl                cout    q new    endl             return output     which outputs this current                              desired  vector d                                difference  vector d  e           setq                                                                                                                setq is the state which moves the robot to the desires state    either is something wrong with my implementation  or it is a singularity   especially because i am not moving it that much              updates i think i have solved the mystery   it must be the sphere function which creates points that outside the reach of the robot     ,robotic-arm inverse-kinematics
9776,how do i compute the inverse kinematics given a desired transformation matrix ,i am at the moment trying to implement an inverse kinematics function which function is to take a desired transformation matrix  and the current transformation matrix  and compute the q states that is needed to move my robot arm from current state to end state   i have already written the code  but since my simulation isn t showing the right path  or what i would expect it to be  this makes me unsure as to whether my implementation is correct   could someone comment on my implementation and maybe spot an error   example of output   q                                                                      q                                                                            q                                                                                    q                                                                       q                                                                      q                                                                      q                                                                q                                                                      q                                                                     q                                                                  q                                                                    q                                                                 q                                                                       q                                                                       q                                                                   q                                                                                   q                                                                     q                                                                          q                                                                      q                                                                                   q                                                                                   q                                                                   ,robotic-arm inverse-kinematics c++
9783,perspective n point   rpnp algorithm,i need to caculate the pose of a camera using an image of an artificial landmkark  for this porpouse i am trying to use the perspective n point approach so i can calculate it using the intrinsic camera matrix  the world coordinates of the landmark  i am using   points  and its projection in the image  there are some algorithms to solve this  pnp  epnp  rpnp  etc  and i am trying to use the rpnp  i have found an implementation of this here   i used this code but i am having some problems because i can t obtain the correct pose  i am using the p corke s robotics toolbox for matlab to create a centracamera with a known pose and calculating the projection of the landmark in this camera  but the rotation and translation that the rpnp returns me is not the same as i defined before  anyone has used this rpnp algorithm to solve that kind of problems  ,computer-vision cameras 3d-reconstruction
9786,how do the pid parameters  kp  ki  and kd  affect the heading of a differential driving robot when they are increased individually , question  a pid controller has three parameters kp  ki and kd which could affect the output performance  a differential driving robot is controlled by a pid controller  the heading information is sensed by a compass sensor  the moving forward speed is kept constant  the pid controller is able to control the heading information to follow a given direction  explain the outcome on the differential driving robot performance when the three parameters are increased individually    this is a question that has come up in a past paper but most likely won t show up this year but it still worries me  it s the only question that has me thinking for quite some time   i d love an answer in simple terms  most stuff i ve read on the internet don t make much sense to me as it goes heavy into the detail and off topic for my case    my take on this  i know that the proportional term  kp  is entirely based on the error and that  let s say  double the error would mean doubling kp  applying proportional force   this therefore implies that increasing kp is a result of the robot heading in the wrong direction so kp is increased to ensure the robot goes on the right direction or at least tries to reduce the error as time passes so an increase in kp would affect the robot in such a way to adjust the heading of the robot so it stays on the right path  the derivative term  kd  is based on the rate of change of the error so an increase in kd implies that the rate of change of error has increased over time so double the error would result in double the force  an increase by double the change in the robot s heading would take place if the robot s heading is doubled in error from the previous feedback result  kd causes the robot to react faster as the error increases   an increase in the integral term  ki  means that the error is increased over time  the integral accounts for the sum of error over time  even a small increase in the error would increase the integral so the robot would have to head in the right direction for an equal amount of time for the integral to balance to zero   i would appreciate a much better answer and it would be great to be confident for a similar upcoming question in the finals   ,pid wheeled-robot differential-drive
9797,what is the wheel base distance of the create  ,what is the wheel base distance that should be used for the create  to calculate angle  i have seen      mm in code samples but the manual seems to indicate       mm  ,irobot-create roomba
9798,how to compensate the brushless dc motor for voltage drop ,i am working on a quadcopter project based on arduino board  my system is powered by a  s lipo battery      v  but the motors behave differently as the battery voltage drops  when discharging   is there any way that i can make the motors behave the same until a minimum value of  say    volts  my current system works fine at the range from      to    volts  but below that i can t even hover  ,quadcopter
9801,low latency control from a laptop,lets say that i needed to send sensor readings in increments of     bytes from a micro controller to a laptop with sub   ms latencies in real time  the data needs to be processed and acted upon immediately  to control a robot    what interfaces would one use   ftdi usb serial converters aren t an option because they introduce      ms latencies both ways  pci cards are an option though  ,low-latency laptop
9802,all in one gnss localization solution  hardware software ,is there something like an all in one satellite based localization solution that would contain both hardware and software to do gnss localization for robotics  i mean a package that would also contain an imu  would fuse it with gps and filter the result accordingly and then provide a software api to query for location speed etc  i am interested rather in some affordable solution but is there some professional hardware too  i am trying to implement this for my mobile robot and i realize that a smartphone grade gps  samsung j   gives me better preliminary results than an u blox eval board  this neo m t with integrated antenna and ground plane    i wonder why  i guess android may fuse the imu and have better readings even with worse antenna  ,localization software gps gnss hardware
9803,tcp communication with pcduino,i m working on a robot that is controlled by an xbox controller connected to a windows computer and commands are sent to a pcduino through a tcp connection  i have it working by sending a string of   s and   s to tell the pcduino which motors to turn on  i m trying to optimize it by just sending an int and using bit masks to make the decisions on the pcduino but i can t get the pcduino to receive the int correctly  i tested the windows function sending the command with sokit and its sending the correct values but the pcduino is receiving the same number even when the commands are changing  this is what its doing  windows             pcduino command             sendbuff         cmdstring           n      command             sendbuff         cmdstring           n      my windows functions are        bool sendcommand         cmdbuffer    command      cmdstring   cmdbuffer str         if   client  send  char   cmdstring c str                   std  cout     disconnected from server  press enter to exit           std  cin ignore            std  cin get            return false            return true      pcduino loop function void loop         recbuff          deviceflag             read socket                                                                                        read connfd  sendbuff  strlen sendbuff        recbuff   atoi sendbuff                                                                                            set current device to receive instructions from     checkauto recbuff  currdevice          find current device of command     deviceflag   checkdevice recbuff          if current device and set device are the same parse command     if  deviceflag    currdevice                parsehex recbuff             usleep             i have a printf after the read call and that s where i am getting the       number  i think i have everything you guys need but if there s anything else i need to add let me know  i m stumped   i don t know if its just a casting problem or what  update   what i have before everything the setup and loop functions on the pcduino run is  int listenfd      connfd      int n  struct sockaddr in serv addr  char sendbuff        time t ticks   ,communication c++ c
9819,dji wookong m   to unstable to take off,i ve built a quadcopter using the dji wookong m  as of a couple of weeks ago i have been able to get everything to work except for one small thing  when i throttle up the drone tends to flip to the side  i have tested all the motors over and over again and i know that they are spinning the right direction and that i have the right props on the right motors  i tested on both grass and concrete but both times it flipped  it starts to flip once the throttle is past      i don t know if it is catching or if something is off balance although i don t think this is the problem since the quadcopter tips different directions almost every time  if any one could tell me what is wrong i would appreciate it a lot since my project is due in       weeks  thanks in advance ,quadcopter
9822,intropection ros objects using python client library,how can i see attributes and methods of ros objects   can i use inspect module of python   like in python i can use dir    type   commands  ,ros python
9825,stability of pid values update function for quadrotor,a reviewer of the last paper i sent replied me that the it is very dangerous to update a pid with next kind of formula  paper is about quadrotor control    k p  t        k p  t  e t        pe t          pe t      is the   relationship between the desired angles and the real angles  and  is the difference between those angles   and  are the membership functions of a fuzzy function  i think that the reviewer is talking about the time increment update rather than the fuzzy usage and specific formula  how can stability of this formula be tested  please  edit   membership functions are represented in following graph    is not the absolute difference between angles  just the difference  it can be negative ,quadcopter control pid
9826,angular momentum of rimless wheel in passive dynamic walking,in tad mcgeer s work  passive dynamic walking  in       he mentions the rimless wheel model  which is used to approximate the bipedal locomotion  i can t understand why the angular momentum is written as follows   i have the following questions   isn t the angular momentum be    as the paper s notation  if  is  and  approaches to    shouldn t the angular momentum before impact    be negative  then how the conservation goes   ,wheel walking-robot
9828,brushless motor from rc car won t spin with even small resistance,i recently bought a rc car kit and after    minutes it stopped going   when i throttle  i can see the motor trying to spin but it will just grind and get hot quite fast  the motor does move if i disconnect it from the big gear  but not as fast as it did when new and it will still get very hot  also  i can stop it with my fingers with a very slight touch  i don t know anything about motors or escs  so i m not sure if my problem is the motor or the esc   did i burn it out  ,brushless-motor esc radio-control
9832,what are the biggest challenges to build an highly performant robotic hand ,when looking at the robotic hands made by researchers that are said to be rather close to a real human hand  they can easily cost tens of thousands of dollars    what makes them so much expensive  sure there are lots of joints where parts must move  but it s still hard to figure out how it can cost so much even with highly precise servomotors    what is so much expensive when trying to build a humanoid hand  how can we make it less expensive  what do these expensive hands can do  that a diy cheap hand project can t    thank you  ,humanoid
9839,which mechanical device could repeatedly present an id tag to a card reader,i m trying to build a test automation robotic arm which can repeatedly present an id tag  such as rfid or nfc card or fob  to a card reader  i suspect our reader fails either  a  after hundreds of presentations or due to fast presentations or  b  at a specific moment in the reader duty cycle  the tag needs to move in a well controlled manner   quickly present the card   pause  mark  quickly remove the card  pause  space  repeat at     i m calling the present remove sequence the mark space ratio for simplicity  the tests i want to perform involve varying  a  the frequency and  b  the mark space ratio  to  a  stress test and   b  boundary test the re presentation guard times built into the reader to debounce presentations  the guard times are around    ms  response around    ms  so i need something that can move in and out of a     cm range quickly and repeat within those sorts of timescales   the distance the card needs to move depends on the reader model  as they have different field ranges  i want to get through the edge of the field quickly to avoid any inconsistencies in testing  i m able to do any programming  professional  and simple electromechanical design and build  ex professional  now hobbyist   i only need to build one  it doesn t have to be particularly robust  but it does need to be fairly accurate with regard to the timings to do the second test  what i ve done so far  i ve built one version already using a raspberry pi  gpio  a stepper motor with an aluminium arm screwed to a wheel   it works  but it s a bit jerky and too slow  even with a   cm arm to amplify the motion  it will probably do for the repeat test  but it s not time accurate enough to do the timing tests  my other design ideas were    servo  are these also slow   solenoid  fast  but too limited range  and might cause em   motor  too uncontrollable  and will require too much mechanical work for me  rotating drum  fast  stable  but cannot control mark space ratio   i m not a electro mechanical design expert  so i m wondering if i m missing an electrical device or mechanical design which can do this more easily  ,robotic-arm raspberry-pi stepper-motor industrial-robot automation
9840,the velocity profile of my robot is fluctuating,i am presently doing a robotics project  i am using usarsim  urban search and rescue simulation  to spawn a robot  i am trying to create different behaviors  like    goal following behavior   obstacle avoidance behavior  and   wall following behavior for my robot    i first generate the robots in usarsim  then i specify a goal location to the robot and provide it with a speed  the robot then moves to the goal location at the specified speed  usarsim provides me the  x  y  z  coordinates of the vehicle at every time stamp  based on the the coordinates received  i am trying to calculate the instantaneous speed of the robot at every time stamp  the instantaneous speed graph is fluctuating a lot   in a specific case  i am providing the robot with     m s  the velocity profile is shown below  i am unable to understand the reason behind it   here are some observations that i have made    as i increase the speed of the robot  the variations are decreasing  suppose  i provide a straight trajectory to the robot  it doesn t follow the straight trajectory  does it explain why my velocity profile is fluctuating a lot      please let me know if any one can provide me a possible explanation for the variance in my velocity profile  ,mobile-robot
9842,generalized voronoi diagram,i need to compute the voronoi diagram for a map with some obstacles but i can t find any pseudo code or example in matlab  the  voronoi  function in matlab works with points  but in this case the obstacles are polygons  convex and non convex   you can see the map in the attached image   because the obstacles are polygons i found that the voronoi algorithm needed is the gvd  generalized voronoi diagram   can anyone help with code or examples on internet explaining how to compute this gvd  ,mobile-robot motion-planning geometry
9845,path planning vs  linear interpolation ,i at moment trying to convince myself that what i need is a simple path planning algorithm  instead of linearly interpolating between a current and a desired state   i am at moment working with an robot arm  ur  with an camera mounted on to its tcp   the application i am trying to create is a simple ball tracking application which tracks the movement of the ball  while always keeping the object within sight   which meant that i needed some form of path planning algorithm which plans the path between my current state and the desired state  the path should should be such that the ball is always kept in focus while the arm moves to the desired state  but then i began question myself whether it was a bit overkill  and whether a simple straight line interpolation wouldn t suffice    i am actual not sure what form of benefit i would have by choosing a pathplanner  than a simple interpolation   interpolation would also generate the path i desire  so why choose a pathplanner at all  would someone elaborate  it should be noted that obstacle avoidance is also a part of the task  which could cause trouble for a straight line interpolating   ,robotic-arm
9848,path planning for visual servoing,i am at moment trying to implement a visual servoing application   the robot i am using is a ur   and tcp has a stereo camera mounted on to it  the idea is to move the end effector according to the object being tracked   the path planning algorithm for this system should comply with some rules    the path which it creates should be collision free  and always keep the object being tracked at sight at all time    having a path that keeps the object in sight has been bit of problem   sometime will the end effector rotate around itself  messing up  measurements taken and thus the tracking itself    it should be able to maneuver away from static obstacles    a possible solution  i thought of a possible solution  since my current state and desired state is defined by two different sphere  a possible solution would be to create a straight line between each center of each sphere  and between the current position and desired position  such that a straight path in between could be computed easily   which always keeps itself oriented toward the object  problems is that i am not sure how i should handle collision here   update   or use it as a heuristic for a heuristic based path planning   ,robotic-arm motion-planning algorithm
9850,holonomic and non holonomic uav s  gliders vs quadcopters,good day i would just like to ask if a fixed wing aircraft such as a glider without thrust capability therefore needs external forces such as air flow to move constraining its movement  can be considered a non holonomic system considering the fact that it cannot move freely compared to a quadcopter that is holonomic  i found this information from  what s the difference between a holonomic and a nonholonomic system  mathematically  holonomic system are systems for which all constraints are integrable into positional constraints  nonholonomic systems are systems which have constraints that are nonintegrable into positional constraints  intuitively  holonomic system where a robot can move in any direction in the configuration space  nonholonomic systems are systems where the velocities  magnitude and or direction  and other derivatives of the position are constraint  ,quadcopter control uav glider
9851,how do i evaluate the minimum requirements of the processor and camera for a visual slam robot ,i would like to build a visual slam robot  just for self learning purpose  but i get frustrated how i know which processor and camera should be used for visual slam   first  for the processor  i have seen three articles  which shows different systems are used for implementing their slam algorithm   implementing slam algorithm  however it uses ultrasonic sensor rather than visual sensor  in raspberry pi  processing power is only     mhz  in implementing odometry and slam algorithms on a raspberry pi to drive a rover  i have also seen that boston dynamics use pentium cpu  pc    stack and qnx os for their big dog project  bigdog overview november          then  i also found a project uses a modern xilinx zynq      system on chip  a device that combines fpga resources with a dual arm cortex a  on a single chip   for a synchronized visual inertial sensor system  in a synchronized visual inertial sensor system with fpga pre processing for accurate real time slam  but after reading those  i have no clue how they end up with those decisions to use those kinds of processors  stacks or even oses for their project  is there a mathematical way  or a general practice  to evaluate the minimum requirement of the system  as cheap and as power efficient as possible  for an algorithm to run   if not  how could i know what processor or system i have to prepare for a visual slam robot  if there is no simple answer  it is also cool if you can recommend something i could read to have a good start  secondly  i also cannot find clear information which camera i should use for a visual slam robot  i also have no idea how they evaluate the minimum requirement of the camera  i found a lot of papers saying they use rgb d camera but when i google to find one  there are very few commercially available  the one i found is xtion pro live from asus global  for      which is quite affordable for me   but they are out of stock  are there any practice i can choose a suitable camera system for visual slam too   sorry if my question is too long  i feel that choosing the system and camera looks like a thing that requires a lot of experience and background knowledge  so rather than direct suggestions  it is cool if you have some ideas recommended resources for me to learn the general ways people make such decisions in general or in similar projects  if any  ,slam
9852,vector field histogram   vfh  certainty value,good day i am currently trying to implement a vector field histogram algorithm  may i ask if anyone knows what the certainty value pertains to  from my understanding it is like a point system for a cell to increment its certainty every sensor read  is this right  thank you  ,quadcopter motion-planning vfh
9853,maximum distance for robotic arm throwing,i have a  dof robotic arm which i am using to throw a ball  each joint can achieve a maximum velocity of    rpm      deg s   i have been trying to generate joint angles manually and feeding them to see how far i can throw the ball until now  this has shown me that it s like less than   meters   but i feel that i may not be combining the motions of the various motors in order get better throwing distance  i wanted to know if there is a simple way of theoretically determining the maximum distance i can throw  i read a few papers that appear very complicated  i do not need a very accurate value  just an estimate so that i decide whether i should move to a different arm   ,robotic-arm
9856,cosine interpolation between two transformation matrices ,is it possible to perform cosine interpolation between two transformation matrices  it make sense for the translation part  but how about the rotational part  ,robotic-arm stereo-vision
9863,configuration space obstacle   calculating collision,i need to calculate the configuration space obstacle to planning a path with a mobile robot  the idea is to divide the obstacles and the robot in triangles and test whether is there any triangle from the robot colliding with any triangle from the obstacles  the approach to solve this is to test this between two triangles each time so i need to look if any of the   edges    for each triangle  divide the triangles so   vertex from one of them lie in one side and the other   vertex lie on the other side of the line  i wrote some code to calculate the line equation  y   m x   b  and i think it is correct  but i am having problems when the line is vertical  this means that m    inf  because matlab gives me a nan when i calculate the equation for it  i am not sure how to handle this  here you can see a snippet from the code where i test the   edges from the  robot triangle   anyone could help with this issue  ,mobile-robot motion-planning matlab
9870,quadcopter starts at max speed,i am new to quadcopters  just recently started with          kv motors   esc with    hz     esc with    hz  got it from ebay  just found from software  cc d openpilot  now librepilot  flysky fs t     channel   problem   when i configure and calibrate with librepilot software  motors run fine with radio  slow on min and fast on max  but as soon as i remove the usb cable and runs it directly from radio  suddenly on min they go to max speed  i have calibrated manually also with esc cable in receiver with radio  it works perfectly during process and when cable move to cc d and runs again  shows same behaviour   i have calibrated the motors directly  using only the librepilot configuration software and it works fine while connected through usb cable    ,quadcopter calibration
9871,convert toolframe coordinate to world frame coordinates ,i am not sure how i should explain this  i am looking for a way to plot the trajectory an robot arm   an object is seen from the toolframe frame  but how do i plot the position of each joint  such that the frame they uses are the same  one way would be to use the world frame as reference  but how would i plot the position of the object related to the world frame  ,kinematics matlab visualization
9876,connect  s li po battery to   esc,i have   esc with male xt   connector and the battery has   male jst connectors  i want to connect all   esc to this one battery  i will have the following connectors    xt   male to xt   female jst female  but this can connect only one esc to the battery  how can i connect all   esc to the battery  i know last option is soldering  which i want to avoid as i am cse guy  ,quadcopter battery esc connector
9882,madgwick sensor function algorithm  two issues,i am studying the popular madgwick algorithm for imu  and stumbled with two issues   in magnetic distortion compensation  he used the following    why is this assigned to   bx but not  bx  by formula      in his article  it is  bx  is my understanding correct   the raw gyro information is used as  qdot       f     q    gx   q    gy   q    gz   qdot       f    q    gx   q    gz   q    gy   qdot       f    q    gy   q    gz   q    gx   qdot       f    q    gz   q    gy   q    gx     shall the bias drift compensation done in this step  assuming we track the bias with his formula       the bias value shall be applied here as  gx   gx   gyro bias x  gy   gy   gyro bias y gz   gz   gyro bias z  qdot       f     q    gx   q    gy   q    gz   qdot       f    q    gx   q    gz   q    gy   qdot       f    q    gy   q    gz   q    gx   qdot       f    q    gz   q    gy   q    gx    is my understanding correct  ,sensors imu calibration
9890,irobot create    has anyone used the emss irobot create framework to control the create   ,i am having trouble using the emss interface to connect to the irobot create    can i use that framework for create   or is that strictly made for create    sorry in advance i m very new to the robotics field    ,irobot-create software roomba
9891,how to programme an irobot create using a serial to usb cable ,i am trying to programme my irobot create using a serial to usb cable  i have connected the serial end in the cargo bay connector port of the irobot  i am using a software called realterm    to send commands to the irobot  i have set the correct baud rate and other parameters  i downloaded the required driver from    inspite of all this  my irobot is just not responding to the commands  ,irobot-create
9892,issues with running multiple instructions in sequence,i tried to use microsoft robotics dev studio  sample    to write a code that was able for robot to go with a square path by just one clicked  however  there is one problem  when i try to put drivedistancerequest and rotatedegreesrequest in a loop  it would only execute the last request  the problem is that arbiter choice within the drivedistance is activated immediately as soon as the drive operation starts  did anyone have this kind of problem before  if so  how do i solve it  if no  how am i able to fix this problem  thanks your so much                                                                                this file is part of microsoft robotics developer studio code samples         copyright  c  microsoft corporation   all rights reserved                                                                                     using microsoft ccr core  using microsoft ccr adapters winforms  using microsoft dss core  using microsoft dss core attributes  using microsoft dss servicemodel dssp  using microsoft dss servicemodel dsspservicebase  using system  using system collections generic  using system security permissions  using xml   system xml  using drive   microsoft robotics services drive proxy  using w c soap  using microsoft robotics services roboticstutorial  properties  using microsoft robotics services drive proxy  using system componentmodel  namespace microsoft robotics services roboticstutorial       ,mobile-robot control irobot-create mrds
9893,computing the jacobian matrix    chain rule ,i am learning about robot kinematics and the jacobian matrix  and i m trying to understand how to compute the jacobian matrix given a kinematic chain  such as a robot arm  i understand the theory behind the jacobian matrix  but i m not sure actually how it would be calculated in practice  so  let s say that i have a   dof robot arm  with   joints and   links between the joints  i know how to compute the transformation matrix between each joint  and by applying forward kinematics  i know the pose of the end effector for any configuration of joint angles  to calculate this  i have written some code which stores each transformation matrix  and then multiplies them in series to create the transformation matrix between the first joint and the end effector  however  how do i now go about computing the jacobian matrix  my solution so far  is to write down each transformation matrix by hand  then multiply them all by hand  to yield the overall transformation matrix  with respect to the joint angles  i could then differentiate this to create the jacobian matrix  the problem with this though  is that the maths becomes very  very complicated as i move along the kinematic chain  by the end  there are so many terms as a result of the multiple matrix multiplications  that it just becomes so tedious doing this by hand  is there a better way to do this  in the case of calculating the forward kinematics  i didn t have to do it by hand  i just wrote some code to multiply the individual matrices  but when i want the jacobian matrix  it seems like i need to compute the derivative of the overall transformation matrix after it has been computed  and so i need to do this by hand  what s the standard solution to this  is it something to do with the chain rule for differentiation     i m not sure exactly how this applies here though    thank you  ,robotic-arm kinematics inverse-kinematics jacobian manipulator
9894,using accelerometer  gyroscope and any sensor to track speed  position ,problem currently working on reverse engineering this application   this is a wearable device that can track a users   speed positional tracking when the object makes contact with another one    d rendering  currently using an accelerometer and gyroscope to get the yaw  pitch  and roll orientation  of the device  but do not know how to use that information to calculate speed  or if the device has collided with another object  ,imu accelerometer precise-positioning
9895,estimating the displacement of a drone in three dimensions,assuming a drone is in two dimension  it has to predict its future position by calculating its future displacement   for a real quad rotor  why should we not only estimate the displacement of a robot in three dimensions but also the change of orientation of the robot  its linear velocity and its angular velocity  ,quadcopter motion-planning uav
9899,vfh   vector field histogram     is it possible to choose a candidate sector without a set goal point ,good day i am currently implementing the vfh algorithm    is it possible to configure the algorithm such that a reactionary motion is generated at the presence of an obstacle    i have been able to generate the obstacle map  primary polar histogram and the binary polar histogram   how does one prioritize a sector to pass through   i have seen an implementation in labview where in it is possible to implement a simple vector field histogram path planning without any goal points here ,mobile-robot motion-planning mapping c++ vfh
9904,solving inverse kinematics with gradient descent,i am trying to implement my own inverse kinematics solver for a robot arm  my solution is a standard iterative one  where at each step  i compute the jacobian and the pseudo inverse jacobian  then compute the euclidean distance between the end effector and the target  and from these i then compute the next joint angles by following the gradient with respect to the end effector distance  this achieves a reasonable  smooth path towards the solution  however  during my reading  i have learned that typically  there are in fact multiple solutions  particularly when there are many degrees of freedom  but the gradient descent solution i have implemented only reaches one solution  so my questions are as follows   how can i compute all the solutions  can i write down the full forward kinematics equation  set it equal to the desired end effector position  and then solve the linear equations  or is there a better way  is there anything of interest about the particular solution that is achieved by using my gradient descent method  for example  is it guaranteed to be the solution that can be reached the fastest by the robot  are there cases when the gradient descent method will fail  for example  is it possible that it could fall into a local minimum  or is the function convex  and hence has a single global minimum   ,robotic-arm kinematics inverse-kinematics jacobian
9916,what s the difference between the term  pose estimation  and  visual odometry  ,i m reading a paper   choi c  trevor a j b  christensen h i  rgb d edge detection and   edge based registration c   intelligent robots and systems  iros          ieee rsj international conference on  ieee                    which refers    visual features such as corners  keypoints  edges  and color are   widely used in computer vision and robotic perception for applications   such as object recognition and pose estimation  visual odometry  and slam  i previously assume pose estimation to be roughly equal to visual odometry  yet the text above seems to deny  so what s their difference  i didn t find much info from google  imho  it seems pose estimation is estimating the pose of moving object with the camera static  while visual odometry is estimating the pose of camera in a static mostly  scene  is that precise enough  ,slam odometry pose
9918,tring to run    v dc geared motor using samsung li ion icr      batteries,i am trying to run this motor   using the batteries stated in the title  the motor requires    v and i am supplying      v to the motor  through a motor driver  after a while  the motor keeps slowing down and the battery voltage drops down to     v  but after i remove the battery from the motor driver it again shows     v  is this battery capable enough to run my motors  or do i need a new one  ,motor battery
9923,change message interval ardupilot,i am using mavlink protocol  in c    to communicate with the ardupilotmega  i am able to read messages such as attitude for example  i am currently getting only  hz  message rate  and i would like to increase it  i found out that i should use message interval in order to change it  and that i probably need to use the command  to set it  so my question is  how do i send that command using mavlink in c    i tried doing this with the code below but it did not work  i guess that i should use the command that i mentioned above but i don t know how  mavlink message t command  mavlink message interval t interval   interval interval us           interval message id        mavlink msg message interval encode            command   interval   p sensorsport  write message command    update  i also tried this code below  maybe i am not giving it the right system id or component id  mavlink message t command  mavlink command long t interval   interval param    mavlink msg id attitude  interval param            interval command   mav cmd set message interval  interval target system      interval target component       mavlink msg command long encode          command   interval   p sensorsport  write message command    maybe i am missing something about the difference between target system  target component and sysid  compid  i tried few values for each but nothing worked  is there any ack that will be able to tell me if it even got the command   ,quadcopter c++ ardupilot mavlink
9925,vfh  vector field histogram    obtaining the primary polar histogram,good day note  i have found out that my code works  i have placed a minor explanation to be further expounded  i have been having trouble obtaining the right directional output from my implementation  i noticed that every time i put an obstacle at the right  it gives left  it gives the right steering direction  the problem is with the presence of a left obstacle where it still tends to steer itself towards that obstacle  i have checked the occupancy map generated using matlab and was found to be correct  i couldn t pinpoint what is exactly wrong with my code for i have been debugging this for almost a week now and was hoping if someone can see the error i cannot  here is my code implementation   ,mobile-robot motion-planning vfh path-planning
9926,calculate the uncertainty of a   dof pose for graph based slam,this question is strongly related to my other question over here  i am estimating   dof poses  of a trajectory using a graph based slam approach  the estimation is based on   dof transformation measurements  with uncertainty  which connect the poses   to avoid singularities i represent both poses and transforms with a  x  vector consisting of a  d vector and a unit quaternion  x  i     left   begin matrix  t    q  end matrix   right  the optimization yields  x  manifold increment vectors    delta  tilde x  i    left   begin matrix  t    log q   end matrix   right  which are applied to the pose estimates after each optimization iteration   x i  leftarrow x i  boxplus  delta  tilde x  i the uncertainty gets involved during the hessian update in the optimization step    tilde h    ii       tilde a   ij  t  sigma  ij        tilde a   ij   where    tilde a   ij   leftarrow a  ij  m  i     frac  partial e  ij  x    partial x i   frac  partial x i  boxplus  delta  tilde x  i   partial  delta x i      delta  tilde x  i      and  e  ij    log  left   x  j   ominus x  i    ominus z  ij   right   is the error function between a measurement  and its estimate   since  is a  x  matrix and we re optimizing for   dof  is also a  x  matrix   based on imu measurements of acceleration  and rotational velocity  one can build up a  x  sensor noise matrix   sigma  sensor     left   begin matrix   sigma  a                sigma   omega     end matrix   right   further we have a process model which integrates acceleration twice and rotational velocity once to obtain a pose measurement  to properly model the uncertainty both sensor noise and integration noise have to be considered  anything else    thus  i want to calculate the uncertainty as   sigma  ij   t    j  iterate   sigma  ij   t    j  iterate  t   j  process   sigma  sensor  j  process  t where  and  and current measurement   according to this formula  is a  x  matrix  but i need a  x  matrix instead  i think i have to include a manifold projection somewhere  but how   for further details take a look at the following publication  especially at their algorithm    g  grisetti  r  k mmerle  c  stachniss  and w  burgard   a tutorial on graph based slam   ieee intelligent transportation systems maga  zine  vol     no     pp                for a similar calculation of the uncertainty take a look at the end of section iii a  in  corominas murtra  andreu  and josep m  mirats tur   imu and cable encoder data fusion for in pipe mobile robot localization   technologies for practical robot applications  tepra        ieee international conference on  ieee            or section iii a  and iv a  in  ila  viorela  josep m  porta  and juan andrade cetto   information based compact pose slam   robotics  ieee transactions on                     ,slam ekf jacobian
9927,graph based slam optimization fails with numeric error,i am implementing a graph based slam system which works fine  i e  it converges  if i assume a constant covariance matrix  for all my constraints  however  if i model my  more realistically  i e  with increasing entries for progress in time  see my other question  it fails after one successful iteration  i e  after solving the system once but before applying the pose increments  to the poses  for the first time  i use the cholesky based sparse solver implementation of eigen which fails with a numeric error  of course  the failure might occur due to a bug in my implementation  but maybe there s also a problem about representing the math with computers  e g  some overflow in double representation or something similar  could anybody comment on this assumption  please   my implementation makes use of manifolds and is based on algorithm   in  g  grisetti  r  k mmerle  c  stachniss  and w  burgard   a tutorial on graph based slam   ieee intelligent transportation systems maga  zine  vol     no     pp               ,slam
9932,how to split tasks between interrupts and the main loop on a bare metal controller ,i m working on a robotics project where i have   services running  i have my sensor daq  my logic isr  motor controller at   khz  and my ethercat slave controller  daq and ethercat run in the idle and the logic runs during an interrupt  the logic does some calculations and controls the motor  the ethercat service  kinda like canbus  runs together with my daq in the idle loop  i can not run the daq in the interrupt because that leaves me with less than    ns for the ethercat service to run  i m not sure whether this is the right way to do this especially considering all the scary things i ve read regarding data corruption when using interrupts  does anyone have some nice ideas on how to handle these services  i m running all my code on a zynq       on the arm cortex  and it s written in c    here is an example of my code   ,c++ interrupts
9935,how to find friction or viscous force b  nmsec  in dc motor,please guide me  how to find friction or viscous force b  nmsec  in dc motor for a particlar speed  the motor is connected with a gear and the ration is      i want to find for     rpm and the motor no load speed is     rpm please guide me ,quadcopter wheeled-robot brushless-motor stepper-motor
9936,path planning   quadtree decomposition  cell decomposition ,i need to solve a path planning problem using a cell decomposition method  more precisely the quadtree decomposition  i need to do it in matlab so i would like to know whether there is any exmaple or code i could to make some tests  i read about the  matlab function but i couldn t do anything useful  in addition i would need to decompose the cells until a path is found and this functionality is not in the previous function  anyone knows how could i program this quadtree decomposition  ,mobile-robot matlab path-planning
9937,do you have to stop first when switching direction for proper encoding readings ,since the encoder is square wave not quadrature  do you have to stop first before changing directions for proper measurements  in other words  if you are commanding along in one direction at some low speed like   mm s or less and want to change direction to    mm s  would you first need command it to zero and wait for the encoder to read   speed  and then command the reverse direction  in order to get as accurate as possible encoder readings  ,irobot-create roomba
9941,suggestion for correct battery pack,i am trying to run     v geared dc motors which has no load current       ma max   load current   upto     a max   runtime to be atleast     hours  the motor takes about       v for operation  i need a proper battery pack for these  but how can i determine the specs i should go for  ,motor battery
9946,quadcopter  x y velocity pid controller,good day  introduction i am currently working on an autonomous quadcopter project  i have currently implemented a cascaded pid controller consisting of two loops  the inner rate loop takes the angular velocity from the gyroscope as measurements  the outer stabilize angle loop takes in angle measurements from the complementary filter  gyroscope   accelerometer angles    question  i would like to ask if it is effective to cascade a lateral velocity  x and y   axis  pid controller to the the angle controller  roll and pitch  to control drift along the x y plane  for the outermost pid controller  the setpoint is   m s with the measured velocities obtained from integrating linear accelerations from the accelerometer  this then controls the pid controller responsible for the pitch  if y velocity pid  and roll  if x velocity pid   ,quadcopter control pid raspberry-pi stability
9947,starting out  dissertation project using computer controlled drone,for my final year in computer science university i will be doing a dissertation that includes controlling a drone through computer and communication with an onboard camera for computer vision  the first step is obtaining a drone that suits my needs  and i have no clue how to go about it  basically what is needed is a drone that will be able to communicate with a computer both for its movement and to  stream  the video to the computer for analysis   so  would i go for a store bought drone  a rasperry pi or some other microcontroller based one etc  what do i need to take into consideration etc  p s  the project is going to be based indoors  so i don t need crazy range  or very powerf ,quadcopter control microcontroller computer-vision
9951,why do series elastic actuators have more accurate and stable force control ,the other day  somebody was telling me about a robot in their lab  and they mentioned that it has  series elastic  actuators  but after doing a bit of googling  i m still not sure as to what this means  and have been unable to find a simple explanation  it seems that it is something to do with the link between the actuator and the load having a spring like quality to it  but this is rather vague    in any case  the what i am really interested in is the advantages and disadvantages of series elastic actuators  specifically  i have read that one of the advantages is that it allows for  more accurate and stable force control   however  this appears counter intuitive to me  i would have thought that if the link between the actuator and the load was more  springy   then this would lower the ability to have accurate control over the force send to the load  because more of this force would be stored and dissipated in the spring  with less directly transferred to the load  so  why do series elastic actuators have  more accurate and stable force control   ,robotic-arm actuator dynamics torque
9953,kalman filter with redundant sensors,suppose i have one robot with two  d position sensors based on different physical principles and i want to run them through a kalman filter  i construct an observation matrix two represent my two sensors by vertically concatenating two identity matrices      so that   which represents both sensors reading the exact position of the robot  makes sense so far  the problem comes when i compute the innovation covariance  since    then  no matter what  is  i m going to wind up with  innovations from the first sensor being correlated to  innovations from the second  which seems intuitively wrong  if i m interpreting this right   proceeding from here  my gain matrix    winds up doing some pretty odd stuff  swapping rows and the like  so that  when updating a static system    with a constant measurement  i wind up with a predicted state   if i separate the sensors and update the filter with each measurement separately  then   and i get sensible results  i think i am confused about some technical points in one or more of these steps  where am i going wrong  does it not make sense to vertically concatenate the observation matrices  i suppose that i could just set the off diagonal  x  blocks of  to    since i know that the sensors are independent  but is there anything in the theory that suggests or incorporates this step  ,kalman-filter
9954,using fri and aticombineddaqft simultaneously in visual studio,i am trying to the force control experiment with kuka lwr iv  i have a mini   ati force sensor  our data acquisition board is pcie      which is not supported using linux and it seems that i should use windows  one of the lab guys has previously tried to use  fri  and  aticombineddaqft  simultaneously in windows but he was not hopeful  two libraries did not work with each other  did anybody do the same experiment in kuka  or at least encounter the same problem with another sensor and fri  it is noteworthy that our force sensor does not have  net box  to use  udp   i am a bit in a hurry and i really appreciate your suggestions  thanks  ,force-sensor kuka
9955,i m looking for hands on experience with different types of leg and hip designs for walking robots,i m looking to find out  how do human like legs compare to chicken legs and four leg systems  in terms of cost  performance  speed  strength and accuracy  i m interested in things like speed  agility  turning radius  complexity and cost  for a design large enough for a person to ride  rider fatigue is also important    how do they compare in terms of achievable ride smoothness  vibration  and so on  are there quantitative benefits of   dof hip joints  compared to   dof  i realize other factors will come into play as well  such as actuators  joint designs and control systems  however  my interest at the moment is how basic leg designs compare to one another  edit  i m looking for someone who has used these mechanisms first hand  ,kinematics walking-robot
9956,need help in implementing ekf based slam,i just started learning about slam and i have been trying to simulate a robot moving around a set of landmarks for the past   days  the landmarks have known correspondences   my problem is  if i add motion noise to the covariance matrix in the prediction step  the robot starts to behave very weirdly  if i don t add motion noise in the prediction step  the robot will move around perfectly  i have been trying to figure out why this is happening for   days now but cannot find anything wrong with my code  i have attached a link to github which has all the files pertaining to my project  in the folder named  octave  the file  prediction step  and  correction step  contains code for the prediction and correction steps respectively  the ekf slam file is the main loop which calls the above two functions  my github repository also contains   videos which correspond to robot with no motion noise  robot with motion noise and another video which shows how the robot should ideally go about  please help me in figuring out what is wrong with my code in  prediction step  and  correction step   link to my github repository  please click here  ,slam ekf
9962,linearize a non linear system,how do i linearize the following system using taylor series expansion    here   is the heading direction of my robot  measured counter clockwise with respect to  axis   is the linear velocity of the robot   is the angular velocity of the robot  ,mobile-robot localization
9963,distance calculation with two robots and two obstacles,i have a problem with two robots and two obstacles in a space  each robot can communicate its measurements to the other and can measure angles and distances  the two obstacles in the environment are identical to each other  each robot can see both obstacles but not each other  therefore have angle theta   and   combined with distance   and    can the distance between the two robots be calculated   so far i have placed circles with radius of the measured distance over each landmark  triangles in my workings   this provides   possible positions for each robot  red and black circles correspond to robot   and blue and green to robot    using the relative size of the angle measurements i can discount two of these positions per robot  this still leaves me with two possible positions for each robot shown with the filled or hashed circles   is it possible to calculate which side the robot is to the landmarks and the distance between each other  robot   only has the two measurements of angle and distance and can therefore assign an id to each obstacle  but when information is transmitted to robot    robot   does not know which obstacle will have been designated an id of   or    ,localization kinematics
9965,how to get manufactured part from cad file ,i am working through the book learning robotics using python  which is for python programmers who want to learn some robotics  chapter   shows you how to use librecad to design the plates and poles that form the chassis of the turtlebot like robot  for instance  the base plate looks like this   then  there is nothing more about it but suddenly in a later chapter there is a picture of the fully manufactured plates assembled into a chassis  and the author acts as if this should just be something we know how to do   how did he do that  we have these cad drawings  and suddenly there are these plates that were manufactured via some magical process the book never discusses  he never gives things like tolerances  the material that they are supposed to be made out of  etc   the kinds of things discussed here    i know nothing about this stuff  in terms of how to go from cad design specs to getting an actual part manufactured  what kinds of companies should i use  what is a reasonable price to expect  what is the process   in general  how do i go from cad design to manufactured item  do i find a local machine shop that specializes in robotics  bring my cad drawings  and work with them to try to build the parts  i am totally a noob  i hope this isn t a question like this   ,design software manufacturing chassis hardware
9967,how to further understand the computed torque model controller,for the following controller what do  and  stand for  also  what is the general principle of this controller   thanks  ,control microcontroller torque
9969,augmenting room magnetic field for smartphone sensors,is it possible to enhance  or redirect  the earth s magnetic field in a room or house so that one can write a small program that makes smartphones with hall effect sensors detect more reliably in which direction they are pointing  i presume a fridge magnet won t do the job    ,sensors hall-sensor
9971,what software to use to send  oi  commands to create    using windows laptop and supplied create   cable ,i read most of the irobot create   open interface  oi   it says send these serial commands to the create   to get it to do the described action  but no suggestion of what software to use to send these serial commands through the usb interface   i did install the ftdi drivers to enable the usb to serial connection   question  what serial software should i use to communicate with create     is there a tool to verify that the supplied usb to serial cable supplied with create   is functioning and if the create   is functioning   i did a reset on create   using spot and dock buttons  ,irobot-create serial
9972,issue using digit leds raw  op code      on create ,if i understand the manual  each leg in each of the   segment displays is labeled with a letter a g   these letters then map to specific bits in a byte     byte for each of the   displays   setting a bit turns on the corresponding leg while not setting it leaves it off  with this understanding  i tried to turn on all the a segments by sending  instead of the a segment in each display turning on  the displays all showed a    further testing shows that if i send the numbers     for any of the displays  they will display the number sent   sending the number    or greater turns on various combinations of the segments  i was able to activate individual segments with the following numbers     g    a    b    c    d    e    f  however  i haven t been able to determine how the bytes sent affect the individual segments  either i don t understand the manual or digit leds raw does not work as the manual specifies  update   june     i have confirmed this behavior exists in the following firmware versions   r  robot tags release            clean r  robot tags release            clean  ,irobot-create
9978,can too much input current destroy my motor driver ,i have a    v rated driver i m using to drive two    v dc gear motors using my arduino  i bought a new battery pack which is rated      mah   c      v making the total current input      a  my driver is rated for   v min and    v max  no current rating is given  my motors are   v max current under load is     a  so just to be sure  can using this battery destroy my motor driver  this is the datasheet  ,motor battery current
9985,is there an algorithm using the kinect depth image  not the point cloud  for registration ,i know given the intrinsics   where fx  fy are the horizontal and vertical focal length  and  cx  cy  is the location of principal point of the camera if pinhole camera model assumed  of an kinect depth camera or other range sensor    a depth pixel px  u  v  d    u  v  is the pixel coordinate  d is the depth value  can be converted to a  d point p  p  x  y  z  x  u cx  fx d y  v cy  fy d z d  so that a depth image can be converted to a point cloud  and indeed  a depth image represents a unique point cloud physically  slam systems e g  kinectfusion use such point clouds for icp based registration to obtain camera pose at each time and then fuse new point cloud to the previously reconstructed model  however  my mentor told me that depth image cannot be inveribly converted to a point cloud since it s  d   d mapping with ambiguity  which i disagree   and he claims that i should use the depth image at time  i    and  i  for registration  not the derived point cloud   if i have to obey my mentor s order  i ve been reading papers and found one using gradient descent to solve camera pose  tx  ty  tz  qw  qx  qy  qz    prisacariu v a  reid i d  pwp d  real time segmentation and tracking   of  d objects j   international journal of computer vision                           which uses rgb images and a known model for pose estimation  however  i ve never found a paper  e g   kinectfusion and other later rgb d slam algorithms  deals with depth data just as plane image but not point cloud for registration  so could someone give me some hint  papers or opensource code  about   how to do depth image registration without converting them to point clouds  ,localization slam kinect
9986,need help with motors for high load,i need to select motors for the wheeled robot i m planning to build  my requirements are   robot should be able to carry    kg platform size around    cm x       cm speed     mph or  m s planning to use   driven wheels  but can increase if not enough   other parameters like diameter of the wheels  acceleration are not fixed  please help me to calculate required torque and rpm of the motors  it would be great if you can provide equations  or post any lessons related to this problem  ,motor design wheeled-robot torque
9987,how to compile arm compatible binary from an x   precompiled library on a pc host to be run on an arm target ,i am using a library precompiled on x   on my pc  x        does there exist any toolchain to compile the x   library and in the end generate an executable for armv l ubuntu  ,arm linux
9988,instantaneous velocity calculation from accelerometer ,i am trying derive velocity from accelerometer  mpu     in sensor tag board   i saw lot of blogs which talk about noise and exact estimation problems  i started seeing velocity derivation  integration of accelerometer data over time  yielding me towards ramp because of noise presence in mpu      is the velocity can be estimated only by accelerometer or we need assistance of another sensor such as gps or gyroscope  etc   please let me know as i see my velocity calculations never converge at all  also i have limitation in compute power  so kalman filter kind of estimation techniques is difficult to implement  can you please suggest whether i am in right direction or not  ,sensors accelerometer
9994,why wouldn t my robot stop ,i am working on an arduino based robot which engages a braking mechanism detecting anything in front  i was using an ultrasonic sensor  to detect obstacles which worked well while the robot was on my table  i e under construction   but when i ran it on the ground  it doesn t stops and crashes  the robot is programmed as if anything is detected    cm ahead if the robot  the braking mechanism stops the wheels  but when testing  the robot just wouldn t stop  my robot is running at an average    m s   thinking that doppler s effect might have rendered my sensor useless  i tried a little ir sensor i had lying around  range    cm approx   but that didn t work as well  what am i doing wrong here  ,arduino motor ultrasonic-sensors
10002,control of wmr  wheeled mobile robot  in  d,i ve implemented smc  sliding mode controller  on wmr in both x y and x z plane   now i want to combine both of these to control wmr in  d  for this purpose i m trying to use resultant vector of simulation in xy plane and track that resultant vector in xz plane as value of x in previously designed code   tracking control of resultant vector is shown in figure   while vector sum decomposed in rectangular coordinates after simulation is shown in figure     am i going wrong    what other tecniques can i apply to do  d control of vehicle using sliding mode controller  can i reduce the time delay offset  i ve implemented right equations for smc tracking controller equations but simulation does not gives exact results these equations work well for control of vehicle in two dimensions  x z plane     ,wheeled-robot matlab simulation
10003,how to go around in a circle ,i have the mbot robot and i m trying to get it to go to the other side of a cylindral obstacle   something like this   what i know   radius of the cylinder   r robot s distance from the cylinder wheel thickness       cm distance between the middle of each wheel        cm  how would i achieve the above path  the only thing i saw was this so question that says    the distance between the left and right wheel of the robot is     inches  so the left wheel should travel at a distance of   pi  radius    and the right wheel should travel at a distance of   pi   radius     the problem with my robot is that you can t tell it to go   cm to the right  nor can you tell it to turn    degrees to the right  all you can do is set each motor s speed        so there s not way to put it in the formula disatance   time x speed  i assume i have to set each motor s speed to a different value so they would go in a circle of radius x and then just exit at the half of the circle  like shown in the picture  ,arduino wheeled-robot
10004,solving inverse kinematics with non linear least squares,i want to write my own inverse kinematics solver  and i have been recommended to use google s ceres solver to help  now  according to the documentation  ceres solver is usually used for non linear least squares problems     this minimises the sum of squared differences between the measured and target values  over all data  what i am confused about  is how this relates to inverse kinematics  in inverse kinematics  with the example of a robot arm  the goal is to determine what joint angles the robot should be positioned in  in order to reach a target end effector pose  there exists a single equation which determines the end effector pose  given the set of joint angles  and we want to determine the parameters in that equation  the joint angles   but how does this relate to the least squares problem  where there are multiple measurements  is the problem i am trying to solve essentially the same  except that the number of measurements is one  and in that case  is using ceres solver s non linear least squares solver really necessary  thanks  ,robotic-arm inverse-kinematics
10006,build a simple robot to learn ros,i am a beginner to ros and i wanted to know if i could build a simple robot to learn ros   i currently have the following components available   arduino uno simple two wheeled robot chassis some motors l   d motor driver some ultrasonic sensors some infrared sensors  ,arduino slam ros beginner ultrasonic-sensors
10007,how to produce a continuous variation of a discontinuous function ,i have a differential equation that connects the  velocity  of a point in the fov of a camera with the velocities of a robot s joints  that is  dot s j s   dot q where s is a vector with the   coordinates of the point in the fov   is the interaction matrix and  is the vector of the joint positions   if i have a certain point whose velocity i am tracking and this point remains in the fov  then  is well defined  but if i change this point online  that is at the time instant  i have point  and at the time instant  i have the point   then  is not defined  can i create a filter to produce a continuous variation of   if not  what can i do  more specifically  i want to perform occlusion avoidance  in order to do this i want to compute the minimum distance of each feature point of my target object from the possibly occluding object  but  obviously  this distance can be discontinuous due to the fact that another possibly occluding object can appear in the fov nearer to my target than the previously measured    ,cameras visual-servoing filter
10011,stabilising an inverted pendulum,with the problem of stabilising an inverted pendulum on a cart  it s clear that the cart needs to move toward the side the pendulum leans  but for a given angle   how much should the cart move  and how fast  is there a theory determining the distance and speed of the cart or is it just trial and error  i ve seen quite a few videos of inverted pendulum  but it s not clear how the distance and speed are determined  ,mobile-robot sensors accelerometer gyroscope
10014,design in the robotics world,apologies if this isn t really the right place to be asking  but i was wondering whether third party design firms are ever contracted to design industrial and or consumer robots   if not is it something that is usually done in house  and who within an org would usually take care of this process  thanks  ,design
10018,what is the sensor equation for odometry in a kalman filter ,i would like to use an extended kalman filter for the localization of a wheeled robot  with this filter i would like to do sensor fusion between   encoder sensors and an imu with gyro and accelero sensors   the only method i can find for the odometry data to blend in the filter  is to add this as input  uk  to the system xk   f xk   uk   i would like to add the odometry data as normal measurement data  so in the zk vector   but then i need measurement equations g xt    this was what i had  nkleft     t n      pi r  sqrt xv  yv     tn  b     pi r  tauv   n nkright     tn      pi r  sqrt xv  yv     tn  b     pi r   tauv   n with  nkleft nkright   number of odometry pulses during sample period       t   sample time       n    total pulses in one wheelspeed sensor       r   wheel radius       xv   speed in x direction       yv   speed in y direction       tauv   angular velocity       n   sensor noise but when i test my implementation  i don t get the results i expect  so i think there is something wrong in these equations   does anyone know an example where the odometry is inserted as a sensor measurement  so not in the system equation   ,kalman-filter odometry
10019,should i use gyro or encoders for robot moving in straight line ,i ve recently succeeded in building my first collision avoidance arduino robot with   dc motors  and it works pretty well  however  it doesn t move in a straight line yet  when it should  i m now studying which method should i implement to make the robot go straight  i ve heard about using imu or encoders with feedback control  i pretty much understand how to use the encoders  but i m not sure about the gyro  should i use just one of those or a combination of them  ,mobile-robot arduino control gyroscope
10023,what is the most realistic grasping simulator ,i am looking for a physics simulator which can accurately model a robot hand picking up an object  the main requirement is for accuracy   realism  rather than speed  it needs to be able to model soft bodies  such as the rubber  skin  on robotic finger tips  it also needs to be a dynamics engine  such that the object is actually moved around by the hand  modelling effects such as slippage  from the research i have already done  there are two good candidates  first  graspit      this is open source  and specifically designed for grasping  rather than physics simulation in general  second  mujoco     this is a more general simulator  is a commercial product  and has been adopted by some big names such as deepmind  i have tried using the bullet physics engine for robot grasping simulation  but soon realised that this was not going to be strong enough  because bullet is really designed for games  and hence sacrifices realism for speed  however  i m much more interested in something which is as realistic as possible  even if the computation is slow  does anyone have any suggestions as to how i can proceed  anybody with any experience with graspit  or mujoco  thanks  ,robotic-arm simulator simulation
10026,raspberry pi   location in a set field  no gps,i m developing a project which involves a raspberry pi   remote control rover and i need to know the exact location of the raspberry pi rover in a set field  let s say i have four logs  one in each corner of the square field  the goal right now is to extend this to any shape field  any number of corners   every of them equipped with  some kind of wave technology  that allows me to triangulate the position  based on signal intensity  of the raspberry pi rover  the distance between logs should not be bigger than   m      feet  and there is no line of sight guaranted  the question is  which kind of technology should i use  infrared  wifi  bluetooth  radio  ultrasound  etc  or  is there any better approach to this problem  ,wireless
10029,damping vs friction,i am using a physics simulator to simulate a robot arm  for a revolute joint in the arm  there are two parameters which need to be specified  damping  and friction  if a torque is applied to the joint  both the damping and the friction seem to reduce the resultant force on the torque  but what is the difference between the damping and the friction  ,robotic-arm dynamics
10033,first build   quadcopter   need help deciding hardware and connections,i am building my first drone   objective    need to control drone by wifi on phone or laptop using   ground station software of openpilot  i have a arduino        cc d openpilot flight controller   raspberry pi with wifi bluetooth in built    now i am not able to understand   how to go forward   should i connect arduino with openpilot cc d flight controller   or raspberry pi directory with cc d flight controller      do i really need arduino      now   also how to connect r pi with cc d flight controller   and how to mock pwm signals   ,quadcopter arduino raspberry-pi
10034,s curve motion profile  discontinuous acceleration profile in a multipoint trajectory,i am trying to implement an s curve motion profile to reduce the effects of the jerk on a mobile robot   i had succeeded in calculating the equations of the trajectory in case of a point to point trajectory   my problem is in the case of multipoint trajectory  first i introduce to my robot a start position and stop position with initial speed  max speed  max acceleration and max jerk  then  while he is running  i introduce a new stop position and i re calculate the equations of the trajectory  when i generated the trajectory  i found that the acceleration profile becomes null suddenly  what should i do to fixe this problem    ,mobile-robot
10035,handling of a  wd robot frame as a   wheel differential drive,i have a  baron  robot frame with   static wheels  all driven by a motor  at the moment i m thinking of handling it like a   wheel differential drive  left and right wheels would receive the same signal  actually you can interpret it as a tank on caterpillars  exept there is no link between the two tires   does anyone have a different idea about this   ps  the purpose of the robot will be to know it s exact location  i will use a kalman filter  ekf  to do sensor fusion of the odometry and an imu with accelero  gyro and magnetometer  so in the kalman filter i add the odometry model of a differential drive robot  ,differential-drive
10040,rotate  d vector value into a single axis using a rotation quaternion,i want to rotate the whole value of a  d vector into one axis using quaternion rotations  the reason behind is that i want to align the x and y axis of my smartphone with the x and y axis of my vehicle in order to detect lateral and longitudinal acceleration separated on these two axis  therefore i want to detect the first straight acceleration of the car and rotate the whole acceleration value into the heading axis  x axis  of the phone assuming a straight forward motion  how do i achieve this    ,sensors accelerometer rotation
10045,what information an imu gives to a drone ,an inertial measurement unit  imu  is an important sensor used in aerial robotics  a typical imu will contain an accelerometer and a rate gyroscope  which of the following information does a robot get from an imu    position orientation linear velocity angular velocity linear acceleration angular acceleration  i don t think it gets its orientation information from imu  the last time i took the test  i said that all but the first two are true  i failed  ,imu
10048,double triple inverted pendulum always on a cart ,all of the examples of keeping a double triple inverted pendulum balanced using a pid controller i ve seen seem to be on a cart  like this one  how come the pid controller always controls a cart rather than a servo that holds the first pendulum  the second third pendulum could be connected loosely on the first pendulum and the pid controller controls the first pendulum  is it because servos tend to be too slow or are there other reasons  ,motor mechanism servos
10049,question about sampling of proposal distribution in gmapping algorithm,i m trying to reimplement the gmapping algorithm  which is based on the paper by grisetti et al        for my own purposes and therefore would like to understand in detail both the algorithm and the default parameter values people use  to my understanding  gmapping uses a proposal distribution for each particle whose moments are determined by sampling around a scan matching estimate  my questions are   how many samples  does the standard gmapping implementation use to estimate the mean and covariance of the proposal distribution   the samples  are drawn from   where  is the scan matching estimate of particle   how is  determined  how much does this parameter matter   i couldn t find the values they used neither in their paper nor in their implementation of gmapping at openslam org  any pointers regarding the practical significance of these parameters is highly appreciated  ,slam particle-filter
10050,what does simultaneous localization and mapping  slam  software do ,i took a course to have a better understanding of drones and their design  at the end of the course there was a test question that i got wrong and i would like to understand why   i was supposed to select the choices that best describe slam  and the possible answers were   estimates the location of features in the environment   controls the robot s flight through the environment  causes the robot to avoid obstacles in the environment  navigate in a cluttered environment  estimates the position and orientation of the robot with respect to     the environment   at first i knew that at least   and   were right because i watched a drone doing these things  i also thought that the last answer was linked to these two so i said yes to it too  finally  i thought that the only thing that was still controlled by the user would be the flight    yet i failed again    therefore what does simultaneous localization and mapping  slam  software do  ,slam
10052,position control vs velocity control vs torque control,please can somebody explain to me the difference between position control  velocity control  and torque control  specifically  i am thinking in terms of a robot arm  i understand that position control tries to control the position of the actuators  such that the error signal is the difference between the current position and the desired position  velocity control is then trying to control the velocity of each actuator  and torque control is trying to control the torque of each actuator  however  i don t understand why these are not all the same thing  if you want to send a robot arm to a certain position  then you could use position control  but in order to move an actuator to a certain position  you need to give it a velocity  and in order to give it a velocity  you need to give it a torque  therefore  whether the error is in position  velocity  or torque  it always seems to come back to just the error in torque  what am i missing  ,control kinematics dynamics roboti-arm
10053,load pre built occupancy map in gazebo,i have built an occupancy map using the gmapping package in ros for a  real  hallway  now i want to use this map in gazebo so that i can simulate my robot in this environment  it seems that gazebo can only support the map built from its own models  not from an external occupancy map  is there any way that i can use an occupancy map in gazebo or some other simulators  it is easier to obtain an occupancy map from real world than building a physical world in a simulator    ,mapping gazebo occupancygrid
10056,choice of a motor for robotic arm,this is my first post here  so hello all  i really hope i can learn a lot from you guys  i am trying to build a robotic arm to carry an object and put it inside of different boxes that are placed in different fixed locations  i found a few robotic arms that can do it  but i am still trying to find the right motor for the job  i read a lot on line about the different motors  but i am not sure which on to pick  since the boxes are located in fixed places  the motors have to move in a precise way  so  according to my research  servo motors are the ones i should use    since it is a low budget project  i am college student   i wasn t sure which motor to choose  there are a lot of servo motors out there   i found several servo motors on line  for example   analog feedback servo  and i was wondering what is the best servo motor i can buy for a really low cost project  i think i can spend about        per motor  i need   motors   i already have an rpi and i know that pin    is the pwm pin that controls the motor s precision movement  but before i purchase a pwm controller and additional motors i need to run some testing to find how precise the motor is  by the way  how can i calculate the amount of weight the motor can handle  any ideas and information will be greatly appreciated  thank you ,robotic-arm raspberry-pi servomotor python
10059,in how many ways can a six propellers drone fly or rotate ,i thought it were twelve ways   six for each ways between two propellers six others for each rotation on these ways   but according to vijay kumar dean of penn engineering   it seems that i was wrong    then i read this article  about modeling and robust trajectory tracking control for a novel six rotor unmanned aerial vehicle and this one about navigation and autonomous control of a hexacopter in indoor environments but was never able to find such an information  i then guessed that   of the rotors could go one direction and three others into another which would add   other ways for rotating and therefore   others for simply flying but that is only a guess   ,multi-rotor
10060,motor choice given size constraint and load requirement,good day everyone    i am an undergraduate student working on a project involving the use of high torque small sized dc motors for use in designing a person following trolley bag  where in the problem is to use small sized motors but still maintain the usability and efficiency in carrying loaded luggages  i have been looking for motors in local stores as well as in rs components as well as element     however i am not sure if my choices are the right fit as i am at a loss on what specifications to look for when selecting a particular motor for this application  i have also tried to look for motors used in current products that can be used in my application such as todays electric skate boards but unfortunately have no luck on finding their suppliers   basically the question i would like to ask  is what specifications or calculations can i perform to select the proper motors given size constraints and weight carrying requirments  or does anyone have suggestions on common motors that are already normally used for this application  my target maximum load capacity is   kg   thank you  ,mobile-robot motor gearing
10063,rostock delta robot  d printer degrees of freedom  dof ,what is the degrees of freedom  dof  of the rostock delta robot  d printer  delta mechanism that consists of three prismatic joints   here s the link to the delta mechanism i m referring to    thanks in advance for your help  ,kinematics inverse-kinematics actuator manipulator 3d-printing
10070,tracked robots dimensioning,i m designing a tank tracked robot  i would like to know how do we calculate the minimum height difference between the sprocket wheel axis and the boogie wheel axis  if the maximum height of any obstacle is    cm   ,design mechanism tracks
10072,how to make a robot ,for instance  how would you hook up a electric pump communicate with a motherboard  let s say i buy a electric pump  i hook it up to some sort of metal structure that if the pump is turned on it moves the metal structure  how would i hook up the pump to my motherboard so that i can program it   ,control motor robotic-arm microcontroller machine-learning
10076,problem with vex updating,hi i am having a problem with my vex robot updating system   right now i am using vex iq firmare update and my mac states that everything is up to date   however when i look online there is a new update out   i can not use the radios for the controller because i can t update the brain  ,vex
10077,how are industrial robotics components purchased ,for hobbyists  you go to a store to buy products  the prices for these products are all clearly listed in the store catalog  and you can easily search for parts by lowest price or read customer reviews of the products  for industrial engineers building complex machines  how do they buy components  or don t they worry about cost  and leave it to their employer to eat the cost as a part of doing their line of work  is it possible to  shop around  for low cost engineering components    it is unclear to me how someone building a robot on their own as a small one man startup can make the step from the world of toy robots  to larger and more industrial robotic components  most of the non hobbyist stuff is hidden away and not exposed to the world  while a product catalog might be available  there are no prices listed for anything  for larger industrial components  there does not seem to be any realistic way to shop around for the lowest price or best value  since pricing for much of the big stuff is basically unavailable    for me personally  i am interested in trying to build my own powered exoskeleton on a middle class american income  so i can t afford to be paying      bucks for a single electrohydraulic proportioning servo valve  when i ll need probably    of them  but shopping around for low cost ones is basically impossible as far as i can determine  because pricing info is generally not available or searchable from the majority of manufacturers  ,industrial-robot
10087,task space to joint motion space conversion,i am the moment trying to read and understand this paper task constrained motion planning in robot joint space but seem to have a hard time understanding the math    the paper describes how to perform task constrained motion planning in cases where a frame is constrained to a specific task  the problem the paper tackles is when sampling in joint space  randomized planners typically produce samples that lie outside the constraint manifold  the method  they proposed methods use a specified motion constrain vector to formulate a distance metric in task space and project samples within a tolerance distance of the constrain     given the this i am seem to a bit confused on some simple terms they define in this paper   examples  how is a task space coordinate defined   what information does it have  they compute the  delta x   t e t q s  which is transformation matrix of the end effector with respect to the task frame   what i don t get is why the end effector  and why the end effector with respect to the task frame  secondly  later in the paper they write down an expression that relates the task space to the joint space motion  they do it using the jacobian  but seem to miss explaining  in my opinion  what  actually do   j q s    e q s j t q s  what is said about it in the paper is that   given the configuration   instantaneous velocities have a linear   relationship   why the need of instaneous  what is the definition of an instantaneous component  how does it differ from the information given by the jacobian  basically i don t understand how and why the mapping is as it is     ,robotic-arm motion-planning jacobian
10088,send quad copter control signals from arduino or raspberry pi to receiver on open pilot cc d,i have open pilot cc d attached to a receiver which can accept signals from a rc transmitter after configuration through gcs     objective is to   send these control signals   yaw throttle roll pitch     from r pi or through arduino   whichever is best to transmit   signals  by using a simple radio transmitter   like     mhz tx   i want to use a usb based game controller   which will be connected to raspberry pi and then it can transmit signals through radio to receiver    is this feasible  or need to be scrapped    ,quadcopter arduino raspberry-pi radio-control
10089,locking the yaw direction of a laser pointer,i have a laser pointer on a handle grip and i m trying to keep the laser pointer s yaw direction  which can rotate at around   deg s  so i have the laser pointer on a stepper motor and an accelerometer gyro in the handle  but what s a good way for maintaining its yaw direction  could i simply turn the shaft according to the accelerometer gyro s yaw readings or is control theory  pid  needed  that is  if my stepper makes      steps rev  one gives        deg  if the handle is turned by  say        deg  then turn    steps in reverse  instantaneously   would this be jerky and pid be needed  any thought appreciated  ,sensors stability
10092,arduino or raspberry pi ,i want to make a object tracking quadcopter for a project  while i m using the arduino mega      as the flight controller  i was thinking of using an additional offboard microcontroller board for getting data from the onboard camera which would then send an appropriate command to the onboard arduino  i was hoping someone could provide clarification on the advantages disadvantages of doing object tracking with either choice  thanks     ,quadcopter arduino raspberry-pi
10096,how can i charge a      volt lipo akku ,i didn t found any modules to charge my      volt lipo akku  only for     volt with   volt power supply  how can i handle that with a micro usb connector on my robotplatform  ,arduino power lithium-polymer
10098,storing a  d map,i am trying to build a  d map using two cameras  i have found the coordinates of all the objects  what is the best way to store this data i would also like to display this map later  my range will be     meters         cms   the accuracy i have managed to achieve is within   cm  i have used opencv and python on a laptop i would like to shift to a raspberry pi later if the pi can perform well enough  my main issue is how can store this  d map  ,cameras mapping 3d-reconstruction opencv
10099,hubsan x  drone camera recording black,i m unsure if this is the correct community to ask this question  vs stackexchange electronics or aviation  for example   but i recently purchased a hubsan x  hd video drone from amazon  this is my second hubsan drone so i am already familiar with using the recording feature  however  after every recording  the recordings are the correct length  with the correct audio  but the image is black  i tried formatting the micro sd  using different micro sds  reading up on forums  etc  but nothing seems to do the trick  is mine defective  or has someone had this issue and has been able to solve it  thanks ,quadcopter cameras
10101,ultrasonic sensor through a column,i am trying to measure the height of water inside a column  the column is   mm in dia and    mm long  i have mounted the sensor just above the column   to measure the accuracy of the sensor  i filled the column up to a known value  a  and got the average sensor reading  b   a b should give me the height of the sensor from the base of the column  repeating this for different values of a  i got very different values for  a b   see attached chart   my question is  is the sensor expected to have error of this order   is my setup of confining the sensor through a column producing such errors   any other ideas to get the water column height  please note that during the actual test  the water inside will be oscillating  up and down  i am thinking of making a capacitive sensor using aluminium foil  water will work as the dielectric and the level of water will determine the capacitance   p s  i also did some open tests  not through a column  to get the distance of a fixed object  and it was quite accurate  any help is appreciated  arduino code  ,arduino ultrasonic-sensors
10103,is there a way to combine and sync two  k cameras     fps with ics,i am searching for a way to minimize the size of a stereo vision module and cannot find any ics that will combine and sync two mipi csi      lane  data streams without an fpga and too much code   there was one online  max    a  d video combiner synchronizer with two mipi csi   input and one mipi csi   output  but the product is not publicly available    does anyone have knowledge of an arrangement of ics that i could try   ,computer-vision
10106,how to use the opcode to start ,i am new to robotics recently came into contact code so the teacher let me use the serial port app for android to enter the opcode but the robot did not have any reaction   i use the communications cable with adapter in android phone  app use  droidterm  usb serial port  serial port settings baud                  also used  data bits    parity  none stop bits    flow control  none  i try to enter opcode  but no response     enter                  but it did not show any reaction to the phone and robot  i hope according to opcode instructions to control robots to make the specified action  ,irobot-create
10110,visualizing raw accelerometer and gyro data,i have an arduino wired to an mpu     breakout board  the arduino continuously collects accelerometer and gyroscope data from the mpu     and calculates angle and velocity   simply plotting the vector components  x y z  of this data does not allow one to reason about the motion of the sensor or robot  it s possible  though not easy  to do sanity checks  is the sensor oriented as expected  is gravity working    but it s very difficult to look at a x y z plot of accelerometer log data and imagine what the robot did for instance   i was wondering if there is some sort of tool or python library to visualise accelerometer and gyro  or imu data   i m looking for something like this    ,arduino accelerometer gyroscope visualization
10115,slam   odometry motion model,i am making a project with a   wheeled differential robot to make visual slam using a stereo rig  i have some encoders to measure de displacement and the steering angle of the robot and i want to use the odometry motion model in the fastslam algorithm  to use the odometry motion model you need to calculate the values it needs from the odometry reading  incremental encoders    where  and  are the previous and the current pose extracted from the odometry of the vehicle  my question is about how to obtain those values from the encoders  i guess that in this case i would need to obtain the equations from the geometric model for the differential robot      where  is the advance of the left wheel   is the advance of the right wheel   is the lecture from the left encoder   the lecture from the right encoder   the total number of pulses of the encoder type   is the total distance achieved by the robot and  the angle steered   is the distance between the wheels  using those equations is possible to obtain the pose in every time step     so those last are the values i need to inject to the modometry motion model and then add gaussian noise to them  am i right  or is there another way of computing the pose from odometry for a differential   wheel robot  ,mobile-robot slam odometry movement
10117,how to preprogram irobot create  ,i want to program a set path for the irobot to follow without having to be tethered all the time to my computer  what is the best way to do that   ,programming-languages
10118,how to decide the torque of the motor and the gearbox ratio for a robotic arm ,how to decide the torque of the motor and the gearbox ratio for a  say   dof  robotic arm  having a   kg payload capacity for instance  i am mainly concerned about the inertial mismatch  how do i calculate it  are there any other factors that i should consider   ,motor robotic-arm torque manipulator
10119,how to create a model for temperature control ,i have a heated compartment  inside which  there is another object heated up by independent heater  i want to control temperatures of both chamber and the object   i could achieve this by simple pid  or pi  controllers for both chamber and object  but i would like to try more thoughtful approach    i have two temperature sensors  and two pwm outputs for heaters  how do i identify a model for an object i want to control     ,control pid automation
10125,what kind of torque is needed for a small     axis robotic arm ,i m new to robotics and i m looking to make a     axis robotic arm out of stepper motors but i honestly dont know how much torque i should have for each part  below i have described in more detail what my current plan is but i m really not sure as to how much i really should be spending on each of these joints  my general plan for this project was to make a arm that when fully extended would only be around       max  cm long  it would be consisted of light weight aluminum and i am hoping for it to weigh only a couple of pounds when done  anyway here is my current list of actuators for each of the joints   bottom      top         st joint   i cant actually post the link because i don t have enough rep  but this is what it is called on amazon  nema    cnc stepper motor    a     nd and  rd joints   th   th and  th joints  my real questions is  is this overkill or is it not enough for what i m really trying to make  i really don t need it to be able to pick up a lot of weight  at most   to   kilos but i highly doubt i will ever be picking up anything more than that  anyway i just wanted to see if this was sufficient enough for my project    i know this isn t really the best place to ask but i really need some help because i am new to this and i don t want to throw money where i don t need to  thanks in advanced    ,robotic-arm stepper-motor actuator
10127,pid with position and velocity goal ,i m trying to design a control system for a robot that tracks moving object  thus i want to robot to match the position and velocity state of the object  i don t want robot to simply to arrive at the position  but i want to arrive at the position with the same velocity of the object   object velocity and position data will be provided externally  i m not sure if a traditional pid controller  with velocity controls  with just a position based error is enough  wouldn t position only state goal result in tracking that is always lagging behind  is pid what i want or should i be looking at something else like trajectory controls  ,pid
10129,disable mavlink heartbeat using telemetry,i am using an apm     that is connected to an odroid usb via telemetry port  uart to usb   i am trying to get mavlink messages without the need to keep sending a heartbeat message    if i switch to usb connection  not telemetry  i get mavlink messages continuously  without sending heartbeat messages to the apm  i want to be able to do the same using the telemetry port  is there any place in the firmware  arducopter  code that i can change  or maybe just a parameter  i am using       baud rate  i tried also         and the usb cable is not connected  ,quadcopter ardupilot mavlink
10130,detect physical touch hit,i m making a target to an outdoor robot competition  the target should detect if some of the robot got touched or got an hit   automatically  and the target can get hit     degree   i m searching for the perfect sensor to detect an hit  without get false positive from a wind  my option right now are     ultrasonic sensor  bad coverage     tilt sensor   bad fp rate     wooden conductive  i would like to know if someone has other ideas  that affordable   less than     dollar per target might be o k  edit  the target is static  and just waiting to a robot to touch it  edit  the specs are     the target dimension is   meter height      meter width       depth     to trigger the target  the robot should be around    centimeter long to any point of the target surface    to trigger the target the robot needs to get close up to    centimeter or even press with around   newton force  the robot might even throw an object that satisfy the previous condition    detection must be only from intentional touch    wooden conductive is trigger because a human is electrically conductive  this might not be the option when we throw an object     target will be placed outdoor  so the sensor need to be wind resistance  not extreme wind condition  just around       km h     i  prefer a sensor that detect touch  more than proximity because it might make my solution more cheap and reliable in factor of amount sensors as i estimate   thanks  guy ,arduino sensors force-sensor
10132,what is the best way to plug in more than   stepper motors into a arduino uno board ,i m developing a   axis robotic arm with stepper motors and i am getting around to ordering most of my parts  i plan on using   easydriver shields to drive all of my motors  i am also planning on using just a basic arduino uno board to go with it  so here are my questions  is there any alternative instead of buying a ton of easy drivers and connecting all of them to a single board  and if there isn t  then how would the setup look to use more than   stepper motors  this is the most useful picture i found  however it only shows   and while i know i could plug in a  th i am unsure whether i could plug in a  th  ,stepper-motor
10136,irobot create   granularity of drive control ,i own an irobot create  on which i am planning to implement a control algorithm  after playing with the different drive commands  i noticed that changing the desired velocity values marginally doesn t seem to do anything  even the drive pwm command that ranges from      to     seems to have an internal granularity that is bigger than    in this video the create seems to change its driving direction nearly seamlessly  which i am not able to reproduce with the described behavior   does anyone have any suggestions  ,control motor irobot-create
10148,what s new about drone technology ,in recent years  we ve heard a lot about drones  what new technology is enabling these new devices  why are they making news  when i was a kid  we used to call those things  similar to what we now call drones  remote control or rc  but  apparently it s not just a nomenclature change because we now have new fcc regulations  commercial applications like amazon prime air  news of military applications and i still see rc labeled devices in the stores  so  what is this  new drone stuff all about  and why now  what new technology has recently emerged that enables these devices  ,untagged
10150,how does ode determine contact points in gazebo ,i was looking at the contact points for the atlas in the drcsim package  each foot has   contact points at each vertex of the rectangle  i d like to know how these points are determined  i ve tried looking at the ode code  but c   isn t my strong suit so i had some difficulty figuring out what was going on  what i understand is that ode compares the geometries one by one however it s not possible to compare all points so it only compare a select few points  what i m trying to understand is what basis are those particular points selected  why does the atlas have the   contacts set up the way they are  and not some additional points on the heel  can i add them myself  thanks  ,gazebo
10153,apm     response only once after request data stream,i am trying to get mavlink messages from apm     via telemetry that is connected to my ordoid u  usb port   i am able to read messages when i send the request data stream message  but it sends them only once  i want to be able to get them continuously without needing to send the request again  any ways to solve this  ,quadcopter communication ardupilot mavlink
10154,bldc motors erratic behavior with arduino program,i ve been making my own quadcopter flight controller using arduino mega  this is the sample code i wrote in order to test the esc timers and motors   however  my issue here is that the bldc motors i m using don t work smoothly when connected to the arduino  they erratically stop and even change direction of rotation at the same throttle input  i ve tested them by connecting them directly to the transmitter and they work fine there with perfect rotation and speed  can someone please help me out and tell me where i might be going wrong   edit  i do realize posting the entire arduino code might be overkill  but i ve been trying to solve this problem for three days  as of   nd june     and i really do hope someone can point out any improvements corrections in my code  ,quadcopter arduino brushless-motor esc
10159,icreate   with arduino  just getting going ,i am new to the irobot create   but i do know a thing or two about the arduino  don t assume too much though   however  in this case  i am beyond stumped over what i am sure is something simple but is somehow not obvious to me  three people have confirmed my wiring from the create   to the arduino to be correct and the code i have looks similar to many examples that i have seen on this forum  however  i cannot get my create   to do anything  i am not at all sure what is wrong and i am starting to wonder if the robot is even receiving commands let alone doing anything with them  is there anything wrong with this code and can anybody suggest a way to verify that the robot is receiving data  since it does not beep or provide return messages   thank you  edit              est   updated code  with a few notes    ,arduino irobot-create
10167,getting i c sensor output from ardupilot to arduino,i am trying to get the airspeed for arduplane from erle brain     ardupilot  through its i c port  and send it to arduino   what i have discovered  there already exists i c driver cpp  and i can use this to send data  by using the functions in arduplane cpp  however  i am lost on how to implement the sending part  as in how i use the functions  the functions like write accept arguments of address  length  data  how do i know that  and do i send the data in binary  any help will be really appreciated   thanks  ,arduino ardupilot i2c
10169,what are the prerequisites for learning ros ,it is helpful in robotics to first learn about  linux kernel development  or  device driver development in linux  before i start learning ros  i know c and java  in brief  i want to know any prerequisites which are essential to understand ros better  ,ros linux
10172,covering up ultrasonic sensor,i m using a basic trig echo ultrasonic sensor with an arduino uno  i get accurate readings until i cover the sensor at which point i receive very large numbers  why is this  program  example output i moved my hand from     away until i cover the sensor       distance     my hand is     away from the sensor       distance       distance       distance       distance       distance       distance       distance       distance       distance       distance          distance     my hand is now pressed up against the sensor         distance          distance          distance          distance          distance   edit i changed the amounts from inches to milimeters to get a more precise reading  i held the sensor     mm from a granite counter top and quickly lowered it until the tabletop covered the front of the sensor  distance               mm from tabletop distance        distance        distance        distance        distance        distance        distance        distance        distance        distance        distance        distance        distance        distance        distance           sensor continues toward table but values start to increase when they would logically decrease    distance        distance        distance        distance        distance             sensor is now flush against tabletop distance          distance          distance          distance          distance          distance          distance          distance          distance              extreme high   low values with sensor is same place against tabletop distance        distance           distance        distance           distance         ,arduino ultrasonic-sensors
10178,switch activated by a microcontroller,i m working on a project where i m using a voltage that is higher than what most microcontrollers can handle  i m looking for a kind of switch that will connect a power source to an electromagnet and all of this controlled by my microcontroller  i also thought about using a potentiometer to control the speed of two high voltage dc motors via my microcontroller so please tell me if this is a good idea aswell   thanks for your time  zakary ,arduino microcontroller
10187,proper naming of pid regulators,i was wondering either there is any special naming for regulators that   outputs unit is the same as inputs  ie  velocity  m s  as input and velocity as output  m s   outputs unit is different than inputs  ie  position as input  m   velocity as output   m s   i would appreciate all help  ,pid
10190,can a robot or mechanical part be programmed to exert a specific force,so i was thinking about projectiles that don t need a propellant like gunpowder i ve seen coils gun but that s a little out my way  i was wondering if i know the force required to propel a object could i program a robot to exert that force to propel the object the same way  in a linear propelled fashion   ,force-sensor
10192,create  incremental encoder rollover method,i have never yet had the create  s incremental encoder rollover but want to write my code to be prepared for this to happen and test it  when the encoder rolls past            m   does it rollover to        and count there or start at   again and count up from there  one other odd thing but not a big deal  when i reset the create   the first value is   not     ,irobot-create roomba
10193,what is liadar alternative for indoor rc car,i am new to robotics and working on autonomous rc car for indoor purpose only  i was wondering how can i detect expected collision  i am planning to put dummy cars near by rc car   please guide me if there is any other alternative or any one has worked on similar project  reference what are some low cost alternatives for lidar  thanks  sandy ,mobile-robot
10195,starting out  arduino vs raspberry pi drone,for my dissertation project  i will have to use a drone  what it will do is look for an object in a closed space  what i will most deffinately need are   a camera sensors to avoid collision pc communication     stream video  receive directions  the pc will control the drone  give it directions etc    now i m wondering what would be the best platform to build on considering these requirements and i have absolutely no idea what s going on in the microcontroller world  so i don t know which of the two has more shields and whatnot that would be suitable for my needs  ,quadcopter arduino raspberry-pi
10196,using quaternions to feed a quadcopter pid stabilizing controller to avoid gimbal lock,i am trying to control my f    dji quadcopter using a pid controller  from my imu  i am getting the quaternions  then i convert them to euler s angles  this is causing me to have the gimbal lock issue  however  is there a way that i directly use the quaternions to generate my control commands without converting them to euler s angle  this conversation here discusses a similar issue but without mentioning a clear answer for my problem  the three errors so far i am trying to drive to   are   where the master generates the desired rotation and the slave is the imu  update  here are some pieces of my code  getting the current and the reference quaternions for bot the master and the slave from the rotation vector      master s current quaternion    double x     measurements get     double y     measurements get     double z     measurements get     double w     measurements get          slave s current quaternion    double xs    measurements get     double ys    measurements get     double zs    measurements get     double ws    measurements get          master s reference quaternion    double x     measurements get     double y     measurements get      double z     measurements get      double w     measurements get           slave s reference quaternion      if the code has not been initialized yet  save the current quaternion     of the slave as the slave s reference orientation  the orientation of     the slave will henceforth be computed relative to this initial     orientation      if   initialized        x s   xs      y s   ys      z s   zs      w s   ws      initialized   true     then i want to know the orientation of the current quaternion relative to the reference quaternion for both the master and the slave              compute the orientation of the current quaternion relative to the        reference quaternion  where the relative quaternion is given by the        quaternion product  q    conj q                 w    x  i   y  j   z  k     w   x i   y j   z k                  pre         see                    pre                 for the master     double wr   w   w    x   x    y   y    z   z       double xr   w   x    x   w    y   z    z   y       double yr   w   y    x   z    y   w    z   x       double zr   w   z    x   y    y   x    z   w           for the slave     double wrs   ws   w s   xs   x s   ys   y s   zs   z s      double xrs   ws   x s   xs   w s   ys   z s   zs   y s      double yrs   ws   y s   xs   z s   ys   w s   zs   x s      double zrs   ws   z s   xs   y s   ys   x s   zs   w s   finally  i calculate the euler angles             compute the roll and pitch adopting the tait bryan angles  z y  x  sequence                 pre         see         or            pre              double rollmaster     math atan       wr   xr   yr   zr            xr   xr   yr   yr        double pitchmaster    math asin       wr   yr   zr   xr        double yawmaster      math atan       wr   zr   xr   yr            yr   yr   zr   zr     and i do the same thing for the slave   at the beginning  the reference quaternion should be equal to the current quaternion for each of the slave and the master  and thus  the relative roll  pitch and yaw should be all zeros  but they are not  ,quadcopter pid stability
10200,create   reading sensor values,i am trying to solve some create   sensor reading problem that i am having when i came across  nbckly s posts  part   and part    that i believe are exactly what i am looking for  i copied his code from the original post into my project and updated the code from the second post as best as i could interpret   but something is not going according to plan  for example  i am printing the angle to my serial monitor  for now  but i am constantly getting a value of    sometimes     can  nbckly or anybody please check out this code and tell me what i m doing wrong  i would appreciate it  thank you very much       what i am asking is why do i only get an angle of rotation of   or   degrees when the robot is moving in a circle  the angle should be incrementing while the robot is moving   the output i am getting on the serial monitor shows a line of what looks like garble which i assume is supposed to be the bytes sent back from the create which is followed by  angle     or     what i was expecting to see was an increasing angle value                and so on   ,arduino sensors irobot-create
10202,the   key components of a robot are controller  servo  and reducer  can someone give us an  official  explanation of what they do respectively ,i ve googled a lot but wasn t able to find official definitions of these   parts  maybe the explanations of servo and controller are good enough  but i m still trying to look for a more  official  one  any ideas  thanks  snakeninny ,microcontroller servos
10210,is this the right way to do motor mixing with pid outputs for a quadcopter ,these are the motor mixing formulas i ve written for my quadcopter s flight controller  arduino mega  and i was wondering if its all right to use all three  roll pitch yaw  in each of the esc s signals    ,quadcopter arduino pid esc
10213,triangulation from calibrated stereo rig,i am using a stereo rig to do slam  calibrated using the matlab calibration tool  i need to compute the  d coordinates of a landmark using the observation model obtained from triangulation  the images are rectified    the equations obtained from triangulation are the ones presented in the blue box here  because i am doing slam in  d the coordinates i need to use are  and   the parameters needed to compute those values are    and   after doing the calibration intrinsics matrices  and  are obtained and a common intrinsic matrix for the stereo rig is calculated from  so i get the parameters needed in triangulation from  this common matrix  the focal length is supplied from the manufacturer  and for my logitech c    is    mm  the baseline  from the calibration is         mm  to compute the disparity i am obtaining surf points and using ransac to discard the outliers so i get x coordinates from both rectified images  the problem is that with those values i can t obtain correct values for  and  and i am not sure why or where i am doing the wrong step  anyone can help with this  are those the correct steps to do triangulation from rectified stereo images  edit  my stereo rig looks like the figure i attach  if you compare the coordinates system with the one used in the link before is easy to see that my  corresponds to the  from the link and the  corresponds to   so the equations to calculate the distance using triangulation and with the coordinate system of the figure are     being  the focal length   the baseline   the x coordinate of the central point and  the disparity  the   coordinate system is situated between the two cameras  so this is the meaning of the  displacement in the equations  calibration  to obtain the cameras calibration i am using the stereo camera calibrator toolbox with the chessboard pattern  after calibration  i made some tests using matlab functions triangulate and reconstructscene to know whether the parameteres are well calculated  the distances i obtained using this functions  which use the stereoparams object created by the calibrator  works well and i obtain distances very similar to the actual ones  so i suposse the calibration works well  the problem  as i explained before  is when i try to calculate the distances using the equations  and  because i am not sure how to obtain the common matrix  for the stereo rig  the calibrator gives one intrinsic matrix for each camera  so you have two matrices   the value of the baseline given from calibration make sense  i made a measurement with a ruler and gives me    mm approximately  the  value i assume should be in pixels but here again the calibration gives an  and  value so i am not sure which one should i use  those are the intrinsic matrices i obtain  left    right   being the parameters of    ,mobile-robot slam computer-vision stereo-vision
10215,piezo sensors and multiplexers,i got asked to make some sort of trigger pads for the foot section of an organ working over midi to a electric piano and my friend wants it to be pressure sensitive so we can program in the note velocity when he s not using the organ sound   that is what i try to achive  i want the pads to not just be on off but also be able to control the velocity of the midi note  im planning to use a adruino uno with a mux shield ii from mayhew labs to get    analog inputs  not exactly sure on the wiring yet but have looked at some guides and videos on google to get a feel for how it can be made   all these    piezo  sensors  is planned to register how hard you push the pedals and then send out a midi signal with a specific note correspondig to the pedal  and velocity to the electric piano so you can control the low notes with your feet   just like that but more pedals and a lot cheaper   will the arduino be able to read the analog output of the piezo sensor even though it s going through a multiplexer  ,control electronics
10220,quadcopter that can carry heavy things ,so  while i was out drinking with a couple of my friends  one of us said something like  man  wouldn t it be cool if the beer just came to us   and that got me thinking  we all have seen some crazy things people do with quadcopters  or polycopters even   but would it be possible  and not too expensive  to build a quadcopter that could carry  say  a crate of beer        kg  i m a bit of a tinkerer and i ve built some minor things with rasp  pi s before but never tried myself at a quadcopter  because they are quite a big piece of work  but being able to fly a crate of beer right in front of me would be pretty awesome  that aside  how strong would such a quadcopter have to be  in terms of motors  propellers  battery   frame  i m a complete noob when it comes to rpm and the like  so i wouldn t even know where to begin  i have  of course  read through most of the available tutorials on the internet  but they don t answer my question of what exactly to look for when i want my quadcopter to be able to carry something specific  ,quadcopter raspberry-pi
10221,should i use or not ekf for baro acc altitude estimation ,i ve recently implemented a kalman filter to estimate altitude for a small robot with an imu baro sensor mounted on it  my objective is to get max precision i can have  using this two sensor  with small computing power that a mcu can provide me  i ve tuned my filter and it seems to work pretty well  can i obtain a significant improvement using an extended kalman filter instead of a normal kalman filter and if it worth time to implement it  more in detail  since this request is too specific for each application  if a model function that use baro and accel as states should be linearized and used in a ekf and if this can improve data reliability compared to a simply kf  ,kalman-filter accelerometer ekf
10224,landmark extraction algorithm,hi the landmark are very used in slam   what are the algorithme those be used to extract them   and how robot can diferentiate the landmark   if they detecte one in point a at xt and another in xt   how the robot can know if its the same or not   sorry for my bad english    ,slam ekf lidar ransac
10227,are there any others alternatives for pid controllers for line following robots ,are there any better  advanced ways of steering a line following robot other than pid controller  if so what are them   ,pid line-following steering
10229,how to select dc motors for a line following robot ,what are the criteria to consider when ordering dc motors for a line following robot  is there a way to calculate the torque required  ,motor line-following
10233,generate synthetic accelerometer data based on  x y z  coordinate,i would like to create a simulation model  basically a signal generator  which will allow me to generate the   output signals of an accelerometer based on   location input signals  x y and z   i would like a more realistic model of the data produced by an accelerometer  with some noise and bias offsets   how can i convert the series of points into a simulated accelerometer output  specifically  i have a series of positions which describe a trajectory in  d space   if an accelerometer was moving along the trajectory described by the series of positions  i am interested in knowing  simulating   the data that the accelerometer would produce as the result of moving along the described trajectory   i could just calculate the  nd derivative of the trajectory  but that would probably be too ideal  i am looking for a model which is more realistic   ,accelerometer simulation
10237,what does internal sparking in a motor mean ,my arduino   raspberry pi robot was working fine in the morning  i tested it  it ran perfectly  and then i switched it off   now in the evening when i m trying to run it again  with the same batteries and everything  it just doesn t move  i stripped it down to the motor compartment and found that when i try to run my main motor  i can see sparks through the translucent plastic on the back  does that mean my motor is gone  ,arduino motor raspberry-pi battery
10239,what are some pitfalls of an ultrasonic sensor ,i m using a hc sr   sensor to detect obstacles  what are the pitfalls with an ultrasonic sensor  here are a couple i ve found during my testing   the signal can bounce off of one wall to another and then get picked up  distorting latency absorbent materials sometimes don t bounce the signal back check the datasheet for supported range  min max   ,ultrasonic-sensors
10241,cc d pwm control signal characteristic  to be simulated by raspberry pi ,my goal is to control drone by raspberry pi  the raspberry pi uses camera and opencv  sends control commands to avr microcontroller which will generate the pwm control signal  meaning that it will simulate pilot with transmitter receiver setup  in other words  to make it more clear   raspberry tells the atmega  that the drone needs to go more forward  atmega  generates custom pwm signals on   pins  those signals are sent directly to cc d pins responsible for roll  pitch etc  atmega  replaces controller receiver in this setup  it generates signal not based on user input but on what raspberry tells it  in order to do that i need the parameters  period  voltage etc   of the pwm signal that cc d accepts to properly simulate it  i have found this topic  cc d   replacing rc emitter with an rpi he has the same problem as i do and he found the solution  unfortunately i can t send pm and i can t comment because i m new to the site    so basically there is no way for me to contact him  so any help would be appreciated  ,quadcopter arduino raspberry-pi uav avr
10247,doosan lynx     where to find inputs and outputs,i want to add an robot to my machine the doosan lynx     lsy  for that i need this inputs and output  inputs  cycle start  chuck  open  chuck  close  chuck  open  chuck  close outputs  cycle finished  check chuck  opend  check chuck  closed  check chuck  opend  check chuck  closed i already found a book where i found those inputs and outputs but it justs says for example cycle start  sb      i cant find these number on the i o board or anywhere else  can someone help me to find my listed outputs  ,cnc
10248,compass sensor for robot,what s an appropriate compass sensor to use on a robot  there are a ton of cheap digital compass sensors  and i was thinking of using an mpu     combined accel gyro magnetometer as a compass  but i m finding these are terribly unreliable and need constant calibration via the  wave in a figure   pattern  method whenever it gets near other electronics or small magnets  which a robot obviously won t be able to do  is there a digital compass technology that mimics traditional compasses that requires little to no calibration  appropriate for installation on a robot  ,magnetometer compass
10249,fence avoidance for manually controlled robot,i m trying to find known techniques for keeping a manually controlled robot within a known polygon fence  more specifically  a pilot controls a robot by issuing desired velocity vectors  and the autopilot adjusts the velocity so that the distance to any boundary is always at least the stopping distance of the robot  my goal is to implement a system that   tries to follow the pilot s desired velocity as closely as possible  is robust to changes in position and desired velocity  at a minimum  i want the velocity to change continuously with respect to the position of the robot and desired velocity of the pilot  informally  this means that sufficiently small changes in the position or desired velocity of the pilot induce arbitrarily small changes in the velocity   the second point is particularly important  suppose that the policy were to find the intersection with the boundary in the direction of the desired velocity and slow down smoothly to that point  the below figure depicts a couple of scenarios in which this would not be continuous  in this figure  the black lines represent the fence boundary  the red dot is the position of the robot  and the blue line is the desired velocity of the pilot  in figure  a   a small perturbation of the position to the left will cause a large increase in allowed velocity because the desired velocity will intersect the far edge instead of the near edge  in figure  b   a small clockwise rotation of the velocity vector will result in a large decrease in allowed velocity because the desired velocity will intersect the near edge instead of the far edge   i have searched for relevant papers  but most of the papers i ve seen have dealt with fully autonomous obstacle avoidance  moreover  i haven t seen any papers address the robustness continuity of the system   edit  the robot knows its own location and the location of the boundary at all times  i also have some equations for maximum velocity that allow a smooth ramp down to a single line boundary  though i d be interested in seeing a better one   i would like the velocity limits to be continuous in the position and desired velocity of the pilot  i want to continuously throttle the user s input such that a minimum safe distance between the robot and the boundary is maintained  but see the figure that i added to the question  the hard part  i think  is to make sure that small changes in position  e g  due to sensor noise  or small changes in desired velocity  e g  due to pilot noise  don t cause huge changes in what the autopilot allows  i want continuity because i think it will provide a much nicer experience for the pilot while still enforcing the fence boundary  there is a trade off with optimally but i think this is worth it  even though the physical world smoothes any discontinuities in velocity  big changes could still cause large jerk which will be somewhat disturbing to the pilot  the goal is to not have the autopilot introduce large oscillations not intended by the pilot  this will be implemented on a physical system that has sensors that provide an estimation of position  and the boundary shape is known and is unchanging  the actual system that i m targeting is a quadcopter  ,control geometry reference-request
10252,obstacle avoidance while navigating,i need some ideas for strategies or algorithms to apply on these strategies to perform obstacle avoidance while navigating  at the moment i m doing offline path planning and obstacle avoidance of known obstacles with an occupancy grid  and running the a  algorithm over the created matrix  after that my robot follows along the resulting trajectory  this is done by splitting the whole trajectory into sub path  the robot adjust it s heading to the new target and follows the straight line  the robot is controlled by a fuzzy logic controller to correct deviations from the ideal line  steering  and adjusting the velocity according to the steering action and distance to the target  so far so good  and it s working very well  as sensor system  i solely use the google project tango  motion tracking and area learning for proper path following   now i want to use the depth perception capability of the device  getting the appropriate depth information and extracting a possible obstacle is done with a quite simple strategy  the robot analyses the depth information in front of the robot and if any object is in between the robot and the target point of the sub path  an obstacle must be there  now i m wondering how to bypass this obstacle most efficiently  the robot is only aware of the height and width of the obstacle  but has no clue about the depth  only the front of the obstacle is scanned   feeding the occupancy grid with this new obstacle and running again the a  algorithm is not effective  because of the missing depth  one possible strategy i could imagine is estimating a depth of the length of the grid cell  re plan and continue the navigation  if the robot faces the same obstacle again  the depth is increased by the size of one additional grid cell length  but i think this is extremely ineffective   the requirement is to only use the google project tango and no additional sensors  such as ultrasonic to sense the sides  update   the first picture illustrates the given trajectory from the path planning  orange   the gray and blue data points are the sensed obstacles in front of the robot  the notch behind the blue obstacle is actually the wall  but is shadowed by the blue obstacle  image   shows the same scene just from a different perspective  the issue i have to treat is  how to optimally bypass the blue obstacle even i don t know how deep it is  driving to the left and to the right only to capture better data points  to generate a  d model  is not possible     update   yes  i m using a depth sensor  the one integrated in google project tango  it s a visual measurement  a infra red laser beams a grid onto the objects and a rgb ir camera capture these information and evaluates the appropriate depth information  ,control motion-planning algorithm
10253,steering using different speeds in dc motors or using a servo ,i am trying to assess the pros and cons of steering a robot car using different speeds of   or more dc motors versus using a servo and a steering mechanism  from your experience which is better in terms of   steering accuracy  e g  prompt responsiveness or skidding while on higher speeds  efficiency in electrical power consumption durability and maintenance control complexity  coding and electronics   i researched and understood how both approaches work  but i need some practical insight to select the most suitable approach  any hint or research direction is appreciated  ,motor servos steering
10256,dynamic torque simulation for a   dof robotic arm,i am working on a   dof robotic arm industrial manipulator   i have the basic structural specs  dimensions  weights etc  for the links and joints with me   basically  i want to simulate both static torque due to the weight of the arm  and dynamic torque due to the accelerating joint s motion  torque that the joints will need to bear for a given set of motions   i have looked on the web and found tools like the ros moveit visualiser  gazebo  v rep which let me visually see a robotic arm and simulate the position logic and external factors like collisions etc  but i have been unable to simulate calculate dynamic torque values from these tools  ideally  i d want to define a fixed motion of the end effector i e  move the robot between   positions  and measure the torque both static and dynamic  during that particular move  these torque values are essential for selecting the optimum motors and gearboxes for my design and payload  ,robotic-arm dynamics torque simulation manipulator
10259,find object using only distance,i m working on a extremely simple robot  very first project  that attempts to find the source of a bluetooth signal  there are two motors that drive the platform and each has an encoder  we ve already used a kalman filter to calculate the approximate distance to the bluetooth beacon within reasonable error  i worked out a manual solution using some trig that solves the problem in theory  but it fails if there is any error  for example  it attempts to turn    degrees  but turns      my question is how can i reasonably drive the motors based on the encoder data to continuously minimize the distance to the signal  furthermore  is there a generic solution to problems like these   i guess you might call it a stochastic  hotter colder  problem  thanks in advance  ,raspberry-pi wheeled-robot
10265,how does a quadcopter startup work   will they tune every copter before releasing to market ,we know that a quadcopter needs to be tuned to its perfect pid values to minimise the pitch  roll   yaw errors and etc   before releasing to the market will they tune every unit and ship it   or a any different algorithm is used which doesn t require any tuning   because every motor esc or a chassis will not be exactly same  which will add to the noise   ,quadcopter
10267,path planning of   arm  dof robot,i am working on path planning for a   arm  dof    dof for each arm  robot  i am currently using a centralised planning methodology  considering the multi robot system as a single one with higher dof    in this case  and a  algorithm to find the shortest path  the problem with this algorithm is its high computation time is there any way to reduce the computation time while still obtaining the shortest route   note decentralised path planning is not good enough for my case  ,robotic-arm motion-planning path-planning
10272,stereo vision using compute module  pi camera synchronization,good day  i am currently working on an obstacle avoiding uav using stereo vision to obtain depth maps  i noticed that the quadcopter would sometimes not steer to the correct direction  i am using the raspberry pi compute module io board which comes with two csi ports used with two v  pi cameras  issue i soon found out that due to the latency between the cameras  the left and the right images are not in sync thus the errors in the depth map result  steps taken  i noticed the image blur when moving the cameras around so i adjusted the shutter speed by setting the uv l raspicam driver  with the shutter speed  i also tried to increase the framerate as i ve read  it improves the latency issue  in my code which uses the opencv library  i used the grab   and retrieve   commands to replace the read   command so that the frames from both cameras is grabbed at the nearest time possible however it didn t help much  does anyone know any possible solutions  ,computer-vision stereo-vision c++ opencv
10277,what is the thread screw size for the irobot create   internal screw bosses described in the open interface spec doc,in the  irobot roomba     open interface spec pdf  provided for the irobot create    there is a section titled  roomba internal screw boss locations    it states that  screws may be replaced with threaded standoffs   does anyone know what screw thread size of standoffs should be used to match the screw threads   i saw another similar thread but the only solution listed was to re thread the holes  which i would like to avoid if at all possible   thanks  ,irobot-create
10284,mounting a gimbal bldc motor,i m trying to build my own motorised camera gimbal using a bldc like this  where the shaft is hollow  does anyone know how the camera platform should be mounted  should a shaft be somehow pressed into the hole  any thought appreciated  ,brushless-motor
10285,using a six wire stepper motor with l   n,i am using a l   n ic and  not a driver shield  and an arduino  i would like to know how to use the ic with the arduino to run a six wire stepper motor  apparently i am new to electronics can i have a detailed explaination for wiring the ic connections on the breadboard and the arduino  thanks ,stepper-motor
10286,question about what motor to use for opening window,first off  just to be transparent  i m a total newbie when it comes to dc motors  and pretty much anything robotic    i ve got a couch that s right up to a window with the lever type openings  anderson windows   with the couch  i have no clearance to turn the lever to open it  given i ve replaced most of my house switches outlets with home automatable ones  i figured i d see if i can build myself a small motor that i can automate to open these also  to be absolutely honest  i ve got no clue where to start  i have no problem with coding the automation part  but i don t even know what kind of motors to look for that would be able to turn my knob  or rather how to actuate the thing my knob connects to     help  thanks    ,motor
10294,lidar problems in a multi robot setup,consider multiple mobile bases driving around in some area  in order to get meaningful data from the lidar of each base  the sensors should be mounted as horizontal as possible  due to safety regulations  the lidars should also be mounted at a height of    cm from the floor  when i checked the data sheet of sick lidars  it shows that all models use the wavelength     nm  does that mean that mobile bases equipped with lidars with a coplanar scan lines will end up mutually blinding each other   if it is the case  how is this problem solved   i don t consider tilting the lidars a solution as it defeats the purpose of having   d  lidars where even if the tilting angle is known  what the lidar observes becomes dependent on the robot s pose and distance from eventual obstacles  ,sensors lidar rangefinder
10295,compressedimage to an image in a node,update hey i have the following subscriber on nvidia tx  board running on an agricultural robot  we have the following issue with subscribing to sensor msgs  compressed   and the callback function void imagecallback const sensor msgs  compressedimageconstptr  msg   when i compile this i get an error  from  home johann catkin ws src uncompressimage src publisher uncompressed images cpp     usr include boost function function template hpp  in instantiation of  static void boost  detail  function  function void mem invoker  memberptr  r  t    invoke boost  detail  function  function buffer   t    with memberptr   void  imageconverter     const boost  shared ptr const sensor msgs  compressedimage  std  allocator void         r   void  t    const boost  shared ptr const sensor msgs  image  std  allocator void           usr include boost function function template hpp           required from  void boost  function  r  t    assign to functor   with functor   void  imageconverter     const boost  shared ptr const sensor msgs  compressedimage  std  allocator void         r   void  t    const boost  shared ptr const sensor msgs  image  std  allocator void          usr include boost function function template hpp          required from  boost  function  r  t    function  functor  typename boost  enable if c boost  type traits  ice not boost  is integral functor   value   value  int   type   with functor   void  imageconverter     const boost  shared ptr const sensor msgs  compressedimage  std  allocator void         r   void  t    const boost  shared ptr const sensor msgs  image  std  allocator void        typename boost  enable if c boost  type traits  ice not boost  is integral functor   value   value  int   type   int    usr include boost function function template hpp            required from  boost  function r t     function functor  typename boost  enable if c boost  type traits  ice not boost  is integral functor   value   value  int   type   with functor   void  imageconverter     const boost  shared ptr const sensor msgs  compressedimage  std  allocator void         r   void  t    const boost  shared ptr const sensor msgs  image  std  allocator void        typename boost  enable if c boost  type traits  ice not boost  is integral functor   value   value  int   type   int    home johann catkin ws src uncompressimage src publisher uncompressed images cpp           required from here  the red error statement was   usr include boost function function template hpp         error  no match for call to   boost   mfi  mf  void  imageconverter  const boost  shared ptr const sensor msgs  compressedimage  std  allocator void          const boost  shared ptr const sensor msgs  image  std  allocator void                    boost function return boost  mem fn  f  boost function args     i am not using boost  and searching around hasn t helped me solve it ,ros c++ opencv
10296,rviz transform error base link and camera link,i am working on a differential drive robot with two motor wheels with encoders and caster wheels  the robot also has a intel realsense depth camera  when i launch rviz   thee global option   fixed frame is set to base link and shows all the transforms for the differential driver nodes  but an error appears for the depth camera nodes with message saying   no transform from camera depth frame to baselink no transform from camera depth optical frame to baselink no transform from camera link to baselink no transform from camera rgb frame to baselink if i change the global option   fixed frame to camera link i can see all the transforms for the depth camera but now the differential drive transforms are now not available hope you can help  ,ros
10297,   volt input to   volt ouput of arduino,i accidentally ended up supplying    v to the arduino  v output pin instead of the vin pin  does that mean that i can t use the  v output pin anymore i e  its fried  ,arduino
10301,what books do you suggest for a beginner like me  ,i am studying bacholar of dental surgery but have intrest in learning this subjet so tell me about a good book to read  ,mobile-robot
10312,difference between  d camera using ir projection  and stereo camera ,i am currently busy with a final year project which requires me to track people walking through a doorway  i initially thought this may be possible using a normal camera and using some motion detection functions given in opencv  i have however come to the conclusion that the the camera is mounted too low for this to work effectively  height shown in the image below   i have now been looking into using a  d camera or a stereo camera to try and get around this problem  i have seen similar examples where a kinect from xbox      has been used to generate a depth map which is then processed and used to do the tracking  this was however done from a higher vantage point  and i found that the minimum operating range of the kinect is    m  from what i have found  the kinect uses an ir projector and receiver to generate its depth map  and have been looking at the orbbec astra s which uses a similar system and has a minimum working distance of    m  my question now  what exactly would the difference be between the depth maps produced by a  d camera that uses an ir projector and receiver  and a stereo camera such as the duo zed type options  i am just looking for some insight from people that may have used these types of cameras before on a side note  am i going about this the right way  or should i be looking into time of flight cameras instead       edit      my goal is to count the people moving into and out of the train doorway  i began this using opencv  initially with a background subtraction and blob detection method  this only worked for one person at a time and with a test video filmed at a higher vantage point as a  blob merging  problem was encountered as shown in the left image below  so the next method tested involved an optical flow method using motion vectors obtained from opencv s dense optical flow algorithm  from which i was able to obtain motion vectors from the higher test videos and track them as shown in the middle image below  because of the densely packed and easily detected motion vectors it was simple to cluster them  but when this same system was attempted with footage taken from inside a train at a lower height  it was unable to give a consistant output  my thoughts of the reasons for this was because of the low height of the camera  single camera tracking is able to function when there is sufficient space between the camera and the top of the person  but as the distance is minimized  the area of the frame that the moving person takes up becomes larger and larger  and the space to which the person can be compared is reduced  or atleast that is how i understand it   below on the right you can see how in the image the color of the persons clothing is almost uniform  optical flow is therefore unable to detect it as motion in both cases   i only started working with computer vision a few months ago so please forgive me if i have missed some crucial aspects  from what i have seen from research  most commercial systems make used of a  d cameras  stereo cameras or time of flight cameras  but i am unsure as to how the specifics of each of these would be best suited for my application  ,computer-vision cameras stereo-vision
10314,openrave output torques and simulation timestep,i m using openrave to simulate a quadruped  in order to get an idea of torque requirements   to get started i made a single dof  single link pendulum to test controllers etc out on  i ve whipped up an inverse dynamics based pd controller using computeinversedynamics    which i set the outputs using setdoftorques    i then set a desired position  with the desired velocity being zero  this all appears to work well and i can start the simulation  with the pendulum driving up to the desired position and settling   my concern is the value of the output torques  my pendulum is modeled as a simple box of length    mass manually set to    with a com of      when i run my simulation  i output the gravity component from computeinversedynamics    this gives    nm  which matches up with hand calculated torques i expect from the pendulum  eg the static case  when it is driven to the desired position  from down to horizontal   but the output torques to setdoftorques   are much higher and vary depending what i set the simulation timestep to  if i maintain a controller update rate of       seconds  then for a simulation update of        seconds  my output torque is approximately   nm  if i alter the simulation timestep to        seconds  keeping the controller rate the same the output torques drop down to about   nm  as an experiment i removed the inverse dynamics controller and replaced it with a plain pd controller  but i still see large output torques  can anyone shed some light on this  it s very possible i m missing something here  thanks very much edits  i m adding the main section of my code  there is no trajectory generation  really  i m just trying to get to a fixed static position  in the code  if i keep dt fixed  and alter env startsimulation timestep          i get the issues popping up   here is some data for dt         and env startsimulation timestep         in this data   taus is the torque command to the simulation   torquegravity torquecoriolis is returned from the inverse dynamics  a cmd is the controller command and m a cmd is the command after being multiplied by the mass matrix  the gravity and coriolis parts appear to be correct for steady state  where it should be about    nm taus  torquegravity torquecoriolis  a cmd  m a cmd                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            and here is some data for dt         and env startsimulation timestep         taus  torquegravity torquecoriolis  a cmd  m a cmd                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       despite the differences in torque command  a cmd  i still get similar performance  in that the arm drives to the right position fairly quickly  as another experiment i set the initial position to pi   and just fed back the gravity term to the torque output  my understanding of this is that the arm should float  ala a gravity compensation sort of thing  but it just drops as if a small torque is applied  thanks again   ,robotic-arm torque
10322,is it possible to get all possible solutions of inverse kinematics of a   dof arm ,i would like to know if there is any way to get all the possible solutions of inverse kinematics of a   dof robotic arm  i have found some good matlab codes but gives only one solution like in peter corke s book   thank you in advance   ,inverse-kinematics
10324,when was the first time a robot killed a human ,scott adams  creator of dilbert  recently shared an article about a robot the police used to kill a suspect by detonating a bomb in close range  this made me wonder    when was the first time a robot took a human life  good comments were made on this which leads me to clarify that i mean a pureposeful taking of life  i shy away from the term  murder  because that involves legal concepts  but i mean an intentional killing  an interesting subdivision would be between robots under active human direction   remote control   and those with a degree of autonomy   ,mobile-robot
10325,is horsepower related to torque in electric motors ,is torque related to size or power at all in electric motors  and what about gas motors too  i have a go kart that is    hp and it s   cc and its about  ft x  ft x  ft in size  i also see online there are     cubic inch gas motors for r c cars that are also    hp  the difference being that the r c motor spins at   k rpm while the go kart motor spins at   k rpm  if i were to put a gear reduction on the r c motor  would it preform more or less the same as the go kart motor  why is there a size difference  same for electric motors  i can buy an rc car electric motor that s   hp and the size of a pop can  the cnc machine at work has a   hp motor the size of a   gal bucket  again  the only difference is the rpm  if i were to reduce both setups so they spun at the same rpm  would they preform the same  the only reasons i could think of is    cooling and    rpm control  for pid loops and sensors  ,motor power torque engine
10326,slam with irobot create  ,i have an irobot create   and have been working with it and have gotten to the point where i can control it via bluetooth  this is great but i also want it to be able to be autonomous and navigate itself room to room for example  are there any slam irobot tutorials or any other materials you d recommend for autonomous navigation  ,mobile-robot slam irobot-create
10330,localising a robot placed at an unknown position in a known environment,i am a third year electrical engineering student and am working on an intelligent autonomous robot in my summer vacations  the robot i am trying to make is supposed to be used in rescue operations  the information i would know is the position of the person  the coordinates of the person in a json file  to be rescued from a building on fire  i would also know the rooms of the building from a map  but i don t know where the robot may be placed inside the building to start the rescue operation  that means i have to localise the robot placed at an unknown position in a known environment  and then the robot can plan its path to the person who has to be rescued  but  since this is not my domain i would like you to guide me on what is the best method for localising given that i can use an imu   or gyro  accelerometer  magnetometer  and ultrasonic sensors to do the localising job  i cannot use a gps module or a camera for this purpose   i  however  do know how to do path planning  as far as my research on the internet is concerned i have found a method called  kalman filtering  that maybe can do the localising job  but there are i think some other filtering methods as well  which one should i use  or is there any other simpler better method out there of which i don t know yet  i am also attaching the map of the building which is known to me   edit  the terrain is flat  and i would like to know where the robot is on the map like at coordinate     etc  ,mobile-robot localization imu accelerometer gyroscope
10334,autonomous navigation without distance sensors,i m doing a project with the irobot create    i want it to be able to map out a room and navigate to a point for example  my problem is that the robot doesn t have any distance sensors  what it can do is detect if there is an obstacle ahead of it or not    or    and it can measure how far it has traveled in millimeters  any good techniques out there or best to buy an ir sensor  ,mobile-robot irobot-create
10335,typical laser scanner noise values,i am building an application that executes graphslam using datasets recorded in a simulated environment  the dataset has been produced in mrpt using the gridmapnavsimul application  to simulate the laserscans one can issue the bearing and range error standard deviation of the range finder   currently i am using a dataset recorded with range noise       m  bearing noise       deg  am i exaggerating with these values  could somebody provide me with typical values for these quantities  do laser scanner manufacturers provide these values  thanks in advance  ,slam laser rangefinder
10348,quaternion implementation,i am trying to implement quaternions and i am using cc     sensortag board from ti  this board has mpu     from invensense which has digital motion processor  dmp  in it  this dmp gives quaternion  but for my understanding i implemented my own quaternion  i used gyroscope and acceleorometer values coming out of dmp  which are calibrated   to calculate angle of rotation  i feed this angle  in   directions  x y z   to my quaternion  i am not able to match my quaternion values with dmp quaternion values  in fact it s way off  so wondering what i have done wrong  following are detailed steps that i did       tapped gyro sensor values from function  read from mpl       converted gyro values in to float by diving by       as gyro values are in q   format      now used gyro values of   axis and found out resultant using formula    gr   sqrt gx   gy   gz    where gx gy and gz are gyro values along x axis y axis and z axis respectively      now angle is derived using above found resultant gr by     angle   gr   sample rate         where sample rate is found using api call  mpu get sample rate  sample rate      this angle is fed to angle to quater function which basically converts angle to axis and then quaternion multiplication       i also added  doing angle calculations from accelerometer as follows   here also accelerometer is converted to float by dividing by       as acceleorometer values also in q   format     acc data     ax  acc data     ay  acc data     az temp    acc data    acc data        acc data    acc data      acc angle    atan  acc data    temp  rad to deg  temp    acc data    acc data        acc data    acc data      acc angle    atan  acc data    temp  rad to deg  temp    acc data    acc data        acc data    acc data      acc angle    atan  acc data    temp  rad to deg     find resultant angle of this also as   inst acc angle    sqrt acc angle    acc angle      acc angle    acc angle      acc angle    acc angle             then complimentary filter is    finalangle        angle        inst acc angle  this final angle is fed to step   to get quaternion   quaternion multiplication is done as below and then normailized to get new quaternion  q    quater mul   q  w    q  x   q  x   q  y   q  y   q  z   q  z   q  w   q  w  q  x    q  x   q  w   q  y   q  z   q  z   q  y   q  w   q  x  q  y    q  x   q  z   q  y   q  w   q  z   q  x   q  w   q  y  q  z    q  x   q  y   q  y   q  x   q  z   q  w   q  w   q  z   quat normalize  double mag   pow q  w      pow q  x      pow q  y      pow q  z     mag   sqrt mag   q  w   q  w mag  q  x   q  x mag  q  y   q  y mag  q  z   q  z mag   when i check my quaternion values with dmp  they are way off  can you please provide some insights in to what could be wrong here   source code   acc data    data             acc data    data             acc data    data             double temp    acc data    acc data        acc data    acc data      acc angle    atan  acc data    temp  rad to deg  temp    acc data    acc data        acc data    acc data      acc angle    atan  acc data    temp  rad to deg  temp    acc data    acc data        acc data    acc data      acc angle    atan  acc data    temp  rad to deg    gyro rate data    data             gyro rate data    data             gyro rate data    data              float inst angle    sqrt gyro rate data    gyro rate data       gyro rate data    gyro rate data      gyro rate data    gyro rate data       gyro rate data      gyro rate data    inst angle  gyro rate data      gyro rate data    inst angle  gyro rate data      gyro rate data    inst angle  inst angle   inst angle      sam rate  float inst acc angle    sqrt acc angle    acc angle      acc angle    acc angle      acc angle    acc angle       inst angle   wt inst angle        wt  inst acc angle   angle to quat inst angle gyro rate data  q       the function for angle to quaterinion and multiplication normalization    void angle to quat float angle float  gyro axis struct quat  qt        struct quat temp      struct quat res      temp w   cos  angle     rad to deg          temp x   sin  angle     rad to deg          temp y   sin  angle     rad to deg          temp z   sin  angle     rad to deg          temp x   temp x  gyro axis         temp y   temp x  gyro axis         temp z   temp x  gyro axis         res   quat mul  qt temp       quat normalize  res        qt   res      this variation is coming when i am keeping my device stationary  y axis   resultant of all   gyro axis  x axis   the number of samples   have not converted them to time  sample rate is  hz  ,sensor-fusion
10350,q learning and kohonen maps for line follower robot,i m trying to build a line follower robot and i m interested in predicting the curves on the track  i have   binary sensor array qre       my goal is to make a system that it can generalize what it learned about the curves and give me predictions about where should be at the line to pass it as fast as possible  how can i integrate a system like q learning and how can i train it  and also how can i combine this system with a type c pid controlller   there is a paper about it ot you are willing to explain this is a important project for me and i am kinda running on clock so quick help would be appreciated ,differential-drive
10357,pid gains  drop in control loop rate  need to retune ,good day  i am working on an autonomous quadcopter  may i ask if there is a significant difference if my control loop dropped from    hz to    hz due to added lines of code that would require retuning of the pid gains  and if retuning is required  is it correct to assume that only the i and d gains should be retweaked since they are the only constants which are time dependent  thank you    ,quadcopter mobile-robot control pid stability
10367,battery damaged ,could you please see the attached battery images and tell me if it is safe to continue using this battery or should i discard it   ,battery lithium-polymer
10369,what are the specifications of the digital compass used in iphone  s,what are the specifications of the digital compass used in the iphone  s  i am trying to measure yaw angle using the magnetometer   i observed the magnetometer digital compass in the iphone is really very stable  the north direction is always the same  while the magnetometer i am using  or the magnetometer used in nexus  needs to be calibrated again and again to function properly  i found that the digital compass ak    c is used in the iphone    but it needs calibration   so i am not sure what is inside iphone  s because it works without a calibration procedure  ,imu sensor-fusion magnetometer
10371,understanding and correct drift when using breezyslam  aka tinyslam   coreslam ,i was looking for a python implementation of slam and stumbled upon breezyslam which implements tinyslam aka coreslam   my robot is equipped with the hokuyo urg   lx ug     i have odometry hence passing it to the updater    as i start moving the robot starts discovering room a and then room b   c already the map seems to have rotated  i come back to room a and return the initial pose end start using the same path  now i noticed room a has significantly rotated in relation to the other room  consequently the map isn t correct at all  neither is the path travelled by the robot    wasn t the slam supposed to store and keep the boundaries for the first room it discovered  why this rotation may be happening  how could i try to troubleshoot this issue with the data i have collected  odometry  calculated position  lidar scans   can i tune slam to do a better job for my robot   slam is pretty new to me  so please bear with me  any pointers on literature that may clarify and moderate my expectations of what slam can do   extra     and here the best video i found to understand particle filter ,localization slam mapping
10377,need help regarding odometry using encoder motor and raspberry pi,i am doing project on odometry using raspberry pi  i know that encoder motor will tell me how much distance my robot has covered  but i have no idea ho to implement completely  i just need guideline about which steps to follow  till now i have interfaced motor with raspberry pi and counted the number of rotation  i have questions as follow  how to plot map of odometry using which language and library  if you know anything  just give me guideline about steps to follow  ,motor raspberry-pi odometry
10378,robot positioning using imu quaternion data ,i want to use a mpu     to give me the position  xy  and heading  angle  of a wheeled robot  this mpu     from invensense has a digital motion processor in it which can give me a quaternion   but how do i convert this quaternion data to an xy coordinate and an angle so i can plot the position of my vehicle  ,wheeled-robot imu sensor-fusion
10379,battery question for dw    explorer  small quadrocopter ,i recently bought a dw    quadrocopter     after few minutes  the battery is dead  which is understandable since the battery is so tiny  it is a    v    mah battery  included with the quadrocopter  i was thinking about buying spare batteries for it  and i have few questions about this      can i buy any kind of battery    v    mah of the same size or is there any other property i have to pay attention     can i buy batteries of    v and    mah      more than the included battery  and expect my quadrocopter to be more  energic   is it bad to buy batteries with more mah    b  if i buy few    v    mah batteries  will i be able to charge them with the same charger i got with my    v     mah batteries or do i have to buy a specific charger for these too    these are the batteries i want to buy  any comment is greatly appreciated     mah batteries x   and or  x    mah batteries   charger   thank you very much for your input  i think i just discovered my new hobby and i can t wait to have my spare batteries  ,quadcopter battery
10382,need help regarding development of extended kalman filter for sensor data fusion of odometry and imu data,i m trying to develop an extended kalman filter  ekf  for the positioning of a wheeled vehicle  i have a  baron  robot frame with   static wheels  all driven by a motor  on the   rear wheels i have an encoder  i want to fuse this odometry data with data from an  mpu        dof imu   this is my mathlab code for the what i call  medium size  ekf  this uses data from encoders  accelerometer in x and y axis and gyroscope z axis  medium size ekf  inputs    x   a priori  state estimate vector   x              t  sampling time  s             p   a priori  estimated state covariance vector   x              z  current measurement vector   x    encoder left  encoder right  x acceleration  y acceleration  z axis gyroscope  output    x   a posteriori  state estimate vector   x              p   a posteriori  state covariance vector   x   state vector x  a  x  vector  measurement vector z     a  x  vector    end this is the filter in schematic    these are the state transition equations i use      x  t      x  t    t  cdot  dot x  t     frac t          cdot  ddot x  t     dot x  t       dot x  t    t  cdot  ddot x  t      ddot x  t       ddot x  t    u        y  t      y  t    t  cdot  dot y  t     frac t          cdot  ddot y  t     dot y  t       dot y  t    t  cdot  ddot y  t      ddot y  t       ddot y  t    u         dot  theta  t       dot  theta  t    t  cdot  ddot  theta  t      ddot  theta  t       ddot  theta  t    u      these are the observation equations i use      eta  left     frac t  cdot n         cdot  pi  cdot r   cdot  sqrt  dot x        dot y         frac t  cdot n      cdot b     cdot  pi  cdot r   cdot  dot  theta   n        eta  right     frac t  cdot n         cdot  pi  cdot r   cdot  sqrt  dot x        dot y         frac t  cdot n      cdot b     cdot  pi  cdot r   cdot  dot  theta   n        dot  theta  z     dot  theta   n       a  x     ddot x  sin  theta    ddot y  cos  theta   n       a  y     ddot x  cos  theta    ddot y  sin  theta   n     small size ekf i wanted to test my filter  therefore i started with a smaller one  in which i only give the odometry measurements as input  this because i know that if i always receive the same amount of pulses on the left and right encoder  than my vehicle should be driving a straight line    inputs    x   a priori  state estimate vector   x              t  sampling time  s             p   a priori  estimated state covariance vector   x              z  current measurement vector   x    encoder left  encoder right  output    x   a posteriori  state estimate vector   x              p   a posteriori  state covariance vector   x   state vector x  a  x  vector  measurement vector z    a  x  vector     check if input matrixes are of correct size  rows columns    size x   if  rows         columns           error  input vector size incorrect   end  rows columns    size z   if  rows         columns           error  input data vector size incorrect   end    constants n        r       b        q   zeros       q        sigma ax  q        sigma ay  q        sigma atau    q      q      q         deal small    dfdx   eye      dfdx      dfdx      dfdx         deal t    dfda   zeros        dfda      dfda      dfda         deal      dhdn   eye        r   zeros        r      r         deal sigma odo     r      r         deal small       predict next state   xk   f xk    xtemp   zeros       xtemp      x      t x     u    normrnd   sigma ax   xtemp      x      u   xtemp      x      t x     u    normrnd   sigma ay   xtemp      x      u   xtemp      x      t x     u    normrnd   sigma atau   xtemp      x      u    x   xtemp    predict next state covariance   pk   dfdx   pk     transpose dfdx    dfda   q   transpose dfda  p   dfdx   p   transpose dfdx    dfda   q   transpose dfda      calculate kalman gain   kk   p   transpose dhdx   dhdx   p   transpose dhdx    dhdn   r   transpose dhdn      dhdx   zeros       if  x                   x                    dhdx      dhdx         deal  t n      pi r         dhdx      dhdx         deal  t n      pi r    else      dhdx      dhdx         deal   t n      pi r    x    sqrt x      x               dhdx      dhdx         deal   t n      pi r    x    sqrt x      x          end   dhdx      dhdx         deal   t n      pi r    x    sqrt x      x            dhdx      dhdx         deal   t n      pi r    x    sqrt x      x          dhdx         t n  b     pi r   dhdx          t n  b     pi r    kk   p   transpose dhdx      dhdx   p   transpose dhdx    dhdn   r   transpose dhdn            update state h   zeros       n    normrnd   sigma odo   h         t n      pi r   sqrt x      x           t n  b     pi r   x       n   n    normrnd   sigma odo   h         t n      pi r   sqrt x      x           t n  b     pi r   x       n    x   x   kk  z h     update state covariance p    eye    kk dhdx  p   end odometry observation equations if you would wonder how i come to the observation equations for the odometry data     problem if i try the small size ekf  using a matlab user interface  it does seem to drive a straight line  but not under a heading of    like i would expect  eventhough i start with a state vector of  meaning starting at position       in the global coordinate frame  with speed and acceleration of zero and under an angle of      in the top right corner you can see the measurement data which i give as input  which is   wheelspeed counts on every wheel  every sampling period   simulating straight driving vehicle  in the top left corner you see a plot of the x and y coordinate  from state vector  at the end of one predict update cycle of the filter  labeled with the timecycle  bottom left corner is a plot of the angle in the state vector  you see that after    cycles the angle is still almost    like i would expect  could anyone please provide some insights in to what could be wrong here   solutions i ve been thinking on  i could use the  odometry motion model  like explained in this question  the difference is that the odometry data is inserted in the predict step of the filter  but if i would do this  i see   problems     i don t see how to make a small size version of this for testing purposes  because i don t know which measurements to add in the update step and    for the medium size version i don t know how to make the observation equations as the state vector doesn t imply velocity and acceleration  i could use the  odometry motion model  and in the update step use the euler angle  which can be linked to   this euler angle i can obtain from the digital motion processor  dmp   implemented in the imu  then it is no problem that angular velocity is not in the state matrix  but than i still have a problem with the acceleration observation equations    ,kalman-filter imu sensor-fusion odometry
10383,issue with drivedistance and rotatedegree,currently  i m using microsoft robotics dev studio  and the visual studio c  programming language to write some code that is able to drive the irobot create   on a particular path  moreover  when i run the code in simulation  it works fine  but if i connect to the actual irobot create    the code only executes the drivedistance part  and then stops  the problem is that  how come the simulation works  and real robot does not work   the following is the code  i edited on  roboticstutorial  cs  file  so  if anyone need additional code  you can just go to mrds sample   to see the entire file    ,mobile-robot irobot-create mrds
10387,how do i interface with a drone ,i recently bought a drone quadcopter   i like how the drone works but now i would like to create an application that will allow me to control the drone remotely from my pc or phone  how does a computer or phone interface to an aerial vehicle  some of my initial thoughts were   get a rf detector and detect what signals are being sent to the drone and replicate it using a new transmitter  replace the control circuit in the drone with an arduino and send corresponding signals to it to fly the drone  both these methods seem to be kind of far fetched and hard  but i m not sure how this could otherwise be done  ,quadcopter software radio-control wireless
10388,how to check which gazebo ode functions are being called ,i m trying to take a simple event in which the atlas steps on the ground plane  i want to see which functions ode calls and the functions ode uses to determine the constraint forces  i d like to see this happen while the simulation is running  is there a way i could do that  i d like to know what constraint equations and constraint forces ode is using for that particular case  thanks  ,ros dynamics gazebo
10392,view angle of distance sensor,i need a distance sensor  ir or optical or any other  with    degree view angle to sense a rectangle surface  in this case sensor must putting at the same level of surface area  please help me to solve this   ,mobile-robot
10394,why my   dc motors of same model run at different speeds ,i have   wheels for my robot  and they re both powered by the same battery  yet my robot has a differential motion as both wheels are running at differnt speeds  why is this  ,mobile-robot motor
10404,addressing the sample impoverishment in particle filter,i have implemented a particle filter algorithm for the state estimation of a mobile robot  there are several external range sensors transmitters  in the environment which gives information on the distance  radius  of the robot based on the time taken for the receiver on the robot to send back its acknowledgement  so  using three or more such transmitters it will be possible to triangulate the position of the robot  the particle filter is initialized with       particles and the sensor noise is relatively low      m   update phase  at each iteration a range information from an external sensor is received  this assigns higher weights to the particles along the radius of the external sensor  not all the particles are equally weighted since the process noise is low  hence in most of the cases  the particle relatively closer to the robot gets lower weight than an incorrect one that happens to be along the radius  the weight is a pdf  resampling phase  at this stage  the lower weighted particle the correct one  that has negligible weight gets lost because the higher weighted particle gets picked up  all this happens at the first iteration and so when the range information from another sensor arrives  the robot is already kidnapped  googling around  said that this problem is called as sample impoverishment and the most common approach is to resample only when the particle variance is low   effective sample size   number of particles      but  when the particles are assigned negligible weights and there are relatively very few particles with higher weights  the diversity of the particles are lost at resampling phase  so  when the variance is higher resampling is done which removes the lower weighted particle and hence the diversity of the particles is lost  isnt this completely the opposite of the above idea of ess  is my understanding of sample impoverishment correct  is there a way this issue can be fixed  any pointers or help would be highly appreciated  ,mobile-robot localization particle-filter probability
10407,what is the interpretation of unsampled particles in particle filters ,i implemented particle filters few years back  i was experimenting few things with particle filters  i learned that we can resolve robot kidnapping problem by introducing new particles  what if we left some particles unsampled e g     of the population  what is the interpretation of unsampled particles in this context  how they can effect our localization output    ,localization algorithm particle-filter
10408,localization of a robot to find it coordinates according to the known map,i am a third year electrical engineering student and am working on an intelligent autonomous robot in my summer vacations  the robot i am trying to make is supposed to be used in rescue operations  the information i would know is the position of the person  the coordinates of the person in a json file that can be changed anytime except during the challenge  to be rescued from a building on fire  i would also know the rooms of the building from a map  but i don t know where the robot may be placed inside the building to start the rescue operation  that means i have to localise the robot placed at an unknown position in a known environment  and then the robot can plan its path to the person who has to be rescued  i can use gyroscope  accelerometer  magnetometer and ultrasonic sensors to do the localising job  i cannot use a gps module or a camera for this purpose  the object to be rescued  whose location is known in terms of coordinates   can be changed anytime  is surrounded by walls from   sides  hence  adding more walls in this map  according to my research particle filter is the best method used for localization of robot  but how can i deal with the landmarks  walls  that are fixed as shown in the map image and that are variable depending on the location of the object to be rescued being provided in the json file  i can do the path planning from a known position to the target position  but i m not sure how to determine the starting position  more about json file      json file containing the coordinates of the object to be rescued can change      it won t change during the challenge      json file will be provided to me in an sd card that my robot has to read  i have successfully written the code that will allow the robot to read the json file and hence the coordinates of the object to be rescued  here is the map of the building which is known to me   ,localization particle-filter
10415,determining the graspable range of a robot arm,i have a   dof robot arm  and i want to do some object grasping experiments  here  the robot is rigidly mounted to a table  and the object is placed on a different adjacent table  the robot must pick up the object with its gripper parallel to the normal of the object s table  such that it is pointing directly downwards at the point of grasping  now  the two tables have adjustable heights  for any given height difference between them  there will be a fixed range of positions over which the robot arm can achieve this perpendicular pose  what i am trying to figure out  is what the optimum relative distance of the tables is such that this range of positions is maximum  is there a way to compute this analytically given the robot arm kinematics  or is there a solution which applies to all robot arms  e g  it is optimum when the tables are at the same height   if it is important  the arm is the kinova mico    thanks  ,robotic-arm kinematics
10416,sensors in collaborative robots,i m currently doing some research on collaborative robotics  one area of interest is the type of sensor s  used in these kind of machines   i had a look at some robots by fanuc and universal robots and i ve noticed that they do not come equipped with sensors  they are sold as an add on  is this inherent with collaborative robots  do customers need to buy sensors as an add on   which has advantages and disadvantages   thanks for your help  ,sensors industrial-robot
10425,ir distance sensor,i am trying to make a ir distance sensor  i have seen this online  my goal however is to see the distance between a ir transmitter and my ir sensor  in the example above he uses the ir led s ambient light and timing to track the distance  is there a way to find the distance between lets say a ir remote and a sensor  it would only have to be accurate to about   meter  i am also open to other ideas of accurately tracking distance between two objects weither that be bluetooth ir ultrasonic  ,sensors
10426,will this pseudocode work as a basis for a flight controller ,i m programming a flight controller on an arduino  i ve researched how other people have written theirs but without notes it s often so obfuscated that i ve decided it will be easier and better to write my own  this is my pseudocode thus far  will this work  all of this will happen inside the constant arduino loop  read rx signal calculate desired pitch  roll  and yaw angles from rx input signal escs using pwm in order to match desired pitch  roll  and yaw from rx input gather imu values  using kalman filter to reduce noise  compare filtered imu values vs  rx input to find errors in desired outcome vs  actual outcome use pid algo to settle errors between imu vs  rx rinse and repeat  suggestions are greatly appreciated ,arduino microcontroller uav
10427,is there a portable and accurate sensor to measure the position of the hand relative to the body ,my team has been working on a wearable glove to capture data about hand movements  and use it as a human computer interface for a variety of applications  one of the major applications is the translation of sign language  shown here   right now we can only translate letters and numbers  because the signs for them require the person to hold their hand still in one position   stationary  signs   i want to be able to translate words as well  which are non stationary signs  also the position of the hands really matters when signing words  for example it matters whether the hand is in front of the forehead  eyes  mouth  chest  cheeks  etc  for this we need a portable and highly accurate position sensor  we have tried getting position from a   dof imu  accelerometer  gyroscope  magnetometer  but as you might guess  there were many problems with double integration of the noise and accelerometer bias  so is there a device that can provide accurate position information  it should be portable and wearable  for example worn in the chest pocket  headband cap  etc   be creative    edit  more details   i m going to emphasize certain aspects of this design that weren t clear before  based on people s comments   my current problem of position detection is due to errors in double integration of the accelerometer data  so hopefully the solution has some incredibly powerful kalman filter  i think this is unlikely  or  uses some other portable device instead of an accelerometer  i do not need absolute position of the hand in space on earth  i only need the hand position relative to some stable point on the body  such as the chest or belly  so maybe there can be a device on the hand that can measure position relative to a wearable device on the body  i don t know if such technology exists  i guess it d use either magnets  ultrasound  bend sensors  or em waves of some sort  be creative     ,sensors sensor-error precise-positioning
10429,difference between slam and   d reconstruction  ,i m reading this paper    the role of rgb d benchmark datasets  an overview  and see the following words   thanks to accurate depth data  currently published papers could   present a broad range of rgb d setups addressing well known problems   in computer vision in which the microsoft kinect ranging from slam                            over  d reconstruction                      over realtime face      and hand      tracking to motion capturing and   gait analysis                    i thought of the term slam and  d reconstruction being the same thing  while the paper says the opposite with a bunch of citations  which still haven t tell the two apart   in my opinion  mapping in slam is the same term as  d reconstruction  while localization is the essential part for mapping  so i don t find a difference between slam and  d reconstruction  am i wrong  or is the author misclassfying   ,slam 3d-reconstruction
10436,what is the difference between rosberry pi builds ,i went to go install ros for my rassberry pi and found that there are   different variants  what is the difference between them and where can i go to learn about these differences for future updates  link to the rosberrypi downloads i m talking about   ,ros raspberry-pi
10438,i robot create   connectors,am i correct in assuming that the i robot create   does not have the    pin connector like the original version of i robot create has  thanks much   rick ,irobot-create
10443,stereo vision for outdoor obstacle detection,i m trying to detect obstacles for a distance of up to    meters in an outdoor environment  up to meaning that i also want to be able to detect obstacles that are close to the robot  i am thinking of doing this using stereo vision  but i am unsure if this is in fact even possible  before i buy expensive hardware   so is it possible  has anyone had any success  if this isn t possible  then what kind of sensors could give me a decent point cloud for such a range  outdoors   i need a sensor that will fit a medium size robot  also it needs to be not overly expensive since i have a limited budget  thanks ,sensors stereo-vision
10445,nameerror  name  tk  is not defined,i reference the following article   i have followed article s code   but it appears   how can i solve this problem  ,irobot-create
10447,unable to install ros kinetic in ubuntu      ,i am trying to install ros kinetic kame in ubuntu         but after trying the first step setup your sources  list   i am getting  cannot create  etc apt sources list d ros latest list  permission denied what to do now ,ros irobot-create
10450,conversion gps  longitude latitude  to  x y  of local reference frame ,i would like to use gps data as measurement input for an extended kalman filter  therefore i need to convert from gps longitude and lattitude to x and y coordinate  i found information about the  equirectangular projection given these formulas     x   r  earth   cdot  lambda  cdot cos  phi       y   r  earth   cdot  phi  however i think these formulas are only for use when the axis x  and y axis of my local frame are parallel to north and south axis of the earth   but my vehicle is starting in my local reference frame in the origin and heading straight in y direction  in whatever compas angle i put my vehicle  this should always be the starting position   i can measure the angle  to north with a compass on my vehicle  now what is the relationship between  longitude lattitude  an  x y  of my local frame  ,kalman-filter gps
10454,how can a dmp be used for simulating physics ,i read a paper from        structural bootstrapping   a novel  generative mechanism for faster and more efficient acquisition of action knowledge    which introduces a concept called   structural bootstrapping with semantic event chains and dynamic movement primitives   which confused me a little bit   according to my knowledge a robotarm is controlled by a pddl like planner  the pddl file is a  qualitative physics engine  which can predict future events  the paper says the  qualitative physics engine  consists of dynamic movement primitive  dmp  which are learned from motion capture data   my question is  how can a dmp be used for simulating physics  ,motion-planning algorithm machine-learning
10455,replacing just the wheels on create ,is it possible to replace just the wheels on the create  robot  is it a standard shaft coupling  ,irobot-create roomba
10461,measure   diffrent battery voltages on arduino,is it possible to measure the voltage of   different batteries on arduino  currently i am able to use a resistor divider   voltage divider of  x   k resistors to an analog pin to read the voltage of the battery supplying the arduino  currently the system looks like  v battery     v power regulator to arduino    resistor divider attached to  v  unregulated  battery  gnd is common throughout  how could i measure the voltage of another battery given that it will be on a different circuit  e g  different ground loop  ,arduino power
10462,name of the linkage  or carriage  in video,i am trying to find the name  nomenclature  of the linkage  or carriage  that is being driven by the dual linear servo  actuator  arrangement in the following youtube videos   servo basic concepts youtube     x linear servo application  the linkage  carriage  appears to be able to rotate about a     degree arc  what is this metal linkage  or carriage  system called    ,mechanism arm
10463,reward function for q learning on a robot,i have   wheeled differential drive robot which i use pid for low level control to follow line  i implemented q learning which uses samples for    iterations then uses them to decide the best position to be on the line so car takes the turn from there  this allows pid to setup and smooth fast following  my question is how can i setup a reward function that improves the performance i e  lets the q learning to find the best edit what it tries to learn is this  it has    inputs which contains the line positions for the last    iterations and this iteration  line position is between    and   which    means only left most sensor sees the line and   means the line is in the center  i want it to learn a line position that when it faces this input again it will set that line position like its the center and take the curve according to that line position  for example error is required position   line position so let say i had      as input then i calculated the required as      so after that the car will center itself at     i hope this helps    you asked for my source code i post it below    my sensor reading returns a value between     f and    f     f means outer sensor on the right is only the line  i have   sensors  void linefollower  follow float lineposition    float requiredpos   qpredictor process lineposition currentspeed   float error   requiredpos   lineposition   float errorder   error  lasterror    float diffspeed    kpterm   error    kdterm   errorder     float rightmotorspeed   currentspeed   diffspeed  float leftmotorspeed   currentspeed   diffspeed   lasterror   error   driver  drive leftmotorspeed rightmotorspeed      here is the logic for the value for qpredictor i call the learning part as this  and finally qpredictor float memory memorysize  datavectorlength                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   qpredictor  qpredictor    for int i   i memorysize i         output i     f      input i     f     state      prevstate         float qpredictor  process float lineposition float currentbasespeed   for int i   i datavectorlength i         input i    input i        input      m abs lineposition     int minindex      float distance          f   float sum      f   for int i   i memorysize i         sum      f      for int j   j datavectorlength j             sum   m abs input j    memory i  j               if sum    distance           minindex   i          distance   sum             sum      f  for int i   i datavectorlength i         sum    input i      float eta       f   output minindex    eta   output minindex         eta    sum   return  m sgn lineposition    output minindex          float qpredictor  rewardfunction float  inputdata float currentbasespeed   float sum      f   for int i   i datavectorlength i         sum    inputdata i      sum    datavectorlength   return sum     i now only have average error and currently not using learning because it s not complete without reward function  how can i adjust it according to the dimensions of my robot   ,machine-learning
10467,nameerror  global name  sendcommandascii  is not defined,when i execute  following code   but errors  traceback  most recent call last     file  c  python     lib lib tk tkinter py   line       in   call       return self func  args    file  c  python     irobot py   line     in callbackkey     sendcommandascii        nameerror  global name  sendcommandascii  is not defined       line program   how can i solve  ,irobot-create python
10468,inverse kinematics computation    why are alpha angle values not included,given a desired transform matrix of the end effector relevant to the base frame of the p      john j  craig  in his book  introduction to robotics mechanics and control  computes the inverse kinematic solutions of a puma      with  correct me if wrong  modified dh parameters and gets the following set of equations for theta angles   and i noticed that there are no alpha angles in these calculations  so my question is why aren t the alpha angle values not used in the calculation for the desired pose with the given end effector transform  why is it independent of the axes twist angles of the robot  ,inverse-kinematics
10469,heading and yaw rate measurements,i am working in the field of automated vehicles mainly in the domain of passenger and commercial vehicles  i have been studying whatever i can get regarding the measurement the state  relative position  relative velocity  relative heading and roation  a k a  yaw rate  of surrounding objects especially other vehicles using sensors  while everything else is possible to measure precisely using on board sensors  i have found out that not much literature is available for measuring the vehicle heading and yaw rate of other vehicles which is baffling to me given the extreme precision of laser based sensing  albeit using time stamps   i am looking for   reference to literature with experiments for estimation of yaw rate and vehicle heading  as i can see from the literature available  or the lack thereof   no direct way of measuring yaw rate is available but by using lidar or camera with consecutive time stamps or scans of data  however  this inherently requires the data to be correct  hence  i would think that due to the inaccuracies involved  this method is not used  is this correct  are there any commercially available sensors that give accurate heading and yaw rate information of other vehicles   sources and research papers would be most welcome  edit  by this inherently requires the data to be correct i mean  given the high sensitivity to error in heading or yaw rate at high vehicle speeds  the values computed using sensor information is not accurate enough to be put to use in practice  ,localization
10471,what is difference between roboearth and knowrob ,i am not able to clearly differentiate between the two platforms   roboearth  and  knowrob   ,theory cloud
10472,i robot create   reset after sleep issue ,i am having issues with bringing the robot out of its sleep or off mode  seems it goes into sleep mode when there is no activity for about   minutes  i am using the i robot create   serial cable  when it is in its sleep mode i try removing the cable end plugged into robot and connect jumper wire between pins   and   on the robot   pin connector for a brief time period  this effectively shorts the brc pin to gnd for a short period of time   less than   second   then i reconnect the serial port cable into the robot   pin connector and try giving the robot a command but no go  i have also read that commands     and         can help with this issue but i may be mistaken  any help on this is very much appreciated      rick ,irobot-create
10474,odometry motion model for kalman filter  but is the error zero mean ,i was planning on using the odometry model in the prediction stage of an extended kalman filter  state transition equations   f x t a t     begin bmatrix  x  t      x t    frac  delta s r    delta s l      cdot  cos  theta t   u      y  t      y t    frac  delta s r    delta s l      cdot  sin  theta t    u       theta  t       theta t    frac  delta s r    delta s l  b   cdot  sin  theta t  u    end bmatrix   with  and    state matrix containing xy coordinate and heading  of vehicle in global reference frame     and  distance travelled by respectively right and left wheel     distance from center of the vehicle to the wheel     encoder pulses count during sampling period t     total pulses count in   wheelturn     wheel radius     and  random noise n       now i doubt if this noise indeed does have a zero mean  wheelslip will always make the estimated distance travelled shorter than the measured distance isn t it  ,kalman-filter odometry noise
10479,gps observation equations for kalman filter ,in the design of an extended kalman filter for the position estimation of a vehicle  i am searching for the observation equations for inserting gps data  longitude  latitude  into the update step of the filter  the state vector of my filter  contains the x and y coordinate of the vehicle in the local reference frame and the angle under which the vehicle is standing relative to the x axis   the observation equations should look like this  h x t     begin bmatrix  longitude   f x t y t     latitude   f x t y t  end bmatrix   can anybody fill them in  ,kalman-filter gps
10484,equations of motion of  d pendulum like system,i m trying to get the equations of motion of a  d pendulum system  spherical pendulum   however i don t want to describe the system using spherical coordinates  which there is lot of information about    instead i want to describe the system using x y z coordinates of the mass as well as the euler angles phi  theta  psi  the roll  pitch and yaw of the mass    that is  i want to assume that the mass has a position and an orientation in relation to the inertial frame   furthermore this is a  d pendulum system  where the mass  which is symmetric  is actuated  notice that this is a simplification of the system needed to actuate the mass  where only the resulting forces and torques are taken into account    there is a force f acting in the x axis direction of the mass reference frame there is a torque t acting about the z axis of the mass reference frame there is also the gravitational force acting on the center of mass  in the negative direction of z axis of the inertial reference frame  in order to clear misconceptions about how this forces are generated  think of the mass as a differential drive robot using fans instead of wheels  the cable connecting the mass to the anchor point is assumed rigid and works as a distance constraint modeled by   where  is the position of the anchor point to which the mass is connected through the cable and  is the position of the mass  this constraint makes it so that it is similar to having two spherical joints  one at the anchor point and another at the mass  futhermore the cable is assumed to have no mass   it s important to note that this rigid connection  calbe  is meant to be modeled by the distant constraint refered above   i m looking for help solving this system to obtain its equations of motion  thanks in advance ,kinematics dynamics
10486,combine individually working cartesian coordinates, i am trying to control a dobot arm   the arm moves with angles whereas i need to work with cartesian coordinates  from inverse kinematics equations and polar coordinates i have implemented x y and z coordinates working very well on their own  but i can not combine the coordinates in order to work all together  when i add them up it is not going to the desired place  how can i combine these coordinates  i got some help from    but could not manage to successfully move dobot   edit  i ve written the codes in qt and also i ve added the triangles used for angle calculations   float dobotinversekinematics  gotox float x    func for x axis float h qsqrt qpow lengthreararm    qpow x        height from ground qlist float  zeffect gotoz h     trying to find the effect of x movement on z axis float cosq h lengthreararm    desired joint angle float joint  qradianstodegrees qacos cosq          move in range control if joint     joint    joint         qdebug      joint nan    return joint    qlist float  dobotinversekinematics  gotoy float y    func for y axis qlist float  result   float actualdist lengthforearm disttotool    distance to the end effector float x  qsqrt qpow actualdist    qpow y      actualdist    calculating x movement caused by y movement float joint  qradianstodegrees qacos actualdist  actualdist x       desired joint angle float joint  gotox x      the angle calculation of y movement on x axis if joint     joint    joint         qdebug      joint nan    result append joint    result append joint    return result   qlist float  dobotinversekinematics  gotoz float z    func  for z axis qlist float  result   float joint  qsqrt qpow          qpow z               desired joint angle float temp     qsqrt qpow          qpow z        float joint  qsqrt qpow lengthreararm    qpow temp       lengthreararm    desired joint angle if joint     joint    joint         qdebug      joint nan    joint  qacos joint        m pi   joint  qacos joint        m pi   result append joint    result append joint    return result   ,robotic-arm inverse-kinematics c++
10487,what type of motor can be hooked up on a bike ,as the title briefly explains  my question is  what type of motor is powerful enough be on a cycle  my plan is to convert a cycle into an electric bike by mounting a motor and controlling it through either a raspberry pi or an arduino board  ,motor electric
10490,is it possible to use a lipo charger as a lab bench power supply ,i recently thought about building a lab bench power supply  it comes in cheaper and i love to build things    but then i also have a lipo charger an imax b ac  that i had bought for my quadcopter  then came the idea of whether i can use the charger as a lab bench power supply    my questions is  could this work and how could i make it work  ,power
10491,examples of zeno behaviour in the real world,zeno behaviour or zeno phenomenon can be informally stated as the behavior of a system making an infinite number of jumps in a finite amount of time  while this is an important control system problem in ideal systems  can zeno behavior exist in real systems  any examples  if so  why don t noise or external factors deviate a system from achieving zeno  ,mobile-robot control
10492,why don t cheap toy robotic arms move smoothly ,why don t cheap toy robotic arms like this move smoothly   why can t it even move itself smoothly   even without any load   in other words   what do real industrial robotic arms have  that cheap toys don t  ,robotic-arm
10502,what are good  low cost  actuators for a braille tablet to be controlled by arduino ,i want to basically make a pin matrix controlled either by spring  electromagnets or small motors spring being the most viable option   something like what s shown in the image  i m pretty new to arduino and hardware in general so any input would be appreciated  i mostly know the arduino end but don t have clue about the hardware part  plus i don t have the technical expertise  as in i know electromagnets won t be a good option as i have to control individual pins and not clusters  plus springs have the disadvantage of pushing them back in but other than that a very option  and its not viable to have individual motors for so many pins   ,arduino motor electronics
10503,running a cycle on brushless outrunner motors ,is it possible to convert a cycle into an electric bike by using brushless outrunner motors that usually are for rc planes  multicopter  helicopter  etc  if it is possible  what specs do my motors need to be to provide enough power to bring my cycle to speed  will i need a gear system  ,motor power electric
10504,how to properly calibrate a magnetometer in imu for precise yaw ,i m using sparkfun razor imu  dof sensor which incorporates accelerometer  gyroscope  and magnetometer  for giving the euler s angles  yaw  pitch  and roll   i m using the firmware at this link  it has processing sketch for calibration of magnetometer  but it doesn t give the precise measurements  especially  the yaw is imprecise  i m using this sensor for measuring azimuth and altitude of stellar objects  the altitude is mostly correct  but azimuth  yaw  isn t   i have several questions   is there a better way to calibrate magnetometer  is the calibration sufficient  without using the madgwick or kalman filter  is there some nonlinearity present in the sensor  since the yaw offset isn t constant  it changes  around     degrees up north to almost correct value at southwest   and if it is  how could i measure that nonlinearity and apply to the yaw measurements  if i have to use madgwick or kalman  do i have to apply them on quaternions  i believe that applying them at the final yaw measurements wouldn t do the job   ,kalman-filter imu calibration magnetometer precise-positioning
10505,covariance check ,i have a localization data estimated and gps truth and generated   x   covariance matrix along with them   what i would like to do is to see if the covariance is correct or not   can we check it by plotting the covariance   ,localization slam visualization
10507,do dh parameters change for a scaled robot  d model ,i have the actual dh parameters of a robot   all other di s and ai s are zero  can i use these for an inverse kinematics analytic closed form computation or should i measure the virtual distances in the  d environment  i am actually asking if the theta angles that will be yeld after the computations are dependent on the scale of those distances  edit  scale factor is unknown ,inverse-kinematics dh-parameters 3d-model
10508,building an rc airbus a   ,i am planning to build a scale version of an airbus a    as the title suggests and i have a few questions with the build     are there any template plans for this build  if so please reply with the links    can i control the plane with a cc d revolution and fly it with ground station  if there are any ground telemetry application that will help me  please send me the link    how do i make the landing gears  i don t really fancy spending above      i live in london     i want to make all my landing gears shock absorbing and i want to make the nose gear have a steering mechanism with servos    how do i make the outer shell for the edf motors    i am ready to spend as much time and effort with this build  i want the build to not be very costly  this is going to be a hobby  and i have also built a quadcopter  so i hope i can apply that knowledge to this build    ,servos
10511,accelerometer  gyro  and magnetometer sensor fusion for material resource survey,as a hardware engineer  i have studied quite a lot on sensor spec such as accel  gyro and magnetometer including custom made fluxgate  i have studied matrix and quadarion  complex number  and so on  i moving into calibration arena  i seen lot of article on calibration but not sure which is best solution to fix offset and mis alignment axis  can anyone point to best open source code  i m not interested in output results related to flight such as quadchopter and gps  but more interested in directional math for drilling pipes  where toolface  inclination  azimuth and position is most important  what the best thesis or paper that cover this topic and open source or example code  in c  for this application  do i need kalnman filter or such advance post data capture processing  any tip how to avoid getting too involved with maths ,control kalman-filter imu calibration precise-positioning
10514,scale factor of a  d robot model relative to the real measurements of a robot,i have some measurements of a real life robot  and a  d model of that robot  lets say in unity  and i want to know the scale factor  plus i dont want to find the  d models measurements and then divide with the real world ones to find the scale factor  in order not to get more confused with more mathematics than i am already  so  is there a methodology or will i have to do it as i mentioned  ,3d-model
10515,basic components for having a  follow me  mode on quad ,i want to know what all essential components i need to have on a multirotor inorder to have a  follow me  mode  with me carrying a device reference piece to track     ,localization
10516,can t find ros package in kinetic driver base,i can t find the package  in the ros site   i saw it not maintainable  how can i migrate the package from  jade indigo  to became a package in kinetic  that important because it s dependency for my quad gazebo pacakge ,ros
10517,which kind of motors and how powerfull should they be for a robotic arm,i am building a robotic arm with these specifications     meter long approx   kg weight it is made of   motors     at the base  one for rotating the whole arm left and right and another one for rotating up down    motor for rotating the second half of the arm  only up and down    for the claw used for grabbing  it must be able to lift at least  kg    kg  it s own weight   and have a speed of     degrees in   seconds       degrees in   second resulting   rpm   which kind of motor would be best for the project  servo or stepper  and how much torque will it need   please also give me an explanation of how i can calculate the torque needed   could you also give me an example or two of the motors i would need and or a gearbox for them  models or links   ,motor robotic-arm stepper-motor servos torque
10519,math for dynamic gait,i m researching dynamic gaits for bipedal robots  can anyone recommend a reference that reviews and explains the math behind modern approaches  ,walking-robot
10520,once matching features are computed between a stereo pair  how can they be tracked ,i am currently working on a slam like application using a variable baseline stereo rig  assuming i m trying to perform visual slam using a stereo camera  my initialization routine would involve producing a point cloud of all  good  features i detect in the first pair of images     once this map is created and the cameras start moving  how do i keep  track  of the original features that were responsible for this map  as i need to estimate my pose  along with feature matching between the stereo pair of cameras  do i also have to perform matching between the initial set of images and the second set to see how many features are still visible  and thereby get their coordinates   or is there a more efficient way of doing this  through for instance  locating the overlap in the two points clouds  ,slam computer-vision stereo-vision
10521,help finding robot tracks,i have a robot with tracks  one of the tracks broke and i need to find a replacement  the tracks use the same plastic interconnects pieces as this   they were very popular years back  does anyone know the brand name  ,mobile-robot tracks
10523,determining position from a  d map and lidar,we need to determine the  d position of my robot  to do so  we have a lidar at a known high  with an horizontal plane  which gives us the distance to the nearest point for each angular degree  so     points for one rotation   the environment is known  so i have a map of the position of every object that the lidar is susceptible to hit  my question is  based on the scatter plot that the lidar is returning  how can we retrieve the position of my robot in the map   we would need the   y position in the map frame and also the theta angle from the map frame to my robot frame  we have tried to match objects on map with groups of points based on their distance between each other and by identifying those objects and the way the lidar  sees  them to retrieve the robot position  but it is still unsuccessful  to put it in a nutshell  we want to make slam without the mapping part  how is it possible  and with what kind of algorithms   a first step could be to stop the robot while acquiring data if it seems easier to process  ,localization lidar precise-positioning
10525,shield imu from magnetic interferences,i experienced some drifting when coming near to magnetic fields with my imu  so i wondered if it is possible to completely shield the imu from external influences  would this be theoretically possible or does the imu rely on external fields like the earth magnetic field  are there maybe alternatives to imus that are less susceptible to magnetic interferences  i only need the rotational data of the sensor and don t use translational output  ,sensors imu rotation
10527,is it a bad design decision to implement high number of moving parts in an automation robot ,i m currently designing an autonomous robotic system to manipulate clothes using computer vision and complex moving hardware  my current design incorporates quite a number of moving parts  my biggest worry is a frame      x    x    cm  rotates from   to    degrees every time it manipulates a piece of cloth  other than this the design involves various other moving parts to achieve successful manipulation of the cloth  it seems like the hardware is capable of achieving the task despite the high number of complex and moving parts   so the question is  what are the design considerations i should take in designing an automated system  should i think of a alternative design with less number of parts  or proceed with the current design if it does the job   sorry i am in a position where i can t disclose much information about the project   thank you     ,computer-vision automation
10533,how to make a simple arduino insect robot ,i want to make a simple arduino based programmable insect robot  i want it to walk on legs and legs will be made of hard aluminum wire  it needs to have   legs  i am planning to use arduino nano for that  i just had few questions like   how to arrange servos and wire to have motion  i also want it to turn sideways  where can i read good theory on making insect like robots   ,arduino
10536,what is the difference between cc d revolution mini and cc d revolution,i recently came across this doubt    as the title suggests what s the difference between the two flight controller  they have a big price difference and size difference  that s all i know    do they all function the same way  so does the two flight controller differ in size  answers appreciated  sid ,quadcopter microcontroller
10537,lidar points as landmarks,i am currently trying to implement a graphslam sam algorithm for lidar  from papers i ve read  you generate a directed graph from expected lidar measurements to landmarks similar to the image below  taken from the square root slam paper by dellaert    however in practice the point clouds you obtain from lidar are similar to this  taken from the kitti car collected dataset    it seems algorithms such as sift for  d point clouds aren t as accurate yet  is there a commonly used technique to efficiently find features in consecutive point clouds to find landmarks for slam algorithms without using         points in a point cloud  ,localization slam lidar
10544,programmable wheeled vehicle,ok  this may be a simple question  but here goes  i would like to build some type wheeled vehicle that can sustain a tripod mount but also be programmable to follow a programmed path  however  i would like to be able to change this path as well   this started with trying to mount my ricoh theta s on an rc car to create  d video of a room  i m really not familiar with any type of robotics but i m convinced it s possible to create something better    more efficient if you will    i ve looked at drones  but for what i would like to do i don t think i can find something as precise as i would like  i could be completely wrong    any guidance on this is extremely appreciated  ,mobile-robot
10546,is it possible to implement a robot that moves to spcific locations based on dynamic inputs ,i d like to build a robot that can move to different places like different rooms  in a floor based on the input that i m giving to it dynamically  i ve surfed about it and i don t need a line follower  except this  can you give me a way to implement this      thanks in advance     ,wheeled-robot
10547,how to get live audio from robot ,i am building a robot and i want to be able to hear sounds from it s environment  ideally from my laptop   what is the best way to get live audio from my robot s microphone to my computer  i have looked into a few solutions for hosting live audio streams using packages such as  and icecast  i m just wondering about better solutions for robotic applications  additional details    i have access to hardware such as raspberry pi  arduino  etc  ,real-time digital-audio
10549,power solution for raspberry pi robot,i am building a pi car with   gear motors         mah each max   now i want to use my      mah usb power bank to power up raspberry pi along with the   gear motors  i can power up the raspberry pi directly but i want to use my power bank as the only source of power for the pi car  how can i connect both my rpi and motor controller l   n to my usb power bank  ,motor raspberry-pi power
10554,what types of motor should i use for a particular application ,i want to create an amateur wire looping machine with arduino  that has similar functionality than this machine  i don t need the automatic wire feeding as for my purposes this part can be done manually  i just want to automate the wire loop creation process  assuming that i already have straight wires  i m new to the world of motors  robotics  etc   so please be as descriptive as possible    from the video  i can tell that there are two motors   makes the initial wire bending spins to create the loop  the wire that i will be working with is galvanized steel of    gauge            mm diameter   so what type of motors would be recommended for this application  taking into account   they need to be accurate in their positioning for repeat ability they need to have enough torque  specially the one that creates the loop itself  to work with this type of material they re as fast as  or close to  the ones in the video this is not going to be an industrial grade machine that will be running all the time ideally  they need to be not that expensive   i don t want to be bankrupt by the end of this project    if links can be included for recommended products  it would be great   thanks  ,motor
10555,  axis gimbal stabilization system can replace with   axis accelerometer,i have  tarot zyx gs   axis gimbal stabilization system zyx    sensor that gives me the value of roll tilt and pan the   axis accelerometer give me the value of x y and z so can we use the gimbal stabiliztion system in place of accelerometer ,quadcopter sensors accelerometer
10556,quadrature encoder signal from dc motor is very noisy,i m starting out with robotics  got my first dc gear motor with quadrature encoder      i ultimately plan to hook it up to a motor driver connected to a tiva launchpad  however  since i m a noob  and curious  i am starting by just playing with it with my breadboard  oscilloscope  and voltage source  e g   when i plug in the motor power lines into my  variable  voltage source the axis spins nicely as expected between   and    v  the problems start when i try to check how the encoder works  to do this  first i plug a a  v source into the encoder gnd vcc  and then try to monitor the encoder output  while the motor is running  i check the yellow  encoder a output  cable  referencing it to the green  encoder gnd  cable    i made a video that shows a representative output from one of the lines  no usb on my old oscilloscope so i took a video of it using my phone   as you would see at the video  the output doesn t look anything like the beautiful square waves you typically see in the documentation  instead  it is an extremely degraded noisy sin wave  at the correct frequency for the encoder   the amplitude of the sin is not constant  but changes drastically over time  strangely  sometimes it  locks in  and looks like the ideal square wave  for about a second or two  but then it gets all wonky again  both of the lines  encoder a and b output  act this way  and they act this way at the same time  e g   they will both lock in and square up at the same time  for those brief glorious moments of clarity   both of my motors are the same  so i don t think it s that i have a bad motor  i have also checked using vcc   v  but it made no difference other than changing the amplitude of the output  note i already posted this question at reddit   ,motor quadrature-encoder
10561,can i use a  d gimbal system as a simplistic quadcopter imu   axis accelerometer  ,i have  d gimbal system and i want to use this sensor in place of imu   axsis accelerometer  in quadcopter  ,quadcopter accelerometer gyroscope
10562,what is the torque transmission efficiency using a bycicle chain setup for robot ,for this robot the gear attached to the motor is linked to the gear attached to the wheels by a bicycle chain  i am using a bicycle wheel and transmission set as the parts for the robots movements   how does using a bicycle chain affect the power transmission efficiency  how does this impact the torque  ,mobile-robot torque gearing
10567,is there any c   library i could use to program a robotic manipulator involving forward and inverse kinematics ,i came across robotics library  rl   but quite unclear about its real purpose  is it a fk ik solver library or simply an graphical simulator   rl has poor documentation  so its not clear how to use it  im looking for some c   library where there apis to solve fk if analytically  thank you  ,inverse-kinematics c++ forward-kinematics
10568,what types of actuators do these industrial bots use ,i have a particular example robot that interests me   see first image  the bigger robot on the left  in particular the shoulder pitch joint that would support the most weight  i m curious because i know it s really hard to balance strength and precision in these types of robots  and want to know how close a hobbyist could get  would they be something similar to this  rotary tables w  worm gears    looking for more actuation schemes to research  thanks  ,motor robotic-arm actuator torque
10573,technique to increase pov resolution,i have thought of a technique to increase the resolution of a pov  persistence of vision  display  in an usual pov display  the leds are arranged in a strip and spun in a circle  there are two limiting factors to increasing the radial resolution along the circumference of any one circular path that an led follows  one is  depending on the speed of the pov wheel  the minimum time required  decided by the microcontroller  to change the led s color in case of a rgb  the other factor is the led s width  that increases the  bleeding  of color from one pixel to the neighboring pixel if the led changes color or brightness too fast   if one were to fix a slit in the front of an led           like so  would this help improve the resolution of the pov display  by doing this one would in effect be reducing the width of the  pixel  along the circumference on which the led would be traversing  thus if one were to use a fast enough microcontroller and a narrow enough slit  one could probably obtain a very high resolution along one dimension at least  to be clear i ve not yet implemented this  and am just looking for any experienced person who can tell if this will work or not  ,microcontroller electronics
10580,how can i upload sketches to an arduino over a raspberry pi ,i am doing robotics project on raspberry pi and arduino  the arduino uno is connected to raspberry pi  i am using the raspberry pi in putty  ssh  now   i want to setup user interface for raspberry pi also most importantly i want to use arduino ide to work and load arduino sketch into system  how to do this  ,arduino raspberry-pi embedded-systems first-robotics linux
10581,ekf slam  d laser scanned datasets usage,how to understand the  d laser scanner scanned data and use it in the implementation of ekf slam  if someone can provide an implementation of ekf slam in python with pseudo datasets  ,slam ekf first-robotics
10584,communication in swarm robotics,hey so i am trying to research into swarm robotics  and trying to find helpful information or even articles papers to read on the process of setting up communication protocols between different robots  for instance using a lan connection  does each robot need to have a wireless adapter  and how would i begin setting up a network for say      smaller robots  more generally could someone help me understand how devices connect and communicate across networks  i understand the basics of ip addressing  but i haven t researched into further complexities  any advice or direction is appreciated  ,wireless
