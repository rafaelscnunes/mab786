{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:52:00.256470Z",
     "start_time": "2018-05-04T10:52:00.142639Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "from nltk import word_tokenize, ngrams\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import itertools\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:15.432975Z",
     "start_time": "2018-05-04T10:40:13.646260Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('pizza.csv')\n",
    "# df = pd.read_csv('pizza.csv', parse_dates=['dates'])\n",
    "# df = pd.read_csv('pizza.csv', usecols=['foo', 'bar'])\n",
    "\n",
    "df = {\n",
    "    \"cooking\": pd.read_csv('../dataset/processed/cooking.csv', usecols=['title', 'content']),\n",
    "    \"crypto\": pd.read_csv('../dataset/processed/crypto.csv', usecols=['title', 'content']),\n",
    "    \"robotics\": pd.read_csv('../dataset/processed/robotics.csv', usecols=['title', 'content']),\n",
    "    \"biology\": pd.read_csv('../dataset/processed/biology.csv', usecols=['title', 'content']),\n",
    "    \"travel\": pd.read_csv('../dataset/processed/travel.csv', usecols=['title', 'content']),\n",
    "    \"diy\": pd.read_csv('../dataset/processed/diy.csv', usecols=['title', 'content']),\n",
    "    #\"physics\": pd.read_csv('physics.csv'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new .csv file with title+content and class columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:26.678811Z",
     "start_time": "2018-05-04T10:40:15.780798Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../dataset/processed/data.csv', 'w') as f:\n",
    "    f.write('title_content|label\\n')\n",
    "    for _class in df:\n",
    "        df[_class]['title_content'] = df[_class][['title', 'content']].apply(lambda x: '{} {}'.format(x[0],x[1]), axis=1)\n",
    "        df[_class]['label'] = _class\n",
    "        df[_class].to_csv(f, sep='|', columns=['title_content', 'label'], header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T02:48:59.162152Z",
     "start_time": "2018-04-27T02:48:59.120563Z"
    }
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:28.774510Z",
     "start_time": "2018-05-04T10:40:27.112912Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../dataset/processed/data.csv', sep='|')\n",
    "# dataset.head()\n",
    "# dataset.tail()\n",
    "dataset.sample(5)\n",
    "# dataset.shape\n",
    "dataset.describe()\n",
    "# dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolut numbers & Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:29.427615Z",
     "start_time": "2018-05-04T10:40:29.348681Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = dataset['label'].value_counts()\n",
    "print(labels.describe())\n",
    "print(labels.sort_index())\n",
    "print(labels.sort_index()/labels.sum()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:31.114469Z",
     "start_time": "2018-05-04T10:40:29.909405Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax1 = sns.countplot(dataset['label'].sort_values())\n",
    "plt.ylabel('Observations', fontsize=12)\n",
    "plt.xlabel('Labels', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Labels frequency histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics of the number of words (size) of title_content text field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:32.886012Z",
     "start_time": "2018-05-04T10:40:31.769017Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['size'] = dataset['title_content'].apply(lambda x : len(str(x).split()))\n",
    "sizes = dataset['size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:33.387012Z",
     "start_time": "2018-05-04T10:40:33.325513Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['size'].describe()\n",
    "print('The top 20 most frequent size of title_content, and their respective frequency:')\n",
    "print(sizes.nlargest(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:45.709583Z",
     "start_time": "2018-05-04T10:40:34.001819Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax1 = sns.barplot(sizes.index, sizes.values, alpha=0.8)\n",
    "ax1.set_xticklabels([])\n",
    "plt.title('Number of words frequency histogram')\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Number of words', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robotics texts with more than 200 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:47.757891Z",
     "start_time": "2018-05-04T10:40:46.340950Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_data = dataset[(dataset.label == 'robotics') & (dataset.title_content.apply(lambda x : len(str(x).split())) > 200)]\n",
    "filtered_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell content example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:53.904778Z",
     "start_time": "2018-05-04T10:40:53.877676Z"
    }
   },
   "outputs": [],
   "source": [
    "line=61041\n",
    "print('TEXT: {0}'.format(dataset.loc[61041, 'title_content']))\n",
    "print('LABEL: {0}'.format(dataset.loc[61041, 'label']))\n",
    "print('LENGTH: {0} words.'.format(len(dataset.loc[61041, 'title_content'].split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:40:57.103969Z",
     "start_time": "2018-05-04T10:40:56.061772Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = {}\n",
    "for label in labels.keys():\n",
    "    ds[label] = dataset[dataset.label == label]\n",
    "#     ds[label] = resample(ds[label], replace=False, n_samples=labels.min(), random_state=711)\n",
    "ds = pd.concat(ds[label] for label in ds)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax1 = sns.countplot(ds['label'].sort_values())\n",
    "plt.ylabel('Observations', fontsize=12)\n",
    "plt.xlabel('Labels', fontsize=12)\n",
    "# plt.xticks(rotation='vertical')\n",
    "plt.title('Labels Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:41:05.330271Z",
     "start_time": "2018-05-04T10:41:02.853236Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word',\n",
    "                        stop_words=STOP_WORDS,\n",
    "                        ngram_range=(1,1),\n",
    "                        max_df=0.7, min_df=2,\n",
    "                        sublinear_tf=True)\n",
    "X = tfidf.fit_transform(ds['title_content'])\n",
    "print(X.shape)\n",
    "\n",
    "l_enc = LabelEncoder()\n",
    "y = l_enc.fit_transform(ds['label'])\n",
    "print('Encoded labels: ', list([(i, l_enc.classes_[i]) for i in range(0, len(l_enc.classes_))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:42:30.254572Z",
     "start_time": "2018-05-04T10:41:13.591926Z"
    }
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=1000, algorithm='randomized')\n",
    "X_svd = svd.fit_transform(X)\n",
    "print('Shape of svd matrix: ', X_svd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Valid/Train/Test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:42:31.235795Z",
     "start_time": "2018-05-04T10:42:31.029728Z"
    }
   },
   "outputs": [],
   "source": [
    "# X = np.concatenate([svd_titulo, svd_resumo], axis=1)\n",
    "X_temp, X_valid, y_temp, y_valid = train_test_split(X_svd, y, test_size=0.1, random_state=283)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state=283)\n",
    "\n",
    "print('X_train matrix shape is: {0}'.format(X_train.shape))\n",
    "print('X_test matrix shape is: {0}'.format(X_test.shape))\n",
    "print('X_valid matrix shape is: {0}'.format(X_valid.shape))\n",
    "print('y_train matrix shape is: {0}'.format(y_train.shape))\n",
    "print('y_test matrix shape: {0}'.format(y_test.shape))\n",
    "print('y_valid matrix shape: {0}'.format(y_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:42:31.883651Z",
     "start_time": "2018-05-04T10:42:31.809181Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        plt.title(title + \" normalized confusion matrix\")\n",
    "    else:\n",
    "        plt.title(title + ' confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve-Bayes Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:42:34.509944Z",
     "start_time": "2018-05-04T10:42:32.664607Z"
    }
   },
   "outputs": [],
   "source": [
    "nbg = GaussianNB()\n",
    "nbg.fit(X_train, y_train)\n",
    "y_pred = nbg.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))\n",
    "plot_confusion_matrix(cm, l_enc.classes_, title='Naïve-Bayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve-Bayes Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:48:45.422365Z",
     "start_time": "2018-05-04T10:48:43.671073Z"
    }
   },
   "outputs": [],
   "source": [
    "nbb = BernoulliNB()\n",
    "nbb.fit(X_train, y_train)\n",
    "y_pred = nbb.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))\n",
    "plot_confusion_matrix(cm, l_enc.classes_, title='Naïve-Bayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T10:52:32.186740Z",
     "start_time": "2018-05-04T10:52:22.042745Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred)))\n",
    "plot_confusion_matrix(cm, l_enc.classes_, title='Naïve-Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
